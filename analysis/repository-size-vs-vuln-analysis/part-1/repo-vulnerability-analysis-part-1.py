import json
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import LinearSegmentedColormap


def load_vulnerability_data(data_dir: str = "../../../nvd_data") -> list:
    """Load and process all vulnerability JSON files from the specified directory."""
    data = []
    nvd_path = Path(data_dir)

    for json_file in nvd_path.glob("*.json"):
        try:
            with open(json_file) as f:
                vuln = json.load(f)

            # Extract required fields, using get() to handle missing data
            repo_name = vuln.get("github_data", {}).get("repository")
            repo_size = vuln.get("repository_context", {}).get("size")
            cvss_score = vuln.get("vulnerability_details", {}).get("cvss_score")

            # Only include entries with all required data
            if all(v is not None for v in [repo_name, repo_size, cvss_score]):
                data.append(
                    {
                        "repository": repo_name,
                        "size": repo_size,
                        "cvss_score": cvss_score,
                    }
                )

        except Exception as e:
            print(f"Error processing {json_file}: {e}")
            continue

    return data


def process_repository_metrics(data: list) -> pd.DataFrame:
    """Calculate repository metrics from vulnerability data."""
    # Convert to DataFrame
    df = pd.DataFrame(data)

    # Group by repository and calculate metrics
    repo_metrics = (
        df.groupby("repository")
        .agg(
            {
                "size": "first",  # Repository size is the same for all entries
                "cvss_score": [
                    "count",
                    "mean",
                ],  # Count vulnerabilities and average CVSS
            }
        )
        .reset_index()
    )

    # Flatten column names
    repo_metrics.columns = ["repository", "size", "vuln_count", "avg_cvss"]

    return repo_metrics


def create_visualization(
    df: pd.DataFrame, output_file: str = "vulnerability_analysis_part_1.png"
):
    """Create scatter plot visualization of repository metrics."""
    plt.figure(figsize=(12, 8))

    # Create custom colormap from cool to warm colors
    colors = [
        "#4575b4",
        "#74add1",
        "#abd9e9",
        "#fee090",
        "#fdae61",
        "#f46d43",
        "#d73027",
    ]
    cmap = LinearSegmentedColormap.from_list("custom_cmap", colors)

    # Create scatter plot
    scatter = plt.scatter(
        df["size"],
        df["vuln_count"],
        c=df["avg_cvss"],
        cmap=cmap,
        alpha=0.6,
        s=100,
        vmin=0,
        vmax=10,
    )

    # Set x-axis to log scale
    plt.xscale("log")

    # Add colorbar
    cbar = plt.colorbar(scatter)
    cbar.set_label("Average CVSS Score", fontsize=10)

    # Add labels and title
    plt.xlabel("Repository Size (KB)", fontsize=12)
    plt.ylabel("Number of Vulnerabilities", fontsize=12)
    plt.title(
        "Repository Size vs. Vulnerability Count\nColored by Average CVSS Score",
        fontsize=14,
        pad=20,
    )

    # Add grid
    plt.grid(True, alpha=0.3)

    # Add hover annotations
    hover_texts = []
    for _, row in df.iterrows():
        hover_text = (
            f"Repository: {row['repository']}\n"
            f"Size: {row['size']:,} KB\n"
            f"Vulnerabilities: {row['vuln_count']}\n"
            f"Avg CVSS: {row['avg_cvss']:.2f}"
        )
        hover_texts.append(hover_text)

    # Save plot
    plt.tight_layout()
    plt.savefig(output_file, dpi=300, bbox_inches="tight")
    plt.close()

    return hover_texts


def main():
    # Load and process data
    print("Loading vulnerability data...")
    vuln_data = load_vulnerability_data()

    if not vuln_data:
        print("No valid vulnerability data found!")
        return

    print("Processing repository metrics...")
    repo_metrics = process_repository_metrics(vuln_data)

    print("Creating visualization...")
    hover_texts = create_visualization(repo_metrics)

    # Print summary statistics
    print("\nAnalysis Summary:")
    print(f"Total repositories analyzed: {len(repo_metrics)}")
    print(
        f"Average vulnerabilities per repository: {repo_metrics['vuln_count'].mean():.2f}"
    )
    print(
        f"Average CVSS score across all repositories: {repo_metrics['avg_cvss'].mean():.2f}"
    )
    print(f"Largest repository: {repo_metrics['size'].max():,} KB")
    print(
        f"Repository with most vulnerabilities: {repo_metrics.loc[repo_metrics['vuln_count'].idxmax(), 'repository']}"
    )


if __name__ == "__main__":
    main()
