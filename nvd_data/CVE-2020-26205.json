{
  "cve_id": "CVE-2020-26205",
  "github_data": {
    "repository": "salopensource/sal",
    "fix_commit": "145bb72daf8460bdedbbc9fb708d346283e7a568",
    "related_commits": [
      "145bb72daf8460bdedbbc9fb708d346283e7a568",
      "145bb72daf8460bdedbbc9fb708d346283e7a568"
    ],
    "patch_url": "https://github.com/salopensource/sal/commit/145bb72daf8460bdedbbc9fb708d346283e7a568.patch",
    "fix_commit_details": {
      "sha": "145bb72daf8460bdedbbc9fb708d346283e7a568",
      "commit_date": "2020-10-07T02:56:18Z",
      "author": {
        "login": "grahamgilbert",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Merge pull request #405 from salopensource/xss",
        "length": 102,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 316,
        "additions": 189,
        "deletions": 127
      },
      "files": [
        {
          "filename": ".flake8",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -1,5 +1,5 @@\n [flake8]\n max-line-length = 120\n-ignore = F401,F405,E402,F403,W504,W605\n+ignore = F401,F405,E402,F403,W504,W605,E203\n max-complexity = 126\n exclude = venv/*,*/migrations/*,wip_plugins/*,datatableview/*, sal/settings.py"
        },
        {
          "filename": "sal/version.plist",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -3,6 +3,6 @@\n <plist version=\"1.0\">\n <dict>\n \t<key>version</key>\n-\t<string>4.1.6.2167</string>\n+\t<string>4.1.6.2169</string>\n </dict>\n </plist>"
        },
        {
          "filename": "server/non_ui_views.py",
          "status": "modified",
          "additions": 187,
          "deletions": 125,
          "patch": "@@ -11,70 +11,83 @@\n from django.conf import settings\n from django.contrib.auth.decorators import login_required\n from django.db.models import Q\n-from django.http import (\n-    HttpResponse, JsonResponse, Http404, HttpResponseBadRequest)\n+from django.http import HttpResponse, JsonResponse, Http404, HttpResponseBadRequest\n from django.shortcuts import get_object_or_404\n from django.urls import reverse\n from django.views.decorators.csrf import csrf_exempt\n from django.views.decorators.http import require_POST\n+from django.utils.html import escape\n \n import server.utils\n import utils.csv\n from sal.decorators import key_auth_required\n from sal.plugin import Widget, ReportPlugin, PluginManager\n-from server.models import (Machine, Fact, HistoricalFact, MachineGroup, Message, Plugin, Report,\n-                           ManagedItem, MachineDetailPlugin, ManagementSource, ManagedItemHistory)\n+from server.models import (\n+    Machine,\n+    Fact,\n+    HistoricalFact,\n+    MachineGroup,\n+    Message,\n+    Plugin,\n+    Report,\n+    ManagedItem,\n+    MachineDetailPlugin,\n+    ManagementSource,\n+    ManagedItemHistory,\n+)\n \n \n # The database probably isn't going to change while this is loaded.\n IS_POSTGRES = server.utils.is_postgres()\n-HISTORICAL_FACTS = set(server.utils.get_django_setting('HISTORICAL_FACTS', []))\n-if server.utils.get_django_setting('IGNORE_FACTS'):\n+HISTORICAL_FACTS = set(server.utils.get_django_setting(\"HISTORICAL_FACTS\", []))\n+if server.utils.get_django_setting(\"IGNORE_FACTS\"):\n     IGNORE_PREFIXES = re.compile(\n-        '|'.join(server.utils.get_django_setting('IGNORE_FACTS')))\n+        \"|\".join(server.utils.get_django_setting(\"IGNORE_FACTS\"))\n+    )\n else:\n     IGNORE_PREFIXES = None\n # Build a translation table for serial numbers, to remove garbage\n # VMware puts in.\n-SERIAL_TRANSLATE = {ord(c): None for c in '+/'}\n+SERIAL_TRANSLATE = {ord(c): None for c in \"+/\"}\n \n logger = logging.getLogger(__name__)\n \n \n @login_required\n-def tableajax(request, plugin_name, data, group_type='all', group_id=None):\n+def tableajax(request, plugin_name, data, group_type=\"all\", group_id=None):\n     \"\"\"Table ajax for dataTables\"\"\"\n     # Pull our variables out of the GET request\n-    get_data = request.GET['args']\n+    get_data = request.GET[\"args\"]\n     get_data = json.loads(get_data)\n-    draw = get_data.get('draw', 0)\n-    start = int(get_data.get('start', 0))\n-    length = int(get_data.get('length', 0))\n-    search_value = ''\n-    if 'search' in get_data:\n-        if 'value' in get_data['search']:\n-            search_value = get_data['search']['value']\n+    draw = get_data.get(\"draw\", 0)\n+    start = int(get_data.get(\"start\", 0))\n+    length = int(get_data.get(\"length\", 0))\n+    search_value = \"\"\n+    if \"search\" in get_data:\n+        if \"value\" in get_data[\"search\"]:\n+            search_value = get_data[\"search\"][\"value\"]\n \n     # default ordering\n     order_column = 2\n-    order_direction = 'desc'\n-    order_name = ''\n-    if 'order' in get_data:\n-        order_column = get_data['order'][0]['column']\n-        order_direction = get_data['order'][0]['dir']\n-    for column in get_data.get('columns', None):\n-        if column['data'] == order_column:\n-            order_name = column['name']\n+    order_direction = \"desc\"\n+    order_name = \"\"\n+    if \"order\" in get_data:\n+        order_column = get_data[\"order\"][0][\"column\"]\n+        order_direction = get_data[\"order\"][0][\"dir\"]\n+    for column in get_data.get(\"columns\", None):\n+        if column[\"data\"] == order_column:\n+            order_name = column[\"name\"]\n             break\n \n     plugin_object = process_plugin(plugin_name, group_type, group_id)\n     queryset = plugin_object.get_queryset(\n-        request, group_type=group_type, group_id=group_id)\n+        request, group_type=group_type, group_id=group_id\n+    )\n     machines, title = plugin_object.filter_machines(queryset, data)\n-    machines = machines.values('id', 'hostname', 'console_user', 'last_checkin')\n+    machines = machines.values(\"id\", \"hostname\", \"console_user\", \"last_checkin\")\n \n     if len(order_name) != 0:\n-        if order_direction == 'desc':\n+        if order_direction == \"desc\":\n             order_string = \"-%s\" % order_name\n         else:\n             order_string = \"%s\" % order_name\n@@ -83,52 +96,60 @@ def tableajax(request, plugin_name, data, group_type='all', group_id=None):\n         hostname_q = Q(hostname__icontains=search_value)\n         user_q = Q(console_user__icontains=search_value)\n         checkin_q = Q(last_checkin__icontains=search_value)\n-        searched_machines = machines.filter(hostname_q | user_q | checkin_q).order_by(order_string)\n+        searched_machines = machines.filter(hostname_q | user_q | checkin_q).order_by(\n+            order_string\n+        )\n     else:\n         searched_machines = machines.order_by(order_string)\n \n-    limited_machines = searched_machines[start:(start + length)]\n+    limited_machines = searched_machines[start : (start + length)]\n \n     return_data = {}\n-    return_data['title'] = title\n-    return_data['draw'] = int(draw)\n-    return_data['recordsTotal'] = machines.count()\n-    return_data['recordsFiltered'] = return_data['recordsTotal']\n+    return_data[\"title\"] = title\n+    return_data[\"draw\"] = int(draw)\n+    return_data[\"recordsTotal\"] = machines.count()\n+    return_data[\"recordsFiltered\"] = return_data[\"recordsTotal\"]\n \n-    return_data['data'] = []\n+    return_data[\"data\"] = []\n     settings_time_zone = None\n     try:\n         settings_time_zone = pytz.timezone(settings.TIME_ZONE)\n     except Exception:\n         pass\n \n     for machine in limited_machines:\n-        if machine['last_checkin']:\n+        if machine[\"last_checkin\"]:\n             # formatted_date = pytz.utc.localize(machine.last_checkin)\n             if settings_time_zone:\n-                formatted_date = machine['last_checkin'].astimezone(\n-                    settings_time_zone).strftime(\"%Y-%m-%d %H:%M %Z\")\n+                formatted_date = (\n+                    machine[\"last_checkin\"]\n+                    .astimezone(settings_time_zone)\n+                    .strftime(\"%Y-%m-%d %H:%M %Z\")\n+                )\n             else:\n-                formatted_date = machine['last_checkin'].strftime(\"%Y-%m-%d %H:%M\")\n+                formatted_date = machine[\"last_checkin\"].strftime(\"%Y-%m-%d %H:%M\")\n         else:\n             formatted_date = \"\"\n-        hostname_link = \"<a href=\\\"%s\\\">%s</a>\" % (\n-            reverse('machine_detail', args=[machine['id']]), machine['hostname'])\n+        hostname_link = '<a href=\"%s\">%s</a>' % (\n+            reverse(\"machine_detail\", args=[machine[\"id\"]]),\n+            escape(machine[\"hostname\"]),\n+        )\n \n-        list_data = [hostname_link, machine['console_user'], formatted_date]\n-        return_data['data'].append(list_data)\n+        list_data = [hostname_link, escape(machine[\"console_user\"]), formatted_date]\n+        return_data[\"data\"].append(list_data)\n \n     return JsonResponse(return_data)\n \n \n @login_required\n-def plugin_load(request, plugin_name, group_type='all', group_id=None):\n+def plugin_load(request, plugin_name, group_type=\"all\", group_id=None):\n     plugin_object = process_plugin(plugin_name, group_type, group_id)\n     return HttpResponse(\n-        plugin_object.widget_content(request, group_type=group_type, group_id=group_id))\n+        plugin_object.widget_content(request, group_type=group_type, group_id=group_id)\n+    )\n \n \n-def process_plugin(plugin_name, group_type='all', group_id=None):\n+def process_plugin(plugin_name, group_type=\"all\", group_id=None):\n     plugin = PluginManager.get_plugin_by_name(plugin_name)\n \n     # Ensure that a plugin was instantiated before proceeding.\n@@ -148,10 +169,11 @@ def process_plugin(plugin_name, group_type='all', group_id=None):\n \n \n @login_required\n-def export_csv(request, plugin_name, data, group_type='all', group_id=None):\n+def export_csv(request, plugin_name, data, group_type=\"all\", group_id=None):\n     plugin_object = process_plugin(plugin_name, group_type, group_id)\n     queryset = plugin_object.get_queryset(\n-        request, group_type=group_type, group_id=group_id)\n+        request, group_type=group_type, group_id=group_id\n+    )\n     machines, title = plugin_object.filter_machines(queryset, data)\n \n     return utils.csv.get_csv_response(machines, utils.csv.machine_fields(), title)\n@@ -165,12 +187,14 @@ def preflight_v2(request):\n     server.utils.load_default_plugins()\n     output = []\n     # Old Sal scripts just do a GET; just send everything in that case.\n-    os_family = None if request.method != 'POST' else request.POST.get('os_family')\n+    os_family = None if request.method != \"POST\" else request.POST.get(\"os_family\")\n \n     enabled_reports = Report.objects.all()\n     enabled_plugins = Plugin.objects.all()\n     enabled_detail_plugins = MachineDetailPlugin.objects.all()\n-    for enabled_plugin in itertools.chain(enabled_reports, enabled_plugins, enabled_detail_plugins):\n+    for enabled_plugin in itertools.chain(\n+        enabled_reports, enabled_plugins, enabled_detail_plugins\n+    ):\n         plugin = PluginManager.get_plugin_by_name(enabled_plugin.name)\n         if not plugin:\n             continue\n@@ -203,73 +227,85 @@ def report_broken_client(request):\n \n     # Take out some of the weird junk VMware puts in. Keep an eye out in case\n     # Apple actually uses these:\n-    serial = data.get('serial', '').upper().translate(SERIAL_TRANSLATE)\n+    serial = data.get(\"serial\", \"\").upper().translate(SERIAL_TRANSLATE)\n     # Are we using Sal for some sort of inventory (like, I don't know, Puppet?)\n     machine = get_object_or_404(Machine, serial=serial)\n \n-    machine_group_key = data.get('key')\n+    machine_group_key = data.get(\"key\")\n     machine.machine_group = get_object_or_404(MachineGroup, key=machine_group_key)\n \n     machine.last_checkin = django.utils.timezone.now()\n-    machine.hostname = data.get('name', '<NO NAME>')\n-    machine.sal_version = data.get('sal_version')\n+    machine.hostname = data.get(\"name\", \"<NO NAME>\")\n+    machine.sal_version = data.get(\"sal_version\")\n \n-    if server.utils.get_django_setting('DEPLOYED_ON_CHECKIN', False):\n+    if server.utils.get_django_setting(\"DEPLOYED_ON_CHECKIN\", False):\n         machine.deployed = True\n \n-    if bool(data.get('broken_client', False)):\n+    if bool(data.get(\"broken_client\", False)):\n         machine.broken_client = True\n         machine.save()\n-        return HttpResponse(\"Broken Client report submmitted for %s\" % data.get('serial'))\n+        return HttpResponse(\n+            \"Broken Client report submmitted for %s\" % data.get(\"serial\")\n+        )\n     return HttpResponseBadRequest()\n \n \n @csrf_exempt\n @require_POST\n @key_auth_required\n def checkin(request):\n-    if request.content_type != 'application/json':\n-        return HttpResponseBadRequest('Checkin must be content-type \"application/json\"!')\n+    if request.content_type != \"application/json\":\n+        return HttpResponseBadRequest(\n+            'Checkin must be content-type \"application/json\"!'\n+        )\n     # Ensure we have the bare minimum data before continuing.\n     try:\n         submission = json.loads(request.body.decode())\n     except json.JSONDecodeError:\n-        return HttpResponseBadRequest('Checkin has invalid JSON!')\n-    if not isinstance(submission, dict) or 'Machine' not in submission:\n+        return HttpResponseBadRequest(\"Checkin has invalid JSON!\")\n+    if not isinstance(submission, dict) or \"Machine\" not in submission:\n         return HttpResponseBadRequest('Checkin JSON is missing required key \"Machine\"!')\n \n     # Process machine submission information.\n     try:\n-        serial = submission['Machine']['extra_data'].get('serial')\n+        serial = submission[\"Machine\"][\"extra_data\"].get(\"serial\")\n     except KeyError:\n-        return HttpResponseBadRequest('Checkin JSON is missing required \"Machine\" key \"serial\"!')\n+        return HttpResponseBadRequest(\n+            'Checkin JSON is missing required \"Machine\" key \"serial\"!'\n+        )\n     if not serial:\n-        return HttpResponseBadRequest('Checkin JSON is missing required \"Machine\" key \"serial\"!')\n+        return HttpResponseBadRequest(\n+            'Checkin JSON is missing required \"Machine\" key \"serial\"!'\n+        )\n \n     machine = process_checkin_serial(serial)\n-    machine_group = get_object_or_404(MachineGroup, key=submission['Sal']['extra_data'].get('key'))\n+    machine_group = get_object_or_404(\n+        MachineGroup, key=submission[\"Sal\"][\"extra_data\"].get(\"key\")\n+    )\n     machine.machine_group = machine_group\n     machine.broken_client = False\n     machine.save()\n     clean_related(machine)\n \n     object_queue = {\n-        'facts': [],\n-        'historical_facts': [],\n-        'managed_items': [],\n-        'managed_item_histories': [],\n-        'messages': []\n+        \"facts\": [],\n+        \"historical_facts\": [],\n+        \"managed_items\": [],\n+        \"managed_item_histories\": [],\n+        \"messages\": [],\n     }\n \n     # Pop off the plugin_results, because they are a list instead of\n     # a dict.\n-    plugin_results = submission.pop('plugin_results', {})\n+    plugin_results = submission.pop(\"plugin_results\", {})\n     for management_source_name, management_data in submission.items():\n         management_source, _ = ManagementSource.objects.get_or_create(\n-            name=management_source_name)\n+            name=management_source_name\n+        )\n \n         object_queue = process_management_submission(\n-            management_source, management_data, machine, object_queue)\n+            management_source, management_data, machine, object_queue\n+        )\n \n     object_queue = process_managed_item_histories(object_queue, machine)\n \n@@ -278,7 +314,7 @@ def checkin(request):\n     server.utils.process_plugin_script(plugin_results, machine)\n     server.utils.run_plugin_processing(machine, submission)\n \n-    if server.utils.get_setting('send_data') in (None, True):\n+    if server.utils.get_setting(\"send_data\") in (None, True):\n         # If setting is None, it hasn't been configured yet; assume True\n         try:\n             # If the report server is down, don't halt all submissions\n@@ -297,7 +333,7 @@ def process_checkin_serial(serial):\n     serial = serial.upper().translate(SERIAL_TRANSLATE)\n \n     # Are we using Sal for some sort of inventory (like, I don't know, Puppet?)\n-    if server.utils.get_django_setting('ADD_NEW_MACHINES', True):\n+    if server.utils.get_django_setting(\"ADD_NEW_MACHINES\", True):\n         try:\n             machine = Machine.objects.get(serial=serial)\n         except Machine.DoesNotExist:\n@@ -339,9 +375,10 @@ def process_management_submission(source, management_data, machine, object_queue\n     # The func's signature must be\n     # f(management_data: dict, machine: Machine, object_queue: dict)\n     processing_funcs = {\n-        'Machine': process_machine_submission,\n-        'Sal': process_sal_submission,\n-        'Munki': process_munki_extra_keys}\n+        \"Machine\": process_machine_submission,\n+        \"Sal\": process_sal_submission,\n+        \"Munki\": process_munki_extra_keys,\n+    }\n \n     processing_func = processing_funcs.get(source.name)\n     if processing_func:\n@@ -355,104 +392,122 @@ def process_management_submission(source, management_data, machine, object_queue\n \n \n def process_machine_submission(machine_submission, machine, object_queue):\n-    extra_data = machine_submission.get('extra_data', {})\n-    machine.hostname = extra_data.get('hostname', '<NO NAME>')\n+    extra_data = machine_submission.get(\"extra_data\", {})\n+    machine.hostname = extra_data.get(\"hostname\", \"<NO NAME>\")\n     # Drop the setup assistant user if encountered.\n-    console_user = extra_data.get('console_user')\n-    console_user = console_user if console_user != '_mbsetupuser' else None\n+    console_user = extra_data.get(\"console_user\")\n+    console_user = console_user if console_user != \"_mbsetupuser\" else None\n     machine.console_user = console_user\n-    machine.os_family = extra_data.get('os_family', 'Darwin')\n-    machine.operating_system = extra_data.get('operating_system')\n-    machine.hd_space = extra_data.get('hd_space')\n-    machine.hd_total = extra_data.get('hd_total')\n-    machine.hd_percent = extra_data.get('hd_percent')\n-    machine.machine_model = extra_data.get('machine_model')\n-    machine.machine_model_friendly = extra_data.get('machine_model_friendly')\n-    machine.cpu_type = extra_data.get('cpu_type')\n-    machine.cpu_speed = extra_data.get('cpu_speed')\n-    machine.memory = extra_data.get('memory')\n-    machine.memory_kb = extra_data.get('memory_kb', 0)\n+    machine.os_family = extra_data.get(\"os_family\", \"Darwin\")\n+    machine.operating_system = extra_data.get(\"operating_system\")\n+    machine.hd_space = extra_data.get(\"hd_space\")\n+    machine.hd_total = extra_data.get(\"hd_total\")\n+    machine.hd_percent = extra_data.get(\"hd_percent\")\n+    machine.machine_model = extra_data.get(\"machine_model\")\n+    machine.machine_model_friendly = extra_data.get(\"machine_model_friendly\")\n+    machine.cpu_type = extra_data.get(\"cpu_type\")\n+    machine.cpu_speed = extra_data.get(\"cpu_speed\")\n+    machine.memory = extra_data.get(\"memory\")\n+    machine.memory_kb = extra_data.get(\"memory_kb\", 0)\n     machine.save()\n     return object_queue\n \n \n def process_sal_submission(sal_submission, machine, object_queue):\n-    extras = sal_submission.get('extra_data', {})\n-    machine.sal_version = extras.get('sal_version')\n+    extras = sal_submission.get(\"extra_data\", {})\n+    machine.sal_version = extras.get(\"sal_version\")\n     machine.last_checkin = django.utils.timezone.now()\n \n-    if server.utils.get_django_setting('DEPLOYED_ON_CHECKIN', True):\n+    if server.utils.get_django_setting(\"DEPLOYED_ON_CHECKIN\", True):\n         machine.deployed = True\n \n     machine.save()\n     return object_queue\n \n \n def process_munki_extra_keys(management_data, machine, object_queue):\n-    extra_data = management_data.get('extra_data', {})\n-    machine.munki_version = extra_data.get('munki_version')\n-    machine.manifest = extra_data.get('manifest')\n+    extra_data = management_data.get(\"extra_data\", {})\n+    machine.munki_version = extra_data.get(\"munki_version\")\n+    machine.manifest = extra_data.get(\"manifest\")\n     machine.save()\n     return object_queue\n \n \n def process_facts(management_source, management_data, machine, object_queue):\n     now = django.utils.timezone.now()\n-    for fact_name, fact_data in management_data.get('facts', {}).items():\n+    for fact_name, fact_data in management_data.get(\"facts\", {}).items():\n         if IGNORE_PREFIXES and IGNORE_PREFIXES.match(fact_name):\n             continue\n \n-        object_queue['facts'].append(\n+        object_queue[\"facts\"].append(\n             Fact(\n-                machine=machine, fact_data=fact_data, fact_name=fact_name,\n-                management_source=management_source))\n+                machine=machine,\n+                fact_data=fact_data,\n+                fact_name=fact_name,\n+                management_source=management_source,\n+            )\n+        )\n \n         if fact_name in HISTORICAL_FACTS:\n-            object_queue['historical_facts'].append(\n+            object_queue[\"historical_facts\"].append(\n                 HistoricalFact(\n-                    machine=machine, fact_data=fact_data, fact_name=fact_name,\n-                    management_source=management_source, fact_recorded=now))\n+                    machine=machine,\n+                    fact_data=fact_data,\n+                    fact_name=fact_name,\n+                    management_source=management_source,\n+                    fact_recorded=now,\n+                )\n+            )\n \n     return object_queue\n \n \n def process_managed_items(management_source, management_data, machine, object_queue):\n     now = django.utils.timezone.now()\n-    for name, managed_item in management_data.get('managed_items', {}).items():\n-        object_queue['managed_items'].append(\n-            _process_managed_item(name, managed_item, machine, management_source, now))\n+    for name, managed_item in management_data.get(\"managed_items\", {}).items():\n+        object_queue[\"managed_items\"].append(\n+            _process_managed_item(name, managed_item, machine, management_source, now)\n+        )\n \n     return object_queue\n \n \n def _process_managed_item(name, managed_item, machine, management_source, now):\n-    submitted_date = managed_item.get('date_managed')\n+    submitted_date = managed_item.get(\"date_managed\")\n     try:\n         # Make sure there isn't somerthing stupid in the date format\n         date_managed = dateutil.parser.parse(submitted_date) if submitted_date else now\n     except Exception:\n         date_managed = now\n-    status = managed_item.get('status', 'UNKNOWN')\n-    data = managed_item.get('data')\n+    status = managed_item.get(\"status\", \"UNKNOWN\")\n+    data = managed_item.get(\"data\")\n     dumped_data = json.dumps(data) if data else None\n     return ManagedItem(\n-        name=name, machine=machine, management_source=management_source,\n-        date_managed=date_managed, status=status, data=dumped_data)\n+        name=name,\n+        machine=machine,\n+        management_source=management_source,\n+        date_managed=date_managed,\n+        status=status,\n+        data=dumped_data,\n+    )\n \n \n def process_managed_item_histories(object_queue, machine):\n     histories = machine.manageditemhistory_set.all()\n-    for managed_item in object_queue['managed_items']:\n+    for managed_item in object_queue[\"managed_items\"]:\n         item_histories = histories.filter(\n-            name=managed_item.name, management_source=managed_item.management_source)\n+            name=managed_item.name, management_source=managed_item.management_source\n+        )\n         if _history_creation_needed(managed_item, item_histories.first()):\n-            object_queue['managed_item_histories'].append(\n+            object_queue[\"managed_item_histories\"].append(\n                 ManagedItemHistory(\n                     name=managed_item.name,\n                     status=managed_item.status,\n                     management_source=managed_item.management_source,\n                     machine=machine,\n-                    recorded=managed_item.date_managed))\n+                    recorded=managed_item.date_managed,\n+                )\n+            )\n \n     return object_queue\n \n@@ -466,22 +521,29 @@ def _history_creation_needed(managed_item, last_history):\n \n def process_messages(management_source, management_data, machine, object_queue):\n     now = django.utils.timezone.now()\n-    for message_item in management_data.get('messages', []):\n-        object_queue['messages'].append(\n+    for message_item in management_data.get(\"messages\", []):\n+        object_queue[\"messages\"].append(\n             Message(\n                 machine=machine,\n                 management_source=management_source,\n-                text=message_item.get('text'),\n-                message_type=message_item.get('message_type'),\n-                date=message_item.get('date', now)))\n+                text=message_item.get(\"text\"),\n+                message_type=message_item.get(\"message_type\"),\n+                date=message_item.get(\"date\", now),\n+            )\n+        )\n \n     return object_queue\n \n \n def create_objects(object_queue):\n     \"\"\"Bulk create Fact, HistoricalFact, Message, and ManagedItem objects.\"\"\"\n-    models = {'facts': Fact, 'historical_facts': HistoricalFact, 'managed_items': ManagedItem,\n-              'messages': Message, 'managed_item_histories': ManagedItemHistory}\n+    models = {\n+        \"facts\": Fact,\n+        \"historical_facts\": HistoricalFact,\n+        \"managed_items\": ManagedItem,\n+        \"messages\": Message,\n+        \"managed_item_histories\": ManagedItemHistory,\n+    }\n \n     for name, objects in object_queue.items():\n         _bulk_create_or_iterate_save(objects, models[name])"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 0,
        "unique_directories": 3,
        "max_directory_depth": 1
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "2f230dd3ba15a82e2e794d5be6c9b080f7f4e966",
            "date": "2024-11-08T16:48:01Z",
            "author_login": "grahamgilbert"
          },
          {
            "sha": "aa25ee5de2bf3421c9f098f818cf1e91dfed5500",
            "date": "2024-11-08T16:43:37Z",
            "author_login": "grahamgilbert"
          },
          {
            "sha": "d175497860c0204303f0408a2790b5bdc93e1330",
            "date": "2024-11-07T01:25:40Z",
            "author_login": "grahamgilbert"
          },
          {
            "sha": "4c9e5c04956ea15d6c8f7d9228c7ed086845a153",
            "date": "2024-11-07T01:15:01Z",
            "author_login": "grahamgilbert"
          },
          {
            "sha": "9bfaf3828f715c383757a35b3c099798236743d5",
            "date": "2024-11-07T01:13:57Z",
            "author_login": "grahamgilbert"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.6,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:H/A:N",
    "cwe_id": "CWE-79",
    "description": "Sal is a multi-tenanted reporting dashboard for Munki with the ability to display information from Facter. In Sal through version 4.1.6 there is an XSS vulnerability on the machine_list view.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2020-10-29T20:15:19.353",
    "last_modified": "2024-11-21T05:19:31.313",
    "fix_date": "2020-10-07T02:56:18Z"
  },
  "references": [
    {
      "url": "https://github.com/salopensource/sal/commit/145bb72daf8460bdedbbc9fb708d346283e7a568",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/salopensource/sal/pull/405",
      "source": "security-advisories@github.com",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/salopensource/sal/commit/145bb72daf8460bdedbbc9fb708d346283e7a568",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/salopensource/sal/pull/405",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:01:08.440579",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "sal",
    "owner": "salopensource",
    "created_at": "2015-05-19T13:21:57Z",
    "updated_at": "2024-12-27T18:47:54Z",
    "pushed_at": "2024-12-18T15:39:29Z",
    "size": 6562,
    "stars": 214,
    "forks": 64,
    "open_issues": 16,
    "watchers": 214,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "main"
    ],
    "languages": {
      "Python": 549602,
      "JavaScript": 282660,
      "CSS": 186856,
      "HTML": 150533,
      "Less": 67048,
      "SCSS": 51035,
      "Shell": 4141,
      "Dockerfile": 2309,
      "Makefile": 2250,
      "Procfile": 23
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "apache-2.0"
    },
    "collected_at": "2025-01-14T21:43:15.086589"
  }
}