{
  "cve_id": "CVE-2021-29541",
  "github_data": {
    "repository": "tensorflow/tensorflow",
    "fix_commit": "ba424dd8f16f7110eea526a8086f1a155f14f22b",
    "related_commits": [
      "ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "ba424dd8f16f7110eea526a8086f1a155f14f22b"
    ],
    "patch_url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b.patch",
    "fix_commit_details": {
      "sha": "ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "commit_date": "2021-04-22T20:29:54Z",
      "author": {
        "login": "mihaimaruseac",
        "type": "User",
        "stats": {
          "total_commits": 1590,
          "average_weekly_commits": 3.3125,
          "total_additions": 0,
          "total_deletions": 0,
          "weeks_active": 214
        }
      },
      "commit_message": {
        "title": "Enhance validation of ngram op and handle case of 0 tokens.",
        "length": 142,
        "has_description": true,
        "references_issue": false
      },
      "stats": {
        "total": 86,
        "additions": 75,
        "deletions": 11
      },
      "files": [
        {
          "filename": "tensorflow/core/kernels/string_ngrams_op.cc",
          "status": "modified",
          "additions": 41,
          "deletions": 11,
          "patch": "@@ -61,16 +61,28 @@ class StringNGramsOp : public tensorflow::OpKernel {\n     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n     const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n \n-    // Validate that the splits are valid indices into data\n+    // Validate that the splits are valid indices into data, only if there are\n+    // splits specified.\n     const int input_data_size = data->flat<tstring>().size();\n     const int splits_vec_size = splits_vec.size();\n-    for (int i = 0; i < splits_vec_size; ++i) {\n-      bool valid_splits = splits_vec(i) >= 0;\n-      valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n-      OP_REQUIRES(\n-          context, valid_splits,\n-          errors::InvalidArgument(\"Invalid split value \", splits_vec(i),\n-                                  \", must be in [0,\", input_data_size, \"]\"));\n+    if (splits_vec_size > 0) {\n+      int prev_split = splits_vec(0);\n+      OP_REQUIRES(context, prev_split == 0,\n+                  errors::InvalidArgument(\"First split value must be 0, got \",\n+                                          prev_split));\n+      for (int i = 1; i < splits_vec_size; ++i) {\n+        bool valid_splits = splits_vec(i) >= prev_split;\n+        valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n+        OP_REQUIRES(context, valid_splits,\n+                    errors::InvalidArgument(\n+                        \"Invalid split value \", splits_vec(i), \", must be in [\",\n+                        prev_split, \", \", input_data_size, \"]\"));\n+        prev_split = splits_vec(i);\n+      }\n+      OP_REQUIRES(context, prev_split == input_data_size,\n+                  errors::InvalidArgument(\n+                      \"Last split value must be data size. Expected \",\n+                      input_data_size, \", got \", prev_split));\n     }\n \n     int num_batch_items = splits_vec.size() - 1;\n@@ -174,13 +186,31 @@ class StringNGramsOp : public tensorflow::OpKernel {\n         ngram->append(left_pad_);\n         ngram->append(separator_);\n       }\n+      // Only output first num_tokens - 1 pairs of data and separator\n       for (int n = 0; n < num_tokens - 1; ++n) {\n         ngram->append(data[data_start_index + n]);\n         ngram->append(separator_);\n       }\n-      ngram->append(data[data_start_index + num_tokens - 1]);\n-      for (int n = 0; n < right_padding; ++n) {\n-        ngram->append(separator_);\n+      // Handle case when there are no tokens or no right padding as these can\n+      // result in consecutive separators.\n+      if (num_tokens > 0) {\n+        // If we have tokens, then output last and then pair each separator with\n+        // the right padding that follows, to ensure ngram ends either with the\n+        // token or with the right pad.\n+        ngram->append(data[data_start_index + num_tokens - 1]);\n+        for (int n = 0; n < right_padding; ++n) {\n+          ngram->append(separator_);\n+          ngram->append(right_pad_);\n+        }\n+      } else {\n+        // If we don't have tokens, then the last item inserted into the ngram\n+        // has been the separator from the left padding loop above. Hence,\n+        // output right pad and separator and make sure to finish with a\n+        // padding, not a separator.\n+        for (int n = 0; n < right_padding - 1; ++n) {\n+          ngram->append(right_pad_);\n+          ngram->append(separator_);\n+        }\n         ngram->append(right_pad_);\n       }\n "
        },
        {
          "filename": "tensorflow/core/kernels/string_ngrams_op_test.cc",
          "status": "modified",
          "additions": 34,
          "deletions": 0,
          "patch": "@@ -542,6 +542,40 @@ TEST_F(NgramKernelTest, TestEmptyInput) {\n   assert_int64_equal(expected_splits, *GetOutput(1));\n }\n \n+TEST_F(NgramKernelTest, TestNoTokens) {\n+  MakeOp(\"|\", {3}, \"L\", \"R\", -1, false);\n+  // Batch items are:\n+  // 0:\n+  // 1: \"a\"\n+  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n+  AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  std::vector<tstring> expected_values(\n+      {\"L|L|R\", \"L|R|R\",             // no input in first split\n+       \"L|L|a\", \"L|a|R\", \"a|R|R\"});  // second split\n+  std::vector<int64> expected_splits({0, 2, 5});\n+\n+  assert_string_equal(expected_values, *GetOutput(0));\n+  assert_int64_equal(expected_splits, *GetOutput(1));\n+}\n+\n+TEST_F(NgramKernelTest, TestNoTokensNoPad) {\n+  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n+  // Batch items are:\n+  // 0:\n+  // 1: \"a\"\n+  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n+  AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  std::vector<tstring> expected_values({});\n+  std::vector<int64> expected_splits({0, 0, 0});\n+\n+  assert_string_equal(expected_values, *GetOutput(0));\n+  assert_int64_equal(expected_splits, *GetOutput(1));\n+}\n+\n TEST_F(NgramKernelTest, ShapeFn) {\n   ShapeInferenceTestOp op(\"StringNGrams\");\n   INFER_OK(op, \"?;?\", \"[?];[?]\");"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 1,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "fd41705e0ad7a123a9d01b8be2a3b34b3266493e",
            "date": "2025-01-14T13:33:52Z",
            "author_login": "loislo"
          },
          {
            "sha": "af5275c5731565cbf2a2c01ee418a8cf62388431",
            "date": "2025-01-14T12:48:20Z",
            "author_login": "akuegel"
          },
          {
            "sha": "ee156c15e5d1cd7d2bd85885e7fd2bf7e143c2c3",
            "date": "2025-01-14T12:46:22Z",
            "author_login": "pifon2a"
          },
          {
            "sha": "bd43a8255ce9e203b740bcdc09e8f79d3a26f887",
            "date": "2025-01-14T12:33:02Z",
            "author_login": "metaflow"
          },
          {
            "sha": "8003fb40987f176d35364da2af8fcdfab339349e",
            "date": "2025-01-14T11:27:47Z",
            "author_login": "vwbaker"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 2.5,
    "cvss_vector": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L",
    "cwe_id": "CWE-476",
    "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a dereference of a null pointer in `tf.raw_ops.StringNGrams`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/1cdd4da14282210cc759e468d9781741ac7d01bf/tensorflow/core/kernels/string_ngrams_op.cc#L67-L74) does not fully validate the `data_splits` argument. This would result in `ngrams_data`(https://github.com/tensorflow/tensorflow/blob/1cdd4da14282210cc759e468d9781741ac7d01bf/tensorflow/core/kernels/string_ngrams_op.cc#L106-L110) to be a null pointer when the output would be computed to have 0 or negative size. Later writes to the output tensor would then cause a null pointer dereference. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
    "attack_vector": "LOCAL",
    "attack_complexity": "HIGH"
  },
  "temporal_data": {
    "published_date": "2021-05-14T20:15:12.487",
    "last_modified": "2024-11-21T06:01:20.530",
    "fix_date": "2021-04-22T20:29:54Z"
  },
  "references": [
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xqfj-35wv-m3cr",
      "source": "security-advisories@github.com",
      "tags": [
        "Exploit",
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-xqfj-35wv-m3cr",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit",
        "Patch",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:01:57.087879",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "tensorflow",
    "owner": "tensorflow",
    "created_at": "2015-11-07T01:19:20Z",
    "updated_at": "2025-01-14T12:53:26Z",
    "pushed_at": "2025-01-14T12:53:14Z",
    "size": 1120707,
    "stars": 187254,
    "forks": 74432,
    "open_issues": 6569,
    "watchers": 187254,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "C++": 101199988,
      "Python": 45779571,
      "MLIR": 10763008,
      "HTML": 7662661,
      "Starlark": 7430486,
      "Go": 2171370,
      "C": 1288066,
      "Java": 1178817,
      "Jupyter Notebook": 805736,
      "Shell": 701425,
      "Objective-C++": 279654,
      "Objective-C": 169202,
      "CMake": 148610,
      "Smarty": 121630,
      "Swift": 81659,
      "Dockerfile": 37903,
      "C#": 13585,
      "Batchfile": 12126,
      "Ruby": 8898,
      "Perl": 7536,
      "Roff": 5034,
      "Cython": 3899,
      "Makefile": 2845,
      "CSS": 2761,
      "Vim Snippet": 58
    },
    "commit_activity": {
      "total_commits_last_year": 15729,
      "avg_commits_per_week": 302.4807692307692,
      "days_active_last_year": 357
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "apache-2.0"
    },
    "collected_at": "2025-01-14T12:54:01.412891"
  }
}