{
  "cve_id": "CVE-2021-29542",
  "github_data": {
    "repository": "tensorflow/tensorflow",
    "fix_commit": "ba424dd8f16f7110eea526a8086f1a155f14f22b",
    "related_commits": [
      "ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "ba424dd8f16f7110eea526a8086f1a155f14f22b"
    ],
    "patch_url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b.patch",
    "fix_commit_details": {
      "sha": "ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "commit_date": "2021-04-22T20:29:54Z",
      "author": {
        "login": "mihaimaruseac",
        "type": "User",
        "stats": {
          "total_commits": 1590,
          "average_weekly_commits": 3.3125,
          "total_additions": 0,
          "total_deletions": 0,
          "weeks_active": 214
        }
      },
      "commit_message": {
        "title": "Enhance validation of ngram op and handle case of 0 tokens.",
        "length": 142,
        "has_description": true,
        "references_issue": false
      },
      "stats": {
        "total": 86,
        "additions": 75,
        "deletions": 11
      },
      "files": [
        {
          "filename": "tensorflow/core/kernels/string_ngrams_op.cc",
          "status": "modified",
          "additions": 41,
          "deletions": 11,
          "patch": "@@ -61,16 +61,28 @@ class StringNGramsOp : public tensorflow::OpKernel {\n     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n     const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n \n-    // Validate that the splits are valid indices into data\n+    // Validate that the splits are valid indices into data, only if there are\n+    // splits specified.\n     const int input_data_size = data->flat<tstring>().size();\n     const int splits_vec_size = splits_vec.size();\n-    for (int i = 0; i < splits_vec_size; ++i) {\n-      bool valid_splits = splits_vec(i) >= 0;\n-      valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n-      OP_REQUIRES(\n-          context, valid_splits,\n-          errors::InvalidArgument(\"Invalid split value \", splits_vec(i),\n-                                  \", must be in [0,\", input_data_size, \"]\"));\n+    if (splits_vec_size > 0) {\n+      int prev_split = splits_vec(0);\n+      OP_REQUIRES(context, prev_split == 0,\n+                  errors::InvalidArgument(\"First split value must be 0, got \",\n+                                          prev_split));\n+      for (int i = 1; i < splits_vec_size; ++i) {\n+        bool valid_splits = splits_vec(i) >= prev_split;\n+        valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n+        OP_REQUIRES(context, valid_splits,\n+                    errors::InvalidArgument(\n+                        \"Invalid split value \", splits_vec(i), \", must be in [\",\n+                        prev_split, \", \", input_data_size, \"]\"));\n+        prev_split = splits_vec(i);\n+      }\n+      OP_REQUIRES(context, prev_split == input_data_size,\n+                  errors::InvalidArgument(\n+                      \"Last split value must be data size. Expected \",\n+                      input_data_size, \", got \", prev_split));\n     }\n \n     int num_batch_items = splits_vec.size() - 1;\n@@ -174,13 +186,31 @@ class StringNGramsOp : public tensorflow::OpKernel {\n         ngram->append(left_pad_);\n         ngram->append(separator_);\n       }\n+      // Only output first num_tokens - 1 pairs of data and separator\n       for (int n = 0; n < num_tokens - 1; ++n) {\n         ngram->append(data[data_start_index + n]);\n         ngram->append(separator_);\n       }\n-      ngram->append(data[data_start_index + num_tokens - 1]);\n-      for (int n = 0; n < right_padding; ++n) {\n-        ngram->append(separator_);\n+      // Handle case when there are no tokens or no right padding as these can\n+      // result in consecutive separators.\n+      if (num_tokens > 0) {\n+        // If we have tokens, then output last and then pair each separator with\n+        // the right padding that follows, to ensure ngram ends either with the\n+        // token or with the right pad.\n+        ngram->append(data[data_start_index + num_tokens - 1]);\n+        for (int n = 0; n < right_padding; ++n) {\n+          ngram->append(separator_);\n+          ngram->append(right_pad_);\n+        }\n+      } else {\n+        // If we don't have tokens, then the last item inserted into the ngram\n+        // has been the separator from the left padding loop above. Hence,\n+        // output right pad and separator and make sure to finish with a\n+        // padding, not a separator.\n+        for (int n = 0; n < right_padding - 1; ++n) {\n+          ngram->append(right_pad_);\n+          ngram->append(separator_);\n+        }\n         ngram->append(right_pad_);\n       }\n "
        },
        {
          "filename": "tensorflow/core/kernels/string_ngrams_op_test.cc",
          "status": "modified",
          "additions": 34,
          "deletions": 0,
          "patch": "@@ -542,6 +542,40 @@ TEST_F(NgramKernelTest, TestEmptyInput) {\n   assert_int64_equal(expected_splits, *GetOutput(1));\n }\n \n+TEST_F(NgramKernelTest, TestNoTokens) {\n+  MakeOp(\"|\", {3}, \"L\", \"R\", -1, false);\n+  // Batch items are:\n+  // 0:\n+  // 1: \"a\"\n+  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n+  AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  std::vector<tstring> expected_values(\n+      {\"L|L|R\", \"L|R|R\",             // no input in first split\n+       \"L|L|a\", \"L|a|R\", \"a|R|R\"});  // second split\n+  std::vector<int64> expected_splits({0, 2, 5});\n+\n+  assert_string_equal(expected_values, *GetOutput(0));\n+  assert_int64_equal(expected_splits, *GetOutput(1));\n+}\n+\n+TEST_F(NgramKernelTest, TestNoTokensNoPad) {\n+  MakeOp(\"|\", {3}, \"\", \"\", 0, false);\n+  // Batch items are:\n+  // 0:\n+  // 1: \"a\"\n+  AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});\n+  AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});\n+  TF_ASSERT_OK(RunOpKernel());\n+\n+  std::vector<tstring> expected_values({});\n+  std::vector<int64> expected_splits({0, 0, 0});\n+\n+  assert_string_equal(expected_values, *GetOutput(0));\n+  assert_int64_equal(expected_splits, *GetOutput(1));\n+}\n+\n TEST_F(NgramKernelTest, ShapeFn) {\n   ShapeInferenceTestOp op(\"StringNGrams\");\n   INFER_OK(op, \"?;?\", \"[?];[?]\");"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 1,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "b13ee8b852a232dc6dd339e0de4e22f735136b7a",
            "date": "2025-01-14T16:59:22Z",
            "author_login": "Moerafaat"
          },
          {
            "sha": "d65ab241c92b18a8e82a53b03575775279713930",
            "date": "2025-01-14T16:17:42Z",
            "author_login": "akuegel"
          },
          {
            "sha": "7f1cdb4f94bf497a8f81b47cb0b0f6f33dfcdf2f",
            "date": "2025-01-14T15:43:26Z",
            "author_login": "vwbaker"
          },
          {
            "sha": "8f888e57d9fab1d2e4127fdeaabc3f8976471065",
            "date": "2025-01-14T15:28:59Z",
            "author_login": "ddunl"
          },
          {
            "sha": "4e74930bd620da4ea2bb691359aaa9b2dc6b0605",
            "date": "2025-01-14T15:28:20Z",
            "author_login": "tensorflower-gardener"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 2.5,
    "cvss_vector": "CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:N/A:L",
    "cwe_id": "CWE-131",
    "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a heap buffer overflow by passing crafted inputs to `tf.raw_ops.StringNGrams`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/1cdd4da14282210cc759e468d9781741ac7d01bf/tensorflow/core/kernels/string_ngrams_op.cc#L171-L185) fails to consider corner cases where input would be split in such a way that the generated tokens should only contain padding elements. If input is such that `num_tokens` is 0, then, for `data_start_index=0` (when left padding is present), the marked line would result in reading `data[-1]`. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
    "attack_vector": "LOCAL",
    "attack_complexity": "HIGH"
  },
  "temporal_data": {
    "published_date": "2021-05-14T20:15:12.537",
    "last_modified": "2024-11-21T06:01:20.657",
    "fix_date": "2021-04-22T20:29:54Z"
  },
  "references": [
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4hrh-9vmp-2jgg",
      "source": "security-advisories@github.com",
      "tags": [
        "Exploit",
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-4hrh-9vmp-2jgg",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit",
        "Patch",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:01:57.088020",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "tensorflow",
    "owner": "tensorflow",
    "created_at": "2015-11-07T01:19:20Z",
    "updated_at": "2025-01-14T12:53:26Z",
    "pushed_at": "2025-01-14T12:53:14Z",
    "size": 1120707,
    "stars": 187254,
    "forks": 74432,
    "open_issues": 6569,
    "watchers": 187254,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "C++": 101199988,
      "Python": 45779571,
      "MLIR": 10763008,
      "HTML": 7662661,
      "Starlark": 7430486,
      "Go": 2171370,
      "C": 1288066,
      "Java": 1178817,
      "Jupyter Notebook": 805736,
      "Shell": 701425,
      "Objective-C++": 279654,
      "Objective-C": 169202,
      "CMake": 148610,
      "Smarty": 121630,
      "Swift": 81659,
      "Dockerfile": 37903,
      "C#": 13585,
      "Batchfile": 12126,
      "Ruby": 8898,
      "Perl": 7536,
      "Roff": 5034,
      "Cython": 3899,
      "Makefile": 2845,
      "CSS": 2761,
      "Vim Snippet": 58
    },
    "commit_activity": {
      "total_commits_last_year": 15729,
      "avg_commits_per_week": 302.4807692307692,
      "days_active_last_year": 357
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "apache-2.0"
    },
    "collected_at": "2025-01-14T12:54:01.412891"
  }
}