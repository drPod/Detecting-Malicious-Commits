{
  "cve_id": "CVE-2021-32628",
  "github_data": {
    "repository": "redis/redis",
    "fix_commit": "f6a40570fa63d5afdd596c78083d754081d80ae3",
    "related_commits": [
      "f6a40570fa63d5afdd596c78083d754081d80ae3",
      "f6a40570fa63d5afdd596c78083d754081d80ae3"
    ],
    "patch_url": "https://github.com/redis/redis/commit/f6a40570fa63d5afdd596c78083d754081d80ae3.patch",
    "fix_commit_details": {
      "sha": "f6a40570fa63d5afdd596c78083d754081d80ae3",
      "commit_date": "2021-06-03T09:10:02Z",
      "author": {
        "login": "oranagra",
        "type": "User",
        "stats": {
          "total_commits": 812,
          "average_weekly_commits": 0.9830508474576272,
          "total_additions": 0,
          "total_deletions": 0,
          "weeks_active": 261
        }
      },
      "commit_message": {
        "title": "Fix ziplist and listpack overflows and truncations (CVE-2021-32627, CVE-2021-32628)",
        "length": 686,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 388,
        "additions": 339,
        "deletions": 49
      },
      "files": [
        {
          "filename": "src/geo.c",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -635,7 +635,7 @@ void georadiusGeneric(client *c, int flags) {\n         robj *zobj;\n         zset *zs;\n         int i;\n-        size_t maxelelen = 0;\n+        size_t maxelelen = 0, totelelen = 0;\n \n         if (returned_items) {\n             zobj = createZsetObject();\n@@ -650,13 +650,14 @@ void georadiusGeneric(client *c, int flags) {\n             size_t elelen = sdslen(gp->member);\n \n             if (maxelelen < elelen) maxelelen = elelen;\n+            totelelen += elelen;\n             znode = zslInsert(zs->zsl,score,gp->member);\n             serverAssert(dictAdd(zs->dict,gp->member,&znode->score) == DICT_OK);\n             gp->member = NULL;\n         }\n \n         if (returned_items) {\n-            zsetConvertToZiplistIfNeeded(zobj,maxelelen);\n+            zsetConvertToZiplistIfNeeded(zobj,maxelelen,totelelen);\n             setKey(c,c->db,storekey,zobj);\n             decrRefCount(zobj);\n             notifyKeyspaceEvent(NOTIFY_ZSET,\"georadiusstore\",storekey,"
        },
        {
          "filename": "src/listpack.c",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -283,7 +283,7 @@ int lpEncodeGetType(unsigned char *ele, uint32_t size, unsigned char *intenc, ui\n     } else {\n         if (size < 64) *enclen = 1+size;\n         else if (size < 4096) *enclen = 2+size;\n-        else *enclen = 5+size;\n+        else *enclen = 5+(uint64_t)size;\n         return LP_ENCODING_STRING;\n     }\n }"
        },
        {
          "filename": "src/quicklist.c",
          "status": "modified",
          "additions": 15,
          "deletions": 2,
          "patch": "@@ -29,6 +29,7 @@\n  */\n \n #include <string.h> /* for memcpy */\n+#include \"redisassert.h\"\n #include \"quicklist.h\"\n #include \"zmalloc.h\"\n #include \"ziplist.h\"\n@@ -43,11 +44,16 @@\n #define REDIS_STATIC static\n #endif\n \n-/* Optimization levels for size-based filling */\n+/* Optimization levels for size-based filling.\n+ * Note that the largest possible limit is 16k, so even if each record takes\n+ * just one byte, it still won't overflow the 16 bit count field. */\n static const size_t optimization_level[] = {4096, 8192, 16384, 32768, 65536};\n \n /* Maximum size in bytes of any multi-element ziplist.\n- * Larger values will live in their own isolated ziplists. */\n+ * Larger values will live in their own isolated ziplists.\n+ * This is used only if we're limited by record count. when we're limited by\n+ * size, the maximum limit is bigger, but still safe.\n+ * 8k is a recommended / default size limit */\n #define SIZE_SAFETY_LIMIT 8192\n \n /* Minimum ziplist size in bytes for attempting compression. */\n@@ -449,6 +455,8 @@ REDIS_STATIC int _quicklistNodeAllowInsert(const quicklistNode *node,\n     unsigned int new_sz = node->sz + sz + ziplist_overhead;\n     if (likely(_quicklistNodeSizeMeetsOptimizationRequirement(new_sz, fill)))\n         return 1;\n+    /* when we return 1 above we know that the limit is a size limit (which is\n+     * safe, see comments next to optimization_level and SIZE_SAFETY_LIMIT) */\n     else if (!sizeMeetsSafetyLimit(new_sz))\n         return 0;\n     else if ((int)node->count < fill)\n@@ -468,6 +476,8 @@ REDIS_STATIC int _quicklistNodeAllowMerge(const quicklistNode *a,\n     unsigned int merge_sz = a->sz + b->sz - 11;\n     if (likely(_quicklistNodeSizeMeetsOptimizationRequirement(merge_sz, fill)))\n         return 1;\n+    /* when we return 1 above we know that the limit is a size limit (which is\n+     * safe, see comments next to optimization_level and SIZE_SAFETY_LIMIT) */\n     else if (!sizeMeetsSafetyLimit(merge_sz))\n         return 0;\n     else if ((int)(a->count + b->count) <= fill)\n@@ -487,6 +497,7 @@ REDIS_STATIC int _quicklistNodeAllowMerge(const quicklistNode *a,\n  * Returns 1 if new head created. */\n int quicklistPushHead(quicklist *quicklist, void *value, size_t sz) {\n     quicklistNode *orig_head = quicklist->head;\n+    assert(sz < UINT32_MAX); /* TODO: add support for quicklist nodes that are sds encoded (not zipped) */\n     if (likely(\n             _quicklistNodeAllowInsert(quicklist->head, quicklist->fill, sz))) {\n         quicklist->head->zl =\n@@ -510,6 +521,7 @@ int quicklistPushHead(quicklist *quicklist, void *value, size_t sz) {\n  * Returns 1 if new tail created. */\n int quicklistPushTail(quicklist *quicklist, void *value, size_t sz) {\n     quicklistNode *orig_tail = quicklist->tail;\n+    assert(sz < UINT32_MAX); /* TODO: add support for quicklist nodes that are sds encoded (not zipped) */\n     if (likely(\n             _quicklistNodeAllowInsert(quicklist->tail, quicklist->fill, sz))) {\n         quicklist->tail->zl =\n@@ -852,6 +864,7 @@ REDIS_STATIC void _quicklistInsert(quicklist *quicklist, quicklistEntry *entry,\n     int fill = quicklist->fill;\n     quicklistNode *node = entry->node;\n     quicklistNode *new_node = NULL;\n+    assert(sz < UINT32_MAX); /* TODO: add support for quicklist nodes that are sds encoded (not zipped) */\n \n     if (!node) {\n         /* we have no reference node, so let's create only node in the list */"
        },
        {
          "filename": "src/rdb.c",
          "status": "modified",
          "additions": 24,
          "deletions": 12,
          "patch": "@@ -1561,7 +1561,7 @@ robj *rdbLoadObject(int rdbtype, rio *rdb, sds key) {\n     } else if (rdbtype == RDB_TYPE_ZSET_2 || rdbtype == RDB_TYPE_ZSET) {\n         /* Read list/set value. */\n         uint64_t zsetlen;\n-        size_t maxelelen = 0;\n+        size_t maxelelen = 0, totelelen = 0;\n         zset *zs;\n \n         if ((zsetlen = rdbLoadLen(rdb,NULL)) == RDB_LENERR) return NULL;\n@@ -1598,15 +1598,19 @@ robj *rdbLoadObject(int rdbtype, rio *rdb, sds key) {\n \n             /* Don't care about integer-encoded strings. */\n             if (sdslen(sdsele) > maxelelen) maxelelen = sdslen(sdsele);\n+            totelelen += sdslen(sdsele);\n \n             znode = zslInsert(zs->zsl,score,sdsele);\n             dictAdd(zs->dict,sdsele,&znode->score);\n         }\n \n         /* Convert *after* loading, since sorted sets are not stored ordered. */\n         if (zsetLength(o) <= server.zset_max_ziplist_entries &&\n-            maxelelen <= server.zset_max_ziplist_value)\n-                zsetConvert(o,OBJ_ENCODING_ZIPLIST);\n+            maxelelen <= server.zset_max_ziplist_value &&\n+            ziplistSafeToAdd(NULL, totelelen))\n+        {\n+            zsetConvert(o,OBJ_ENCODING_ZIPLIST);\n+        }\n     } else if (rdbtype == RDB_TYPE_HASH) {\n         uint64_t len;\n         int ret;\n@@ -1635,21 +1639,25 @@ robj *rdbLoadObject(int rdbtype, rio *rdb, sds key) {\n                 return NULL;\n             }\n \n-            /* Add pair to ziplist */\n-            o->ptr = ziplistPush(o->ptr, (unsigned char*)field,\n-                    sdslen(field), ZIPLIST_TAIL);\n-            o->ptr = ziplistPush(o->ptr, (unsigned char*)value,\n-                    sdslen(value), ZIPLIST_TAIL);\n-\n             /* Convert to hash table if size threshold is exceeded */\n             if (sdslen(field) > server.hash_max_ziplist_value ||\n-                sdslen(value) > server.hash_max_ziplist_value)\n+                sdslen(value) > server.hash_max_ziplist_value ||\n+                !ziplistSafeToAdd(o->ptr, sdslen(field)+sdslen(value)))\n             {\n-                sdsfree(field);\n-                sdsfree(value);\n                 hashTypeConvert(o, OBJ_ENCODING_HT);\n+                ret = dictAdd((dict*)o->ptr, field, value);\n+                if (ret == DICT_ERR) {\n+                    rdbExitReportCorruptRDB(\"Duplicate hash fields detected\");\n+                }\n                 break;\n             }\n+\n+            /* Add pair to ziplist */\n+            o->ptr = ziplistPush(o->ptr, (unsigned char*)field,\n+                    sdslen(field), ZIPLIST_TAIL);\n+            o->ptr = ziplistPush(o->ptr, (unsigned char*)value,\n+                    sdslen(value), ZIPLIST_TAIL);\n+\n             sdsfree(field);\n             sdsfree(value);\n         }\n@@ -1726,6 +1734,10 @@ robj *rdbLoadObject(int rdbtype, rio *rdb, sds key) {\n                     while ((zi = zipmapNext(zi, &fstr, &flen, &vstr, &vlen)) != NULL) {\n                         if (flen > maxlen) maxlen = flen;\n                         if (vlen > maxlen) maxlen = vlen;\n+                        if (!ziplistSafeToAdd(zl, (size_t)flen + vlen)) {\n+                            rdbExitReportCorruptRDB(\"Hash zipmap too big (%u)\", flen);\n+                        }\n+\n                         zl = ziplistPush(zl, fstr, flen, ZIPLIST_TAIL);\n                         zl = ziplistPush(zl, vstr, vlen, ZIPLIST_TAIL);\n                     }"
        },
        {
          "filename": "src/server.h",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -1999,7 +1999,7 @@ unsigned char *zzlFirstInRange(unsigned char *zl, zrangespec *range);\n unsigned char *zzlLastInRange(unsigned char *zl, zrangespec *range);\n unsigned long zsetLength(const robj *zobj);\n void zsetConvert(robj *zobj, int encoding);\n-void zsetConvertToZiplistIfNeeded(robj *zobj, size_t maxelelen);\n+void zsetConvertToZiplistIfNeeded(robj *zobj, size_t maxelelen, size_t totelelen);\n int zsetScore(robj *zobj, sds member, double *score);\n unsigned long zslGetRank(zskiplist *zsl, double score, sds o);\n int zsetAdd(robj *zobj, double score, sds ele, int *flags, double *newscore);"
        },
        {
          "filename": "src/t_hash.c",
          "status": "modified",
          "additions": 9,
          "deletions": 4,
          "patch": "@@ -39,17 +39,22 @@\n  * as their string length can be queried in constant time. */\n void hashTypeTryConversion(robj *o, robj **argv, int start, int end) {\n     int i;\n+    size_t sum = 0;\n \n     if (o->encoding != OBJ_ENCODING_ZIPLIST) return;\n \n     for (i = start; i <= end; i++) {\n-        if (sdsEncodedObject(argv[i]) &&\n-            sdslen(argv[i]->ptr) > server.hash_max_ziplist_value)\n-        {\n+        if (!sdsEncodedObject(argv[i]))\n+            continue;\n+        size_t len = sdslen(argv[i]->ptr);\n+        if (len > server.hash_max_ziplist_value) {\n             hashTypeConvert(o, OBJ_ENCODING_HT);\n-            break;\n+            return;\n         }\n+        sum += len;\n     }\n+    if (!ziplistSafeToAdd(o->ptr, sum))\n+        hashTypeConvert(o, OBJ_ENCODING_HT);\n }\n \n /* Get the value from a ziplist encoded hash, identified by field."
        },
        {
          "filename": "src/t_list.c",
          "status": "modified",
          "additions": 30,
          "deletions": 0,
          "patch": "@@ -29,6 +29,8 @@\n \n #include \"server.h\"\n \n+#define LIST_MAX_ITEM_SIZE ((1ull<<32)-1024)\n+\n /*-----------------------------------------------------------------------------\n  * List API\n  *----------------------------------------------------------------------------*/\n@@ -196,6 +198,14 @@ void listTypeConvert(robj *subject, int enc) {\n \n void pushGenericCommand(client *c, int where) {\n     int j, pushed = 0;\n+\n+    for (j = 2; j < c->argc; j++) {\n+        if (sdslen(c->argv[j]->ptr) > LIST_MAX_ITEM_SIZE) {\n+            addReplyError(c, \"Element too large\");\n+            return;\n+        }\n+    }\n+\n     robj *lobj = lookupKeyWrite(c->db,c->argv[1]);\n \n     if (lobj && lobj->type != OBJ_LIST) {\n@@ -277,6 +287,11 @@ void linsertCommand(client *c) {\n         return;\n     }\n \n+    if (sdslen(c->argv[4]->ptr) > LIST_MAX_ITEM_SIZE) {\n+        addReplyError(c, \"Element too large\");\n+        return;\n+    }\n+\n     if ((subject = lookupKeyWriteOrReply(c,c->argv[1],shared.czero)) == NULL ||\n         checkType(c,subject,OBJ_LIST)) return;\n \n@@ -344,6 +359,11 @@ void lsetCommand(client *c) {\n     long index;\n     robj *value = c->argv[3];\n \n+    if (sdslen(value->ptr) > LIST_MAX_ITEM_SIZE) {\n+        addReplyError(c, \"Element too large\");\n+        return;\n+    }\n+\n     if ((getLongFromObjectOrReply(c, c->argv[2], &index, NULL) != C_OK))\n         return;\n \n@@ -510,6 +530,11 @@ void lposCommand(client *c) {\n     int direction = LIST_TAIL;\n     long rank = 1, count = -1, maxlen = 0; /* Count -1: option not given. */\n \n+    if (sdslen(ele->ptr) > LIST_MAX_ITEM_SIZE) {\n+        addReplyError(c, \"Element too large\");\n+        return;\n+    }\n+\n     /* Parse the optional arguments. */\n     for (int j = 3; j < c->argc; j++) {\n         char *opt = c->argv[j]->ptr;\n@@ -610,6 +635,11 @@ void lremCommand(client *c) {\n     long toremove;\n     long removed = 0;\n \n+    if (sdslen(obj->ptr) > LIST_MAX_ITEM_SIZE) {\n+        addReplyError(c, \"Element too large\");\n+        return;\n+    }\n+\n     if ((getLongFromObjectOrReply(c, c->argv[2], &toremove, NULL) != C_OK))\n         return;\n "
        },
        {
          "filename": "src/t_stream.c",
          "status": "modified",
          "additions": 38,
          "deletions": 10,
          "patch": "@@ -40,6 +40,12 @@\n #define STREAM_ITEM_FLAG_DELETED (1<<0)     /* Entry is deleted. Skip it. */\n #define STREAM_ITEM_FLAG_SAMEFIELDS (1<<1)  /* Same fields as master entry. */\n \n+/* Don't let listpacks grow too big, even if the user config allows it.\n+ * doing so can lead to an overflow (trying to store more than 32bit length\n+ * into the listpack header), or actually an assertion since lpInsert\n+ * will return NULL. */\n+#define STREAM_LISTPACK_MAX_SIZE (1<<30)\n+\n void streamFreeCG(streamCG *cg);\n void streamFreeNACK(streamNACK *na);\n size_t streamReplyWithRangeFromConsumerPEL(client *c, stream *s, streamID *start, streamID *end, size_t count, streamConsumer *consumer);\n@@ -191,8 +197,11 @@ int streamCompareID(streamID *a, streamID *b) {\n  *\n  * The function returns C_OK if the item was added, this is always true\n  * if the ID was generated by the function. However the function may return\n- * C_ERR if an ID was given via 'use_id', but adding it failed since the\n- * current top ID is greater or equal. */\n+ * C_ERR in several cases:\n+ * 1. If an ID was given via 'use_id', but adding it failed since the\n+ *    current top ID is greater or equal. errno will be set to EDOM.\n+ * 2. If a size of a single element or the sum of the elements is too big to\n+ *    be stored into the stream. errno will be set to ERANGE. */\n int streamAppendItem(stream *s, robj **argv, int64_t numfields, streamID *added_id, streamID *use_id) {\n     \n     /* Generate the new entry ID. */\n@@ -206,7 +215,23 @@ int streamAppendItem(stream *s, robj **argv, int64_t numfields, streamID *added_\n      * or return an error. Automatically generated IDs might\n      * overflow (and wrap-around) when incrementing the sequence \n        part. */\n-    if (streamCompareID(&id,&s->last_id) <= 0) return C_ERR;\n+    if (streamCompareID(&id,&s->last_id) <= 0) {\n+        errno = EDOM;\n+        return C_ERR;\n+    }\n+\n+    /* Avoid overflow when trying to add an element to the stream (listpack\n+     * can only host up to 32bit length sttrings, and also a total listpack size\n+     * can't be bigger than 32bit length. */\n+    size_t totelelen = 0;\n+    for (int64_t i = 0; i < numfields*2; i++) {\n+        sds ele = argv[i]->ptr;\n+        totelelen += sdslen(ele);\n+    }\n+    if (totelelen > STREAM_LISTPACK_MAX_SIZE) {\n+        errno = ERANGE;\n+        return C_ERR;\n+    }\n \n     /* Add the new entry. */\n     raxIterator ri;\n@@ -265,9 +290,10 @@ int streamAppendItem(stream *s, robj **argv, int64_t numfields, streamID *added_\n      * if we need to switch to the next one. 'lp' will be set to NULL if\n      * the current node is full. */\n     if (lp != NULL) {\n-        if (server.stream_node_max_bytes &&\n-            lp_bytes >= server.stream_node_max_bytes)\n-        {\n+        size_t node_max_bytes = server.stream_node_max_bytes;\n+        if (node_max_bytes == 0 || node_max_bytes > STREAM_LISTPACK_MAX_SIZE)\n+            node_max_bytes = STREAM_LISTPACK_MAX_SIZE;\n+        if (lp_bytes + totelelen >= node_max_bytes) {\n             lp = NULL;\n         } else if (server.stream_node_max_entries) {\n             int64_t count = lpGetInteger(lpFirst(lp));\n@@ -1267,11 +1293,13 @@ void xaddCommand(client *c) {\n \n     /* Append using the low level function and return the ID. */\n     if (streamAppendItem(s,c->argv+field_pos,(c->argc-field_pos)/2,\n-        &id, id_given ? &id : NULL)\n-        == C_ERR)\n+        &id, id_given ? &id : NULL) == C_ERR)\n     {\n-        addReplyError(c,\"The ID specified in XADD is equal or smaller than the \"\n-                        \"target stream top item\");\n+        if (errno == EDOM)\n+            addReplyError(c,\"The ID specified in XADD is equal or smaller than \"\n+                            \"the target stream top item\");\n+        else\n+            addReplyError(c,\"Elements are too large to be stored\");\n         return;\n     }\n     addReplyStreamID(c,&id);"
        },
        {
          "filename": "src/t_zset.c",
          "status": "modified",
          "additions": 28,
          "deletions": 15,
          "patch": "@@ -1238,15 +1238,18 @@ void zsetConvert(robj *zobj, int encoding) {\n }\n \n /* Convert the sorted set object into a ziplist if it is not already a ziplist\n- * and if the number of elements and the maximum element size is within the\n- * expected ranges. */\n-void zsetConvertToZiplistIfNeeded(robj *zobj, size_t maxelelen) {\n+ * and if the number of elements and the maximum element size and total elements size\n+ * are within the expected ranges. */\n+void zsetConvertToZiplistIfNeeded(robj *zobj, size_t maxelelen, size_t totelelen) {\n     if (zobj->encoding == OBJ_ENCODING_ZIPLIST) return;\n     zset *zset = zobj->ptr;\n \n     if (zset->zsl->length <= server.zset_max_ziplist_entries &&\n-        maxelelen <= server.zset_max_ziplist_value)\n-            zsetConvert(zobj,OBJ_ENCODING_ZIPLIST);\n+        maxelelen <= server.zset_max_ziplist_value &&\n+        ziplistSafeToAdd(NULL, totelelen))\n+    {\n+        zsetConvert(zobj,OBJ_ENCODING_ZIPLIST);\n+    }\n }\n \n /* Return (by reference) the score of the specified member of the sorted set\n@@ -1355,20 +1358,28 @@ int zsetAdd(robj *zobj, double score, sds ele, int *flags, double *newscore) {\n             }\n             return 1;\n         } else if (!xx) {\n-            /* Optimize: check if the element is too large or the list\n+            /* check if the element is too large or the list\n              * becomes too long *before* executing zzlInsert. */\n-            zobj->ptr = zzlInsert(zobj->ptr,ele,score);\n-            if (zzlLength(zobj->ptr) > server.zset_max_ziplist_entries ||\n-                sdslen(ele) > server.zset_max_ziplist_value)\n+            if (zzlLength(zobj->ptr)+1 > server.zset_max_ziplist_entries ||\n+                sdslen(ele) > server.zset_max_ziplist_value ||\n+                !ziplistSafeToAdd(zobj->ptr, sdslen(ele)))\n+            {\n                 zsetConvert(zobj,OBJ_ENCODING_SKIPLIST);\n-            if (newscore) *newscore = score;\n-            *flags |= ZADD_ADDED;\n-            return 1;\n+            } else {\n+                zobj->ptr = zzlInsert(zobj->ptr,ele,score);\n+                if (newscore) *newscore = score;\n+                *flags |= ZADD_ADDED;\n+                return 1;\n+            }\n         } else {\n             *flags |= ZADD_NOP;\n             return 1;\n         }\n-    } else if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n+    }\n+\n+    /* Note that the above block handling ziplist would have either returned or\n+     * converted the key to skiplist. */\n+    if (zobj->encoding == OBJ_ENCODING_SKIPLIST) {\n         zset *zs = zobj->ptr;\n         zskiplistNode *znode;\n         dictEntry *de;\n@@ -2180,7 +2191,7 @@ void zunionInterGenericCommand(client *c, robj *dstkey, int op) {\n     zsetopsrc *src;\n     zsetopval zval;\n     sds tmp;\n-    size_t maxelelen = 0;\n+    size_t maxelelen = 0, totelelen = 0;\n     robj *dstobj;\n     zset *dstzset;\n     zskiplistNode *znode;\n@@ -2304,6 +2315,7 @@ void zunionInterGenericCommand(client *c, robj *dstkey, int op) {\n                     tmp = zuiNewSdsFromValue(&zval);\n                     znode = zslInsert(dstzset->zsl,score,tmp);\n                     dictAdd(dstzset->dict,tmp,&znode->score);\n+                    totelelen += sdslen(tmp);\n                     if (sdslen(tmp) > maxelelen) maxelelen = sdslen(tmp);\n                 }\n             }\n@@ -2340,6 +2352,7 @@ void zunionInterGenericCommand(client *c, robj *dstkey, int op) {\n                     /* Remember the longest single element encountered,\n                      * to understand if it's possible to convert to ziplist\n                      * at the end. */\n+                     totelelen += sdslen(tmp);\n                      if (sdslen(tmp) > maxelelen) maxelelen = sdslen(tmp);\n                     /* Update the element with its initial score. */\n                     dictSetKey(accumulator, de, tmp);\n@@ -2380,7 +2393,7 @@ void zunionInterGenericCommand(client *c, robj *dstkey, int op) {\n     if (dbDelete(c->db,dstkey))\n         touched = 1;\n     if (dstzset->zsl->length) {\n-        zsetConvertToZiplistIfNeeded(dstobj,maxelelen);\n+        zsetConvertToZiplistIfNeeded(dstobj,maxelelen,totelelen);\n         dbAdd(c->db,dstkey,dstobj);\n         addReplyLongLong(c,zsetLength(dstobj));\n         signalModifiedKey(c,c->db,dstkey);"
        },
        {
          "filename": "src/ziplist.c",
          "status": "modified",
          "additions": 16,
          "deletions": 1,
          "patch": "@@ -265,6 +265,17 @@\n         ZIPLIST_LENGTH(zl) = intrev16ifbe(intrev16ifbe(ZIPLIST_LENGTH(zl))+incr); \\\n }\n \n+/* Don't let ziplists grow over 1GB in any case, don't wanna risk overflow in\n+ * zlbytes*/\n+#define ZIPLIST_MAX_SAFETY_SIZE (1<<30)\n+int ziplistSafeToAdd(unsigned char* zl, size_t add) {\n+    size_t len = zl? ziplistBlobLen(zl): 0;\n+    if (len + add > ZIPLIST_MAX_SAFETY_SIZE)\n+        return 0;\n+    return 1;\n+}\n+\n+\n /* We use this function to receive information about a ziplist entry.\n  * Note that this is not how the data is actually encoded, is just what we\n  * get filled by a function in order to operate more easily. */\n@@ -586,7 +597,8 @@ unsigned char *ziplistNew(void) {\n }\n \n /* Resize the ziplist. */\n-unsigned char *ziplistResize(unsigned char *zl, unsigned int len) {\n+unsigned char *ziplistResize(unsigned char *zl, size_t len) {\n+    assert(len < UINT32_MAX);\n     zl = zrealloc(zl,len);\n     ZIPLIST_BYTES(zl) = intrev32ifbe(len);\n     zl[len-1] = ZIP_END;\n@@ -898,6 +910,9 @@ unsigned char *ziplistMerge(unsigned char **first, unsigned char **second) {\n     /* Combined zl length should be limited within UINT16_MAX */\n     zllength = zllength < UINT16_MAX ? zllength : UINT16_MAX;\n \n+    /* larger values can't be stored into ZIPLIST_BYTES */\n+    assert(zlbytes < UINT32_MAX);\n+\n     /* Save offset positions before we start ripping memory apart. */\n     size_t first_offset = intrev32ifbe(ZIPLIST_TAIL_OFFSET(*first));\n     size_t second_offset = intrev32ifbe(ZIPLIST_TAIL_OFFSET(*second));"
        },
        {
          "filename": "src/ziplist.h",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -49,6 +49,7 @@ unsigned char *ziplistFind(unsigned char *p, unsigned char *vstr, unsigned int v\n unsigned int ziplistLen(unsigned char *zl);\n size_t ziplistBlobLen(unsigned char *zl);\n void ziplistRepr(unsigned char *zl);\n+int ziplistSafeToAdd(unsigned char* zl, size_t add);\n \n #ifdef REDIS_TEST\n int ziplistTest(int argc, char *argv[]);"
        },
        {
          "filename": "tests/support/util.tcl",
          "status": "modified",
          "additions": 17,
          "deletions": 1,
          "patch": "@@ -109,7 +109,23 @@ proc wait_done_loading r {\n \n # count current log lines in server's stdout\n proc count_log_lines {srv_idx} {\n-    set _ [exec wc -l < [srv $srv_idx stdout]]\n+    set _ [string trim [exec wc -l < [srv $srv_idx stdout]]]\n+}\n+\n+# returns the number of times a line with that pattern appears in a file\n+proc count_message_lines {file pattern} {\n+    set res 0\n+    # exec fails when grep exists with status other than 0 (when the patter wasn't found)\n+    catch {\n+        set res [string trim [exec grep $pattern $file 2> /dev/null | wc -l]]\n+    }\n+    return $res\n+}\n+\n+# returns the number of times a line with that pattern appears in the log\n+proc count_log_message {srv_idx pattern} {\n+    set stdout [srv $srv_idx stdout]\n+    return [count_message_lines $stdout $pattern]\n }\n \n # verify pattern exists in server's sdtout after a certain line number"
        },
        {
          "filename": "tests/unit/violations.tcl",
          "status": "added",
          "additions": 156,
          "deletions": 0,
          "patch": "@@ -0,0 +1,156 @@\n+# These tests consume massive amounts of memory, and are not\n+# suitable to be executed as part of the normal test suite\n+set ::str500 [string repeat x 500000000] ;# 500mb\n+\n+# Utility function to write big argument into redis client connection\n+proc write_big_bulk {size} {\n+    r write \"\\$$size\\r\\n\"\n+    while {$size >= 500000000} {\n+        r write $::str500\n+        incr size -500000000\n+    }\n+    if {$size > 0} {\n+        r write [string repeat x $size]\n+    }\n+    r write \"\\r\\n\"\n+}\n+\n+# One XADD with one huge 5GB field\n+# Expected to fail resulting in an empty stream\n+start_server [list overrides [list save \"\"] ] {\n+    test {XADD one huge field} {\n+        r config set proto-max-bulk-len 10000000000 ;#10gb\n+        r config set client-query-buffer-limit 10000000000 ;#10gb\n+        r write \"*5\\r\\n\\$4\\r\\nXADD\\r\\n\\$2\\r\\nS1\\r\\n\\$1\\r\\n*\\r\\n\"\n+        r write \"\\$1\\r\\nA\\r\\n\"\n+        write_big_bulk 5000000000 ;#5gb\n+        r flush\n+        catch {r read} err\n+        assert_match {*too large*} $err\n+        r xlen S1\n+    } {0}\n+}\n+\n+# One XADD with one huge (exactly nearly) 4GB field\n+# This uncovers the overflow in lpEncodeGetType\n+# Expected to fail resulting in an empty stream\n+start_server [list overrides [list save \"\"] ] {\n+    test {XADD one huge field - 1} {\n+        r config set proto-max-bulk-len 10000000000 ;#10gb\n+        r config set client-query-buffer-limit 10000000000 ;#10gb\n+        r write \"*5\\r\\n\\$4\\r\\nXADD\\r\\n\\$2\\r\\nS1\\r\\n\\$1\\r\\n*\\r\\n\"\n+        r write \"\\$1\\r\\nA\\r\\n\"\n+        write_big_bulk 4294967295 ;#4gb-1\n+        r flush\n+        catch {r read} err\n+        assert_match {*too large*} $err\n+        r xlen S1\n+    } {0}\n+}\n+\n+# Gradually add big stream fields using repeated XADD calls\n+start_server [list overrides [list save \"\"] ] {\n+    test {several XADD big fields} {\n+        r config set stream-node-max-bytes 0\n+        for {set j 0} {$j<10} {incr j} {\n+            r xadd stream * 1 $::str500 2 $::str500\n+        }\n+        r ping\n+        r xlen stream\n+    } {10}\n+}\n+\n+# Add over 4GB to a single stream listpack (one XADD command)\n+# Expected to fail resulting in an empty stream\n+start_server [list overrides [list save \"\"] ] {\n+    test {single XADD big fields} {\n+        r write \"*23\\r\\n\\$4\\r\\nXADD\\r\\n\\$1\\r\\nS\\r\\n\\$1\\r\\n*\\r\\n\"\n+        for {set j 0} {$j<10} {incr j} {\n+            r write \"\\$1\\r\\n$j\\r\\n\"\n+            write_big_bulk 500000000 ;#500mb\n+        }\n+        r flush\n+        catch {r read} err\n+        assert_match {*too large*} $err\n+        r xlen S\n+    } {0}\n+}\n+\n+# Gradually add big hash fields using repeated HSET calls\n+# This reproduces the overflow in the call to ziplistResize\n+# Object will be converted to hashtable encoding\n+start_server [list overrides [list save \"\"] ] {\n+    r config set hash-max-ziplist-value 1000000000 ;#1gb\n+    test {hash with many big fields} {\n+        for {set j 0} {$j<10} {incr j} {\n+            r hset h $j $::str500\n+        }\n+        r object encoding h\n+    } {hashtable}\n+}\n+\n+# Add over 4GB to a single hash field (one HSET command)\n+# Object will be converted to hashtable encoding\n+start_server [list overrides [list save \"\"] ] {\n+    test {hash with one huge field} {\n+        catch {r config set hash-max-ziplist-value 10000000000} ;#10gb\n+        r config set proto-max-bulk-len 10000000000 ;#10gb\n+        r config set client-query-buffer-limit 10000000000 ;#10gb\n+        r write \"*4\\r\\n\\$4\\r\\nHSET\\r\\n\\$2\\r\\nH1\\r\\n\"\n+        r write \"\\$1\\r\\nA\\r\\n\"\n+        write_big_bulk 5000000000 ;#5gb\n+        r flush\n+        r read\n+        r object encoding H1\n+    } {hashtable}\n+}\n+\n+# Add over 4GB to a single list member (one LPUSH command)\n+# Currently unsupported, and expected to fail rather than being truncated\n+# Expected to fail resulting in a non-existing list\n+start_server [list overrides [list save \"\"] ] {\n+    test {list with one huge field} {\n+        r config set proto-max-bulk-len 10000000000 ;#10gb\n+        r config set client-query-buffer-limit 10000000000 ;#10gb\n+        r write \"*3\\r\\n\\$5\\r\\nLPUSH\\r\\n\\$2\\r\\nL1\\r\\n\"\n+        write_big_bulk 5000000000 ;#5gb\n+        r flush\n+        catch {r read} err\n+        assert_match {*too large*} $err\n+        r exists L1\n+    } {0}\n+}\n+\n+# SORT which attempts to store an element larger than 4GB into a list.\n+# Currently unsupported and results in an assertion instead of truncation\n+start_server [list overrides [list save \"\"] ] {\n+    test {SORT adds huge field to list} {\n+        r config set proto-max-bulk-len 10000000000 ;#10gb\n+        r config set client-query-buffer-limit 10000000000 ;#10gb\n+        r write \"*3\\r\\n\\$3\\r\\nSET\\r\\n\\$2\\r\\nS1\\r\\n\"\n+        write_big_bulk 5000000000 ;#5gb\n+        r flush\n+        r read\n+        assert_equal [r strlen S1] 5000000000\n+        r set S2 asdf\n+        r sadd myset 1 2\n+        r mset D1 1 D2 2\n+        catch {r sort myset by D* get S* store mylist}\n+        # assert_equal [count_log_message 0 \"crashed by signal\"] 0   - not suitable for 6.0\n+        assert_equal [count_log_message 0 \"ASSERTION FAILED\"] 1\n+    }\n+}\n+\n+# SORT which stores an integer encoded element into a list.\n+# Just for coverage, no news here.\n+start_server [list overrides [list save \"\"] ] {\n+    test {SORT adds integer field to list} {\n+        r set S1 asdf\n+        r set S2 123 ;# integer encoded\n+        assert_encoding \"int\" S2\n+        r sadd myset 1 2\n+        r mset D1 1 D2 2\n+        r sort myset by D* get S* store mylist\n+        r llen mylist\n+    } {2}\n+}"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 2,
        "unique_directories": 3,
        "max_directory_depth": 2
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "0f65806b5b0f21b96e9c688ce7d2d00062203a51",
            "date": "2025-01-14T09:30:18Z",
            "author_login": "sundb"
          },
          {
            "sha": "5b8b58e472fc567337429f63e93927f86db7f838",
            "date": "2025-01-14T07:51:05Z",
            "author_login": "ShooterIT"
          },
          {
            "sha": "342ee426ad0d0731b2272553bd4db2cd78e24772",
            "date": "2024-12-15T19:41:45Z",
            "author_login": "YaacovHazan"
          },
          {
            "sha": "4a95b3005a140165bbb9df373ba61f775c936554",
            "date": "2024-12-15T09:27:48Z",
            "author_login": "YaacovHazan"
          },
          {
            "sha": "73a9b916c9f42f2e07b9338a975f9a473ad0cd9b",
            "date": "2025-01-13T12:09:52Z",
            "author_login": "tezc"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.5,
    "cvss_vector": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:H/I:H/A:H",
    "cwe_id": "CWE-190",
    "description": "Redis is an open source, in-memory database that persists on disk. An integer overflow bug in the ziplist data structure used by all versions of Redis can be exploited to corrupt the heap and potentially result with remote code execution. The vulnerability involves modifying the default ziplist configuration parameters (hash-max-ziplist-entries, hash-max-ziplist-value, zset-max-ziplist-entries or zset-max-ziplist-value) to a very large value, and then constructing specially crafted commands to create very large ziplists. The problem is fixed in Redis versions 6.2.6, 6.0.16, 5.0.14. An additional workaround to mitigate the problem without patching the redis-server executable is to prevent users from modifying the above configuration parameters. This can be done using ACL to restrict unprivileged users from using the CONFIG SET command.",
    "attack_vector": "NETWORK",
    "attack_complexity": "HIGH"
  },
  "temporal_data": {
    "published_date": "2021-10-04T18:15:08.577",
    "last_modified": "2024-11-21T06:07:24.730",
    "fix_date": "2021-06-03T09:10:02Z"
  },
  "references": [
    {
      "url": "https://github.com/redis/redis/commit/f6a40570fa63d5afdd596c78083d754081d80ae3",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/redis/redis/security/advisories/GHSA-vw22-qm3h-49pr",
      "source": "security-advisories@github.com",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/HTYQ5ZF37HNGTZWVNJD3VXP7I6MEEF42/",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/VL5KXFN3ATM7IIM7Q4O4PWTSRGZ5744Z/",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/WR5WKJWXD4D6S3DJCZ56V74ESLTDQRAB/",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://security.gentoo.org/glsa/202209-17",
      "source": "security-advisories@github.com",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://security.netapp.com/advisory/ntap-20211104-0003/",
      "source": "security-advisories@github.com",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://www.debian.org/security/2021/dsa-5001",
      "source": "security-advisories@github.com",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://www.oracle.com/security-alerts/cpuapr2022.html",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/redis/redis/commit/f6a40570fa63d5afdd596c78083d754081d80ae3",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/redis/redis/security/advisories/GHSA-vw22-qm3h-49pr",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/HTYQ5ZF37HNGTZWVNJD3VXP7I6MEEF42/",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/VL5KXFN3ATM7IIM7Q4O4PWTSRGZ5744Z/",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/WR5WKJWXD4D6S3DJCZ56V74ESLTDQRAB/",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://security.gentoo.org/glsa/202209-17",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://security.netapp.com/advisory/ntap-20211104-0003/",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://www.debian.org/security/2021/dsa-5001",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://www.oracle.com/security-alerts/cpuapr2022.html",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:02:07.807318",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "redis",
    "owner": "redis",
    "created_at": "2009-03-21T22:32:25Z",
    "updated_at": "2025-01-14T13:39:40Z",
    "pushed_at": "2025-01-14T13:24:52Z",
    "size": 142912,
    "stars": 67707,
    "forks": 23864,
    "open_issues": 2530,
    "watchers": 67707,
    "has_security_policy": false,
    "default_branch": "unstable",
    "protected_branches": [
      "2.2",
      "2.4",
      "2.6",
      "2.8",
      "3.0",
      "3.2",
      "4.0",
      "5.0",
      "6.0",
      "6.2",
      "7.0",
      "7.2",
      "7.4",
      "8.0",
      "LiorKogan-patch-1",
      "LiorKogan-patch-2",
      "acl-api-pr",
      "acl-log",
      "antiaffinity",
      "aofrdb",
      "argv-accounting",
      "arm",
      "client-unblock",
      "conduct",
      "cow-pipe",
      "csc2",
      "current-client-fix",
      "dict-clustered-entries",
      "dict-split-by-slot"
    ],
    "languages": {
      "C": 6937367,
      "Tcl": 2354158,
      "Python": 40222,
      "Makefile": 26062,
      "Shell": 23597,
      "Ruby": 23260,
      "C++": 5987,
      "Smarty": 1047,
      "JavaScript": 953
    },
    "commit_activity": {
      "total_commits_last_year": 425,
      "avg_commits_per_week": 8.173076923076923,
      "days_active_last_year": 171
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "other"
    },
    "collected_at": "2025-01-14T14:05:59.165273"
  }
}