{
  "cve_id": "CVE-2022-29225",
  "github_data": {
    "repository": "envoyproxy/envoy",
    "fix_commit": "cb4ef0b09200c720dfdb07e097092dd105450343",
    "related_commits": [
      "cb4ef0b09200c720dfdb07e097092dd105450343",
      "cb4ef0b09200c720dfdb07e097092dd105450343"
    ],
    "patch_url": null,
    "fix_commit_details": {
      "sha": "cb4ef0b09200c720dfdb07e097092dd105450343",
      "commit_date": "2022-06-08T23:08:55Z",
      "author": {
        "login": "pradeepcrao",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "decompressors: stop decompressing upon excessive compression ratio (#733)",
        "length": 268,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 164,
        "additions": 155,
        "deletions": 9
      },
      "files": [
        {
          "filename": "docs/root/version_history/current.rst",
          "status": "modified",
          "additions": 0,
          "deletions": 1,
          "patch": "@@ -13,7 +13,6 @@ Bug Fixes\n ---------\n *Changes expected to improve the state of the world and are unlikely to have negative effects*\n \n-\n Removed Config or Runtime\n -------------------------\n *Normally occurs at the end of the* :ref:`deprecation period <deprecated>`"
        },
        {
          "filename": "source/common/runtime/runtime_features.cc",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -40,6 +40,7 @@ RUNTIME_GUARD(envoy_reloadable_features_correctly_validate_alpn);\n RUNTIME_GUARD(envoy_reloadable_features_deprecate_global_ints);\n RUNTIME_GUARD(envoy_reloadable_features_disable_tls_inspector_injection);\n RUNTIME_GUARD(envoy_reloadable_features_do_not_await_headers_on_upstream_timeout_to_emit_stats);\n+RUNTIME_GUARD(envoy_reloadable_features_enable_compression_bomb_protection);\n RUNTIME_GUARD(envoy_reloadable_features_enable_grpc_async_client_cache);\n RUNTIME_GUARD(envoy_reloadable_features_fix_added_trailers);\n RUNTIME_GUARD(envoy_reloadable_features_handle_stream_reset_during_hcm_encoding);"
        },
        {
          "filename": "source/extensions/compression/brotli/common/base.cc",
          "status": "modified",
          "additions": 4,
          "deletions": 3,
          "patch": "@@ -6,9 +6,10 @@ namespace Compression {\n namespace Brotli {\n namespace Common {\n \n-BrotliContext::BrotliContext(const uint32_t chunk_size)\n-    : chunk_size_{chunk_size}, chunk_ptr_{std::make_unique<uint8_t[]>(chunk_size)}, next_in_{},\n-      next_out_{chunk_ptr_.get()}, avail_in_{0}, avail_out_{chunk_size} {}\n+BrotliContext::BrotliContext(uint32_t chunk_size, uint32_t max_output_size)\n+    : max_output_size_{max_output_size}, chunk_size_{chunk_size},\n+      chunk_ptr_{std::make_unique<uint8_t[]>(chunk_size)}, next_in_{}, next_out_{chunk_ptr_.get()},\n+      avail_in_{0}, avail_out_{chunk_size} {}\n \n void BrotliContext::updateOutput(Buffer::Instance& output_buffer) {\n   if (avail_out_ == 0) {"
        },
        {
          "filename": "source/extensions/compression/brotli/common/base.h",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -12,11 +12,12 @@ namespace Common {\n \n // Keeps a `Brotli` compression stream's state.\n struct BrotliContext {\n-  BrotliContext(const uint32_t chunk_size);\n+  BrotliContext(uint32_t chunk_size, uint32_t max_output_size = 0);\n \n   void updateOutput(Buffer::Instance& output_buffer);\n   void finalizeOutput(Buffer::Instance& output_buffer);\n \n+  const uint32_t max_output_size_;\n   const uint32_t chunk_size_;\n   std::unique_ptr<uint8_t[]> chunk_ptr_;\n   const uint8_t* next_in_;"
        },
        {
          "filename": "source/extensions/compression/brotli/decompressor/BUILD",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -19,6 +19,7 @@ envoy_cc_library(\n         \"//envoy/stats:stats_interface\",\n         \"//envoy/stats:stats_macros\",\n         \"//source/common/buffer:buffer_lib\",\n+        \"//source/common/runtime:runtime_features_lib\",\n         \"//source/extensions/compression/brotli/common:brotli_base_lib\",\n     ],\n )"
        },
        {
          "filename": "source/extensions/compression/brotli/decompressor/brotli_decompressor_impl.cc",
          "status": "modified",
          "additions": 20,
          "deletions": 1,
          "patch": "@@ -2,12 +2,24 @@\n \n #include <memory>\n \n+#include \"source/common/runtime/runtime_features.h\"\n+\n namespace Envoy {\n namespace Extensions {\n namespace Compression {\n namespace Brotli {\n namespace Decompressor {\n \n+namespace {\n+\n+// How many times the output buffer is allowed to be bigger than the input\n+// buffer. This value is used to detect compression bombs.\n+// TODO(rojkov): Re-design the Decompressor interface to handle compression\n+// bombs gracefully instead of this quick solution.\n+constexpr uint32_t MaxInflateRatio = 100;\n+\n+} // namespace\n+\n BrotliDecompressorImpl::BrotliDecompressorImpl(Stats::Scope& scope, const std::string& stats_prefix,\n                                                const uint32_t chunk_size,\n                                                const bool disable_ring_buffer_reallocation)\n@@ -22,7 +34,7 @@ BrotliDecompressorImpl::BrotliDecompressorImpl(Stats::Scope& scope, const std::s\n \n void BrotliDecompressorImpl::decompress(const Buffer::Instance& input_buffer,\n                                         Buffer::Instance& output_buffer) {\n-  Common::BrotliContext ctx(chunk_size_);\n+  Common::BrotliContext ctx(chunk_size_, MaxInflateRatio * input_buffer.length());\n \n   for (const Buffer::RawSlice& input_slice : input_buffer.getRawSlices()) {\n     ctx.avail_in_ = input_slice.len_;\n@@ -58,6 +70,13 @@ bool BrotliDecompressorImpl::process(Common::BrotliContext& ctx, Buffer::Instanc\n     return false;\n   }\n \n+  if (Runtime::runtimeFeatureEnabled(\n+          \"envoy.reloadable_features.enable_compression_bomb_protection\") &&\n+      (output_buffer.length() > ctx.max_output_size_)) {\n+    stats_.brotli_error_.inc();\n+    return false;\n+  }\n+\n   ctx.updateOutput(output_buffer);\n \n   return true;"
        },
        {
          "filename": "source/extensions/compression/gzip/common/base.h",
          "status": "modified",
          "additions": 0,
          "deletions": 1,
          "patch": "@@ -12,7 +12,6 @@ namespace Zlib {\n /**\n  * Shared code between the compressor and the decompressor.\n  */\n-// TODO(junr03): move to extensions tree once the compressor side is moved to extensions.\n class Base {\n public:\n   Base(uint64_t chunk_size, std::function<void(z_stream*)> zstream_deleter);"
        },
        {
          "filename": "source/extensions/compression/gzip/decompressor/BUILD",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -21,6 +21,7 @@ envoy_cc_library(\n         \"//source/common/buffer:buffer_lib\",\n         \"//source/common/common:assert_lib\",\n         \"//source/common/common:minimal_logger_lib\",\n+        \"//source/common/runtime:runtime_features_lib\",\n         \"//source/extensions/compression/gzip/common:zlib_base_lib\",\n     ],\n )"
        },
        {
          "filename": "source/extensions/compression/gzip/decompressor/zlib_decompressor_impl.cc",
          "status": "modified",
          "additions": 24,
          "deletions": 0,
          "patch": "@@ -7,6 +7,7 @@\n #include \"envoy/common/exception.h\"\n \n #include \"source/common/common/assert.h\"\n+#include \"source/common/runtime/runtime_features.h\"\n \n #include \"absl/container/fixed_array.h\"\n \n@@ -16,6 +17,16 @@ namespace Compression {\n namespace Gzip {\n namespace Decompressor {\n \n+namespace {\n+\n+// How many times the output buffer is allowed to be bigger than the size of\n+// accumulated input. This value is used to detect compression bombs.\n+// TODO(rojkov): Re-design the Decompressor interface to handle compression\n+// bombs gracefully instead of this quick solution.\n+constexpr uint64_t MaxInflateRatio = 100;\n+\n+} // namespace\n+\n ZlibDecompressorImpl::ZlibDecompressorImpl(Stats::Scope& scope, const std::string& stats_prefix)\n     : ZlibDecompressorImpl(scope, stats_prefix, 4096) {}\n \n@@ -43,13 +54,26 @@ void ZlibDecompressorImpl::init(int64_t window_bits) {\n \n void ZlibDecompressorImpl::decompress(const Buffer::Instance& input_buffer,\n                                       Buffer::Instance& output_buffer) {\n+  uint64_t limit = MaxInflateRatio * input_buffer.length();\n+\n   for (const Buffer::RawSlice& input_slice : input_buffer.getRawSlices()) {\n     zstream_ptr_->avail_in = input_slice.len_;\n     zstream_ptr_->next_in = static_cast<Bytef*>(input_slice.mem_);\n     while (inflateNext()) {\n       if (zstream_ptr_->avail_out == 0) {\n         updateOutput(output_buffer);\n       }\n+\n+      if (Runtime::runtimeFeatureEnabled(\n+              \"envoy.reloadable_features.enable_compression_bomb_protection\") &&\n+          (output_buffer.length() > limit)) {\n+        stats_.zlib_data_error_.inc();\n+        ENVOY_LOG(trace,\n+                  \"excessive decompression ratio detected: output \"\n+                  \"size {} for input size {}\",\n+                  output_buffer.length(), input_buffer.length());\n+        return;\n+      }\n     }\n   }\n "
        },
        {
          "filename": "source/extensions/compression/zstd/decompressor/zstd_decompressor_impl.cc",
          "status": "modified",
          "additions": 24,
          "deletions": 0,
          "patch": "@@ -1,11 +1,23 @@\n #include \"source/extensions/compression/zstd/decompressor/zstd_decompressor_impl.h\"\n \n+#include \"source/common/runtime/runtime_features.h\"\n+\n namespace Envoy {\n namespace Extensions {\n namespace Compression {\n namespace Zstd {\n namespace Decompressor {\n \n+namespace {\n+\n+// How many times the output buffer is allowed to be bigger than the size of\n+// accumulated input. This value is used to detect compression bombs.\n+// TODO(rojkov): Re-design the Decompressor interface to handle compression\n+// bombs gracefully instead of this quick solution.\n+constexpr uint64_t MaxInflateRatio = 100;\n+\n+} // namespace\n+\n ZstdDecompressorImpl::ZstdDecompressorImpl(Stats::Scope& scope, const std::string& stats_prefix,\n                                            const ZstdDDictManagerPtr& ddict_manager,\n                                            uint32_t chunk_size)\n@@ -14,6 +26,8 @@ ZstdDecompressorImpl::ZstdDecompressorImpl(Stats::Scope& scope, const std::strin\n \n void ZstdDecompressorImpl::decompress(const Buffer::Instance& input_buffer,\n                                       Buffer::Instance& output_buffer) {\n+  uint64_t limit = MaxInflateRatio * input_buffer.length();\n+\n   for (const Buffer::RawSlice& input_slice : input_buffer.getRawSlices()) {\n     if (input_slice.len_ > 0) {\n       if (ddict_manager_ && !is_dictionary_set_) {\n@@ -38,6 +52,16 @@ void ZstdDecompressorImpl::decompress(const Buffer::Instance& input_buffer,\n       if (!process(output_buffer)) {\n         return;\n       }\n+      if (Runtime::runtimeFeatureEnabled(\n+              \"envoy.reloadable_features.enable_compression_bomb_protection\") &&\n+          (output_buffer.length() > limit)) {\n+        stats_.zstd_generic_error_.inc();\n+        ENVOY_LOG(trace,\n+                  \"excessive decompression ratio detected: output \"\n+                  \"size {} for input size {}\",\n+                  output_buffer.length(), input_buffer.length());\n+        return;\n+      }\n     }\n   }\n }"
        },
        {
          "filename": "source/extensions/compression/zstd/decompressor/zstd_decompressor_impl.h",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -4,6 +4,7 @@\n #include \"envoy/stats/scope.h\"\n #include \"envoy/stats/stats_macros.h\"\n \n+#include \"source/common/common/logger.h\"\n #include \"source/extensions/compression/zstd/common/base.h\"\n #include \"source/extensions/compression/zstd/common/dictionary_manager.h\"\n \n@@ -40,6 +41,7 @@ struct ZstdDecompressorStats {\n  */\n class ZstdDecompressorImpl : public Common::Base,\n                              public Envoy::Compression::Decompressor::Decompressor,\n+                             public Logger::Loggable<Logger::Id::decompression>,\n                              NonCopyable {\n public:\n   ZstdDecompressorImpl(Stats::Scope& scope, const std::string& stats_prefix,"
        },
        {
          "filename": "test/extensions/compression/brotli/decompressor/brotli_decompressor_impl_test.cc",
          "status": "modified",
          "additions": 26,
          "deletions": 0,
          "patch": "@@ -25,6 +25,32 @@ class BrotliDecompressorImplTest : public testing::Test {\n   static constexpr uint32_t default_input_size{796};\n };\n \n+// Detect excessive compression ratio by compressing a long whitespace string\n+// into a very small chunk of data and decompressing it again.\n+TEST_F(BrotliDecompressorImplTest, DetectExcessiveCompressionRatio) {\n+  const absl::string_view ten_whitespaces = \"          \";\n+  Brotli::Compressor::BrotliCompressorImpl compressor{\n+      default_quality,\n+      default_window_bits,\n+      default_input_block_bits,\n+      false,\n+      Brotli::Compressor::BrotliCompressorImpl::EncoderMode::Default,\n+      4096};\n+  Buffer::OwnedImpl buffer;\n+\n+  for (int i = 0; i < 1000; i++) {\n+    buffer.add(ten_whitespaces);\n+  }\n+\n+  compressor.compress(buffer, Envoy::Compression::Compressor::State::Finish);\n+\n+  Buffer::OwnedImpl output_buffer;\n+  Stats::IsolatedStoreImpl stats_store{};\n+  BrotliDecompressorImpl decompressor{stats_store, \"test.\", 16, false};\n+  decompressor.decompress(buffer, output_buffer);\n+  EXPECT_EQ(1, stats_store.counterFromString(\"test.brotli_error\").value());\n+}\n+\n // Exercises compression and decompression by compressing some data, decompressing it and then\n // comparing compressor's input/checksum with decompressor's output/checksum.\n TEST_F(BrotliDecompressorImplTest, CompressAndDecompress) {"
        },
        {
          "filename": "test/extensions/compression/gzip/compressor_fuzz_test.cc",
          "status": "modified",
          "additions": 4,
          "deletions": 2,
          "patch": "@@ -71,8 +71,10 @@ DEFINE_FUZZER(const uint8_t* buf, size_t len) {\n                                                : Envoy::Compression::Compressor::State::Flush);\n     decompressor.decompress(buffer, full_output);\n   }\n-  RELEASE_ASSERT(full_input.toString() == full_output.toString(), \"\");\n-  RELEASE_ASSERT(compressor.checksum() == decompressor.checksum(), \"\");\n+  if (stats_store.counterFromString(\"test.zlib_data_error\").value() == 0) {\n+    RELEASE_ASSERT(full_input.toString() == full_output.toString(), \"\");\n+    RELEASE_ASSERT(compressor.checksum() == decompressor.checksum(), \"\");\n+  }\n }\n \n } // namespace Fuzz"
        },
        {
          "filename": "test/extensions/compression/gzip/decompressor/zlib_decompressor_impl_test.cc",
          "status": "modified",
          "additions": 25,
          "deletions": 0,
          "patch": "@@ -122,6 +122,31 @@ TEST_F(ZlibDecompressorImplTest, CallingChecksum) {\n   ASSERT_EQ(0, decompressor.decompression_error_);\n }\n \n+// Detect excessive compression ratio by compressing a long whitespace string\n+// into a very small chunk of data and decompressing it again.\n+TEST_F(ZlibDecompressorImplTest, DetectExcessiveCompressionRatio) {\n+  const absl::string_view ten_whitespaces = \"          \";\n+  Buffer::OwnedImpl buffer;\n+  Extensions::Compression::Gzip::Compressor::ZlibCompressorImpl compressor;\n+  compressor.init(\n+      Extensions::Compression::Gzip::Compressor::ZlibCompressorImpl::CompressionLevel::Standard,\n+      Extensions::Compression::Gzip::Compressor::ZlibCompressorImpl::CompressionStrategy::Standard,\n+      gzip_window_bits, memory_level);\n+\n+  for (int i = 0; i < 1000; i++) {\n+    buffer.add(ten_whitespaces);\n+  }\n+\n+  compressor.compress(buffer, Envoy::Compression::Compressor::State::Finish);\n+\n+  Buffer::OwnedImpl output_buffer;\n+  Stats::IsolatedStoreImpl stats_store{};\n+  ZlibDecompressorImpl decompressor{stats_store, \"test.\"};\n+  decompressor.init(gzip_window_bits);\n+  decompressor.decompress(buffer, output_buffer);\n+  ASSERT_EQ(stats_store.counterFromString(\"test.zlib_data_error\").value(), 1);\n+}\n+\n // Exercises compression and decompression by compressing some data, decompressing it and then\n // comparing compressor's input/checksum with decompressor's output/checksum.\n TEST_F(ZlibDecompressorImplTest, CompressAndDecompress) {"
        },
        {
          "filename": "test/extensions/compression/zstd/decompressor/zstd_decompressor_impl_test.cc",
          "status": "modified",
          "additions": 21,
          "deletions": 0,
          "patch": "@@ -149,6 +149,27 @@ TEST_F(ZstdDecompressorImplTest, IllegalConfig) {\n                \"assert failure: id != 0. Details: Illegal Zstd dictionary\");\n }\n \n+// Detect excessive compression ratio by compressing a long whitespace string\n+// into a very small chunk of data and decompressing it again.\n+TEST_F(ZstdDecompressorImplTest, DetectExcessiveCompressionRatio) {\n+  const absl::string_view ten_whitespaces = \"          \";\n+  Buffer::OwnedImpl buffer;\n+  for (int i = 0; i < 1000; i++) {\n+    buffer.add(ten_whitespaces);\n+  }\n+\n+  Zstd::Compressor::ZstdCompressorImpl compressor{default_compression_level_,\n+                                                  default_enable_checksum_, default_strategy_,\n+                                                  default_cdict_manager_, 4096};\n+  compressor.compress(buffer, Envoy::Compression::Compressor::State::Finish);\n+\n+  Buffer::OwnedImpl output_buffer;\n+  Stats::IsolatedStoreImpl stats_store{};\n+  ZstdDecompressorImpl decompressor{stats_store, \"test.\", default_ddict_manager_, 16};\n+  decompressor.decompress(buffer, output_buffer);\n+  ASSERT_EQ(stats_store.counterFromString(\"test.zstd_generic_error\").value(), 1);\n+}\n+\n } // namespace\n \n // Copy from"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 4,
        "unique_directories": 11,
        "max_directory_depth": 5
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "5f7ee8585fd3324925fa694030ce127db746f9ed",
            "date": "2025-01-26T08:12:00Z",
            "author_login": "antoniovleonti"
          },
          {
            "sha": "ad2a1c700b1cc6c8b1581bc3e2990d696501f105",
            "date": "2025-01-24T15:25:19Z",
            "author_login": "asedeno"
          },
          {
            "sha": "969348a552e76101e5dadde6b8f65694a5198fdf",
            "date": "2025-01-24T11:36:03Z",
            "author_login": "zirain"
          },
          {
            "sha": "2a9c998e1732f07f597acfa10c23342730c8fdc4",
            "date": "2025-01-24T11:11:22Z",
            "author_login": "krinkinmu"
          },
          {
            "sha": "ae6cb3254cbf98999993d0120d289a207a57f825",
            "date": "2025-01-24T10:58:35Z",
            "author_login": "mathetake"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.5,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-400",
    "description": "Envoy is a cloud-native high-performance proxy. In versions prior to 1.22.1 secompressors accumulate decompressed data into an intermediate buffer before overwriting the body in the decode/encodeBody. This may allow an attacker to zip bomb the decompressor by sending a small highly compressed payload. Maliciously constructed zip files may exhaust system memory and cause a denial of service. Users are advised to upgrade. Users unable to upgrade may consider disabling decompression.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2022-06-09T20:15:08.000",
    "last_modified": "2024-11-21T06:58:45.477",
    "fix_date": "2022-06-08T23:08:55Z"
  },
  "references": [
    {
      "url": "https://github.com/envoyproxy/envoy/commit/cb4ef0b09200c720dfdb07e097092dd105450343",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/envoyproxy/envoy/security/advisories/GHSA-75hv-2jjj-89hh",
      "source": "security-advisories@github.com",
      "tags": [
        "Exploit",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/envoyproxy/envoy/commit/cb4ef0b09200c720dfdb07e097092dd105450343",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/envoyproxy/envoy/security/advisories/GHSA-75hv-2jjj-89hh",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:03:09.426052",
    "processing_status": "enhanced"
  },
  "repository_context": {
    "name": "envoy",
    "owner": "envoyproxy",
    "created_at": "2016-08-08T15:07:24Z",
    "updated_at": "2025-01-26T06:15:25Z",
    "pushed_at": "2025-01-24T15:25:20Z",
    "size": 241791,
    "stars": 25373,
    "forks": 4864,
    "open_issues": 1660,
    "watchers": 25373,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [],
    "languages": {
      "C++": 48447088,
      "Starlark": 3112278,
      "Java": 1321815,
      "Python": 604443,
      "Assembly": 327095,
      "Kotlin": 309606,
      "Swift": 250537,
      "Shell": 231950,
      "Go": 183281,
      "Rust": 107631,
      "JavaScript": 66339,
      "C": 61597,
      "Objective-C++": 55490,
      "Objective-C": 48840,
      "Jinja": 47798,
      "Smarty": 3528,
      "CSS": 2927,
      "HTML": 1522,
      "Emacs Lisp": 966,
      "Dockerfile": 960,
      "Thrift": 748,
      "PureBasic": 472,
      "Batchfile": 439,
      "Makefile": 303
    },
    "commit_activity": {
      "total_commits_last_year": 3237,
      "avg_commits_per_week": 62.25,
      "days_active_last_year": 300
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "apache-2.0"
    },
    "collected_at": "2025-01-26T07:41:58.674890"
  }
}