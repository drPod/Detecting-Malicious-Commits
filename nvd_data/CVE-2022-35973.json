{
  "cve_id": "CVE-2022-35973",
  "github_data": {
    "repository": "tensorflow/tensorflow",
    "fix_commit": "aca766ac7693bf29ed0df55ad6bfcc78f35e7f48",
    "related_commits": [
      "aca766ac7693bf29ed0df55ad6bfcc78f35e7f48",
      "aca766ac7693bf29ed0df55ad6bfcc78f35e7f48"
    ],
    "patch_url": "https://github.com/tensorflow/tensorflow/commit/aca766ac7693bf29ed0df55ad6bfcc78f35e7f48.patch",
    "fix_commit_details": {
      "sha": "aca766ac7693bf29ed0df55ad6bfcc78f35e7f48",
      "commit_date": "2022-08-04T18:34:01Z",
      "author": {
        "login": "pak-laura",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Fix tf.raw_ops. QuantizedMatMul vulnerability from non scalar min/max a/b arguments.",
        "length": 114,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 93,
        "additions": 73,
        "deletions": 20
      },
      "files": [
        {
          "filename": "tensorflow/core/kernels/quantized_matmul_op.cc",
          "status": "modified",
          "additions": 15,
          "deletions": 0,
          "patch": "@@ -20,11 +20,14 @@ limitations under the License.\n #define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK\n #include \"public/gemmlowp.h\"\n #include \"tensorflow/core/framework/op_kernel.h\"\n+#include \"tensorflow/core/framework/op_requires.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/kernels/reference_gemm.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n+#include \"tensorflow/core/platform/errors.h\"\n \n namespace tensorflow {\n \n@@ -75,9 +78,21 @@ class QuantizedMatMulOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& a = context->input(0);\n     const Tensor& b = context->input(1);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(2).shape()),\n+                errors::InvalidArgument(\"min_a must be a scalar, but got shape\",\n+                                        context->input(2).shape()));\n     const float min_a = context->input(2).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(3).NumElements() == 1,\n+                errors::InvalidArgument(\"max_a must be a scalar, but got shape\",\n+                                        context->input(3).shape()));\n     const float max_a = context->input(3).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(4).NumElements() == 1,\n+                errors::InvalidArgument(\"min_b must be a scalar, but got shape\",\n+                                        context->input(4).shape()));\n     const float min_b = context->input(4).flat<float>()(0);\n+    OP_REQUIRES(context, context->input(5).NumElements() == 1,\n+                errors::InvalidArgument(\"max_b must be a scalar, but got shape\",\n+                                        context->input(5).shape()));\n     const float max_b = context->input(5).flat<float>()(0);\n \n     // Make sure that we have valid quantization ranges for the input buffers."
        },
        {
          "filename": "tensorflow/core/kernels/quantized_matmul_op_test.cc",
          "status": "modified",
          "additions": 58,
          "deletions": 20,
          "patch": "@@ -62,10 +62,10 @@ TEST_F(QuantizedMatMulTest, Small_NoParams) {\n   // | 15 | 16 | 17 | 18 |\n   AddInputFromArray<quint8>(TensorShape({3, 4}),\n                             {7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n \n   TF_ASSERT_OK(RunOpKernel());\n   // Here are the results we expect, from hand calculations:\n@@ -118,10 +118,10 @@ TEST_F(QuantizedMatMulTest, VerySmall_WithParams) {\n   // The B matrix is:\n   // |   1 |\n   AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {256.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   // We're requesting C = A.transposed() * B,\n   // so we expect to get these results:\n@@ -162,12 +162,50 @@ TEST_F(QuantizedMatMulTest, VerySmall_BadRange) {\n   // The B matrix is:\n   // |   1 |\n   AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n   // Here we set the range so that the min and max are equal, so we expect to\n   // see an error when we run.\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  EXPECT_EQ(::tensorflow::error::INVALID_ARGUMENT, RunOpKernel().code());\n+}\n+\n+// This test multiplies two 1x1 8bit matrices, but sets invalid quantized min\n+// and max values, so we expect to get an error\n+TEST_F(QuantizedMatMulTest, VerySmall_BadMinMax) {\n+  // These parameters reflect a typical production usage of eight-bit matmuls\n+  // in an Inception-style network.\n+  const bool transpose_a = true;\n+  const int a_rows = 1;\n+  const int a_cols = 1;\n+  const int b_rows = 1;\n+  const int b_cols = 1;\n+  const bool transpose_b = false;\n+  TF_ASSERT_OK(NodeDefBuilder(\"quantized_mat_mul_op\", \"QuantizedMatMul\")\n+                   .Input(FakeInput(DT_QUINT8))\n+                   .Input(FakeInput(DT_QUINT8))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Input(FakeInput(DT_FLOAT))\n+                   .Attr(\"Toutput\", DataTypeToEnum<qint32>::v())\n+                   .Attr(\"transpose_a\", transpose_a)\n+                   .Attr(\"transpose_b\", transpose_b)\n+                   .Finalize(node_def()));\n+  TF_ASSERT_OK(InitOp());\n+  // The A matrix is:\n+  // |  -1 |\n+  AddInputFromArray<quint8>(TensorShape({a_rows, a_cols}), {11});\n+  // The B matrix is:\n+  // |   1 |\n+  AddInputFromArray<quint8>(TensorShape({b_rows, b_cols}), {0});\n+  // Here we set the error of a non scalar min_a value, so we expect to see an\n+  // error when we run.\n+  AddInputFromArray<float>(TensorShape({1}), {2});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {1.0f});\n+  AddInputFromArray<float>(TensorShape({}), {256.0f});\n   EXPECT_EQ(::tensorflow::error::INVALID_ARGUMENT, RunOpKernel().code());\n }\n \n@@ -233,10 +271,10 @@ TEST_F(QuantizedMatMulTest, Small_WithParams) {\n                                                                3,\n                                                                6,\n                                                            });\n-  AddInputFromArray<float>(TensorShape({1}), {-12.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {243.0f});\n-  AddInputFromArray<float>(TensorShape({1}), {0});\n-  AddInputFromArray<float>(TensorShape({1}), {255.0f});\n+  AddInputFromArray<float>(TensorShape({}), {-12.0f});\n+  AddInputFromArray<float>(TensorShape({}), {243.0f});\n+  AddInputFromArray<float>(TensorShape({}), {0});\n+  AddInputFromArray<float>(TensorShape({}), {255.0f});\n   TF_ASSERT_OK(RunOpKernel());\n   // We're requesting C = A.transposed() * B,\n   // so we expect to get these results:\n@@ -326,10 +364,10 @@ TEST_F(QuantizedMatMulTest, Medium_WithParams) {\n \n   AddInputFromArray<quint8>(a_quantized.shape(), a_quantized.flat<quint8>());\n   AddInputFromArray<quint8>(b_quantized.shape(), b_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {a_min});\n-  AddInputFromArray<float>(TensorShape({1}), {a_max});\n-  AddInputFromArray<float>(TensorShape({1}), {b_min});\n-  AddInputFromArray<float>(TensorShape({1}), {b_max});\n+  AddInputFromArray<float>(TensorShape({}), {a_min});\n+  AddInputFromArray<float>(TensorShape({}), {a_max});\n+  AddInputFromArray<float>(TensorShape({}), {b_min});\n+  AddInputFromArray<float>(TensorShape({}), {b_max});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected_float(DT_FLOAT, {a_cols, b_cols});"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 1,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "df078d626d561e6ae8f34d4702cbead44a3cbf82",
            "date": "2025-01-14T19:36:18Z",
            "author_login": "tensorflower-gardener"
          },
          {
            "sha": "2a6c919b732bc36a8aa444c03c455a5ba7376ad5",
            "date": "2025-01-14T19:00:47Z",
            "author_login": "sdasgup3"
          },
          {
            "sha": "ea89878e945fdb95ec85b5d396d45b70a42d268e",
            "date": "2025-01-14T19:00:19Z",
            "author_login": "eunjaekim-0"
          },
          {
            "sha": "2ed056484b967486920cc8be1740ab1bd13c9f64",
            "date": "2025-01-14T18:40:26Z",
            "author_login": "GleasonK"
          },
          {
            "sha": "f04ac71a7ba0972752968c52b299e9e53795c9bf",
            "date": "2025-01-14T18:36:27Z",
            "author_login": "tensorflower-gardener"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 5.9,
    "cvss_vector": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-20",
    "description": "TensorFlow is an open source platform for machine learning. If `QuantizedMatMul` is given nonscalar input for: `min_a`, `max_a`, `min_b`, or `max_b` It gives a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit aca766ac7693bf29ed0df55ad6bfcc78f35e7f48. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
    "attack_vector": "NETWORK",
    "attack_complexity": "HIGH"
  },
  "temporal_data": {
    "published_date": "2022-09-16T21:15:09.490",
    "last_modified": "2024-11-21T07:12:05.223",
    "fix_date": "2022-08-04T18:34:01Z"
  },
  "references": [
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/aca766ac7693bf29ed0df55ad6bfcc78f35e7f48",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-689c-r7h2-fv9v",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/aca766ac7693bf29ed0df55ad6bfcc78f35e7f48",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-689c-r7h2-fv9v",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:03:39.129627",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "tensorflow",
    "owner": "tensorflow",
    "created_at": "2015-11-07T01:19:20Z",
    "updated_at": "2025-01-14T12:53:26Z",
    "pushed_at": "2025-01-14T12:53:14Z",
    "size": 1120707,
    "stars": 187254,
    "forks": 74432,
    "open_issues": 6569,
    "watchers": 187254,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "C++": 101199988,
      "Python": 45779571,
      "MLIR": 10763008,
      "HTML": 7662661,
      "Starlark": 7430486,
      "Go": 2171370,
      "C": 1288066,
      "Java": 1178817,
      "Jupyter Notebook": 805736,
      "Shell": 701425,
      "Objective-C++": 279654,
      "Objective-C": 169202,
      "CMake": 148610,
      "Smarty": 121630,
      "Swift": 81659,
      "Dockerfile": 37903,
      "C#": 13585,
      "Batchfile": 12126,
      "Ruby": 8898,
      "Perl": 7536,
      "Roff": 5034,
      "Cython": 3899,
      "Makefile": 2845,
      "CSS": 2761,
      "Vim Snippet": 58
    },
    "commit_activity": {
      "total_commits_last_year": 15729,
      "avg_commits_per_week": 302.4807692307692,
      "days_active_last_year": 357
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "apache-2.0"
    },
    "collected_at": "2025-01-14T12:54:01.412891"
  }
}