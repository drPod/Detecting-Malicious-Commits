{
  "cve_id": "CVE-2022-35979",
  "github_data": {
    "repository": "tensorflow/tensorflow",
    "fix_commit": "49b3824d83af706df0ad07e4e677d88659756d89",
    "related_commits": [
      "49b3824d83af706df0ad07e4e677d88659756d89",
      "49b3824d83af706df0ad07e4e677d88659756d89"
    ],
    "patch_url": "https://github.com/tensorflow/tensorflow/commit/49b3824d83af706df0ad07e4e677d88659756d89.patch",
    "fix_commit_details": {
      "sha": "49b3824d83af706df0ad07e4e677d88659756d89",
      "commit_date": "2022-07-19T16:32:39Z",
      "author": {
        "login": "tensorflower-gardener",
        "type": "User",
        "stats": {
          "total_commits": 51283,
          "average_weekly_commits": 106.83958333333334,
          "total_additions": 0,
          "total_deletions": 0,
          "weeks_active": 450
        }
      },
      "commit_message": {
        "title": "Add IsScalar (rank == 0) check to min/max input tensors for QuantizedAdd/Relu/Relu6 op.",
        "length": 117,
        "has_description": true,
        "references_issue": false
      },
      "stats": {
        "total": 124,
        "additions": 112,
        "deletions": 12
      },
      "files": [
        {
          "filename": "tensorflow/core/kernels/quantized_activation_ops.cc",
          "status": "modified",
          "additions": 30,
          "deletions": 4,
          "patch": "@@ -32,8 +32,21 @@ class QuantizedReluOp : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));\n@@ -65,8 +78,21 @@ class QuantizedRelu6Op : public OpKernel {\n \n   void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float min_input = context->input(1).flat<float>()(0);\n-    const float max_input = context->input(2).flat<float>()(0);\n+    const Tensor& min_input_tensor = context->input(1);\n+    const Tensor& max_input_tensor = context->input(2);\n+\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input_tensor.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input_tensor.dims()));\n+\n+    const float min_input = min_input_tensor.scalar<float>()();\n+    const float max_input = max_input_tensor.scalar<float>()();\n+\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, input.shape(), &output));"
        },
        {
          "filename": "tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -55,8 +55,8 @@ TEST_F(QuantizedActivationsTest, TestRelu) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);\n@@ -86,8 +86,8 @@ TEST_F(QuantizedActivationsTest, TestRelu6) {\n \n   AddInputFromArray<quint8>(input_quantized.shape(),\n                             input_quantized.flat<quint8>());\n-  AddInputFromArray<float>(TensorShape({1}), {input_min});\n-  AddInputFromArray<float>(TensorShape({1}), {input_max});\n+  AddInputFromArray<float>(TensorShape({}), {input_min});\n+  AddInputFromArray<float>(TensorShape({}), {input_max});\n   TF_ASSERT_OK(RunOpKernel());\n   const Tensor& output_quantized = *GetOutput(0);\n   const float output_min = GetOutput(1)->flat<float>()(0);"
        },
        {
          "filename": "tensorflow/core/kernels/quantized_add_op.cc",
          "status": "modified",
          "additions": 23,
          "deletions": 4,
          "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n \n #include \"tensorflow/core/framework/op_kernel.h\"\n #include \"tensorflow/core/framework/tensor.h\"\n+#include \"tensorflow/core/framework/tensor_shape.h\"\n #include \"tensorflow/core/kernels/meta_support.h\"\n #include \"tensorflow/core/kernels/quantization_utils.h\"\n #include \"tensorflow/core/lib/core/errors.h\"\n@@ -457,10 +458,28 @@ class QuantizedAddOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& x = context->input(0);\n     const Tensor& y = context->input(1);\n-    const float min_x = context->input(2).flat<float>()(0);\n-    const float max_x = context->input(3).flat<float>()(0);\n-    const float min_y = context->input(4).flat<float>()(0);\n-    const float max_y = context->input(5).flat<float>()(0);\n+    const Tensor& min_x_tensor = context->input(2);\n+    const Tensor& max_x_tensor = context->input(3);\n+    const Tensor& min_y_tensor = context->input(4);\n+    const Tensor& max_y_tensor = context->input(5);\n+\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),\n+                errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",\n+                                        min_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),\n+                errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",\n+                                        max_x_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),\n+                errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",\n+                                        min_y_tensor.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),\n+                errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",\n+                                        max_y_tensor.dims()));\n+\n+    const float min_x = min_x_tensor.scalar<float>()();\n+    const float max_x = max_x_tensor.scalar<float>()();\n+    const float min_y = min_y_tensor.scalar<float>()();\n+    const float max_y = max_y_tensor.scalar<float>()();\n \n     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n     if (!bcast.IsValid()) {"
        },
        {
          "filename": "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "status": "modified",
          "additions": 55,
          "deletions": 0,
          "patch": "@@ -206,5 +206,60 @@ def test_invalid_inputs(self):\n               out_type=dtypes.qint8))\n \n \n+class QuantizedAddOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    x = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+    y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          math_ops.quantized_add(\n+              x=x,\n+              y=y,\n+              min_x=[],\n+              max_x=1.0,\n+              min_y=0.0,\n+              max_y=1.0,\n+              Toutput=dtypes.qint32))\n+\n+\n+class QuantizedReluOpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n+class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):\n+\n+  @test_util.run_in_graph_and_eager_modes\n+  def test_invalid_inputs(self):\n+    inputs = constant_op.constant(\n+        np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)\n+\n+    with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),\n+                                \"must be rank 0\"):\n+      self.evaluate(\n+          nn_ops.quantized_relu6(\n+              features=inputs,\n+              min_features=[],\n+              max_features=127.0,\n+              out_type=dtypes.quint8))\n+\n+\n if __name__ == \"__main__\":\n   googletest.main()"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 2,
        "unique_directories": 2,
        "max_directory_depth": 4
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "d93cc4f4f767f0d4a72f2fafcc59005be939c019",
            "date": "2025-01-14T20:36:32Z",
            "author_login": "sdasgup3"
          },
          {
            "sha": "d4e4516cc7d11a68a81a82227f3a432f7ab350a0",
            "date": "2025-01-14T19:59:15Z",
            "author_login": "ddunl"
          },
          {
            "sha": "65367823d999b6a36a685617100a7bb6ce03add4",
            "date": "2025-01-14T19:58:00Z",
            "author_login": "sdasgup3"
          },
          {
            "sha": "36cbae5466dbf356d91cf56127b2ab2ccd5a8b1f",
            "date": "2025-01-14T19:54:19Z",
            "author_login": "penpornk"
          },
          {
            "sha": "0a99598a8f76735ac32b5466385b0f5af08a06bb",
            "date": "2025-01-14T19:45:23Z",
            "author_login": "wangpengmit"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 5.9,
    "cvss_vector": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-20",
    "description": "TensorFlow is an open source platform for machine learning. If `QuantizedRelu` or `QuantizedRelu6` are given nonscalar inputs for `min_features` or `max_features`, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 49b3824d83af706df0ad07e4e677d88659756d89. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
    "attack_vector": "NETWORK",
    "attack_complexity": "HIGH"
  },
  "temporal_data": {
    "published_date": "2022-09-16T22:15:11.117",
    "last_modified": "2024-11-21T07:12:06.053",
    "fix_date": "2022-07-19T16:32:39Z"
  },
  "references": [
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/49b3824d83af706df0ad07e4e677d88659756d89",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v7vw-577f-vp8x",
      "source": "security-advisories@github.com",
      "tags": [
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/commit/49b3824d83af706df0ad07e4e677d88659756d89",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-v7vw-577f-vp8x",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:03:39.130041",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "tensorflow",
    "owner": "tensorflow",
    "created_at": "2015-11-07T01:19:20Z",
    "updated_at": "2025-01-14T12:53:26Z",
    "pushed_at": "2025-01-14T12:53:14Z",
    "size": 1120707,
    "stars": 187254,
    "forks": 74432,
    "open_issues": 6569,
    "watchers": 187254,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "C++": 101199988,
      "Python": 45779571,
      "MLIR": 10763008,
      "HTML": 7662661,
      "Starlark": 7430486,
      "Go": 2171370,
      "C": 1288066,
      "Java": 1178817,
      "Jupyter Notebook": 805736,
      "Shell": 701425,
      "Objective-C++": 279654,
      "Objective-C": 169202,
      "CMake": 148610,
      "Smarty": 121630,
      "Swift": 81659,
      "Dockerfile": 37903,
      "C#": 13585,
      "Batchfile": 12126,
      "Ruby": 8898,
      "Perl": 7536,
      "Roff": 5034,
      "Cython": 3899,
      "Makefile": 2845,
      "CSS": 2761,
      "Vim Snippet": 58
    },
    "commit_activity": {
      "total_commits_last_year": 15729,
      "avg_commits_per_week": 302.4807692307692,
      "days_active_last_year": 357
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "apache-2.0"
    },
    "collected_at": "2025-01-14T12:54:01.412891"
  }
}