{
  "cve_id": "CVE-2023-1665",
  "github_data": {
    "repository": "linagora/twake",
    "fix_commit": "599f397561a771251dfc7cafb8cecda5ab22b8b3",
    "related_commits": [
      "599f397561a771251dfc7cafb8cecda5ab22b8b3",
      "599f397561a771251dfc7cafb8cecda5ab22b8b3"
    ],
    "patch_url": "https://github.com/linagora/twake/commit/599f397561a771251dfc7cafb8cecda5ab22b8b3.patch",
    "fix_commit_details": {
      "sha": "599f397561a771251dfc7cafb8cecda5ab22b8b3",
      "commit_date": "2023-03-25T15:50:43Z",
      "author": {
        "login": "RomaricMourgues",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "\ud83d\udee0 Fix drive migration (#2784)",
        "length": 72,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 290,
        "additions": 150,
        "deletions": 140
      },
      "files": [
        {
          "filename": "twake/backend/node/src/cli/cmds/migration_cmds/php-drive-file/drive-migrator-service.ts",
          "status": "modified",
          "additions": 150,
          "deletions": 140,
          "patch": "@@ -65,6 +65,8 @@ class DriveMigrator {\n           company: { id: company.id },\n         });\n       }\n+\n+      console.log(\"Loop over companies...\", page.page_token);\n     } while (page.page_token);\n   };\n \n@@ -159,158 +161,166 @@ class DriveMigrator {\n     logger.info(`Migrating php drive item ${item.id} - parent: ${parentId ?? \"root\"}`);\n \n     try {\n-      const migrationRecord = await this.phpDriveService.getMigrationRecord(\n-        item.id,\n-        context.company.id,\n-      );\n+      await new Promise(async (resolve, reject) => {\n+        const migrationRecord = await this.phpDriveService.getMigrationRecord(\n+          item.id,\n+          context.company.id,\n+        );\n \n-      const newDriveItem = getDefaultDriveItem(\n-        {\n-          name: item.name || item.id,\n-          extension: item.extension,\n-          added: item.added.toString(),\n-          content_keywords:\n-            item.content_keywords && item.content_keywords.length\n-              ? item.content_keywords.join(\",\")\n-              : \"\",\n-          creator: item.creator || context.user.id,\n-          is_directory: item.isdirectory,\n-          is_in_trash: item.isintrash,\n-          description: item.description,\n-          tags: item.tags || [],\n-          parent_id: parentId,\n-          company_id: context.company.id,\n-          access_info: access,\n-        },\n-        context,\n-      );\n+        const newDriveItem = getDefaultDriveItem(\n+          {\n+            name: item.name || item.id,\n+            extension: item.extension,\n+            added: item.added.toString(),\n+            content_keywords:\n+              item.content_keywords && item.content_keywords.length\n+                ? item.content_keywords.join(\",\")\n+                : \"\",\n+            creator: item.creator || context.user.id,\n+            is_directory: item.isdirectory,\n+            is_in_trash: item.isintrash,\n+            description: item.description,\n+            tags: item.tags || [],\n+            parent_id: parentId,\n+            company_id: context.company.id,\n+            access_info: access,\n+          },\n+          context,\n+        );\n \n-      if (migrationRecord && migrationRecord.company_id === context.company.id) {\n-        console.debug(`${item.id} is already migrated`);\n-      } else {\n-        await this.nodeRepository.save(newDriveItem);\n-      }\n+        if (migrationRecord && migrationRecord.company_id === context.company.id) {\n+          console.debug(`${item.id} is already migrated`);\n+        } else {\n+          await this.nodeRepository.save(newDriveItem);\n+        }\n \n-      if (item.isdirectory) {\n-        const newParentId =\n-          migrationRecord && migrationRecord.company_id === context.company.id\n-            ? migrationRecord.new_id\n-            : newDriveItem.id;\n-\n-        let page: Pagination = { limitStr: \"100\" };\n-\n-        do {\n-          const directoryChildren = await this.phpDriveService.listDirectory(\n-            page,\n-            item.id,\n-            context.workspace_id,\n-          );\n-          page = directoryChildren.nextPage as Pagination;\n-\n-          for (const child of directoryChildren.getEntities()) {\n-            try {\n-              await this.migrateDriveFile(child, newParentId, access, context);\n-            } catch (error) {\n-              logger.error(`Failed to migrate drive item ${child.id}`);\n-              console.error(`Failed to migrate drive item ${child.id}`);\n+        if (item.isdirectory) {\n+          const newParentId =\n+            migrationRecord && migrationRecord.company_id === context.company.id\n+              ? migrationRecord.new_id\n+              : newDriveItem.id;\n+\n+          let page: Pagination = { limitStr: \"100\" };\n+\n+          do {\n+            const directoryChildren = await this.phpDriveService.listDirectory(\n+              page,\n+              item.id,\n+              context.workspace_id,\n+            );\n+            page = directoryChildren.nextPage as Pagination;\n+\n+            for (const child of directoryChildren.getEntities()) {\n+              try {\n+                await this.migrateDriveFile(child, newParentId, access, context);\n+              } catch (error) {\n+                logger.error(`Failed to migrate drive item ${child.id}`);\n+                console.error(`Failed to migrate drive item ${child.id}`);\n+              }\n             }\n+          } while (page.page_token);\n+        } else {\n+          let versionPage: Pagination = { limitStr: \"100\" };\n+          if (\n+            migrationRecord &&\n+            migrationRecord.item_id === item.id &&\n+            migrationRecord.company_id === context.company.id\n+          ) {\n+            logger.info(`item is already migrated - ${item.id} - skipping`);\n+            console.log(`item is already migrated - ${item.id} - skipping`);\n+            return;\n           }\n-        } while (page.page_token);\n-      } else {\n-        let versionPage: Pagination = { limitStr: \"100\" };\n-        if (\n-          migrationRecord &&\n-          migrationRecord.item_id === item.id &&\n-          migrationRecord.company_id === context.company.id\n-        ) {\n-          logger.info(`item is already migrated - ${item.id} - skipping`);\n-          console.log(`item is already migrated - ${item.id} - skipping`);\n-          return;\n-        }\n \n-        const mime = mimes[item.extension];\n-\n-        let createdVersions = 0;\n-\n-        do {\n-          const itemVersions = await this.phpDriveService.listItemVersions(\n-            versionPage,\n-            item.id,\n-            context,\n-          );\n-          versionPage = itemVersions.nextPage as Pagination;\n-\n-          for (const version of itemVersions.getEntities()) {\n-            try {\n-              const newVersion = getDefaultDriveItemVersion(\n-                {\n-                  creator_id: version.creator_id || context.user.id,\n-                  data: version.data,\n-                  date_added: +version.date_added,\n-                  drive_item_id: newDriveItem.id,\n-                  file_size: version.file_size,\n-                  filename: version.filename,\n-                  key: version.key,\n-                  provider: version.provider,\n-                  realname: version.realname,\n-                  mode: version.mode,\n-                },\n-                context,\n-              );\n-\n-              logger.info(\n-                `Migrating version ${version.id} of item ${item.id}... (downloading then uploading...)`,\n-              );\n-              const file = await this.phpDriveService.migrate(\n-                version.file_id,\n-                item.workspace_id,\n-                version.id,\n-                {\n-                  filename: version.filename,\n-                  userId: version.creator_id || context.user.id,\n-                  totalSize: version.file_size,\n-                  waitForThumbnail: true,\n-                  chunkNumber: 1,\n-                  totalChunks: 1,\n-                  type: mime,\n-                },\n-                context,\n-              );\n-\n-              if (!file) {\n-                throw Error(\"cannot download file version\");\n+          const mime = mimes[item.extension];\n+\n+          let createdVersions = 0;\n+\n+          const timeout = setTimeout(() => reject(\"Timeout\"), 60000);\n+\n+          do {\n+            const itemVersions = await this.phpDriveService.listItemVersions(\n+              versionPage,\n+              item.id,\n+              context,\n+            );\n+            versionPage = itemVersions.nextPage as Pagination;\n+\n+            for (const version of itemVersions.getEntities()) {\n+              try {\n+                const newVersion = getDefaultDriveItemVersion(\n+                  {\n+                    creator_id: version.creator_id || context.user.id,\n+                    data: version.data,\n+                    date_added: +version.date_added,\n+                    drive_item_id: newDriveItem.id,\n+                    file_size: version.file_size,\n+                    filename: version.filename,\n+                    key: version.key,\n+                    provider: version.provider,\n+                    realname: version.realname,\n+                    mode: version.mode,\n+                  },\n+                  context,\n+                );\n+\n+                logger.info(\n+                  `Migrating version ${version.id} of item ${item.id}... (downloading then uploading...)`,\n+                );\n+                const file = await this.phpDriveService.migrate(\n+                  version.file_id,\n+                  item.workspace_id,\n+                  version.id,\n+                  {\n+                    filename: version.filename,\n+                    userId: version.creator_id || context.user.id,\n+                    totalSize: version.file_size,\n+                    waitForThumbnail: true,\n+                    chunkNumber: 1,\n+                    totalChunks: 1,\n+                    type: mime,\n+                  },\n+                  context,\n+                );\n+\n+                if (!file) {\n+                  throw Error(\"cannot download file version\");\n+                }\n+\n+                newVersion.file_metadata = {\n+                  external_id: file.id,\n+                  mime: file.metadata.mime,\n+                  name: file.metadata.name || version.filename,\n+                  size: file.upload_data.size || version.file_size,\n+                };\n+\n+                await globalResolver.services.documents.documents.createVersion(\n+                  newDriveItem.id,\n+                  newVersion,\n+                  context,\n+                );\n+\n+                createdVersions++;\n+              } catch (error) {\n+                logger.error(`Failed to migrate version ${version.id} for drive item ${item.id}`);\n+                console.error(`Failed to migrate version ${version.id} for drive item ${item.id}`);\n               }\n-\n-              newVersion.file_metadata = {\n-                external_id: file.id,\n-                mime: file.metadata.mime,\n-                name: file.metadata.name || version.filename,\n-                size: file.upload_data.size || version.file_size,\n-              };\n-\n-              await globalResolver.services.documents.documents.createVersion(\n-                newDriveItem.id,\n-                newVersion,\n-                context,\n-              );\n-\n-              createdVersions++;\n-            } catch (error) {\n-              logger.error(`Failed to migrate version ${version.id} for drive item ${item.id}`);\n-              console.error(`Failed to migrate version ${version.id} for drive item ${item.id}`);\n             }\n+          } while (versionPage.page_token);\n+\n+          clearTimeout(timeout);\n+\n+          if (createdVersions === 0) {\n+            await this.nodeRepository.remove(newDriveItem);\n+            return;\n           }\n-        } while (versionPage.page_token);\n+        }\n \n-        if (createdVersions === 0) {\n-          await this.nodeRepository.remove(newDriveItem);\n-          return;\n+        if (!migrationRecord) {\n+          await this.phpDriveService.markAsMigrated(item.id, newDriveItem.id, context.company.id);\n         }\n-      }\n \n-      if (!migrationRecord) {\n-        await this.phpDriveService.markAsMigrated(item.id, newDriveItem.id, context.company.id);\n-      }\n+        resolve(true);\n+      });\n     } catch (error) {\n       logger.error(\n         `Failed to migrate Drive item ${item.id} / workspace ${item.workspace_id} / company_id: ${context.company.id}`,"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 0,
        "unique_directories": 1,
        "max_directory_depth": 8
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "39f533e5e838ef5c7b89168ee6349585a9ec950c",
            "date": "2024-07-05T12:59:20Z",
            "author_login": "artembru"
          },
          {
            "sha": "801f0a3b94e17cd294f5ce921e8d2d32606eb76f",
            "date": "2024-03-11T10:53:21Z",
            "author_login": "rezk2ll"
          },
          {
            "sha": "53be17a3c2b6057a838424182d929c7b7cb5f1ab",
            "date": "2024-03-11T10:47:05Z",
            "author_login": "rezk2ll"
          },
          {
            "sha": "58b1e8a82028ce193eb82639dc485c4f6579d85b",
            "date": "2024-03-07T15:07:32Z",
            "author_login": "rezk2ll"
          },
          {
            "sha": "753bdbef5b41ea5281077aecb7480e541fd1fd2c",
            "date": "2024-03-07T14:50:38Z",
            "author_login": "rezk2ll"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 9.8,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",
    "cwe_id": "CWE-307",
    "description": "Improper Restriction of Excessive Authentication Attempts in GitHub repository linagora/twake prior to 0.0.0.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2023-03-27T22:15:21.517",
    "last_modified": "2024-11-21T07:39:38.910",
    "fix_date": "2023-03-25T15:50:43Z"
  },
  "references": [
    {
      "url": "https://github.com/linagora/twake/commit/599f397561a771251dfc7cafb8cecda5ab22b8b3",
      "source": "security@huntr.dev",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.dev/bounties/db8fcbab-6ef0-44ba-b5c6-3b0f17ca22a2",
      "source": "security@huntr.dev",
      "tags": [
        "Exploit",
        "Issue Tracking",
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/linagora/twake/commit/599f397561a771251dfc7cafb8cecda5ab22b8b3",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.dev/bounties/db8fcbab-6ef0-44ba-b5c6-3b0f17ca22a2",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit",
        "Issue Tracking",
        "Patch",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:05:09.017793",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "Twake",
    "owner": "linagora",
    "created_at": "2020-06-13T11:17:32Z",
    "updated_at": "2025-01-10T01:23:38Z",
    "pushed_at": "2024-12-03T06:30:44Z",
    "size": 203256,
    "stars": 1800,
    "forks": 194,
    "open_issues": 331,
    "watchers": 1800,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "main"
    ],
    "languages": {
      "TypeScript": 3365096,
      "PHP": 1850897,
      "JavaScript": 1847218,
      "SCSS": 293774,
      "CSS": 80537,
      "Twig": 66740,
      "HTML": 48140,
      "Less": 38753,
      "Dockerfile": 10561,
      "Shell": 7132
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "agpl-3.0"
    },
    "collected_at": "2025-01-14T13:45:43.084996"
  }
}