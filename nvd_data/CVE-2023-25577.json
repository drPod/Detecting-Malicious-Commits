{
  "cve_id": "CVE-2023-25577",
  "github_data": {
    "repository": "pallets/werkzeug",
    "fix_commit": "517cac5a804e8c4dc4ed038bb20dacd038e7a9f1",
    "related_commits": [
      "517cac5a804e8c4dc4ed038bb20dacd038e7a9f1",
      "517cac5a804e8c4dc4ed038bb20dacd038e7a9f1"
    ],
    "patch_url": "https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb20dacd038e7a9f1.patch",
    "fix_commit_details": {
      "sha": "517cac5a804e8c4dc4ed038bb20dacd038e7a9f1",
      "commit_date": "2023-02-14T17:08:57Z",
      "author": {
        "login": "davidism",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Merge pull request from GHSA-xg9f-g7g7-2323",
        "length": 93,
        "has_description": true,
        "references_issue": false
      },
      "stats": {
        "total": 78,
        "additions": 60,
        "deletions": 18
      },
      "files": [
        {
          "filename": "CHANGES.rst",
          "status": "modified",
          "additions": 4,
          "deletions": 0,
          "patch": "@@ -21,6 +21,10 @@ Unreleased\n     the requested size in one ``read`` call. :issue:`2558`\n -   A cookie header that starts with ``=`` is treated as an empty key and discarded,\n     rather than stripping the leading ``==``.\n+-   Specify a maximum number of multipart parts, default 1000, after which a\n+    ``RequestEntityTooLarge`` exception is raised on parsing. This mitigates a DoS\n+    attack where a larger number of form/file parts would result in disproportionate\n+    resource use.\n \n \n Version 2.2.2"
        },
        {
          "filename": "docs/request_data.rst",
          "status": "modified",
          "additions": 20,
          "deletions": 17,
          "patch": "@@ -73,23 +73,26 @@ read the stream *or* call :meth:`~Request.get_data`.\n Limiting Request Data\n ---------------------\n \n-To avoid being the victim of a DDOS attack you can set the maximum\n-accepted content length and request field sizes.  The :class:`Request`\n-class has two attributes for that: :attr:`~Request.max_content_length`\n-and :attr:`~Request.max_form_memory_size`.\n-\n-The first one can be used to limit the total content length.  For example\n-by setting it to ``1024 * 1024 * 16`` the request won't accept more than\n-16MB of transmitted data.\n-\n-Because certain data can't be moved to the hard disk (regular post data)\n-whereas temporary files can, there is a second limit you can set.  The\n-:attr:`~Request.max_form_memory_size` limits the size of `POST`\n-transmitted form data.  By setting it to ``1024 * 1024 * 2`` you can make\n-sure that all in memory-stored fields are not more than 2MB in size.\n-\n-This however does *not* affect in-memory stored files if the\n-`stream_factory` used returns a in-memory file.\n+The :class:`Request` class provides a few attributes to control how much data is\n+processed from the request body. This can help mitigate DoS attacks that craft the\n+request in such a way that the server uses too many resources to handle it. Each of\n+these limits will raise a :exc:`~werkzeug.exceptions.RequestEntityTooLarge` if they are\n+exceeded.\n+\n+-   :attr:`~Request.max_content_length` Stop reading request data after this number\n+    of bytes. It's better to configure this in the WSGI server or HTTP server, rather\n+    than the WSGI application.\n+-   :attr:`~Request.max_form_memory_size` Stop reading request data if any form part is\n+    larger than this number of bytes. While file parts can be moved to disk, regular\n+    form field data is stored in memory only.\n+-   :attr:`~Request.max_form_parts` Stop reading request data if more than this number\n+    of parts are sent in multipart form data. This is useful to stop a very large number\n+    of very small parts, especially file parts. The default is 1000.\n+\n+Using Werkzeug to set these limits is only one layer of protection. WSGI servers\n+and HTTPS servers should set their own limits on size and timeouts. The operating system\n+or container manager should set limits on memory and processing time for server\n+processes.\n \n \n How to extend Parsing?"
        },
        {
          "filename": "src/werkzeug/formparser.py",
          "status": "modified",
          "additions": 11,
          "deletions": 1,
          "patch": "@@ -179,6 +179,8 @@ class FormDataParser:\n     :param cls: an optional dict class to use.  If this is not specified\n                        or `None` the default :class:`MultiDict` is used.\n     :param silent: If set to False parsing errors will not be caught.\n+    :param max_form_parts: The maximum number of parts to be parsed. If this is\n+        exceeded, a :exc:`~exceptions.RequestEntityTooLarge` exception is raised.\n     \"\"\"\n \n     def __init__(\n@@ -190,6 +192,8 @@ def __init__(\n         max_content_length: t.Optional[int] = None,\n         cls: t.Optional[t.Type[MultiDict]] = None,\n         silent: bool = True,\n+        *,\n+        max_form_parts: t.Optional[int] = None,\n     ) -> None:\n         if stream_factory is None:\n             stream_factory = default_stream_factory\n@@ -199,6 +203,7 @@ def __init__(\n         self.errors = errors\n         self.max_form_memory_size = max_form_memory_size\n         self.max_content_length = max_content_length\n+        self.max_form_parts = max_form_parts\n \n         if cls is None:\n             cls = MultiDict\n@@ -281,6 +286,7 @@ def _parse_multipart(\n             self.errors,\n             max_form_memory_size=self.max_form_memory_size,\n             cls=self.cls,\n+            max_form_parts=self.max_form_parts,\n         )\n         boundary = options.get(\"boundary\", \"\").encode(\"ascii\")\n \n@@ -346,10 +352,12 @@ def __init__(\n         max_form_memory_size: t.Optional[int] = None,\n         cls: t.Optional[t.Type[MultiDict]] = None,\n         buffer_size: int = 64 * 1024,\n+        max_form_parts: t.Optional[int] = None,\n     ) -> None:\n         self.charset = charset\n         self.errors = errors\n         self.max_form_memory_size = max_form_memory_size\n+        self.max_form_parts = max_form_parts\n \n         if stream_factory is None:\n             stream_factory = default_stream_factory\n@@ -409,7 +417,9 @@ def parse(\n             [None],\n         )\n \n-        parser = MultipartDecoder(boundary, self.max_form_memory_size)\n+        parser = MultipartDecoder(\n+            boundary, self.max_form_memory_size, max_parts=self.max_form_parts\n+        )\n \n         fields = []\n         files = []"
        },
        {
          "filename": "src/werkzeug/sansio/multipart.py",
          "status": "modified",
          "additions": 8,
          "deletions": 0,
          "patch": "@@ -87,10 +87,13 @@ def __init__(\n         self,\n         boundary: bytes,\n         max_form_memory_size: Optional[int] = None,\n+        *,\n+        max_parts: Optional[int] = None,\n     ) -> None:\n         self.buffer = bytearray()\n         self.complete = False\n         self.max_form_memory_size = max_form_memory_size\n+        self.max_parts = max_parts\n         self.state = State.PREAMBLE\n         self.boundary = boundary\n \n@@ -118,6 +121,7 @@ def __init__(\n             re.MULTILINE,\n         )\n         self._search_position = 0\n+        self._parts_decoded = 0\n \n     def last_newline(self) -> int:\n         try:\n@@ -191,6 +195,10 @@ def next_event(self) -> Event:\n                     )\n                 self.state = State.DATA\n                 self._search_position = 0\n+                self._parts_decoded += 1\n+\n+                if self.max_parts is not None and self._parts_decoded > self.max_parts:\n+                    raise RequestEntityTooLarge()\n             else:\n                 # Update the search start position to be equal to the\n                 # current buffer length (already searched) minus a"
        },
        {
          "filename": "src/werkzeug/wrappers/request.py",
          "status": "modified",
          "additions": 8,
          "deletions": 0,
          "patch": "@@ -83,6 +83,13 @@ class Request(_SansIORequest):\n     #: .. versionadded:: 0.5\n     max_form_memory_size: t.Optional[int] = None\n \n+    #: The maximum number of multipart parts to parse, passed to\n+    #: :attr:`form_data_parser_class`. Parsing form data with more than this\n+    #: many parts will raise :exc:`~.RequestEntityTooLarge`.\n+    #:\n+    #: .. versionadded:: 2.2.3\n+    max_form_parts = 1000\n+\n     #: The form data parser that should be used.  Can be replaced to customize\n     #: the form date parsing.\n     form_data_parser_class: t.Type[FormDataParser] = FormDataParser\n@@ -246,6 +253,7 @@ def make_form_data_parser(self) -> FormDataParser:\n             self.max_form_memory_size,\n             self.max_content_length,\n             self.parameter_storage_class,\n+            max_form_parts=self.max_form_parts,\n         )\n \n     def _load_form_data(self) -> None:"
        },
        {
          "filename": "tests/test_formparser.py",
          "status": "modified",
          "additions": 9,
          "deletions": 0,
          "patch": "@@ -127,6 +127,15 @@ def test_limiting(self):\n         req.max_form_memory_size = 400\n         assert req.form[\"foo\"] == \"Hello World\"\n \n+        req = Request.from_values(\n+            input_stream=io.BytesIO(data),\n+            content_length=len(data),\n+            content_type=\"multipart/form-data; boundary=foo\",\n+            method=\"POST\",\n+        )\n+        req.max_form_parts = 1\n+        pytest.raises(RequestEntityTooLarge, lambda: req.form[\"foo\"])\n+\n     def test_missing_multipart_boundary(self):\n         data = (\n             b\"--foo\\r\\nContent-Disposition: form-field; name=foo\\r\\n\\r\\n\""
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 6,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "7868bef5d978093a8baa0784464ebe5d775ae92a",
            "date": "2024-11-08T15:53:55Z",
            "author_login": "davidism"
          },
          {
            "sha": "6b56ed571b338e68fc378e6348266ee99de26646",
            "date": "2024-11-08T15:52:32Z",
            "author_login": "davidism"
          },
          {
            "sha": "6389612fd1ee1bd93579eed5026e8fd471d04abd",
            "date": "2024-11-08T15:46:09Z",
            "author_login": "davidism"
          },
          {
            "sha": "ba15683fb30b51187fa7efa9d212a030ad6ddb94",
            "date": "2024-11-07T16:34:12Z",
            "author_login": "davidism"
          },
          {
            "sha": "d99f72d12698d86e7ebcb894f3c6c729e2b6c067",
            "date": "2024-11-07T16:01:56Z",
            "author_login": "davidism"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.5,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-770",
    "description": "Werkzeug is a comprehensive WSGI web application library. Prior to version 2.2.3, Werkzeug's multipart form data parser will parse an unlimited number of parts, including file parts. Parts can be a small amount of bytes, but each requires CPU time to parse and may use more memory as Python data. If a request can be made to an endpoint that accesses `request.data`, `request.form`, `request.files`, or `request.get_data(parse_form_data=False)`, it can cause unexpectedly high resource usage. This allows an attacker to cause a denial of service by sending crafted multipart data to an endpoint that will parse it. The amount of CPU time required can block worker processes from handling legitimate requests. The amount of RAM required can trigger an out of memory kill of the process. Unlimited file parts can use up memory and file handles. If many concurrent requests are sent continuously, this can exhaust or kill all available workers. Version 2.2.3 contains a patch for this issue.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2023-02-14T20:15:17.543",
    "last_modified": "2024-11-21T07:49:45.740",
    "fix_date": "2023-02-14T17:08:57Z"
  },
  "references": [
    {
      "url": "https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb20dacd038e7a9f1",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/pallets/werkzeug/releases/tag/2.2.3",
      "source": "security-advisories@github.com",
      "tags": [
        "Release Notes"
      ]
    },
    {
      "url": "https://github.com/pallets/werkzeug/security/advisories/GHSA-xg9f-g7g7-2323",
      "source": "security-advisories@github.com",
      "tags": [
        "Vendor Advisory"
      ]
    },
    {
      "url": "https://security.netapp.com/advisory/ntap-20230818-0003/",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://www.debian.org/security/2023/dsa-5470",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb20dacd038e7a9f1",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/pallets/werkzeug/releases/tag/2.2.3",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Release Notes"
      ]
    },
    {
      "url": "https://github.com/pallets/werkzeug/security/advisories/GHSA-xg9f-g7g7-2323",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Vendor Advisory"
      ]
    },
    {
      "url": "https://security.netapp.com/advisory/ntap-20230818-0003/",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://www.debian.org/security/2023/dsa-5470",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:05:04.058162",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "werkzeug",
    "owner": "pallets",
    "created_at": "2010-10-18T11:42:40Z",
    "updated_at": "2025-01-14T07:44:16Z",
    "pushed_at": "2025-01-13T18:59:09Z",
    "size": 15910,
    "stars": 6687,
    "forks": 1734,
    "open_issues": 13,
    "watchers": 6687,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "main",
      "stable"
    ],
    "languages": {
      "Python": 1061077,
      "JavaScript": 10068,
      "CSS": 6078,
      "Shell": 165,
      "HTML": 124
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "bsd-3-clause"
    },
    "collected_at": "2025-01-14T13:31:32.606928"
  }
}