{
  "cve_id": "CVE-2023-30798",
  "github_data": {
    "repository": "encode/starlette",
    "fix_commit": "8c74c2c8dba7030154f8af18e016136bea1938fa",
    "related_commits": [
      "8c74c2c8dba7030154f8af18e016136bea1938fa",
      "8c74c2c8dba7030154f8af18e016136bea1938fa"
    ],
    "patch_url": "https://github.com/encode/starlette/commit/8c74c2c8dba7030154f8af18e016136bea1938fa.patch",
    "fix_commit_details": {
      "sha": "8c74c2c8dba7030154f8af18e016136bea1938fa",
      "commit_date": "2023-02-14T08:01:32Z",
      "author": {
        "login": "tiangolo",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Merge pull request from GHSA-74m5-2c7w-9w3x",
        "length": 754,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 447,
        "additions": 356,
        "deletions": 91
      },
      "files": [
        {
          "filename": "docs/requests.md",
          "status": "modified",
          "additions": 12,
          "deletions": 0,
          "patch": "@@ -114,6 +114,18 @@ state with `disconnected = await request.is_disconnected()`.\n \n Request files are normally sent as multipart form data (`multipart/form-data`).\n \n+Signature: `request.form(max_files=1000, max_fields=1000)`\n+\n+You can configure the number of maximum fields or files with the parameters `max_files` and `max_fields`:\n+\n+```python\n+async with request.form(max_files=1000, max_fields=1000):\n+    ...\n+```\n+\n+!!! info\n+    These limits are for security reasons, allowing an unlimited number of fields or files could lead to a denial of service attack by consuming a lot of CPU and memory parsing too many empty fields.\n+\n When you call `async with request.form() as form` you receive a `starlette.datastructures.FormData` which is an immutable\n multidict, containing both file uploads and text input. File upload items are represented as instances of `starlette.datastructures.UploadFile`.\n "
        },
        {
          "filename": "starlette/formparsers.py",
          "status": "modified",
          "additions": 101,
          "deletions": 87,
          "patch": "@@ -1,4 +1,5 @@\n import typing\n+from dataclasses import dataclass, field\n from enum import Enum\n from tempfile import SpooledTemporaryFile\n from urllib.parse import unquote_plus\n@@ -21,15 +22,13 @@ class FormMessage(Enum):\n     END = 5\n \n \n-class MultiPartMessage(Enum):\n-    PART_BEGIN = 1\n-    PART_DATA = 2\n-    PART_END = 3\n-    HEADER_FIELD = 4\n-    HEADER_VALUE = 5\n-    HEADER_END = 6\n-    HEADERS_FINISHED = 7\n-    END = 8\n+@dataclass\n+class MultipartPart:\n+    content_disposition: typing.Optional[bytes] = None\n+    field_name: str = \"\"\n+    data: bytes = b\"\"\n+    file: typing.Optional[UploadFile] = None\n+    item_headers: typing.List[typing.Tuple[bytes, bytes]] = field(default_factory=list)\n \n \n def _user_safe_decode(src: bytes, codec: str) -> str:\n@@ -120,53 +119,115 @@ class MultiPartParser:\n     max_file_size = 1024 * 1024\n \n     def __init__(\n-        self, headers: Headers, stream: typing.AsyncGenerator[bytes, None]\n+        self,\n+        headers: Headers,\n+        stream: typing.AsyncGenerator[bytes, None],\n+        *,\n+        max_files: typing.Union[int, float] = 1000,\n+        max_fields: typing.Union[int, float] = 1000,\n     ) -> None:\n         assert (\n             multipart is not None\n         ), \"The `python-multipart` library must be installed to use form parsing.\"\n         self.headers = headers\n         self.stream = stream\n-        self.messages: typing.List[typing.Tuple[MultiPartMessage, bytes]] = []\n+        self.max_files = max_files\n+        self.max_fields = max_fields\n+        self.items: typing.List[typing.Tuple[str, typing.Union[str, UploadFile]]] = []\n+        self._current_files = 0\n+        self._current_fields = 0\n+        self._current_partial_header_name: bytes = b\"\"\n+        self._current_partial_header_value: bytes = b\"\"\n+        self._current_part = MultipartPart()\n+        self._charset = \"\"\n+        self._file_parts_to_write: typing.List[typing.Tuple[MultipartPart, bytes]] = []\n+        self._file_parts_to_finish: typing.List[MultipartPart] = []\n \n     def on_part_begin(self) -> None:\n-        message = (MultiPartMessage.PART_BEGIN, b\"\")\n-        self.messages.append(message)\n+        self._current_part = MultipartPart()\n \n     def on_part_data(self, data: bytes, start: int, end: int) -> None:\n-        message = (MultiPartMessage.PART_DATA, data[start:end])\n-        self.messages.append(message)\n+        message_bytes = data[start:end]\n+        if self._current_part.file is None:\n+            self._current_part.data += message_bytes\n+        else:\n+            self._file_parts_to_write.append((self._current_part, message_bytes))\n \n     def on_part_end(self) -> None:\n-        message = (MultiPartMessage.PART_END, b\"\")\n-        self.messages.append(message)\n+        if self._current_part.file is None:\n+            self.items.append(\n+                (\n+                    self._current_part.field_name,\n+                    _user_safe_decode(self._current_part.data, self._charset),\n+                )\n+            )\n+        else:\n+            self._file_parts_to_finish.append(self._current_part)\n+            # The file can be added to the items right now even though it's not\n+            # finished yet, because it will be finished in the `parse()` method, before\n+            # self.items is used in the return value.\n+            self.items.append((self._current_part.field_name, self._current_part.file))\n \n     def on_header_field(self, data: bytes, start: int, end: int) -> None:\n-        message = (MultiPartMessage.HEADER_FIELD, data[start:end])\n-        self.messages.append(message)\n+        self._current_partial_header_name += data[start:end]\n \n     def on_header_value(self, data: bytes, start: int, end: int) -> None:\n-        message = (MultiPartMessage.HEADER_VALUE, data[start:end])\n-        self.messages.append(message)\n+        self._current_partial_header_value += data[start:end]\n \n     def on_header_end(self) -> None:\n-        message = (MultiPartMessage.HEADER_END, b\"\")\n-        self.messages.append(message)\n+        field = self._current_partial_header_name.lower()\n+        if field == b\"content-disposition\":\n+            self._current_part.content_disposition = self._current_partial_header_value\n+        self._current_part.item_headers.append(\n+            (field, self._current_partial_header_value)\n+        )\n+        self._current_partial_header_name = b\"\"\n+        self._current_partial_header_value = b\"\"\n \n     def on_headers_finished(self) -> None:\n-        message = (MultiPartMessage.HEADERS_FINISHED, b\"\")\n-        self.messages.append(message)\n+        disposition, options = parse_options_header(\n+            self._current_part.content_disposition\n+        )\n+        try:\n+            self._current_part.field_name = _user_safe_decode(\n+                options[b\"name\"], self._charset\n+            )\n+        except KeyError:\n+            raise MultiPartException(\n+                'The Content-Disposition header field \"name\" must be ' \"provided.\"\n+            )\n+        if b\"filename\" in options:\n+            self._current_files += 1\n+            if self._current_files > self.max_files:\n+                raise MultiPartException(\n+                    f\"Too many files. Maximum number of files is {self.max_files}.\"\n+                )\n+            filename = _user_safe_decode(options[b\"filename\"], self._charset)\n+            tempfile = SpooledTemporaryFile(max_size=self.max_file_size)\n+            self._current_part.file = UploadFile(\n+                file=tempfile,  # type: ignore[arg-type]\n+                size=0,\n+                filename=filename,\n+                headers=Headers(raw=self._current_part.item_headers),\n+            )\n+        else:\n+            self._current_fields += 1\n+            if self._current_fields > self.max_fields:\n+                raise MultiPartException(\n+                    f\"Too many fields. Maximum number of fields is {self.max_fields}.\"\n+                )\n+            self._current_part.file = None\n \n     def on_end(self) -> None:\n-        message = (MultiPartMessage.END, b\"\")\n-        self.messages.append(message)\n+        pass\n \n     async def parse(self) -> FormData:\n         # Parse the Content-Type header to get the multipart boundary.\n         _, params = parse_options_header(self.headers[\"Content-Type\"])\n         charset = params.get(b\"charset\", \"utf-8\")\n         if type(charset) == bytes:\n             charset = charset.decode(\"latin-1\")\n+        self._charset = charset\n         try:\n             boundary = params[b\"boundary\"]\n         except KeyError:\n@@ -186,68 +247,21 @@ async def parse(self) -> FormData:\n \n         # Create the parser.\n         parser = multipart.MultipartParser(boundary, callbacks)\n-        header_field = b\"\"\n-        header_value = b\"\"\n-        content_disposition = None\n-        field_name = \"\"\n-        data = b\"\"\n-        file: typing.Optional[UploadFile] = None\n-\n-        items: typing.List[typing.Tuple[str, typing.Union[str, UploadFile]]] = []\n-        item_headers: typing.List[typing.Tuple[bytes, bytes]] = []\n-\n         # Feed the parser with data from the request.\n         async for chunk in self.stream:\n             parser.write(chunk)\n-            messages = list(self.messages)\n-            self.messages.clear()\n-            for message_type, message_bytes in messages:\n-                if message_type == MultiPartMessage.PART_BEGIN:\n-                    content_disposition = None\n-                    data = b\"\"\n-                    item_headers = []\n-                elif message_type == MultiPartMessage.HEADER_FIELD:\n-                    header_field += message_bytes\n-                elif message_type == MultiPartMessage.HEADER_VALUE:\n-                    header_value += message_bytes\n-                elif message_type == MultiPartMessage.HEADER_END:\n-                    field = header_field.lower()\n-                    if field == b\"content-disposition\":\n-                        content_disposition = header_value\n-                    item_headers.append((field, header_value))\n-                    header_field = b\"\"\n-                    header_value = b\"\"\n-                elif message_type == MultiPartMessage.HEADERS_FINISHED:\n-                    disposition, options = parse_options_header(content_disposition)\n-                    try:\n-                        field_name = _user_safe_decode(options[b\"name\"], charset)\n-                    except KeyError:\n-                        raise MultiPartException(\n-                            'The Content-Disposition header field \"name\" must be '\n-                            \"provided.\"\n-                        )\n-                    if b\"filename\" in options:\n-                        filename = _user_safe_decode(options[b\"filename\"], charset)\n-                        tempfile = SpooledTemporaryFile(max_size=self.max_file_size)\n-                        file = UploadFile(\n-                            file=tempfile,  # type: ignore[arg-type]\n-                            size=0,\n-                            filename=filename,\n-                            headers=Headers(raw=item_headers),\n-                        )\n-                    else:\n-                        file = None\n-                elif message_type == MultiPartMessage.PART_DATA:\n-                    if file is None:\n-                        data += message_bytes\n-                    else:\n-                        await file.write(message_bytes)\n-                elif message_type == MultiPartMessage.PART_END:\n-                    if file is None:\n-                        items.append((field_name, _user_safe_decode(data, charset)))\n-                    else:\n-                        await file.seek(0)\n-                        items.append((field_name, file))\n+            # Write file data, it needs to use await with the UploadFile methods that\n+            # call the corresponding file methods *in a threadpool*, otherwise, if\n+            # they were called directly in the callback methods above (regular,\n+            # non-async functions), that would block the event loop in the main thread.\n+            for part, data in self._file_parts_to_write:\n+                assert part.file  # for type checkers\n+                await part.file.write(data)\n+            for part in self._file_parts_to_finish:\n+                assert part.file  # for type checkers\n+                await part.file.seek(0)\n+            self._file_parts_to_write.clear()\n+            self._file_parts_to_finish.clear()\n \n         parser.finalize()\n-        return FormData(items)\n+        return FormData(self.items)"
        },
        {
          "filename": "starlette/requests.py",
          "status": "modified",
          "additions": 21,
          "deletions": 4,
          "patch": "@@ -244,7 +244,12 @@ async def json(self) -> typing.Any:\n             self._json = json.loads(body)\n         return self._json\n \n-    async def _get_form(self) -> FormData:\n+    async def _get_form(\n+        self,\n+        *,\n+        max_files: typing.Union[int, float] = 1000,\n+        max_fields: typing.Union[int, float] = 1000,\n+    ) -> FormData:\n         if self._form is None:\n             assert (\n                 parse_options_header is not None\n@@ -254,7 +259,12 @@ async def _get_form(self) -> FormData:\n             content_type, _ = parse_options_header(content_type_header)\n             if content_type == b\"multipart/form-data\":\n                 try:\n-                    multipart_parser = MultiPartParser(self.headers, self.stream())\n+                    multipart_parser = MultiPartParser(\n+                        self.headers,\n+                        self.stream(),\n+                        max_files=max_files,\n+                        max_fields=max_fields,\n+                    )\n                     self._form = await multipart_parser.parse()\n                 except MultiPartException as exc:\n                     if \"app\" in self.scope:\n@@ -267,8 +277,15 @@ async def _get_form(self) -> FormData:\n                 self._form = FormData()\n         return self._form\n \n-    def form(self) -> AwaitableOrContextManager[FormData]:\n-        return AwaitableOrContextManagerWrapper(self._get_form())\n+    def form(\n+        self,\n+        *,\n+        max_files: typing.Union[int, float] = 1000,\n+        max_fields: typing.Union[int, float] = 1000,\n+    ) -> AwaitableOrContextManager[FormData]:\n+        return AwaitableOrContextManagerWrapper(\n+            self._get_form(max_files=max_files, max_fields=max_fields)\n+        )\n \n     async def close(self) -> None:\n         if self._form is not None:"
        },
        {
          "filename": "tests/test_formparsers.py",
          "status": "modified",
          "additions": 222,
          "deletions": 0,
          "patch": "@@ -98,6 +98,29 @@ async def app_read_body(scope, receive, send):\n     await response(scope, receive, send)\n \n \n+def make_app_max_parts(max_files: int = 1000, max_fields: int = 1000):\n+    async def app(scope, receive, send):\n+        request = Request(scope, receive)\n+        data = await request.form(max_files=max_files, max_fields=max_fields)\n+        output: typing.Dict[str, typing.Any] = {}\n+        for key, value in data.items():\n+            if isinstance(value, UploadFile):\n+                content = await value.read()\n+                output[key] = {\n+                    \"filename\": value.filename,\n+                    \"size\": value.size,\n+                    \"content\": content.decode(),\n+                    \"content_type\": value.content_type,\n+                }\n+            else:\n+                output[key] = value\n+        await request.close()\n+        response = JSONResponse(output)\n+        await response(scope, receive, send)\n+\n+    return app\n+\n+\n def test_multipart_request_data(tmpdir, test_client_factory):\n     client = test_client_factory(app)\n     response = client.post(\"/\", data={\"some\": \"data\"}, files=FORCE_MULTIPART)\n@@ -460,3 +483,202 @@ def test_missing_name_parameter_on_content_disposition(\n         assert (\n             res.text == 'The Content-Disposition header field \"name\" must be provided.'\n         )\n+\n+\n+@pytest.mark.parametrize(\n+    \"app,expectation\",\n+    [\n+        (app, pytest.raises(MultiPartException)),\n+        (Starlette(routes=[Mount(\"/\", app=app)]), does_not_raise()),\n+    ],\n+)\n+def test_too_many_fields_raise(app, expectation, test_client_factory):\n+    client = test_client_factory(app)\n+    fields = []\n+    for i in range(1001):\n+        fields.append(\n+            \"--B\\r\\n\" f'Content-Disposition: form-data; name=\"N{i}\";\\r\\n\\r\\n' \"\\r\\n\"\n+        )\n+    data = \"\".join(fields).encode(\"utf-8\")\n+    with expectation:\n+        res = client.post(\n+            \"/\",\n+            data=data,\n+            headers={\"Content-Type\": (\"multipart/form-data; boundary=B\")},\n+        )\n+        assert res.status_code == 400\n+        assert res.text == \"Too many fields. Maximum number of fields is 1000.\"\n+\n+\n+@pytest.mark.parametrize(\n+    \"app,expectation\",\n+    [\n+        (app, pytest.raises(MultiPartException)),\n+        (Starlette(routes=[Mount(\"/\", app=app)]), does_not_raise()),\n+    ],\n+)\n+def test_too_many_files_raise(app, expectation, test_client_factory):\n+    client = test_client_factory(app)\n+    fields = []\n+    for i in range(1001):\n+        fields.append(\n+            \"--B\\r\\n\"\n+            f'Content-Disposition: form-data; name=\"N{i}\"; filename=\"F{i}\";\\r\\n\\r\\n'\n+            \"\\r\\n\"\n+        )\n+    data = \"\".join(fields).encode(\"utf-8\")\n+    with expectation:\n+        res = client.post(\n+            \"/\",\n+            data=data,\n+            headers={\"Content-Type\": (\"multipart/form-data; boundary=B\")},\n+        )\n+        assert res.status_code == 400\n+        assert res.text == \"Too many files. Maximum number of files is 1000.\"\n+\n+\n+@pytest.mark.parametrize(\n+    \"app,expectation\",\n+    [\n+        (app, pytest.raises(MultiPartException)),\n+        (Starlette(routes=[Mount(\"/\", app=app)]), does_not_raise()),\n+    ],\n+)\n+def test_too_many_files_single_field_raise(app, expectation, test_client_factory):\n+    client = test_client_factory(app)\n+    fields = []\n+    for i in range(1001):\n+        # This uses the same field name \"N\" for all files, equivalent to a\n+        # multifile upload form field\n+        fields.append(\n+            \"--B\\r\\n\"\n+            f'Content-Disposition: form-data; name=\"N\"; filename=\"F{i}\";\\r\\n\\r\\n'\n+            \"\\r\\n\"\n+        )\n+    data = \"\".join(fields).encode(\"utf-8\")\n+    with expectation:\n+        res = client.post(\n+            \"/\",\n+            data=data,\n+            headers={\"Content-Type\": (\"multipart/form-data; boundary=B\")},\n+        )\n+        assert res.status_code == 400\n+        assert res.text == \"Too many files. Maximum number of files is 1000.\"\n+\n+\n+@pytest.mark.parametrize(\n+    \"app,expectation\",\n+    [\n+        (app, pytest.raises(MultiPartException)),\n+        (Starlette(routes=[Mount(\"/\", app=app)]), does_not_raise()),\n+    ],\n+)\n+def test_too_many_files_and_fields_raise(app, expectation, test_client_factory):\n+    client = test_client_factory(app)\n+    fields = []\n+    for i in range(1001):\n+        fields.append(\n+            \"--B\\r\\n\"\n+            f'Content-Disposition: form-data; name=\"F{i}\"; filename=\"F{i}\";\\r\\n\\r\\n'\n+            \"\\r\\n\"\n+        )\n+        fields.append(\n+            \"--B\\r\\n\" f'Content-Disposition: form-data; name=\"N{i}\";\\r\\n\\r\\n' \"\\r\\n\"\n+        )\n+    data = \"\".join(fields).encode(\"utf-8\")\n+    with expectation:\n+        res = client.post(\n+            \"/\",\n+            data=data,\n+            headers={\"Content-Type\": (\"multipart/form-data; boundary=B\")},\n+        )\n+        assert res.status_code == 400\n+        assert res.text == \"Too many files. Maximum number of files is 1000.\"\n+\n+\n+@pytest.mark.parametrize(\n+    \"app,expectation\",\n+    [\n+        (make_app_max_parts(max_fields=1), pytest.raises(MultiPartException)),\n+        (\n+            Starlette(routes=[Mount(\"/\", app=make_app_max_parts(max_fields=1))]),\n+            does_not_raise(),\n+        ),\n+    ],\n+)\n+def test_max_fields_is_customizable_low_raises(app, expectation, test_client_factory):\n+    client = test_client_factory(app)\n+    fields = []\n+    for i in range(2):\n+        fields.append(\n+            \"--B\\r\\n\" f'Content-Disposition: form-data; name=\"N{i}\";\\r\\n\\r\\n' \"\\r\\n\"\n+        )\n+    data = \"\".join(fields).encode(\"utf-8\")\n+    with expectation:\n+        res = client.post(\n+            \"/\",\n+            data=data,\n+            headers={\"Content-Type\": (\"multipart/form-data; boundary=B\")},\n+        )\n+        assert res.status_code == 400\n+        assert res.text == \"Too many fields. Maximum number of fields is 1.\"\n+\n+\n+@pytest.mark.parametrize(\n+    \"app,expectation\",\n+    [\n+        (make_app_max_parts(max_files=1), pytest.raises(MultiPartException)),\n+        (\n+            Starlette(routes=[Mount(\"/\", app=make_app_max_parts(max_files=1))]),\n+            does_not_raise(),\n+        ),\n+    ],\n+)\n+def test_max_files_is_customizable_low_raises(app, expectation, test_client_factory):\n+    client = test_client_factory(app)\n+    fields = []\n+    for i in range(2):\n+        fields.append(\n+            \"--B\\r\\n\"\n+            f'Content-Disposition: form-data; name=\"F{i}\"; filename=\"F{i}\";\\r\\n\\r\\n'\n+            \"\\r\\n\"\n+        )\n+    data = \"\".join(fields).encode(\"utf-8\")\n+    with expectation:\n+        res = client.post(\n+            \"/\",\n+            data=data,\n+            headers={\"Content-Type\": (\"multipart/form-data; boundary=B\")},\n+        )\n+        assert res.status_code == 400\n+        assert res.text == \"Too many files. Maximum number of files is 1.\"\n+\n+\n+def test_max_fields_is_customizable_high(test_client_factory):\n+    client = test_client_factory(make_app_max_parts(max_fields=2000, max_files=2000))\n+    fields = []\n+    for i in range(2000):\n+        fields.append(\n+            \"--B\\r\\n\" f'Content-Disposition: form-data; name=\"N{i}\";\\r\\n\\r\\n' \"\\r\\n\"\n+        )\n+        fields.append(\n+            \"--B\\r\\n\"\n+            f'Content-Disposition: form-data; name=\"F{i}\"; filename=\"F{i}\";\\r\\n\\r\\n'\n+            \"\\r\\n\"\n+        )\n+    data = \"\".join(fields).encode(\"utf-8\")\n+    data += b\"--B--\\r\\n\"\n+    res = client.post(\n+        \"/\",\n+        data=data,\n+        headers={\"Content-Type\": (\"multipart/form-data; boundary=B\")},\n+    )\n+    assert res.status_code == 200\n+    res_data = res.json()\n+    assert res_data[\"N1999\"] == \"\"\n+    assert res_data[\"F1999\"] == {\n+        \"filename\": \"F1999\",\n+        \"size\": 0,\n+        \"content\": \"\",\n+        \"content_type\": None,\n+    }"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 3,
        "max_directory_depth": 1
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "0109dce29b76c64e93c56c01fa5020860f935ed3",
            "date": "2025-01-04T09:52:50Z",
            "author_login": "Kludex"
          },
          {
            "sha": "0ad90dcbe26e2cf70858d54dcb1ad724977738ae",
            "date": "2025-01-03T13:24:19Z",
            "author_login": "dependabot[bot]"
          },
          {
            "sha": "950f528bf5f620f68c10fc5a35939b716d38ee98",
            "date": "2025-01-03T13:16:39Z",
            "author_login": "graingert"
          },
          {
            "sha": "7c0d1e6d1a499e6eeb68d447321838be3927e83b",
            "date": "2024-12-30T21:06:32Z",
            "author_login": "Kludex"
          },
          {
            "sha": "76e053ac8221349fc068ef542fa43d20b40340d1",
            "date": "2024-12-30T07:48:16Z",
            "author_login": "Kludex"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.5,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-400",
    "description": "There MultipartParser usage in Encode's Starlette python framework before versions 0.25.0 allows an unauthenticated and remote attacker to specify any number of form fields or files which can cause excessive memory usage resulting in denial of service of the HTTP service.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2023-04-21T16:15:07.510",
    "last_modified": "2024-11-21T08:00:55.400",
    "fix_date": "2023-02-14T08:01:32Z"
  },
  "references": [
    {
      "url": "https://github.com/encode/starlette/commit/8c74c2c8dba7030154f8af18e016136bea1938fa",
      "source": "disclosure@vulncheck.com",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/encode/starlette/security/advisories/GHSA-74m5-2c7w-9w3x",
      "source": "disclosure@vulncheck.com",
      "tags": [
        "Mitigation",
        "Vendor Advisory"
      ]
    },
    {
      "url": "https://vulncheck.com/advisories/starlette-multipartparser-dos",
      "source": "disclosure@vulncheck.com",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/encode/starlette/commit/8c74c2c8dba7030154f8af18e016136bea1938fa",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/encode/starlette/security/advisories/GHSA-74m5-2c7w-9w3x",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Mitigation",
        "Vendor Advisory"
      ]
    },
    {
      "url": "https://vulncheck.com/advisories/starlette-multipartparser-dos",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:05:11.822327",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "starlette",
    "owner": "encode",
    "created_at": "2018-06-25T13:16:21Z",
    "updated_at": "2025-01-14T10:55:54Z",
    "pushed_at": "2025-01-04T09:54:35Z",
    "size": 7018,
    "stars": 10460,
    "forks": 954,
    "open_issues": 39,
    "watchers": 10460,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [
      "master"
    ],
    "languages": {
      "Python": 601931,
      "Shell": 3037
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "bsd-3-clause"
    },
    "collected_at": "2025-01-14T14:33:33.891852"
  }
}