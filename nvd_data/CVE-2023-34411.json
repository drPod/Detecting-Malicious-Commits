{
  "cve_id": "CVE-2023-34411",
  "github_data": {
    "repository": "netvl/xml-rs",
    "fix_commit": "0f084d45aa53e4a27476961785f59f2bd7d59a9f",
    "related_commits": [
      "0f084d45aa53e4a27476961785f59f2bd7d59a9f",
      "c09549a187e62d39d40467f129e64abf32efc35c",
      "0f084d45aa53e4a27476961785f59f2bd7d59a9f",
      "c09549a187e62d39d40467f129e64abf32efc35c"
    ],
    "patch_url": "https://github.com/netvl/xml-rs/commit/0f084d45aa53e4a27476961785f59f2bd7d59a9f.patch",
    "fix_commit_details": {
      "sha": "0f084d45aa53e4a27476961785f59f2bd7d59a9f",
      "commit_date": "2023-05-06T20:34:40Z",
      "author": {
        "login": "kornelski",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Parse DOCTYPE markup declarations",
        "length": 33,
        "has_description": false,
        "references_issue": false
      },
      "stats": {
        "total": 181,
        "additions": 132,
        "deletions": 49
      },
      "files": [
        {
          "filename": "README.md",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -25,8 +25,9 @@ clean manner.\n \n This parser is mostly full-featured, however, there are limitations:\n * Only UTF-8 is supported;\n-* DTD validation is not supported, `<!DOCTYPE>` declarations are completely ignored; thus no\n+* There is only very rudimentary parsing of `<!DOCTYPE>` declarations; thus no\n   support for custom entities too; internal DTD declarations are likely to cause parsing errors;\n+* DTD validation is not supported;\n * attribute value normalization is not performed, and end-of-line characters are not normalized either.\n \n Other than that the parser tries to be mostly XML-1.1-compliant."
        },
        {
          "filename": "src/reader/lexer.rs",
          "status": "modified",
          "additions": 102,
          "deletions": 26,
          "patch": "@@ -54,6 +54,8 @@ pub(crate) enum Token {\n     ReferenceStart,\n     /// `;`\n     ReferenceEnd,\n+    /// `<!` of `ENTITY`\n+    MarkupDeclarationStart,\n }\n \n impl fmt::Display for Token {\n@@ -143,6 +145,7 @@ impl Token {\n     }\n }\n \n+#[derive(Copy, Clone)]\n enum State {\n     /// Default state\n     Normal,\n@@ -154,8 +157,10 @@ enum State {\n     CommentStarted,\n     /// Triggered on '<!D' up to '<!DOCTYPE'\n     DoctypeStarted(DoctypeStartedSubstate),\n+    /// Other items like `<!ELEMENT` in DTD\n+    InsideMarkupDeclaration,\n     /// Triggered after DoctypeStarted to handle sub elements\n-    DoctypeFinishing(u8),\n+    InsideDoctype,\n     /// Triggered on '<![' up to '<![CDATA'\n     CDataStarted(CDataStartedSubstate),\n     /// Triggered on '?'\n@@ -174,6 +179,13 @@ enum State {\n     InsideCdata,\n     /// After `<?`\n     InsideProcessingInstruction,\n+    /// `<!ENTITY \"here\">`\n+    InsideMarkupDeclarationQuotedString(QuoteStyle),\n+}\n+\n+#[derive(Copy, Clone, Eq, PartialEq)]\n+enum QuoteStyle {\n+    Single, Double\n }\n \n #[derive(Copy, Clone)]\n@@ -229,6 +241,8 @@ pub(crate) struct Lexer {\n     head_pos: TextPosition,\n     char_queue: VecDeque<char>,\n     st: State,\n+    /// Default state to go back to after a tag end (may be `InsideDoctype`)\n+    normal_state: State,\n     skip_errors: bool,\n     inside_token: bool,\n     eof_handled: bool\n@@ -248,21 +262,16 @@ impl Lexer {\n             head_pos: TextPosition::new(),\n             char_queue: VecDeque::with_capacity(4),  // TODO: check size\n             st: State::Normal,\n+            normal_state: State::Normal,\n             skip_errors: false,\n             inside_token: false,\n             eof_handled: false\n         }\n     }\n \n-    /// Enables error handling so `next_token` will return `Some(Err(..))`\n-    /// upon invalid lexeme.\n-    #[inline]\n-    pub fn enable_errors(&mut self) { self.skip_errors = false; }\n-\n     /// Disables error handling so `next_token` will return `Some(Chunk(..))`\n     /// upon invalid lexeme with this lexeme content.\n-    #[inline]\n-    pub fn disable_errors(&mut self) { self.skip_errors = true; }\n+    pub(crate) fn disable_errors(&mut self) { self.skip_errors = true; }\n \n     /// Reset the eof handled flag of the lexer.\n     #[inline]\n@@ -326,9 +335,9 @@ impl Lexer {\n             State::TagStarted | State::CommentOrCDataOrDoctypeStarted |\n             State::CommentStarted | State::CDataStarted(_)| State::DoctypeStarted(_) |\n             State::CommentClosing(ClosingSubstate::Second) |\n-            State::InsideComment |\n+            State::InsideComment | State::InsideMarkupDeclaration |\n             State::InsideProcessingInstruction | State::ProcessingInstructionClosing |\n-            State::DoctypeFinishing(_) =>\n+            State::InsideDoctype | State::InsideMarkupDeclarationQuotedString(_) =>\n                 Err(self.error(\"Unexpected end of stream\")),\n             State::EmptyTagClosing =>\n                 Ok(Some(Token::Character('/'))),\n@@ -369,7 +378,7 @@ impl Lexer {\n             State::CommentStarted                 => self.comment_started(c),\n             State::CDataStarted(s)                => self.cdata_started(c, s),\n             State::DoctypeStarted(s)              => self.doctype_started(c, s),\n-            State::DoctypeFinishing(d)            => self.doctype_finishing(c, d),\n+            State::InsideDoctype                  => self.inside_doctype(c),\n             State::EmptyTagClosing                => self.empty_element_closing(c),\n             State::CommentClosing(s)              => self.comment_closing(c, s),\n             State::CDataClosing(s)                => self.cdata_closing(c, s),\n@@ -378,6 +387,8 @@ impl Lexer {\n             State::InsideCdata                    => self.inside_cdata(c),\n             State::InsideProcessingInstruction    => self.inside_processing_instruction(c),\n             State::ProcessingInstructionClosing   => self.processing_instruction_closing(c),\n+            State::InsideMarkupDeclaration       => self.markup_declaration(c),\n+            State::InsideMarkupDeclarationQuotedString(q) => self.markup_declaration_string(c, q),\n         }\n     }\n \n@@ -393,6 +404,13 @@ impl Lexer {\n         Ok(Some(token))\n     }\n \n+    #[inline]\n+    fn move_to_and_reset_normal(&mut self, st: State, token: Token) -> Result {\n+        self.normal_state = st;\n+        self.st = st;\n+        Ok(Some(token))\n+    }\n+\n     #[inline]\n     fn move_to_with_unread(&mut self, st: State, cs: &[char], token: Token) -> Result {\n         self.char_queue.extend(cs.iter().copied());\n@@ -434,6 +452,7 @@ impl Lexer {\n     }\n \n     fn inside_processing_instruction(&mut self, c: char) -> Result {\n+        // These tokens are used by `<?xml?>` parser\n         match c {\n             '?'                        => self.move_to(State::ProcessingInstructionClosing),\n             '<'                        => Ok(Some(Token::OpeningTagStart)),\n@@ -461,10 +480,10 @@ impl Lexer {\n     fn tag_opened(&mut self, c: char) -> Result {\n         match c {\n             '?'                        => self.move_to_with(State::InsideProcessingInstruction, Token::ProcessingInstructionStart),\n-            '/'                        => self.move_to_with(State::Normal, Token::ClosingTagStart),\n+            '/'                        => self.move_to_with(self.normal_state, Token::ClosingTagStart),\n             '!'                        => self.move_to(State::CommentOrCDataOrDoctypeStarted),\n-            _ if is_whitespace_char(c) => self.move_to_with_unread(State::Normal, &[c], Token::OpeningTagStart),\n-            _ if is_name_char(c)       => self.move_to_with_unread(State::Normal, &[c], Token::OpeningTagStart),\n+            _ if is_whitespace_char(c) => self.move_to_with_unread(self.normal_state, &[c], Token::OpeningTagStart),\n+            _ if is_name_char(c)       => self.move_to_with_unread(self.normal_state, &[c], Token::OpeningTagStart),\n             _                          => self.handle_error(\"<\", c)\n         }\n     }\n@@ -475,6 +494,7 @@ impl Lexer {\n             '-' => self.move_to(State::CommentStarted),\n             '[' => self.move_to(State::CDataStarted(CDataStartedSubstate::E)),\n             'D' => self.move_to(State::DoctypeStarted(DoctypeStartedSubstate::D)),\n+            'E' | 'A' | 'N' if matches!(self.normal_state, State::InsideDoctype) => self.move_to_with(State::InsideMarkupDeclaration, Token::MarkupDeclarationStart),\n             _ => self.handle_error(\"<!\", c),\n         }\n     }\n@@ -500,6 +520,27 @@ impl Lexer {\n         )\n     }\n \n+    /// Encountered '<!\u2026' that isn't DOCTYPE or CDATA\n+    fn markup_declaration(&mut self, c: char) -> Result {\n+        match c {\n+            '<'                        => self.handle_error(\"<!\", c),\n+            '>'                        => self.move_to_with(self.normal_state, Token::TagEnd),\n+            '&'                        => Ok(Some(Token::ReferenceStart)),\n+            ';'                        => Ok(Some(Token::ReferenceEnd)),\n+            '\"'                        => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Double), Token::DoubleQuote),\n+            '\\''                       => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Single), Token::SingleQuote),\n+            _ => Ok(None),\n+        }\n+    }\n+\n+    fn markup_declaration_string(&mut self, c: char, q: QuoteStyle) -> Result {\n+        match c {\n+            '\"' if q == QuoteStyle::Double  => self.move_to_with(State::InsideMarkupDeclaration, Token::DoubleQuote),\n+            '\\'' if q == QuoteStyle::Single => self.move_to_with(State::InsideMarkupDeclaration, Token::SingleQuote),\n+            _ => Ok(None),\n+        }\n+    }\n+\n     /// Encountered '<!D'\n     fn doctype_started(&mut self, c: char, s: DoctypeStartedSubstate) -> Result {\n         use self::DoctypeStartedSubstate::{D, DO, DOC, DOCT, DOCTY, DOCTYP};\n@@ -509,33 +550,34 @@ impl Lexer {\n             DOC    ; 'T' ; DOCT   ; \"<!DOC\",\n             DOCT   ; 'Y' ; DOCTY  ; \"<!DOCT\",\n             DOCTY  ; 'P' ; DOCTYP ; \"<!DOCTY\";\n-            DOCTYP ; 'E' ; \"<!DOCTYP\" ; self.move_to_with(State::DoctypeFinishing(1), Token::DoctypeStart)\n+            DOCTYP ; 'E' ; \"<!DOCTYP\" ; self.move_to_and_reset_normal(State::InsideDoctype, Token::DoctypeStart)\n         )\n     }\n \n     /// State used while awaiting the closing bracket for the <!DOCTYPE tag\n-    fn doctype_finishing(&mut self, c: char, d: u8) -> Result {\n+    fn inside_doctype(&mut self, c: char) -> Result {\n         match c {\n-            '<' => self.move_to(State::DoctypeFinishing(d + 1)),\n-            '>' if d == 1 => self.move_to_with(State::Normal, Token::TagEnd),\n-            '>' => self.move_to(State::DoctypeFinishing(d - 1)),\n+            '>' => self.move_to_and_reset_normal(State::Normal, Token::TagEnd),\n+            '<'                        => self.move_to(State::TagStarted),\n+            '&'                        => Ok(Some(Token::ReferenceStart)),\n+            ';'                        => Ok(Some(Token::ReferenceEnd)),\n             _ => Ok(None),\n         }\n     }\n \n     /// Encountered '?'\n     fn processing_instruction_closing(&mut self, c: char) -> Result {\n         match c {\n-            '>' => self.move_to_with(State::Normal, Token::ProcessingInstructionEnd),\n+            '>' => self.move_to_with(self.normal_state, Token::ProcessingInstructionEnd),\n             _ => self.move_to_with_unread(State::InsideProcessingInstruction, &[c], Token::Character('?')),\n         }\n     }\n \n     /// Encountered '/'\n     fn empty_element_closing(&mut self, c: char) -> Result {\n         match c {\n-            '>' => self.move_to_with(State::Normal, Token::EmptyTagEnd),\n-            _ => self.move_to_with_unread(State::Normal, &[c], Token::Character('/')),\n+            '>' => self.move_to_with(self.normal_state, Token::EmptyTagEnd),\n+            _ => self.move_to_with_unread(self.normal_state, &[c], Token::Character('/')),\n         }\n     }\n \n@@ -547,7 +589,7 @@ impl Lexer {\n                 _ => self.move_to_with_unread(State::InsideComment, &[c], Token::Character('-')),\n             },\n             ClosingSubstate::Second => match c {\n-                '>' => self.move_to_with(State::Normal, Token::CommentEnd),\n+                '>' => self.move_to_with(self.normal_state, Token::CommentEnd),\n                 // double dash not followed by a greater-than is a hard error inside comment\n                 _ => self.handle_error(\"--\", c),\n             },\n@@ -576,7 +618,7 @@ impl Lexer {\n                 _ => self.move_to_with_unread(State::Normal, &[c], Token::Character(']')),\n             },\n             ClosingSubstate::Second => match c {\n-                '>' => self.move_to_with(State::Normal, Token::CDataEnd),\n+                '>' => self.move_to_with(self.normal_state, Token::CDataEnd),\n                 _ => self.move_to_with_unread(State::Normal, &[']', c], Token::Character(']')),\n             },\n         }\n@@ -825,19 +867,54 @@ mod tests {\n     #[test]\n     fn doctype_with_internal_subset_test() {\n         let (mut lex, mut buf) = make_lex_and_buf(\n-            r#\"<a><!DOCTYPE ab[<!ELEMENT ba> ]> \"#\n+            r#\"<a><!DOCTYPE ab[<!ELEMENT ba \">>>>>\"> ]> \"#\n         );\n         assert_oks!(for lex and buf ;\n             Token::OpeningTagStart\n             Token::Character('a')\n             Token::TagEnd\n             Token::DoctypeStart\n+            Token::MarkupDeclarationStart\n+            Token::DoubleQuote\n+            Token::DoubleQuote\n+            Token::TagEnd\n             Token::TagEnd\n             Token::Whitespace(' ')\n         );\n         assert_none!(for lex and buf);\n     }\n \n+    #[test]\n+    fn doctype_internal_pi_comment() {\n+        let (mut lex, mut buf) = make_lex_and_buf(\n+            \"<!DOCTYPE a [\\n<!ELEMENT leopard ANY> <!-- <?non?>--> <?pi > ?> \\n]>\"\n+        );\n+        assert_oks!(for lex and buf ;\n+            Token::DoctypeStart\n+            Token::MarkupDeclarationStart\n+            Token::TagEnd\n+            Token::CommentStart\n+            Token::Whitespace(' ')\n+            Token::Character('<')\n+            Token::Character('?')\n+            Token::Character('n')\n+            Token::Character('o')\n+            Token::Character('n')\n+            Token::Character('?')\n+            Token::Character('>')\n+            Token::CommentEnd\n+            Token::ProcessingInstructionStart\n+            Token::Character('p')\n+            Token::Character('i')\n+            Token::Whitespace(' ')\n+            Token::TagEnd // not really\n+            Token::Whitespace(' ')\n+            Token::ProcessingInstructionEnd\n+            Token::TagEnd // DTD\n+        );\n+        assert_none!(for lex and buf);\n+    }\n+\n     #[test]\n     fn end_of_stream_handling_ok() {\n         macro_rules! eof_check(\n@@ -872,7 +949,6 @@ mod tests {\n         eof_check!(\"<![CDA\"   ; 0, 6);\n         eof_check!(\"<![CDAT\"  ; 0, 7);\n         eof_check!(\"<![CDATA\" ; 0, 8);\n-        // eof_check!(\"--\"       ; 0, 2);\n     }\n \n     #[test]"
        },
        {
          "filename": "src/reader/parser/inside_cdata.rs",
          "status": "modified",
          "additions": 0,
          "deletions": 1,
          "patch": "@@ -7,7 +7,6 @@ impl PullParser {\n     pub fn inside_cdata(&mut self, t: Token) -> Option<Result> {\n         match t {\n             Token::CDataEnd => {\n-                self.lexer.enable_errors();\n                 let event = if self.config.cdata_to_characters {\n                     None\n                 } else {"
        },
        {
          "filename": "src/reader/parser/inside_doctype.rs",
          "status": "modified",
          "additions": 14,
          "deletions": 1,
          "patch": "@@ -6,10 +6,23 @@ impl PullParser {\n     pub fn inside_doctype(&mut self, t: Token) -> Option<Result> {\n         match t {\n             Token::TagEnd => {\n-                self.lexer.enable_errors();\n                 self.into_state_continue(State::OutsideTag)\n             }\n \n+            Token::MarkupDeclarationStart => {\n+                self.into_state_continue(State::InsideDoctypeMarkupDeclaration)\n+            },\n+\n+            _ => None,\n+        }\n+    }\n+\n+    pub fn inside_doctype_markup_declaration(&mut self, t: Token) -> Option<Result> {\n+        match t {\n+            Token::TagEnd => {\n+                self.into_state_continue(State::InsideDoctype)\n+            }\n+\n             _ => None,\n         }\n     }"
        },
        {
          "filename": "src/reader/parser/inside_processing_instruction.rs",
          "status": "modified",
          "additions": 0,
          "deletions": 1,
          "patch": "@@ -68,7 +68,6 @@ impl PullParser {\n \n             ProcessingInstructionSubstate::PIInsideData => match t {\n                 Token::ProcessingInstructionEnd => {\n-                    self.lexer.enable_errors();\n                     let name = self.data.take_name();\n                     let data = self.take_buf();\n                     self.into_state_emit("
        },
        {
          "filename": "src/reader/parser/mod.rs",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -139,6 +139,7 @@ pub enum State {\n     InsideCData,\n     InsideDeclaration(DeclarationSubstate),\n     InsideDoctype,\n+    InsideDoctypeMarkupDeclaration,\n     InsideReference(Box<State>),\n }\n \n@@ -337,6 +338,7 @@ impl PullParser {\n             State::InsideProcessingInstruction(s) => self.inside_processing_instruction(t, s),\n             State::InsideDeclaration(s)           => self.inside_declaration(t, s),\n             State::InsideDoctype                  => self.inside_doctype(t),\n+            State::InsideDoctypeMarkupDeclaration => self.inside_doctype_markup_declaration(t),\n             State::InsideOpeningTag(s)            => self.inside_opening_tag(t, s),\n             State::InsideClosingTag(s)            => self.inside_closing_tag_name(t, s),\n             State::InsideComment                  => self.inside_comment(t),"
        },
        {
          "filename": "src/reader/parser/outside_tag.rs",
          "status": "modified",
          "additions": 0,
          "deletions": 1,
          "patch": "@@ -81,7 +81,6 @@ impl PullParser {\n                         // We don't have a doctype event so skip this position\n                         // FIXME: update when we have a doctype event\n                         self.next_pos();\n-                        self.lexer.disable_errors();\n                         self.into_state(State::InsideDoctype, next_event)\n                     }\n "
        },
        {
          "filename": "tests/xmlconf.rs",
          "status": "modified",
          "additions": 12,
          "deletions": 18,
          "patch": "@@ -116,7 +116,6 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"rmt-e2e-18\", // External entity containing start of entity declaration is base URI for system identifier\n         \"rmt-e2e-19\", // Parameter entities and character references are included-in-literal, but general entities are bypassed.\n         \"rmt-e2e-22\", // UTF-8 entities may start with a BOM\n-        \"rmt-e2e-24\", // Either the built-in entity or a character reference can be used to represent greater-than after two close-square-brackets\n         \"rmt-e2e-34\", // A non-deterministic content model is an error even if the element type is not used.\n         \"rmt-e2e-50\", // All line-ends are normalized, even those not passed to the application. NB this can only be tested effectively in XML 1.1, since CR is in the S production; in 1.1 we can use NEL which isn't.\n         \"rmt-e2e-55\", // A reference to an unparsed entity in an entity value is an error rather than forbidden (unless the entity is referenced, of course)\n@@ -278,23 +277,20 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n \n #[test] fn oasis() {\n     run_suite(\"oasis/oasis.xml\", &[\n-        \"o-p43pass1\", // Valid use of character data, comments, processing instructions and CDATA sections within the start and end tag.\n-        \"o-p68pass1\", // Valid entity references.  Also ensures that a charref to           '&' isn't interpreted as an entity reference open delimiter\n-        \"o-p04pass1\", // names with all valid ASCII characters, and one from each               other class in NameChar\n-        \"o-p05pass1\", // various valid Name constructions\n         \"o-p01fail1\", // S cannot occur before the prolog\n         \"o-p01fail2\", // comments cannot occur before the prolog\n         \"o-p01fail3\", // only one document element\n+        \"o-p04pass1\", // names with all valid ASCII characters, and one from each               other class in NameChar\n+        \"o-p05pass1\", // various valid Name constructions\n         \"o-p09fail1\", // EntityValue excludes '%'\n         \"o-p09fail2\", // EntityValue excludes '&'\n         \"o-p09fail3\", // incomplete character reference\n-        \"o-p09fail4\", // quote types must match\n-        \"o-p09fail5\", // quote types must match\n-        \"o-p11fail1\", // quote types must match\n-        \"o-p11fail2\", // cannot contain delimiting quotes\n-        \"o-p12fail1\", // '\"' excluded\n+        \"o-p11pass1\", // p11pass1.xml       system literals may not contain     URI fragments\n+        \"o-p12fail1\", // p12fail1.xml       '\"' excluded\n         \"o-p12fail2\", // '\\' excluded\n         \"o-p12fail3\", // entity references excluded\n+        \"o-p12fail4\", // p12fail4.xml       '>' excluded\n+        \"o-p12fail5\", // p12fail5.xml       '<' excluded\n         \"o-p12fail6\", // built-in entity refs excluded\n         \"o-p12fail7\", // The public ID has a tab character, which is disallowed\n         \"o-p14fail3\", // \"]]>\" excluded\n@@ -303,13 +299,12 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"o-p22fail2\", // prolog must start with XML decl\n         \"o-p23fail1\", // \"xml\" must be lower-case\n         \"o-p27fail1\", // References aren't allowed in Misc,     even if they would resolve to valid Misc.\n-        \"o-p29fail1\", // A processor must not pass unknown declaration types.\n         \"o-p30fail1\", // An XML declaration is not the same as a TextDecl\n         \"o-p31fail1\", // external subset excludes doctypedecl\n         \"o-p32fail3\", // initial S is required\n         \"o-p40fail1\", // S is required between attributes\n+        \"o-p43pass1\", // Valid use of character data, comments, processing instructions and CDATA sections within the start and end tag.\n         \"o-p44fail4\", // Whitespace required between attributes.\n-        \"o-p45fail1\", // ELEMENT must be upper case.\n         \"o-p45fail2\", // S before contentspec is required.\n         \"o-p45fail3\", // only one content spec\n         \"o-p45fail4\", // no comments in declarations (contrast with SGML)\n@@ -371,17 +366,18 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"o-p64fail1\", // section delimiters must balance\n         \"o-p64fail2\", // section delimiters must balance\n         \"o-p66fail5\", // no references to non-characters\n+        \"o-p68pass1\", // Valid entity references.  Also ensures that a charref to           '&' isn't interpreted as an entity reference open delimiter\n         \"o-p69fail1\", // terminating ';' is required\n         \"o-p69fail2\", // no S after '%'\n         \"o-p69fail3\", // no S before ';'\n         \"o-p70fail1\", // This is neither\n         \"o-p71fail1\", // S is required before EntityDef\n         \"o-p71fail2\", // Entity name is a Name, not an NMToken\n-        \"o-p71fail3\", // no S after \"<!\"\n         \"o-p71fail4\", // S is required after \"<!ENTITY\"\n         \"o-p72fail1\", // S is required after \"<!ENTITY\"\n         \"o-p72fail2\", // S is required after '%'\n         \"o-p72fail3\", // S is required after name\n+        \"o-p76fail4\", // p76fail4.xml       notation names are Names\n         \"o-p72fail4\", // Entity name is a name, not an NMToken\n         \"o-p73fail1\", // No typed replacement text\n         \"o-p73fail2\", // Only one replacement value\n@@ -438,8 +434,6 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"content02\", // No whitespace before \"*\" in content model\n         \"content03\", // No whitespace before \"+\" in content model\n         \"decl01\", // External entities may not have standalone decls.\n-        \"nwf-dtd00\", // Comma mandatory in content model\n-        \"nwf-dtd01\", // Can't mix comma and vertical bar in content models\n         \"dtd02\", // PE name immediately after \"%\"\n         \"dtd03\", // PE name immediately followed by \";\"\n         \"dtd04\", // PUBLIC literal must be quoted\n@@ -451,6 +445,9 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"encoding04\", // Illegal character \":\" in encoding name\n         \"encoding05\", // Illegal character \"@\" in encoding name\n         \"encoding06\", // Illegal character \"+\" in encoding name\n+        \"nwf-dtd00\", // Comma mandatory in content model\n+        \"nwf-dtd01\", // Can't mix comma and vertical bar in content models\n+        \"pi\", // pi.xml      No space between PI target name and data\n         \"pubid01\", // Illegal entity ref in public ID\n         \"pubid02\", // Illegal characters in public ID\n         \"pubid03\", // Illegal characters in public ID\n@@ -502,7 +499,6 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"not-wf-sa-060\", // Invalid type NAME defined in ATTLIST.\n         \"not-wf-sa-061\", // External entity declarations require whitespace between public     and system IDs.\n         \"not-wf-sa-062\", // Entity declarations need space after the entity name.\n-        \"not-wf-sa-063\", // Conditional sections may only appear in the external     DTD subset.\n         \"not-wf-sa-064\", // Space is required between attribute type and default values     in <!ATTLIST...> declarations.\n         \"not-wf-sa-065\", // Space is required between attribute name and type     in <!ATTLIST...> declarations.\n         \"not-wf-sa-066\", // Required whitespace is missing.\n@@ -523,7 +519,6 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"not-wf-sa-101\", // Space is not permitted in an encoding name.\n         \"not-wf-sa-105\", // Invalid placement of CDATA section.\n         \"not-wf-sa-106\", // Invalid placement of entity declaration.\n-        \"not-wf-sa-107\", // Invalid document type declaration.  CDATA alone is invalid.\n         \"not-wf-sa-113\", // Parameter entity values must use valid reference syntax;     this reference is malformed.\n         \"not-wf-sa-114\", // General entity values must use valid reference syntax;     this reference is malformed.\n         \"not-wf-sa-121\", // A name of an ENTITY was started with an invalid character.\n@@ -566,7 +561,6 @@ fn expect_ill_formed(xml_path: &Path, msg: &str, id: &str) -> Result<(), Box<dyn\n         \"not-wf-sa-174\", // Character FFFF is not legal anywhere in an XML document.\n         \"not-wf-sa-175\", // Character FFFF is not legal anywhere in an XML document.\n         \"not-wf-sa-177\", // Character FFFF is not legal anywhere in an XML document.\n-        \"not-wf-sa-179\", // Invalid syntax matching double quote is missing.\n         \"not-wf-sa-180\", // The Entity Declared WFC requires entities to be declared     before they are used in an attribute list declaration.\n         \"not-wf-sa-183\", // Mixed content declarations may not include content particles.\n         \"not-wf-sa-184\", // In mixed content models, element names must not be     parenthesized."
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 4,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "c949fd480d95d1681a2beb99e16103383b0cd673",
            "date": "2024-03-31T17:18:34Z",
            "author_login": "kornelski"
          },
          {
            "sha": "a7b8acd46deca0b7bfa4ca906acd60655ee1fb5b",
            "date": "2024-03-31T17:05:42Z",
            "author_login": "kornelski"
          },
          {
            "sha": "4de4170b0040f955fe15c862f57f02c21c798a09",
            "date": "2024-03-31T13:56:38Z",
            "author_login": "kornelski"
          },
          {
            "sha": "068b50d98230d13e48831f64a1587448cf595587",
            "date": "2024-03-31T13:38:16Z",
            "author_login": "kornelski"
          },
          {
            "sha": "910a499ec8cce49afb20c355cf89d7b27f65a988",
            "date": "2024-03-31T13:32:08Z",
            "author_login": "kornelski"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.5,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-611",
    "description": "The xml-rs crate before 0.8.14 for Rust and Crab allows a denial of service (panic) via an invalid <! token (such as <!DOCTYPEs/%<!A nesting) in an XML document. The earliest affected version is 0.8.9.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2023-06-05T04:15:11.153",
    "last_modified": "2025-01-08T17:15:13.440",
    "fix_date": "2023-05-06T20:34:40Z"
  },
  "references": [
    {
      "url": "https://github.com/00xc/xml-rs/commit/0f084d45aa53e4a27476961785f59f2bd7d59a9f",
      "source": "cve@mitre.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/netvl/xml-rs/commit/c09549a187e62d39d40467f129e64abf32efc35c",
      "source": "cve@mitre.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/netvl/xml-rs/compare/0.8.13...0.8.14",
      "source": "cve@mitre.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/netvl/xml-rs/pull/226",
      "source": "cve@mitre.org",
      "tags": [
        "Exploit"
      ]
    },
    {
      "url": "https://github.com/00xc/xml-rs/commit/0f084d45aa53e4a27476961785f59f2bd7d59a9f",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/netvl/xml-rs/commit/c09549a187e62d39d40467f129e64abf32efc35c",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/netvl/xml-rs/compare/0.8.13...0.8.14",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/netvl/xml-rs/pull/226",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:05:59.302361",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "xml-rs",
    "owner": "netvl",
    "created_at": "2014-06-07T21:37:51Z",
    "updated_at": "2025-01-03T11:55:49Z",
    "pushed_at": "2024-03-31T17:18:49Z",
    "size": 3538,
    "stars": 462,
    "forks": 114,
    "open_issues": 17,
    "watchers": 462,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "Rust": 304595
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "mit"
    },
    "collected_at": "2025-01-14T21:16:21.326351"
  }
}