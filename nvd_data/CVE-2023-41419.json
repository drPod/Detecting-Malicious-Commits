{
  "cve_id": "CVE-2023-41419",
  "github_data": {
    "repository": "gevent/gevent",
    "fix_commit": "2f53c851eaf926767fbac62385615efd4886221c",
    "related_commits": [
      "2f53c851eaf926767fbac62385615efd4886221c",
      "2f53c851eaf926767fbac62385615efd4886221c"
    ],
    "patch_url": "https://github.com/gevent/gevent/commit/2f53c851eaf926767fbac62385615efd4886221c.patch",
    "fix_commit_details": {
      "sha": "2f53c851eaf926767fbac62385615efd4886221c",
      "commit_date": "2023-08-31T22:05:48Z",
      "author": {
        "login": "jamadden",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "gevent.pywsgi: Much improved handling of chunk trailers.",
        "length": 120,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 452,
        "additions": 386,
        "deletions": 66
      },
      "files": [
        {
          "filename": "docs/changes/1989.bugfix",
          "status": "added",
          "additions": 26,
          "deletions": 0,
          "patch": "@@ -0,0 +1,26 @@\n+Make ``gevent.pywsgi`` comply more closely with the HTTP specification\n+for chunked transfer encoding. In particular, we are much stricter\n+about trailers, and trailers that are invalid (too long or featuring\n+disallowed characters) forcibly close the connection to the client\n+*after* the results have been sent.\n+\n+Trailers otherwise continue to be ignored and are not available to the\n+WSGI application.\n+\n+Previously, carefully crafted invalid trailers in chunked requests on\n+keep-alive connections might appear as two requests to\n+``gevent.pywsgi``. Because this was handled exactly as a normal\n+keep-alive connection with two requests, the WSGI application should\n+handle it normally. However, if you were counting on some upstream\n+server to filter incoming requests based on paths or header fields,\n+and the upstream server simply passed trailers through without\n+validating them, then this embedded second request would bypass those\n+checks. (If the upstream server validated that the trailers meet the\n+HTTP specification, this could not occur, because characters that are\n+required in an HTTP request, like a space, are not allowed in\n+trailers.) CVE-2023-41419 was reserved for this.\n+\n+Our thanks to the original reporters, Keran Mu\n+(mkr22@mails.tsinghua.edu.cn) and Jianjun Chen\n+(jianjun@tsinghua.edu.cn), from Tsinghua University and Zhongguancun\n+Laboratory."
        },
        {
          "filename": "src/gevent/pywsgi.py",
          "status": "modified",
          "additions": 175,
          "deletions": 49,
          "patch": "@@ -13,7 +13,19 @@\n    This server is intended primarily for development and testing, and\n    secondarily for other \"safe\" scenarios where it will not be exposed to\n    potentially malicious input. The code has not been security audited,\n-   and is not intended for direct exposure to the public Internet.\n+   and is not intended for direct exposure to the public Internet. For production\n+   usage on the Internet, either choose a production-strength server such as\n+   gunicorn, or put a reverse proxy between gevent and the Internet.\n+\n+.. versionchanged:: NEXT\n+\n+   Complies more closely with the HTTP specification for chunked transfer encoding.\n+   In particular, we are much stricter about trailers, and trailers that\n+   are invalid (too long or featuring disallowed characters) forcibly close\n+   the connection to the client *after* the results have been sent.\n+\n+   Trailers otherwise continue to be ignored and are not available to the\n+   WSGI application.\n \n \"\"\"\n from __future__ import absolute_import\n@@ -29,10 +41,7 @@\n import traceback\n from datetime import datetime\n \n-try:\n-    from urllib import unquote\n-except ImportError:\n-    from urllib.parse import unquote # python 2 pylint:disable=import-error,no-name-in-module\n+from urllib.parse import unquote\n \n from gevent import socket\n import gevent\n@@ -57,29 +66,52 @@\n \n MAX_REQUEST_LINE = 8192\n # Weekday and month names for HTTP date/time formatting; always English!\n-_WEEKDAYNAME = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n-_MONTHNAME = [None,  # Dummy so we can use 1-based month numbers\n+_WEEKDAYNAME = (\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")\n+_MONTHNAME = (None,  # Dummy so we can use 1-based month numbers\n               \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n-              \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n+              \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n \n # The contents of the \"HEX\" grammar rule for HTTP, upper and lowercase A-F plus digits,\n # in byte form for comparing to the network.\n _HEX = string.hexdigits.encode('ascii')\n \n+# The characters allowed in \"token\" rules.\n+\n+# token          = 1*tchar\n+# tchar          = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"\n+#                / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"\n+#                / DIGIT / ALPHA\n+#                ; any VCHAR, except delimiters\n+# ALPHA          =  %x41-5A / %x61-7A   ; A-Z / a-z\n+_ALLOWED_TOKEN_CHARS = frozenset(\n+    # Remember we have to be careful because bytestrings\n+    # inexplicably iterate as integers, which are not equal to bytes.\n+\n+    # explicit chars then DIGIT\n+    (c.encode('ascii') for c in \"!#$%&'*+-.^_`|~0123456789\")\n+    # Then we add ALPHA\n+) | {c.encode('ascii') for c in string.ascii_letters}\n+assert b'A' in _ALLOWED_TOKEN_CHARS\n+\n+\n # Errors\n _ERRORS = {}\n _INTERNAL_ERROR_STATUS = '500 Internal Server Error'\n _INTERNAL_ERROR_BODY = b'Internal Server Error'\n-_INTERNAL_ERROR_HEADERS = [('Content-Type', 'text/plain'),\n-                           ('Connection', 'close'),\n-                           ('Content-Length', str(len(_INTERNAL_ERROR_BODY)))]\n+_INTERNAL_ERROR_HEADERS = (\n+    ('Content-Type', 'text/plain'),\n+    ('Connection', 'close'),\n+    ('Content-Length', str(len(_INTERNAL_ERROR_BODY)))\n+)\n _ERRORS[500] = (_INTERNAL_ERROR_STATUS, _INTERNAL_ERROR_HEADERS, _INTERNAL_ERROR_BODY)\n \n _BAD_REQUEST_STATUS = '400 Bad Request'\n _BAD_REQUEST_BODY = ''\n-_BAD_REQUEST_HEADERS = [('Content-Type', 'text/plain'),\n-                        ('Connection', 'close'),\n-                        ('Content-Length', str(len(_BAD_REQUEST_BODY)))]\n+_BAD_REQUEST_HEADERS = (\n+    ('Content-Type', 'text/plain'),\n+    ('Connection', 'close'),\n+    ('Content-Length', str(len(_BAD_REQUEST_BODY)))\n+)\n _ERRORS[400] = (_BAD_REQUEST_STATUS, _BAD_REQUEST_HEADERS, _BAD_REQUEST_BODY)\n \n _REQUEST_TOO_LONG_RESPONSE = b\"HTTP/1.1 414 Request URI Too Long\\r\\nConnection: close\\r\\nContent-length: 0\\r\\n\\r\\n\"\n@@ -207,40 +239,53 @@ def __read_chunk_length(self, rfile):\n         # Read and return the next integer chunk length. If no\n         # chunk length can be read, raises _InvalidClientInput.\n \n-        # Here's the production for a chunk:\n-        # (http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html)\n-        #   chunk          = chunk-size [ chunk-extension ] CRLF\n-        #                    chunk-data CRLF\n-        #   chunk-size     = 1*HEX\n-        #   chunk-extension= *( \";\" chunk-ext-name [ \"=\" chunk-ext-val ] )\n-        #   chunk-ext-name = token\n-        #   chunk-ext-val  = token | quoted-string\n-\n-        # To cope with malicious or broken clients that fail to send valid\n-        # chunk lines, the strategy is to read character by character until we either reach\n-        # a ; or newline. If at any time we read a non-HEX digit, we bail. If we hit a\n-        # ;, indicating an chunk-extension, we'll read up to the next\n-        # MAX_REQUEST_LINE characters\n-        # looking for the CRLF, and if we don't find it, we bail. If we read more than 16 hex characters,\n-        # (the number needed to represent a 64-bit chunk size), we bail (this protects us from\n-        # a client that sends an infinite stream of `F`, for example).\n+        # Here's the production for a chunk (actually the whole body):\n+        # (https://www.rfc-editor.org/rfc/rfc7230#section-4.1)\n+\n+        # chunked-body   = *chunk\n+        #                  last-chunk\n+        #                  trailer-part\n+        #                  CRLF\n+        #\n+        # chunk          = chunk-size [ chunk-ext ] CRLF\n+        #                  chunk-data CRLF\n+        # chunk-size     = 1*HEXDIG\n+        # last-chunk     = 1*(\"0\") [ chunk-ext ] CRLF\n+        # trailer-part   = *( header-field CRLF )\n+        # chunk-data     = 1*OCTET ; a sequence of chunk-size octets\n+\n+        # To cope with malicious or broken clients that fail to send\n+        # valid chunk lines, the strategy is to read character by\n+        # character until we either reach a ; or newline. If at any\n+        # time we read a non-HEX digit, we bail. If we hit a ;,\n+        # indicating an chunk-extension, we'll read up to the next\n+        # MAX_REQUEST_LINE characters (\"A server ought to limit the\n+        # total length of chunk extensions received\") looking for the\n+        # CRLF, and if we don't find it, we bail. If we read more than\n+        # 16 hex characters, (the number needed to represent a 64-bit\n+        # chunk size), we bail (this protects us from a client that\n+        # sends an infinite stream of `F`, for example).\n \n         buf = BytesIO()\n         while 1:\n             char = rfile.read(1)\n             if not char:\n                 self._chunked_input_error = True\n                 raise _InvalidClientInput(\"EOF before chunk end reached\")\n-            if char == b'\\r':\n-                break\n-            if char == b';':\n+\n+            if char in (\n+                b'\\r', # Beginning EOL\n+                b';', # Beginning extension\n+            ):\n                 break\n \n-            if char not in _HEX:\n+            if char not in _HEX: # Invalid data.\n                 self._chunked_input_error = True\n                 raise _InvalidClientInput(\"Non-hex data\", char)\n+\n             buf.write(char)\n-            if buf.tell() > 16:\n+\n+            if buf.tell() > 16: # Too many hex bytes\n                 self._chunked_input_error = True\n                 raise _InvalidClientInput(\"Chunk-size too large.\")\n \n@@ -260,11 +305,72 @@ def __read_chunk_length(self, rfile):\n         if char == b'\\r':\n             # We either got here from the main loop or from the\n             # end of an extension\n+            self.__read_chunk_size_crlf(rfile, newline_only=True)\n+            result = int(buf.getvalue(), 16)\n+            if result == 0:\n+                # The only time a chunk size of zero is allowed is the final\n+                # chunk. It is either followed by another \\r\\n, or some trailers\n+                # which are then followed by \\r\\n.\n+                while self.__read_chunk_trailer(rfile):\n+                    pass\n+            return result\n+\n+    # Trailers have the following production (they are a header-field followed by CRLF)\n+    # See above for the definition of \"token\".\n+    #\n+    # header-field   = field-name \":\" OWS field-value OWS\n+    # field-name     = token\n+    # field-value    = *( field-content / obs-fold )\n+    # field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]\n+    # field-vchar    = VCHAR / obs-text\n+    # obs-fold       = CRLF 1*( SP / HTAB )\n+    #                ; obsolete line folding\n+    #                ; see Section 3.2.4\n+\n+\n+    def __read_chunk_trailer(self, rfile, ):\n+        # With rfile positioned just after a \\r\\n, read a trailer line.\n+        # Return a true value if a non-empty trailer was read, and\n+        # return false if an empty trailer was read (meaning the trailers are\n+        # done).\n+        # If a single line exceeds the MAX_REQUEST_LINE, raise an exception.\n+        # If the field-name portion contains invalid characters, raise an exception.\n+\n+        i = 0\n+        empty = True\n+        seen_field_name = False\n+        while i < MAX_REQUEST_LINE:\n             char = rfile.read(1)\n-            if char != b'\\n':\n+            if char == b'\\r':\n+                # Either read the next \\n or raise an error.\n+                self.__read_chunk_size_crlf(rfile, newline_only=True)\n+                break\n+            # Not a \\r, so we are NOT an empty chunk.\n+            empty = False\n+            if char == b':' and i > 0:\n+                # We're ending the field-name part; stop validating characters.\n+                # Unless : was the first character...\n+                seen_field_name = True\n+            if not seen_field_name and char not in _ALLOWED_TOKEN_CHARS:\n+                raise _InvalidClientInput('Invalid token character: %r' % (char,))\n+            i += 1\n+        else:\n+            # We read too much\n+            self._chunked_input_error = True\n+            raise _InvalidClientInput(\"Too large chunk trailer\")\n+        return not empty\n+\n+    def __read_chunk_size_crlf(self, rfile, newline_only=False):\n+        # Also for safety, correctly verify that we get \\r\\n when expected.\n+        if not newline_only:\n+            char = rfile.read(1)\n+            if char != b'\\r':\n                 self._chunked_input_error = True\n-                raise _InvalidClientInput(\"Line didn't end in CRLF\")\n-            return int(buf.getvalue(), 16)\n+                raise _InvalidClientInput(\"Line didn't end in CRLF: %r\" % (char,))\n+        char = rfile.read(1)\n+        if char != b'\\n':\n+            self._chunked_input_error = True\n+            raise _InvalidClientInput(\"Line didn't end in LF: %r\" % (char,))\n \n     def _chunked_read(self, length=None, use_readline=False):\n         # pylint:disable=too-many-branches\n@@ -297,7 +403,7 @@ def _chunked_read(self, length=None, use_readline=False):\n \n                 self.position += datalen\n                 if self.chunk_length == self.position:\n-                    rfile.readline()\n+                    self.__read_chunk_size_crlf(rfile)\n \n                 if length is not None:\n                     length -= datalen\n@@ -310,9 +416,9 @@ def _chunked_read(self, length=None, use_readline=False):\n                 # determine the next size to read\n                 self.chunk_length = self.__read_chunk_length(rfile)\n                 self.position = 0\n-                if self.chunk_length == 0:\n-                    # Last chunk. Terminates with a CRLF.\n-                    rfile.readline()\n+                # If chunk_length was 0, we already read any trailers and\n+                # validated that we have ended with \\r\\n\\r\\n.\n+\n         return b''.join(response)\n \n     def read(self, length=None):\n@@ -531,7 +637,8 @@ def read_request(self, raw_requestline):\n         elif len(words) == 2:\n             self.command, self.path = words\n             if self.command != \"GET\":\n-                raise _InvalidClientRequest('Expected GET method: %r' % (raw_requestline,))\n+                raise _InvalidClientRequest('Expected GET method; Got command=%r; path=%r; raw=%r' % (\n+                    self.command, self.path, raw_requestline,))\n             self.request_version = \"HTTP/0.9\"\n             # QQQ I'm pretty sure we can drop support for HTTP/0.9\n         else:\n@@ -996,14 +1103,28 @@ def handle_one_response(self):\n             finally:\n                 try:\n                     self.wsgi_input._discard()\n+                except _InvalidClientInput:\n+                    # This one is deliberately raised to the outer\n+                    # scope, because, with the incoming stream in some bad state,\n+                    # we can't be sure we can synchronize and properly parse the next\n+                    # request.\n+                    raise\n                 except socket.error:\n-                    # Don't let exceptions during discarding\n+                    # Don't let socket exceptions during discarding\n                     # input override any exception that may have been\n                     # raised by the application, such as our own _InvalidClientInput.\n                     # In the general case, these aren't even worth logging (see the comment\n                     # just below)\n                     pass\n-        except _InvalidClientInput:\n+        except _InvalidClientInput as ex:\n+            # DO log this one because:\n+            # - Some of the data may have been read and acted on by the\n+            #   application;\n+            # - The response may or may not have been sent;\n+            # - It's likely that the client is bad, or malicious, and\n+            #   users might wish to take steps to block the client.\n+            self._handle_client_error(ex)\n+            self.close_connection = True\n             self._send_error_response_if_possible(400)\n         except socket.error as ex:\n             if ex.args[0] in self.ignored_socket_errors:\n@@ -1046,17 +1167,22 @@ def handle_error(self, t, v, tb):\n     def _handle_client_error(self, ex):\n         # Called for invalid client input\n         # Returns the appropriate error response.\n-        if not isinstance(ex, ValueError):\n+        if not isinstance(ex, (ValueError, _InvalidClientInput)):\n             # XXX: Why not self._log_error to send it through the loop's\n             # handle_error method?\n+            # _InvalidClientRequest is a ValueError; _InvalidClientInput is an IOError.\n             traceback.print_exc()\n         if isinstance(ex, _InvalidClientRequest):\n             # No formatting needed, that's already been handled. In fact, because the\n             # formatted message contains user input, it might have a % in it, and attempting\n             # to format that with no arguments would be an error.\n-            self.log_error(ex.formatted_message)\n+            # However, the error messages do not include the requesting IP\n+            # necessarily, so we do add that.\n+            self.log_error('(from %s) %s', self.client_address, ex.formatted_message)\n         else:\n-            self.log_error('Invalid request: %s', str(ex) or ex.__class__.__name__)\n+            self.log_error('Invalid request (from %s): %s',\n+                           self.client_address,\n+                           str(ex) or ex.__class__.__name__)\n         return ('400', _BAD_REQUEST_RESPONSE)\n \n     def _headers(self):"
        },
        {
          "filename": "src/gevent/subprocess.py",
          "status": "modified",
          "additions": 4,
          "deletions": 3,
          "patch": "@@ -360,10 +360,11 @@ def check_output(*popenargs, **kwargs):\n \n     To capture standard error in the result, use ``stderr=STDOUT``::\n \n-        >>> print(check_output([\"/bin/sh\", \"-c\",\n+        >>> output = check_output([\"/bin/sh\", \"-c\",\n         ...               \"ls -l non_existent_file ; exit 0\"],\n-        ...              stderr=STDOUT).decode('ascii').strip())\n-        ls: non_existent_file: No such file or directory\n+        ...              stderr=STDOUT).decode('ascii').strip()\n+        >>> print(output.rsplit(':', 1)[1].strip())\n+        No such file or directory\n \n     There is an additional optional argument, \"input\", allowing you to\n     pass a string to the subprocess's stdin.  If you use this argument"
        },
        {
          "filename": "src/gevent/testing/testcase.py",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -225,7 +225,7 @@ def __new__(cls, classname, bases, classDict):\n                 classDict.pop(key)\n                 # XXX: When did we stop doing this?\n                 #value = wrap_switch_count_check(value)\n-                value = _wrap_timeout(timeout, value)\n+                #value = _wrap_timeout(timeout, value)\n                 error_fatal = getattr(value, 'error_fatal', error_fatal)\n                 if error_fatal:\n                     value = errorhandler.wrap_error_fatal(value)"
        },
        {
          "filename": "src/gevent/tests/test__pywsgi.py",
          "status": "modified",
          "additions": 180,
          "deletions": 13,
          "patch": "@@ -25,21 +25,11 @@\n monkey.patch_all()\n \n from contextlib import contextmanager\n-try:\n-    from urllib.parse import parse_qs\n-except ImportError:\n-    # Python 2\n-    from urlparse import parse_qs\n+from urllib.parse import parse_qs\n import os\n import sys\n-try:\n-    # On Python 2, we want the C-optimized version if\n-    # available; it has different corner-case behaviour than\n-    # the Python implementation, and it used by socket.makefile\n-    # by default.\n-    from cStringIO import StringIO\n-except ImportError:\n-    from io import BytesIO as StringIO\n+from io import BytesIO as StringIO\n+\n import weakref\n import unittest\n from wsgiref.validate import validator\n@@ -156,6 +146,10 @@ def assertBody(self, body):\n     @classmethod\n     def read(cls, fd, code=200, reason='default', version='1.1',\n              body=None, chunks=None, content_length=None):\n+        \"\"\"\n+        Read an HTTP response, optionally perform assertions,\n+        and return the Response object.\n+        \"\"\"\n         # pylint:disable=too-many-branches\n         _status_line, headers = read_headers(fd)\n         self = cls(_status_line, headers)\n@@ -716,7 +710,14 @@ def test_negative_nonchunked_readline(self):\n \n class TestChunkedPost(TestCase):\n \n+    calls = 0\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.calls = 0\n+\n     def application(self, env, start_response):\n+        self.calls += 1\n         self.assertTrue(env.get('wsgi.input_terminated'))\n         start_response('200 OK', [('Content-Type', 'text/plain')])\n         if env['PATH_INFO'] == '/a':\n@@ -730,6 +731,8 @@ def application(self, env, start_response):\n         if env['PATH_INFO'] == '/c':\n             return list(iter(lambda: env['wsgi.input'].read(1), b''))\n \n+        return [b'We should not get here', env['PATH_INFO'].encode('ascii')]\n+\n     def test_014_chunked_post(self):\n         data = (b'POST /a HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n'\n                 b'Transfer-Encoding: chunked\\r\\n\\r\\n'\n@@ -797,6 +800,170 @@ def test_229_incorrect_chunk_token_ext_too_long(self):\n             fd.write(data)\n             read_http(fd, code=400)\n \n+    def test_trailers_keepalive_ignored(self):\n+        # Trailers after a chunk are ignored.\n+        data = (\n+            b'POST /a HTTP/1.1\\r\\n'\n+            b'Host: localhost\\r\\n'\n+            b'Connection: keep-alive\\r\\n'\n+            b'Transfer-Encoding: chunked\\r\\n'\n+            b'\\r\\n'\n+            b'2\\r\\noh\\r\\n'\n+            b'4\\r\\n hai\\r\\n'\n+            b'0\\r\\n' # last-chunk\n+            # Normally the final CRLF would go here, but if you put in a\n+            # trailer, it doesn't.\n+            b'trailer1: value1\\r\\n'\n+            b'trailer2: value2\\r\\n'\n+            b'\\r\\n' # Really terminate the chunk.\n+            b'POST /a HTTP/1.1\\r\\n'\n+            b'Host: localhost\\r\\n'\n+            b'Connection: close\\r\\n'\n+            b'Transfer-Encoding: chunked\\r\\n'\n+            b'\\r\\n'\n+            b'2\\r\\noh\\r\\n'\n+            b'4\\r\\n bye\\r\\n'\n+            b'0\\r\\n' # last-chunk\n+        )\n+        with self.makefile() as fd:\n+            fd.write(data)\n+            read_http(fd, body='oh hai')\n+            read_http(fd, body='oh bye')\n+\n+        self.assertEqual(self.calls, 2)\n+\n+    def test_trailers_too_long(self):\n+        # Trailers after a chunk are ignored.\n+        data = (\n+            b'POST /a HTTP/1.1\\r\\n'\n+            b'Host: localhost\\r\\n'\n+            b'Connection: keep-alive\\r\\n'\n+            b'Transfer-Encoding: chunked\\r\\n'\n+            b'\\r\\n'\n+            b'2\\r\\noh\\r\\n'\n+            b'4\\r\\n hai\\r\\n'\n+            b'0\\r\\n' # last-chunk\n+            # Normally the final CRLF would go here, but if you put in a\n+            # trailer, it doesn't.\n+            b'trailer2: value2' # not lack of \\r\\n\n+        )\n+        data += b't' * pywsgi.MAX_REQUEST_LINE\n+        # No termination, because we detect the trailer as being too\n+        # long and abort the connection.\n+        with self.makefile() as fd:\n+            fd.write(data)\n+            read_http(fd, body='oh hai')\n+            with self.assertRaises(ConnectionClosed):\n+                read_http(fd, body='oh bye')\n+\n+    def test_trailers_request_smuggling_missing_last_chunk_keep_alive(self):\n+        # When something that looks like a request line comes in the trailer\n+        # as the first line, immediately after an invalid last chunk.\n+        # We detect this and abort the connection, because the\n+        # whitespace in the GET line isn't a legal part of a trailer.\n+        # If we didn't abort the connection, then, because we specified\n+        # keep-alive, the server would be hanging around waiting for more input.\n+        data = (\n+            b'POST /a HTTP/1.1\\r\\n'\n+            b'Host: localhost\\r\\n'\n+            b'Connection: keep-alive\\r\\n'\n+            b'Transfer-Encoding: chunked\\r\\n'\n+            b'\\r\\n'\n+            b'2\\r\\noh\\r\\n'\n+            b'4\\r\\n hai\\r\\n'\n+            b'0' # last-chunk, but missing the \\r\\n\n+            # Normally the final CRLF would go here, but if you put in a\n+            # trailer, it doesn't.\n+            # b'\\r\\n'\n+            b'GET /path2?a=:123 HTTP/1.1\\r\\n'\n+            b'Host: a.com\\r\\n'\n+            b'Connection: close\\r\\n'\n+            b'\\r\\n'\n+        )\n+        with self.makefile() as fd:\n+            fd.write(data)\n+            read_http(fd, body='oh hai')\n+            with self.assertRaises(ConnectionClosed):\n+                read_http(fd)\n+\n+        self.assertEqual(self.calls, 1)\n+\n+    def test_trailers_request_smuggling_missing_last_chunk_close(self):\n+        # Same as the above, except the trailers are actually valid\n+        # and since we ask to close the connection we don't get stuck\n+        # waiting for more input.\n+        data = (\n+            b'POST /a HTTP/1.1\\r\\n'\n+            b'Host: localhost\\r\\n'\n+            b'Connection: close\\r\\n'\n+            b'Transfer-Encoding: chunked\\r\\n'\n+            b'\\r\\n'\n+            b'2\\r\\noh\\r\\n'\n+            b'4\\r\\n hai\\r\\n'\n+            b'0\\r\\n' # last-chunk\n+            # Normally the final CRLF would go here, but if you put in a\n+            # trailer, it doesn't.\n+            # b'\\r\\n'\n+            b'GETpath2a:123 HTTP/1.1\\r\\n'\n+            b'Host: a.com\\r\\n'\n+            b'Connection: close\\r\\n'\n+            b'\\r\\n'\n+        )\n+        with self.makefile() as fd:\n+            fd.write(data)\n+            read_http(fd, body='oh hai')\n+            with self.assertRaises(ConnectionClosed):\n+                read_http(fd)\n+\n+    def test_trailers_request_smuggling_header_first(self):\n+        # When something that looks like a header comes in the first line.\n+        data = (\n+            b'POST /a HTTP/1.1\\r\\n'\n+            b'Host: localhost\\r\\n'\n+            b'Connection: keep-alive\\r\\n'\n+            b'Transfer-Encoding: chunked\\r\\n'\n+            b'\\r\\n'\n+            b'2\\r\\noh\\r\\n'\n+            b'4\\r\\n hai\\r\\n'\n+            b'0\\r\\n' # last-chunk, but only one CRLF\n+            b'Header: value\\r\\n'\n+            b'GET /path2?a=:123 HTTP/1.1\\r\\n'\n+            b'Host: a.com\\r\\n'\n+            b'Connection: close\\r\\n'\n+            b'\\r\\n'\n+        )\n+        with self.makefile() as fd:\n+            fd.write(data)\n+            read_http(fd, body='oh hai')\n+            with self.assertRaises(ConnectionClosed):\n+                read_http(fd, code=400)\n+\n+        self.assertEqual(self.calls, 1)\n+\n+    def test_trailers_request_smuggling_request_terminates_then_header(self):\n+        data = (\n+            b'POST /a HTTP/1.1\\r\\n'\n+            b'Host: localhost\\r\\n'\n+            b'Connection: keep-alive\\r\\n'\n+            b'Transfer-Encoding: chunked\\r\\n'\n+            b'\\r\\n'\n+            b'2\\r\\noh\\r\\n'\n+            b'4\\r\\n hai\\r\\n'\n+            b'0\\r\\n' # last-chunk\n+            b'\\r\\n'\n+            b'Header: value'\n+            b'GET /path2?a=:123 HTTP/1.1\\r\\n'\n+            b'Host: a.com\\r\\n'\n+            b'Connection: close\\r\\n'\n+            b'\\r\\n'\n+        )\n+        with self.makefile() as fd:\n+            fd.write(data)\n+            read_http(fd, body='oh hai')\n+            read_http(fd, code=400)\n+\n+        self.assertEqual(self.calls, 1)\n+\n \n class TestUseWrite(TestCase):\n "
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 2,
        "unique_directories": 4,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "b834cf2989893e9561fbc81b064a5381681922fb",
            "date": "2024-12-02T10:34:23Z",
            "author_login": "jamadden"
          },
          {
            "sha": "5737b06b4d2fb5ff67144224c807349331556530",
            "date": "2024-12-01T21:36:43Z",
            "author_login": "dependabot[bot]"
          },
          {
            "sha": "676d86a3ae799118d79ddc225e9286c6a75755a4",
            "date": "2024-11-30T14:37:59Z",
            "author_login": "jamadden"
          },
          {
            "sha": "6dba97bf5198c36bcd2efb4347cbdefd15d9db57",
            "date": "2024-11-13T01:51:09Z",
            "author_login": "m4yfly"
          },
          {
            "sha": "cbb527d3096502ae251f83002e4a4c0c024c18a9",
            "date": "2024-11-12T07:03:16Z",
            "author_login": "m4yfly"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 9.8,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",
    "cwe_id": null,
    "description": "An issue in Gevent before version 23.9.0 allows a remote attacker to escalate privileges via a crafted script to the WSGIServer component.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2023-09-25T12:15:11.210",
    "last_modified": "2024-11-21T08:21:11.527",
    "fix_date": "2023-08-31T22:05:48Z"
  },
  "references": [
    {
      "url": "https://github.com/gevent/gevent/commit/2f53c851eaf926767fbac62385615efd4886221c",
      "source": "cve@mitre.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/gevent/gevent/issues/1989",
      "source": "cve@mitre.org",
      "tags": [
        "Exploit",
        "Issue Tracking",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/gevent/gevent/commit/2f53c851eaf926767fbac62385615efd4886221c",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/gevent/gevent/issues/1989",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit",
        "Issue Tracking",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:06:10.484821",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "gevent",
    "owner": "gevent",
    "created_at": "2012-09-13T22:03:03Z",
    "updated_at": "2025-01-14T10:36:28Z",
    "pushed_at": "2025-01-01T21:29:44Z",
    "size": 23331,
    "stars": 6289,
    "forks": 939,
    "open_issues": 135,
    "watchers": 6289,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "Python": 7579499,
      "Cython": 109455,
      "C": 55881,
      "Shell": 20859,
      "PowerShell": 7195,
      "Batchfile": 3366
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "other"
    },
    "collected_at": "2025-01-14T16:52:38.046534"
  }
}