{
  "cve_id": "CVE-2023-46117",
  "github_data": {
    "repository": "six2dez/reconftw",
    "fix_commit": "e639de356c0880fe5fe01a32de9d0c58afb5f086",
    "related_commits": [
      "e639de356c0880fe5fe01a32de9d0c58afb5f086",
      "e639de356c0880fe5fe01a32de9d0c58afb5f086"
    ],
    "patch_url": "https://github.com/six2dez/reconftw/commit/e639de356c0880fe5fe01a32de9d0c58afb5f086.patch",
    "fix_commit_details": {
      "sha": "e639de356c0880fe5fe01a32de9d0c58afb5f086",
      "commit_date": "2023-10-20T05:59:36Z",
      "author": {
        "login": "six2dez",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "fix regex",
        "length": 9,
        "has_description": false,
        "references_issue": true
      },
      "stats": {
        "total": 50,
        "additions": 25,
        "deletions": 25
      },
      "files": [
        {
          "filename": "reconftw.sh",
          "status": "modified",
          "additions": 25,
          "deletions": 25,
          "patch": "@@ -446,7 +446,7 @@ function sub_active(){\n \t\t\tcat .tmp/subdomains_tmp.txt | tlsx -san -cn -silent -ro -c $TLSX_THREADS | anew -q .tmp/subdomains_tmp.txt\n \t\tfi\n \t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subdomains_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\tNUMOFLINES=$(cat .tmp/subdomains_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n+\t\tNUMOFLINES=$(cat .tmp/subdomains_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n \t\tend_subfunc \"${NUMOFLINES} subs DNS resolved from passive\" ${FUNCNAME[0]}\n \telse\n \t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n@@ -464,7 +464,7 @@ function sub_noerror(){\n \t\t\t\tdnsx -d $domain -r $resolvers -silent -rcode noerror -w $subs_wordlist | cut -d' ' -f1 | anew -q .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n \t\t\tfi\n \t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subs_noerror.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\t\tNUMOFLINES=$(cat .tmp/subs_noerror.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n+\t\t\tNUMOFLINES=$(cat .tmp/subs_noerror.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n \t\t\tend_subfunc \"${NUMOFLINES} new subs (DNS noerror)\" ${FUNCNAME[0]}\n \t\telse \n \t\t\tprintf \"\\n${yellow} Detected DNSSEC black lies, skipping this technique ${reset}\\n\" \n@@ -483,22 +483,22 @@ function sub_dns(){\n \t\tstart_subfunc ${FUNCNAME[0]} \"Running : DNS Subdomain Enumeration and PTR search\"\n \t\tif [ ! \"$AXIOM\" = true ]; then\n \t\t\t[ -s \"subdomains/subdomains.txt\" ] && cat subdomains/subdomains.txt | dnsx -r $resolvers_trusted -a -aaaa -cname -ns -ptr -mx -soa -silent -retry 3 -json -o subdomains/subdomains_dnsregs.json 2>>\"$LOGFILE\" >/dev/null\n-\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n-\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n+\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n+\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n \t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try \"\\(.host) - \\(.a[])\"' 2>/dev/null | sort -u -k2 | anew -q subdomains/subdomains_ips.txt\n \t\t\tresolvers_update_quick_local\n \t\t\t[ -s \".tmp/subdomains_dns.txt\" ] && puredns resolve .tmp/subdomains_dns.txt -w .tmp/subdomains_dns_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n \t\telse\n \t\t\t[ -s \"subdomains/subdomains.txt\" ] && axiom-scan subdomains/subdomains.txt -m dnsx -retry 3 -a -aaaa -cname -ns -ptr -mx -soa -json -o subdomains/subdomains_dnsregs.json $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | anew -q .tmp/subdomains_dns_a_records.txt\n-\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n-\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subdomains_dns.txt\n+\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[]' | sort -u | hakip2host | cut -d' ' -f 3 | unfurl -u domains | sed -e 's/*\\.//' -e 's/\\.$//' -e '/\\./!d' | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n+\t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try .a[], try .aaaa[], try .cname[], try .ns[], try .ptr[], try .mx[], try .soa[]' 2>/dev/null | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subdomains_dns.txt\n \t\t\t[ -s \"subdomains/subdomains_dnsregs.json\" ] && cat subdomains/subdomains_dnsregs.json | jq -r 'try \"\\(.host) - \\(.a[])\"' 2>/dev/null | sort -u -k2 | anew -q subdomains/subdomains_ips.txt\n \t\t\tresolvers_update_quick_axiom\n \t\t\t[ -s \".tmp/subdomains_dns.txt\" ] && axiom-scan .tmp/subdomains_dns.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subdomains_dns_resolved.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\tfi\n \t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subdomains_dns_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\tNUMOFLINES=$(cat .tmp/subdomains_dns_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n+\t\tNUMOFLINES=$(cat .tmp/subdomains_dns_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n \t\tend_subfunc \"${NUMOFLINES} new subs (dns resolution)\" ${FUNCNAME[0]}\n \telse\n \t\tprintf \"${yellow} ${FUNCNAME[0]} is already processed, to force executing ${FUNCNAME[0]} delete\\n    $called_fn_dir/.${FUNCNAME[0]} ${reset}\\n\\n\"\n@@ -526,7 +526,7 @@ function sub_brute(){\n \t\t\t[ -s \".tmp/subs_brute.txt\" ] && axiom-scan .tmp/subs_brute.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/subs_brute_valid.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\tfi\n \t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/subs_brute_valid.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\tNUMOFLINES=$(cat .tmp/subs_brute_valid.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n+\t\tNUMOFLINES=$(cat .tmp/subs_brute_valid.txt 2>>\"$LOGFILE\" | sed \"s/*.//\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n \t\tend_subfunc \"${NUMOFLINES} new subs (bruteforce)\" ${FUNCNAME[0]}\n \telse\n \t\tif [ \"$SUBBRUTE\" = false ]; then\n@@ -546,9 +546,9 @@ function sub_scraping(){\n \t\t\t\tif [ ! \"$AXIOM\" = true ]; then\n \t\t\t\t\tresolvers_update_quick_local\n \t\t\t\t\tcat subdomains/subdomains.txt | httpx -follow-host-redirects -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info1.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n+\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n \t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && cat .tmp/probed_tmp_scrap.txt | httpx -tls-grab -tls-probe -csp-probe -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info2.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n+\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n \n \t\t\t\t\tif [ \"$DEEP\" = true ]; then\n \t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && katana -silent -list .tmp/probed_tmp_scrap.txt -jc -kf all -c $KATANA_THREADS -d 3 -fs rdn -o .tmp/katana.txt 2>>\"$LOGFILE\" >/dev/null\n@@ -558,24 +558,24 @@ function sub_scraping(){\n \t\t\t\telse\n \t\t\t\t\tresolvers_update_quick_axiom\n \t\t\t\t\taxiom-scan subdomains/subdomains.txt -m httpx -follow-host-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info1.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n-\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n+\t\t\t\t\t[ -s \".tmp/web_full_info1.txt\" ] && cat .tmp/web_full_info1.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n \t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m httpx -tls-grab -tls-probe -csp-probe -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info2.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n-\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n+\t\t\t\t\t[ -s \".tmp/web_full_info2.txt\" ] && cat .tmp/web_full_info2.txt | jq -r 'try .\"tls-grab\".\"dns_names\"[],try .csp.domains[],try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | sort -u | httpx -silent | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n \t\t\t\t\tif [ \"$DEEP\" = true ]; then\n \t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m katana -jc -kf all -d 3 -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\t\t\t\telse\n \t\t\t\t\t\t[ -s \".tmp/probed_tmp_scrap.txt\" ] && axiom-scan .tmp/probed_tmp_scrap.txt -m katana -jc -kf all -d 2 -fs rdn -o .tmp/katana.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\t\t\t\tfi\n \t\t\t\tfi\n \t\t\t\tsed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n-\t\t\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | unfurl -u domains 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/scrap_subs.txt\n+\t\t\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | unfurl -u domains 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/scrap_subs.txt\n \t\t\t\t[ -s \".tmp/scrap_subs.txt\" ] && puredns resolve .tmp/scrap_subs.txt -w .tmp/scrap_subs_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n \t\t\t\tif [ \"$INSCOPE\" = true ]; then\n \t\t\t\t\tcheck_inscope .tmp/scrap_subs_resolved.txt 2>>\"$LOGFILE\" >/dev/null\n \t\t\t\tfi\n-\t\t\t\tNUMOFLINES=$(cat .tmp/scrap_subs_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | tee .tmp/diff_scrap.txt | sed '/^$/d' | wc -l)\n+\t\t\t\tNUMOFLINES=$(cat .tmp/scrap_subs_resolved.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | tee .tmp/diff_scrap.txt | sed '/^$/d' | wc -l)\n \t\t\t\t[ -s \".tmp/diff_scrap.txt\" ] && cat .tmp/diff_scrap.txt | httpx -follow-host-redirects -random-agent -status-code -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -timeout $HTTPX_TIMEOUT -silent -retries 2 -title -web-server -tech-detect -location -no-color -json -o .tmp/web_full_info3.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\t\t\t[ -s \".tmp/web_full_info3.txt\" ] && cat .tmp/web_full_info3.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n+\t\t\t\t[ -s \".tmp/web_full_info3.txt\" ] && cat .tmp/web_full_info3.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew .tmp/probed_tmp_scrap.txt | unfurl -u domains 2>>\"$LOGFILE\" | anew -q .tmp/scrap_subs.txt\n \t\t\t\tcat .tmp/web_full_info1.txt .tmp/web_full_info2.txt .tmp/web_full_info3.txt 2>>\"$LOGFILE\" | jq -s 'try .' | jq 'try unique_by(.input)' | jq 'try .[]' 2>>\"$LOGFILE\" > .tmp/web_full_info.txt\n \t\t\t\tend_subfunc \"${NUMOFLINES} new subs (code scraping)\" ${FUNCNAME[0]}\n \t\t\telse\n@@ -600,7 +600,7 @@ function sub_analytics(){\n \t\t\tmkdir -p .tmp/output_analytics/\n \t\t\tanalyticsrelationships -ch < .tmp/probed_tmp_scrap.txt >> .tmp/analytics_subs_tmp.txt 2>>\"$LOGFILE\"\n \n-\t\t\t[ -s \".tmp/analytics_subs_tmp.txt\" ] && cat .tmp/analytics_subs_tmp.txt | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/|__ //\" | anew -q .tmp/analytics_subs_clean.txt\n+\t\t\t[ -s \".tmp/analytics_subs_tmp.txt\" ] && cat .tmp/analytics_subs_tmp.txt | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/|__ //\" | anew -q .tmp/analytics_subs_clean.txt\n \t\t\tif [ ! \"$AXIOM\" = true ]; then\n \t\t\t\tresolvers_update_quick_local\n \t\t\t\t[ -s \".tmp/analytics_subs_clean.txt\" ] && puredns resolve .tmp/analytics_subs_clean.txt -w .tmp/analytics_subs_resolved.txt -r $resolvers --resolvers-trusted $resolvers_trusted -l $PUREDNS_PUBLIC_LIMIT --rate-limit-trusted $PUREDNS_TRUSTED_LIMIT --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT  --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT 2>>\"$LOGFILE\" >/dev/null\n@@ -664,7 +664,7 @@ function sub_permut(){\n \t\tif [ -s \".tmp/permute_subs.txt\" ]; then\n \t\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/permute_subs.txt\n \t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/permute_subs.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\t\tNUMOFLINES=$(cat .tmp/permute_subs.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n+\t\t\tNUMOFLINES=$(cat .tmp/permute_subs.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n \t\telse\n \t\t\tNUMOFLINES=0\n \t\tfi\n@@ -696,7 +696,7 @@ function sub_regex_permut(){\n \t\tif [ -s \".tmp/regulator.txt\" ]; then\n \t\t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/regulator.txt\n \t\t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/regulator.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\t\tNUMOFLINES=$(cat .tmp/regulator.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n+\t\t\tNUMOFLINES=$(cat .tmp/regulator.txt 2>>\"$LOGFILE\" | grep \".$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew subdomains/subdomains.txt | sed '/^$/d' | wc -l)\n \t\telse\n \t\t\tNUMOFLINES=0\n \t\tfi\n@@ -726,7 +726,7 @@ function sub_recursive_passive(){\n \t\t\t[ -s \".tmp/passive_recursive.txt\" ] && axiom-scan .tmp/passive_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/passive_recurs_tmp.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\tfi\n \t\t[[ \"$INSCOPE\" = true ]] && check_inscope .tmp/passive_recurs_tmp.txt 2>>\"$LOGFILE\" >/dev/null\n-\t\tNUMOFLINES=$(cat .tmp/passive_recurs_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n+\t\tNUMOFLINES=$(cat .tmp/passive_recurs_tmp.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n \t\tend_subfunc \"${NUMOFLINES} new subs (recursive)\" ${FUNCNAME[0]}\n \telse\n \t\tif [ \"$SUB_RECURSIVE_PASSIVE\" = false ]; then\n@@ -792,7 +792,7 @@ function sub_recursive_brute(){\n \t\t\t[ -s \".tmp/brute_recursive.txt\" ] && axiom-scan .tmp/brute_perm_recursive.txt -m puredns-resolve -r /home/op/lists/resolvers.txt --resolvers-trusted /home/op/lists/resolvers_trusted.txt --wildcard-tests $PUREDNS_WILDCARDTEST_LIMIT --wildcard-batch $PUREDNS_WILDCARDBATCH_LIMIT -o .tmp/brute_perm_recursive_final.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\tfi\n \n-\t\tNUMOFLINES=$(cat .tmp/brute_perm_recursive_final.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n+\t\tNUMOFLINES=$(cat .tmp/brute_perm_recursive_final.txt 2>>\"$LOGFILE\" | grep \"\\.$domain$\\|^$domain$\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed '/^$/d' | anew subdomains/subdomains.txt | wc -l)\n \t\tend_subfunc \"${NUMOFLINES} new subs (recursive active)\" ${FUNCNAME[0]}\n \telse\n \t\tif [ \"$SUB_RECURSIVE_BRUTE\" = false ]; then\n@@ -911,7 +911,7 @@ function webprobe_simple(){\n \t\t\taxiom-scan subdomains/subdomains.txt -m httpx ${HTTPX_FLAGS} -no-color -json -random-agent -threads $HTTPX_THREADS -rl $HTTPX_RATELIMIT -retries 2 -timeout $HTTPX_TIMEOUT -o .tmp/web_full_info_probe.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\tfi\n \t\tcat .tmp/web_full_info.txt .tmp/web_full_info_probe.txt webs/web_full_info.txt 2>>\"$LOGFILE\" | jq -s 'try .' | jq 'try unique_by(.input)' | jq 'try .[]' 2>>\"$LOGFILE\" > webs/web_full_info.txt\n-\t\t[ -s \"webs/web_full_info.txt\" ] && cat webs/web_full_info.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew -q .tmp/probed_tmp.txt\n+\t\t[ -s \"webs/web_full_info.txt\" ] && cat webs/web_full_info.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew -q .tmp/probed_tmp.txt\n \t\t[ -s \"webs/web_full_info.txt\" ] && cat webs/web_full_info.txt | jq -r 'try . |\"\\(.url) [\\(.status_code)] [\\(.title)] [\\(.webserver)] \\(.tech)\"' | grep \"$domain\" | anew -q webs/web_full_info_plain.txt\n \t\t[ -s \"$outOfScope_file\" ] && deleteOutScoped $outOfScope_file .tmp/probed_tmp.txt\n \t\tNUMOFLINES=$(cat .tmp/probed_tmp.txt 2>>\"$LOGFILE\" | anew webs/webs.txt | sed '/^$/d' | wc -l)\n@@ -944,7 +944,7 @@ function webprobe_full(){\n \t\t\t\tfi\n \t\t\tfi\n \t\tfi\n-\t\t[ -s \".tmp/web_full_info_uncommon.txt\" ] && cat .tmp/web_full_info_uncommon.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | sed \"s/*.//\" | anew -q .tmp/probed_uncommon_ports_tmp.txt\n+\t\t[ -s \".tmp/web_full_info_uncommon.txt\" ] && cat .tmp/web_full_info_uncommon.txt | jq -r 'try .url' 2>/dev/null | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | sed \"s/*.//\" | anew -q .tmp/probed_uncommon_ports_tmp.txt\n \t\t[ -s \".tmp/web_full_info_uncommon.txt\" ] && cat .tmp/web_full_info_uncommon.txt | jq -r 'try . |\"\\(.url) [\\(.status_code)] [\\(.title)] [\\(.webserver)] \\(.tech)\"' | anew -q webs/web_full_info_uncommon_plain.txt\n \t\tif [ -s \".tmp/web_full_info_uncommon.txt\" ]; then\n \t\t\tif [[ $domain =~ ^[0-9]+\\.[0-9]+\\.[0-9]+\\.[0-9] ]]; then \n@@ -1304,11 +1304,11 @@ function urlchecks(){\n \t\t\tfi\n \t\t\t[ -s \".tmp/katana.txt\" ] && sed -i '/^.\\{2048\\}./d' .tmp/katana.txt\n \t\t\t[ -s \".tmp/katana.txt\" ] && cat .tmp/katana.txt | anew -q .tmp/url_extract_tmp.txt\n-\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | grep -aEi \"\\.(js)\" | anew -q .tmp/url_extract_js.txt\n+\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] && cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | grep -aEi \"\\.(js)\" | anew -q .tmp/url_extract_js.txt\n \t\t\tif [ \"$DEEP\" = true ]; then\n \t\t\t\t[ -s \".tmp/url_extract_js.txt\" ] && interlace -tL .tmp/url_extract_js.txt -threads 10 -c \"python3 $tools/JSA/jsa.py -f target | anew -q .tmp/url_extract_tmp.txt\" &>/dev/null\n \t\t\tfi\n-\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] &&  cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | grep \"=\" | qsreplace -a 2>>\"$LOGFILE\" | grep -aEiv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)$\" | anew -q .tmp/url_extract_tmp2.txt\n+\t\t\t[ -s \".tmp/url_extract_tmp.txt\" ] &&  cat .tmp/url_extract_tmp.txt | grep \"${domain}\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | grep \"=\" | qsreplace -a 2>>\"$LOGFILE\" | grep -aEiv \"\\.(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|pdf|svg|txt|js)$\" | anew -q .tmp/url_extract_tmp2.txt\n \t\t\t[ -s \".tmp/url_extract_tmp2.txt\" ] && cat .tmp/url_extract_tmp2.txt | python3 $tools/urless/urless/urless.py | anew -q .tmp/url_extract_uddup.txt 2>>\"$LOGFILE\" >/dev/null\n \t\t\tNUMOFLINES=$(cat .tmp/url_extract_uddup.txt 2>>\"$LOGFILE\" | anew webs/url_extract.txt | sed '/^$/d' | wc -l)\n \t\t\tnotification \"${NUMOFLINES} new urls with params\" info\n@@ -1383,7 +1383,7 @@ function jschecks(){\n \t\tif [ -s \".tmp/url_extract_js.txt\" ]; then\n \t\t\tprintf \"${yellow} Running : Fetching Urls 1/5${reset}\\n\"\n \t\t\tif [ ! \"$AXIOM\" = true ]; then\n-\t\t\t\tcat .tmp/url_extract_js.txt | subjs -ua \"Mozilla/5.0 (X11; Linux x86_64; rv:72.0) Gecko/20100101 Firefox/72.0\" -c 40 | grep \"$domain\" | grep -E -i '^(((?!-))(xn--|_)?[a-z0-9-]{0,61}[a-z0-9]{1,1}\\.)*(xn--)?([a-z0-9][a-z0-9\\-]{0,60}|[a-z0-9-]{1,30}\\.[a-z]{2,})' | anew -q .tmp/subjslinks.txt\n+\t\t\t\tcat .tmp/url_extract_js.txt | subjs -ua \"Mozilla/5.0 (X11; Linux x86_64; rv:72.0) Gecko/20100101 Firefox/72.0\" -c 40 | grep \"$domain\" | grep -E '^((http|https):\\/\\/)?([a-zA-Z0-9]([a-zA-Z0-9\\-]*[a-zA-Z0-9])?\\.)+[a-zA-Z]{1,}(\\/.*)?$' | anew -q .tmp/subjslinks.txt\n \t\t\telse\n \t\t\t\taxiom-scan .tmp/url_extract_js.txt -m subjs -o .tmp/subjslinks.txt $AXIOM_EXTRA_ARGS 2>>\"$LOGFILE\" >/dev/null\n \t\t\tfi"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 0,
        "unique_directories": 1,
        "max_directory_depth": 0
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "eafc1318620f81c0edf1a90f0661527837c898cc",
            "date": "2024-12-18T11:45:23Z",
            "author_login": "six2dez"
          },
          {
            "sha": "221a04950d0f4ead455383b2c1be441e7ac73a4d",
            "date": "2024-11-22T11:41:42Z",
            "author_login": "six2dez"
          },
          {
            "sha": "695b29b4bb1f593870807a96e9ee0c720f676fe1",
            "date": "2024-11-22T11:38:10Z",
            "author_login": "six2dez"
          },
          {
            "sha": "26c93014f33cca822d9b9f14bfcba6e291b5425c",
            "date": "2024-11-22T10:09:54Z",
            "author_login": "six2dez"
          },
          {
            "sha": "0a048f3aacd62d9ae132ebe96d4f127662cf46ea",
            "date": "2024-11-22T10:06:31Z",
            "author_login": "six2dez"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 8.8,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H",
    "cwe_id": "CWE-78",
    "description": "reconFTW is a tool designed to perform automated recon on a target domain by running the best set of tools to perform scanning and finding out vulnerabilities. A vulnerability has been identified in reconftw where inadequate validation of retrieved subdomains may lead to a Remote Code Execution (RCE) attack. An attacker can exploit this vulnerability by crafting a malicious CSP entry on it's own domain. Successful exploitation can lead to the execution of arbitrary code within the context of the application, potentially compromising the system. This issue has been addressed in version 2.7.1.1 and all users are advised to upgrade. There are no known workarounds for this vulnerability.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2023-10-20T19:15:09.037",
    "last_modified": "2024-11-21T08:27:54.787",
    "fix_date": "2023-10-20T05:59:36Z"
  },
  "references": [
    {
      "url": "https://github.com/six2dez/reconftw/commit/e639de356c0880fe5fe01a32de9d0c58afb5f086",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/six2dez/reconftw/security/advisories/GHSA-fxwr-vr9x-wvjp",
      "source": "security-advisories@github.com",
      "tags": [
        "Vendor Advisory"
      ]
    },
    {
      "url": "https://github.com/six2dez/reconftw/commit/e639de356c0880fe5fe01a32de9d0c58afb5f086",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/six2dez/reconftw/security/advisories/GHSA-fxwr-vr9x-wvjp",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Vendor Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:06:36.915674",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "reconftw",
    "owner": "six2dez",
    "created_at": "2020-12-30T23:52:52Z",
    "updated_at": "2025-01-14T14:02:32Z",
    "pushed_at": "2025-01-13T09:21:27Z",
    "size": 122255,
    "stars": 5887,
    "forks": 950,
    "open_issues": 29,
    "watchers": 5887,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "dev",
      "main"
    ],
    "languages": {
      "Shell": 273300,
      "Dockerfile": 4504,
      "HCL": 1361,
      "Makefile": 1262
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "mit"
    },
    "collected_at": "2025-01-14T19:19:05.085593"
  }
}