{
  "cve_id": "CVE-2024-0763",
  "github_data": {
    "repository": "mintplex-labs/anything-llm",
    "fix_commit": "8a7324d0e77a15186e1ad5e5119fca4fb224c39c",
    "related_commits": [
      "8a7324d0e77a15186e1ad5e5119fca4fb224c39c",
      "8a7324d0e77a15186e1ad5e5119fca4fb224c39c"
    ],
    "patch_url": "https://github.com/mintplex-labs/anything-llm/commit/8a7324d0e77a15186e1ad5e5119fca4fb224c39c.patch",
    "fix_commit_details": {
      "sha": "8a7324d0e77a15186e1ad5e5119fca4fb224c39c",
      "commit_date": "2024-01-19T20:56:00Z",
      "author": {
        "login": "timothycarambat",
        "type": "User",
        "stats": {
          "total_commits": 912,
          "average_weekly_commits": 10.604651162790697,
          "total_additions": 194015,
          "total_deletions": 85620,
          "weeks_active": 81
        }
      },
      "commit_message": {
        "title": "Employ strict validations on document pathing (#627)",
        "length": 149,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 184,
        "additions": 96,
        "deletions": 88
      },
      "files": [
        {
          "filename": "server/utils/files/index.js",
          "status": "modified",
          "additions": 59,
          "deletions": 74,
          "patch": "@@ -1,52 +1,39 @@\n const fs = require(\"fs\");\n const path = require(\"path\");\n const { v5: uuidv5 } = require(\"uuid\");\n+const documentsPath =\n+  process.env.NODE_ENV === \"development\"\n+    ? path.resolve(__dirname, `../../storage/documents`)\n+    : path.resolve(process.env.STORAGE_DIR, `documents`);\n+const vectorCachePath =\n+  process.env.NODE_ENV === \"development\"\n+    ? path.resolve(__dirname, `../../storage/vector-cache`)\n+    : path.resolve(process.env.STORAGE_DIR, `vector-cache`);\n \n // Should take in a folder that is a subfolder of documents\n // eg: youtube-subject/video-123.json\n async function fileData(filePath = null) {\n   if (!filePath) throw new Error(\"No docPath provided in request\");\n+  const fullFilePath = path.resolve(documentsPath, normalizePath(filePath));\n+  if (!fs.existsSync(fullFilePath) || !isWithin(documentsPath, fullFilePath))\n+    return null;\n \n-  const fullPath =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(\n-          __dirname,\n-          `../../storage/documents/${normalizePath(filePath)}`\n-        )\n-      : path.resolve(\n-          process.env.STORAGE_DIR,\n-          `documents/${normalizePath(filePath)}`\n-        );\n-\n-  const fileExists = fs.existsSync(fullPath);\n-  if (!fileExists) return null;\n-\n-  const data = fs.readFileSync(fullPath, \"utf8\");\n+  const data = fs.readFileSync(fullFilePath, \"utf8\");\n   return JSON.parse(data);\n }\n \n async function viewLocalFiles() {\n-  const folder =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(__dirname, `../../storage/documents`)\n-      : path.resolve(process.env.STORAGE_DIR, `documents`);\n-  const dirExists = fs.existsSync(folder);\n-  if (!dirExists) fs.mkdirSync(folder);\n+  if (!fs.existsSync(documentsPath)) fs.mkdirSync(documentsPath);\n \n   const directory = {\n     name: \"documents\",\n     type: \"folder\",\n     items: [],\n   };\n \n-  for (const file of fs.readdirSync(folder)) {\n+  for (const file of fs.readdirSync(documentsPath)) {\n     if (path.extname(file) === \".md\") continue;\n-\n-    const folderPath =\n-      process.env.NODE_ENV === \"development\"\n-        ? path.resolve(__dirname, `../../storage/documents/${file}`)\n-        : path.resolve(process.env.STORAGE_DIR, `documents/${file}`);\n-\n+    const folderPath = path.resolve(documentsPath, file);\n     const isFolder = fs.lstatSync(folderPath).isDirectory();\n     if (isFolder) {\n       const subdocs = {\n@@ -83,10 +70,7 @@ async function cachedVectorInformation(filename = null, checkOnly = false) {\n   if (!filename) return checkOnly ? false : { exists: false, chunks: [] };\n \n   const digest = uuidv5(filename, uuidv5.URL);\n-  const file =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(__dirname, `../../storage/vector-cache/${digest}.json`)\n-      : path.resolve(process.env.STORAGE_DIR, `vector-cache/${digest}.json`);\n+  const file = path.resolve(vectorCachePath, `${digest}.json`);\n   const exists = fs.existsSync(file);\n \n   if (checkOnly) return exists;\n@@ -106,53 +90,39 @@ async function storeVectorResult(vectorData = [], filename = null) {\n   console.log(\n     `Caching vectorized results of ${filename} to prevent duplicated embedding.`\n   );\n-  const folder =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(__dirname, `../../storage/vector-cache`)\n-      : path.resolve(process.env.STORAGE_DIR, `vector-cache`);\n-\n-  if (!fs.existsSync(folder)) fs.mkdirSync(folder);\n+  if (!fs.existsSync(vectorCachePath)) fs.mkdirSync(vectorCachePath);\n \n   const digest = uuidv5(filename, uuidv5.URL);\n-  const writeTo = path.resolve(folder, `${digest}.json`);\n+  const writeTo = path.resolve(vectorCachePath, `${digest}.json`);\n   fs.writeFileSync(writeTo, JSON.stringify(vectorData), \"utf8\");\n   return;\n }\n \n // Purges a file from the documents/ folder.\n async function purgeSourceDocument(filename = null) {\n   if (!filename) return;\n+  const filePath = path.resolve(documentsPath, normalizePath(filename));\n+\n+  if (\n+    !fs.existsSync(filePath) ||\n+    !isWithin(documentsPath, filePath) ||\n+    !fs.lstatSync(filePath).isFile()\n+  )\n+    return;\n+\n   console.log(`Purging source document of ${filename}.`);\n-  const filePath =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(\n-          __dirname,\n-          `../../storage/documents`,\n-          normalizePath(filename)\n-        )\n-      : path.resolve(\n-          process.env.STORAGE_DIR,\n-          `documents`,\n-          normalizePath(filename)\n-        );\n-\n-  if (!fs.existsSync(filePath)) return;\n   fs.rmSync(filePath);\n   return;\n }\n \n // Purges a vector-cache file from the vector-cache/ folder.\n async function purgeVectorCache(filename = null) {\n   if (!filename) return;\n-  console.log(`Purging vector-cache of ${filename}.`);\n-\n   const digest = uuidv5(filename, uuidv5.URL);\n-  const filePath =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(__dirname, `../../storage/vector-cache`, `${digest}.json`)\n-      : path.resolve(process.env.STORAGE_DIR, `vector-cache`, `${digest}.json`);\n+  const filePath = path.resolve(vectorCachePath, `${digest}.json`);\n \n-  if (!fs.existsSync(filePath)) return;\n+  if (!fs.existsSync(filePath) || !fs.lstatSync(filePath).isFile()) return;\n+  console.log(`Purging vector-cache of ${filename}.`);\n   fs.rmSync(filePath);\n   return;\n }\n@@ -161,24 +131,20 @@ async function purgeVectorCache(filename = null) {\n // folder via iteration of all folders and checking if the expected file exists.\n async function findDocumentInDocuments(documentName = null) {\n   if (!documentName) return null;\n-  const documentsFolder =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(__dirname, `../../storage/documents`)\n-      : path.resolve(process.env.STORAGE_DIR, `documents`);\n-\n-  for (const folder of fs.readdirSync(documentsFolder)) {\n+  for (const folder of fs.readdirSync(documentsPath)) {\n     const isFolder = fs\n-      .lstatSync(path.join(documentsFolder, folder))\n+      .lstatSync(path.join(documentsPath, folder))\n       .isDirectory();\n     if (!isFolder) continue;\n \n     const targetFilename = normalizePath(documentName);\n-    const targetFileLocation = path.join(\n-      documentsFolder,\n-      folder,\n-      targetFilename\n-    );\n-    if (!fs.existsSync(targetFileLocation)) continue;\n+    const targetFileLocation = path.join(documentsPath, folder, targetFilename);\n+\n+    if (\n+      !fs.existsSync(targetFileLocation) ||\n+      !isWithin(documentsPath, targetFileLocation)\n+    )\n+      continue;\n \n     const fileData = fs.readFileSync(targetFileLocation, \"utf8\");\n     const cachefilename = `${folder}/${targetFilename}`;\n@@ -194,8 +160,25 @@ async function findDocumentInDocuments(documentName = null) {\n   return null;\n }\n \n+/**\n+ * Checks if a given path is within another path.\n+ * @param {string} outer - The outer path (should be resolved).\n+ * @param {string} inner - The inner path (should be resolved).\n+ * @returns {boolean} - Returns true if the inner path is within the outer path, false otherwise.\n+ */\n+function isWithin(outer, inner) {\n+  if (outer === inner) return false;\n+  const rel = path.relative(outer, inner);\n+  return !rel.startsWith(\"../\") && rel !== \"..\";\n+}\n+\n function normalizePath(filepath = \"\") {\n-  return path.normalize(filepath).replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\");\n+  const result = path\n+    .normalize(filepath.trim())\n+    .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\")\n+    .trim();\n+  if ([\"..\", \".\", \"/\"].includes(result)) throw new Error(\"Invalid path.\");\n+  return result;\n }\n \n module.exports = {\n@@ -207,4 +190,6 @@ module.exports = {\n   storeVectorResult,\n   fileData,\n   normalizePath,\n+  isWithin,\n+  documentsPath,\n };"
        },
        {
          "filename": "server/utils/files/purgeDocument.js",
          "status": "modified",
          "additions": 37,
          "deletions": 14,
          "patch": "@@ -1,30 +1,53 @@\n const fs = require(\"fs\");\n const path = require(\"path\");\n-const { purgeVectorCache, purgeSourceDocument, normalizePath } = require(\".\");\n+const {\n+  purgeVectorCache,\n+  purgeSourceDocument,\n+  normalizePath,\n+  isWithin,\n+  documentsPath,\n+} = require(\".\");\n const { Document } = require(\"../../models/documents\");\n const { Workspace } = require(\"../../models/workspace\");\n \n-async function purgeDocument(filename) {\n+async function purgeDocument(filename = null) {\n+  if (!filename || !normalizePath(filename)) return;\n+\n+  await purgeVectorCache(filename);\n+  await purgeSourceDocument(filename);\n   const workspaces = await Workspace.where();\n   for (const workspace of workspaces) {\n     await Document.removeDocuments(workspace, [filename]);\n   }\n-  await purgeVectorCache(filename);\n-  await purgeSourceDocument(filename);\n   return;\n }\n \n-async function purgeFolder(folderName) {\n-  if (folderName === \"custom-documents\") return;\n-  const documentsFolder =\n-    process.env.NODE_ENV === \"development\"\n-      ? path.resolve(__dirname, `../../storage/documents`)\n-      : path.resolve(process.env.STORAGE_DIR, `documents`);\n+async function purgeFolder(folderName = null) {\n+  if (!folderName) return;\n+  const subFolder = normalizePath(folderName);\n+  const subFolderPath = path.resolve(documentsPath, subFolder);\n+  const validRemovableSubFolders = fs\n+    .readdirSync(documentsPath)\n+    .map((folder) => {\n+      // Filter out any results which are not folders or\n+      // are the protected custom-documents folder.\n+      if (folder === \"custom-documents\") return null;\n+      const subfolderPath = path.resolve(documentsPath, folder);\n+      if (!fs.lstatSync(subfolderPath).isDirectory()) return null;\n+      return folder;\n+    })\n+    .filter((subFolder) => !!subFolder);\n+\n+  if (\n+    !validRemovableSubFolders.includes(subFolder) ||\n+    !fs.existsSync(subFolderPath) ||\n+    !isWithin(documentsPath, subFolderPath)\n+  )\n+    return;\n \n-  const folderPath = path.resolve(documentsFolder, normalizePath(folderName));\n   const filenames = fs\n-    .readdirSync(folderPath)\n-    .map((file) => path.join(folderPath, file));\n+    .readdirSync(subFolderPath)\n+    .map((file) => path.join(subFolderPath, file));\n   const workspaces = await Workspace.where();\n \n   const purgePromises = [];\n@@ -47,7 +70,7 @@ async function purgeFolder(folderName) {\n   }\n \n   await Promise.all(purgePromises.flat().map((f) => f()));\n-  fs.rmSync(folderPath, { recursive: true }); // Delete root document and source files.\n+  fs.rmSync(subFolderPath, { recursive: true }); // Delete target document-folder and source files.\n \n   return;\n }"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 0,
        "unique_directories": 1,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "4d5d8d4dec0e62662c8ec46537038353f45e0e66",
            "date": "2025-01-14T16:20:57Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "21af81085aeb049750942ac5f3b84775cb461693",
            "date": "2025-01-13T21:12:03Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "665e8e5bfe431ad93bed6736d0b450592617d042",
            "date": "2025-01-09T23:39:56Z",
            "author_login": "shatfield4"
          },
          {
            "sha": "865f7eea296e544b2eb1ab8c1f322208eaf5eb05",
            "date": "2025-01-09T21:32:54Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "be886f7d61296a30d5b8a095ca8329f58a0c5a0a",
            "date": "2025-01-09T01:21:30Z",
            "author_login": "root-reindeer-flotilla"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": null,
    "cvss_vector": null,
    "cwe_id": "CWE-20",
    "description": "Any user can delete an arbitrary folder (recursively) on a remote server due to bad input sanitization leading to path traversal. The attacker would need access to the server at some privilege level since this endpoint is protected and requires authorization.",
    "attack_vector": null,
    "attack_complexity": null
  },
  "temporal_data": {
    "published_date": "2024-02-27T22:15:14.597",
    "last_modified": "2024-11-21T08:47:19.257",
    "fix_date": "2024-01-19T20:56:00Z"
  },
  "references": [
    {
      "url": "https://github.com/mintplex-labs/anything-llm/commit/8a7324d0e77a15186e1ad5e5119fca4fb224c39c",
      "source": "security@huntr.dev",
      "tags": []
    },
    {
      "url": "https://huntr.com/bounties/25a2f487-5a9c-4c7f-a2d3-b0527db73ea5",
      "source": "security@huntr.dev",
      "tags": []
    },
    {
      "url": "https://github.com/mintplex-labs/anything-llm/commit/8a7324d0e77a15186e1ad5e5119fca4fb224c39c",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://huntr.com/bounties/25a2f487-5a9c-4c7f-a2d3-b0527db73ea5",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:07:28.168519",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "anything-llm",
    "owner": "mintplex-labs",
    "created_at": "2023-06-04T02:29:14Z",
    "updated_at": "2025-01-14T13:49:57Z",
    "pushed_at": "2025-01-13T21:12:06Z",
    "size": 42916,
    "stars": 30237,
    "forks": 3030,
    "open_issues": 206,
    "watchers": 30237,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "JavaScript": 3056909,
      "CSS": 73785,
      "Dockerfile": 9030,
      "HTML": 3904,
      "Shell": 1382,
      "HCL": 1211
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "mit"
    },
    "collected_at": "2025-01-14T14:04:33.088245"
  }
}