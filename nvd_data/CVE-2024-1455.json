{
  "cve_id": "CVE-2024-1455",
  "github_data": {
    "repository": "langchain-ai/langchain",
    "fix_commit": "727d5023ce88e18e3074ef620a98137d26ff92a3",
    "related_commits": [
      "727d5023ce88e18e3074ef620a98137d26ff92a3",
      "727d5023ce88e18e3074ef620a98137d26ff92a3"
    ],
    "patch_url": "https://github.com/langchain-ai/langchain/commit/727d5023ce88e18e3074ef620a98137d26ff92a3.patch",
    "fix_commit_details": {
      "sha": "727d5023ce88e18e3074ef620a98137d26ff92a3",
      "commit_date": "2024-03-25T20:21:52Z",
      "author": {
        "login": "eyurtsev",
        "type": "User",
        "stats": {
          "total_commits": 822,
          "average_weekly_commits": 7.0256410256410255,
          "total_additions": 0,
          "total_deletions": 0,
          "weeks_active": 81
        }
      },
      "commit_message": {
        "title": "core[patch]: Use defusedxml in XMLOutputParser (#19526)",
        "length": 279,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 158,
        "additions": 122,
        "deletions": 36
      },
      "files": [
        {
          "filename": "libs/core/langchain_core/output_parsers/xml.py",
          "status": "modified",
          "additions": 42,
          "deletions": 8,
          "patch": "@@ -1,6 +1,7 @@\n import re\n-import xml.etree.ElementTree as ET\n from typing import Any, AsyncIterator, Dict, Iterator, List, Optional, Union\n+from xml.etree import ElementTree as ET\n+from xml.etree.ElementTree import TreeBuilder\n \n from langchain_core.exceptions import OutputParserException\n from langchain_core.messages import BaseMessage\n@@ -35,6 +36,10 @@ def get_format_instructions(self) -> str:\n         return XML_FORMAT_INSTRUCTIONS.format(tags=self.tags)\n \n     def parse(self, text: str) -> Dict[str, List[Any]]:\n+        # Imports are temporarily placed here to avoid issue with caching on CI\n+        # likely if you're reading this you can move them to the top of the file\n+        from defusedxml import ElementTree as DET  # type: ignore[import]\n+\n         # Try to find XML string within triple backticks\n         match = re.search(r\"```(xml)?(.*)```\", text, re.DOTALL)\n         if match is not None:\n@@ -46,18 +51,24 @@ def parse(self, text: str) -> Dict[str, List[Any]]:\n \n         text = text.strip()\n         try:\n-            root = ET.fromstring(text)\n+            root = DET.fromstring(text)\n             return self._root_to_dict(root)\n \n-        except ET.ParseError as e:\n+        except (DET.ParseError, DET.EntitiesForbidden) as e:\n             msg = f\"Failed to parse XML format from completion {text}. Got: {e}\"\n             raise OutputParserException(msg, llm_output=text) from e\n \n     def _transform(\n         self, input: Iterator[Union[str, BaseMessage]]\n     ) -> Iterator[AddableDict]:\n+        # Imports are temporarily placed here to avoid issue with caching on CI\n+        # likely if you're reading this you can move them to the top of the file\n+        from defusedxml.ElementTree import DefusedXMLParser  # type: ignore[import]\n+\n+        parser = ET.XMLPullParser(\n+            [\"start\", \"end\"], _parser=DefusedXMLParser(target=TreeBuilder())\n+        )\n         xml_start_re = re.compile(r\"<[a-zA-Z:_]\")\n-        parser = ET.XMLPullParser([\"start\", \"end\"])\n         xml_started = False\n         current_path: List[str] = []\n         current_path_has_children = False\n@@ -83,6 +94,7 @@ def _transform(\n             parser.feed(buffer)\n             buffer = \"\"\n             # yield all events\n+\n             for event, elem in parser.read_events():\n                 if event == \"start\":\n                     # update current path\n@@ -105,18 +117,37 @@ def _transform(\n     async def _atransform(\n         self, input: AsyncIterator[Union[str, BaseMessage]]\n     ) -> AsyncIterator[AddableDict]:\n-        parser = ET.XMLPullParser([\"start\", \"end\"])\n+        # Imports are temporarily placed here to avoid issue with caching on CI\n+        # likely if you're reading this you can move them to the top of the file\n+        from defusedxml.ElementTree import DefusedXMLParser  # type: ignore[import]\n+\n+        _parser = DefusedXMLParser(target=TreeBuilder())\n+        parser = ET.XMLPullParser([\"start\", \"end\"], _parser=_parser)\n+        xml_start_re = re.compile(r\"<[a-zA-Z:_]\")\n+        xml_started = False\n         current_path: List[str] = []\n         current_path_has_children = False\n+        buffer = \"\"\n         async for chunk in input:\n             if isinstance(chunk, BaseMessage):\n                 # extract text\n                 chunk_content = chunk.content\n                 if not isinstance(chunk_content, str):\n                     continue\n                 chunk = chunk_content\n-            # pass chunk to parser\n-            parser.feed(chunk)\n+            # add chunk to buffer of unprocessed text\n+            buffer += chunk\n+            # if xml string hasn't started yet, continue to next chunk\n+            if not xml_started:\n+                if match := xml_start_re.search(buffer):\n+                    # if xml string has started, remove all text before it\n+                    buffer = buffer[match.start() :]\n+                    xml_started = True\n+                else:\n+                    continue\n+            # feed buffer to parser\n+            parser.feed(buffer)\n+            buffer = \"\"\n             # yield all events\n             for event, elem in parser.read_events():\n                 if event == \"start\":\n@@ -130,7 +161,10 @@ async def _atransform(\n                     if not current_path_has_children:\n                         yield nested_element(current_path, elem)\n                     # prevent yielding of parent element\n-                    current_path_has_children = True\n+                    if current_path:\n+                        current_path_has_children = True\n+                    else:\n+                        xml_started = False\n         # close parser\n         parser.close()\n "
        },
        {
          "filename": "libs/core/poetry.lock",
          "status": "modified",
          "additions": 24,
          "deletions": 24,
          "patch": "@@ -660,13 +660,13 @@ files = [\n \n [[package]]\n name = \"importlib-metadata\"\n-version = \"7.0.2\"\n+version = \"7.1.0\"\n description = \"Read metadata from Python packages\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"importlib_metadata-7.0.2-py3-none-any.whl\", hash = \"sha256:f4bc4c0c070c490abf4ce96d715f68e95923320370efb66143df00199bb6c100\"},\n-    {file = \"importlib_metadata-7.0.2.tar.gz\", hash = \"sha256:198f568f3230878cb1b44fbd7975f87906c22336dba2e4a7f05278c281fbd792\"},\n+    {file = \"importlib_metadata-7.1.0-py3-none-any.whl\", hash = \"sha256:30962b96c0c223483ed6cc7280e7f0199feb01a0e40cfae4d4450fc6fab1f570\"},\n+    {file = \"importlib_metadata-7.1.0.tar.gz\", hash = \"sha256:b78938b926ee8d5f020fc4772d487045805a55ddbad2ecf21c6d60938dc7fcd2\"},\n ]\n \n [package.dependencies]\n@@ -675,25 +675,25 @@ zipp = \">=0.5\"\n [package.extras]\n docs = [\"furo\", \"jaraco.packaging (>=9.3)\", \"jaraco.tidelift (>=1.4)\", \"rst.linker (>=1.9)\", \"sphinx (>=3.5)\", \"sphinx-lint\"]\n perf = [\"ipython\"]\n-testing = [\"flufl.flake8\", \"importlib-resources (>=1.3)\", \"packaging\", \"pyfakefs\", \"pytest (>=6)\", \"pytest-checkdocs (>=2.4)\", \"pytest-cov\", \"pytest-enabler (>=2.2)\", \"pytest-mypy\", \"pytest-perf (>=0.9.2)\", \"pytest-ruff (>=0.2.1)\"]\n+testing = [\"flufl.flake8\", \"importlib-resources (>=1.3)\", \"jaraco.test (>=5.4)\", \"packaging\", \"pyfakefs\", \"pytest (>=6)\", \"pytest-checkdocs (>=2.4)\", \"pytest-cov\", \"pytest-enabler (>=2.2)\", \"pytest-mypy\", \"pytest-perf (>=0.9.2)\", \"pytest-ruff (>=0.2.1)\"]\n \n [[package]]\n name = \"importlib-resources\"\n-version = \"6.3.1\"\n+version = \"6.4.0\"\n description = \"Read resources from Python packages\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"importlib_resources-6.3.1-py3-none-any.whl\", hash = \"sha256:4811639ca7fa830abdb8e9ca0a104dc6ad13de691d9fe0d3173a71304f068159\"},\n-    {file = \"importlib_resources-6.3.1.tar.gz\", hash = \"sha256:29a3d16556e330c3c8fb8202118c5ff41241cc34cbfb25989bbad226d99b7995\"},\n+    {file = \"importlib_resources-6.4.0-py3-none-any.whl\", hash = \"sha256:50d10f043df931902d4194ea07ec57960f66a80449ff867bfe782b4c486ba78c\"},\n+    {file = \"importlib_resources-6.4.0.tar.gz\", hash = \"sha256:cdb2b453b8046ca4e3798eb1d84f3cce1446a0e8e7b5ef4efb600f19fc398145\"},\n ]\n \n [package.dependencies]\n zipp = {version = \">=3.1.0\", markers = \"python_version < \\\"3.10\\\"\"}\n \n [package.extras]\n docs = [\"furo\", \"jaraco.packaging (>=9.3)\", \"jaraco.tidelift (>=1.4)\", \"rst.linker (>=1.9)\", \"sphinx (<7.2.5)\", \"sphinx (>=3.5)\", \"sphinx-lint\"]\n-testing = [\"jaraco.collections\", \"pytest (>=6)\", \"pytest-checkdocs (>=2.4)\", \"pytest-cov\", \"pytest-enabler (>=2.2)\", \"pytest-mypy\", \"pytest-ruff (>=0.2.1)\", \"zipp (>=3.17)\"]\n+testing = [\"jaraco.test (>=5.4)\", \"pytest (>=6)\", \"pytest-checkdocs (>=2.4)\", \"pytest-cov\", \"pytest-enabler (>=2.2)\", \"pytest-mypy\", \"pytest-ruff (>=0.2.1)\", \"zipp (>=3.17)\"]\n \n [[package]]\n name = \"iniconfig\"\n@@ -1020,13 +1020,13 @@ test = [\"ipykernel\", \"pre-commit\", \"pytest (<8)\", \"pytest-cov\", \"pytest-timeout\"\n \n [[package]]\n name = \"jupyter-events\"\n-version = \"0.9.1\"\n+version = \"0.10.0\"\n description = \"Jupyter Event System library\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"jupyter_events-0.9.1-py3-none-any.whl\", hash = \"sha256:e51f43d2c25c2ddf02d7f7a5045f71fc1d5cb5ad04ef6db20da961c077654b9b\"},\n-    {file = \"jupyter_events-0.9.1.tar.gz\", hash = \"sha256:a52e86f59eb317ee71ff2d7500c94b963b8a24f0b7a1517e2e653e24258e15c7\"},\n+    {file = \"jupyter_events-0.10.0-py3-none-any.whl\", hash = \"sha256:4b72130875e59d57716d327ea70d3ebc3af1944d3717e5a498b8a06c6c159960\"},\n+    {file = \"jupyter_events-0.10.0.tar.gz\", hash = \"sha256:670b8229d3cc882ec782144ed22e0d29e1c2d639263f92ca8383e66682845e22\"},\n ]\n \n [package.dependencies]\n@@ -1216,13 +1216,13 @@ url = \"../text-splitters\"\n \n [[package]]\n name = \"langsmith\"\n-version = \"0.1.27\"\n+version = \"0.1.31\"\n description = \"Client library to connect to the LangSmith LLM Tracing and Evaluation Platform.\"\n optional = false\n-python-versions = \">=3.8.1,<4.0\"\n+python-versions = \"<4.0,>=3.8.1\"\n files = [\n-    {file = \"langsmith-0.1.27-py3-none-any.whl\", hash = \"sha256:d223176952b1525c958189ab1b894f5bd9891ec9177222f7a978aeee4bf1cc95\"},\n-    {file = \"langsmith-0.1.27.tar.gz\", hash = \"sha256:e0a339d976362051adf3fdbc43fcc7c00bb4615a401321ad7e556bd2dab556c0\"},\n+    {file = \"langsmith-0.1.31-py3-none-any.whl\", hash = \"sha256:5211a9dc00831db307eb843485a97096484b697b5d2cd1efaac34228e97ca087\"},\n+    {file = \"langsmith-0.1.31.tar.gz\", hash = \"sha256:efd54ccd44be7fda911bfdc0ead340473df2fdd07345c7252901834d0c4aa37e\"},\n ]\n \n [package.dependencies]\n@@ -1406,13 +1406,13 @@ test = [\"flaky\", \"ipykernel (>=6.19.3)\", \"ipython\", \"ipywidgets\", \"nbconvert (>=\n \n [[package]]\n name = \"nbconvert\"\n-version = \"7.16.2\"\n+version = \"7.16.3\"\n description = \"Converting Jupyter Notebooks (.ipynb files) to other formats.  Output formats include asciidoc, html, latex, markdown, pdf, py, rst, script.  nbconvert can be used both as a Python library (`import nbconvert`) or as a command line tool (invoked as `jupyter nbconvert ...`).\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"nbconvert-7.16.2-py3-none-any.whl\", hash = \"sha256:0c01c23981a8de0220255706822c40b751438e32467d6a686e26be08ba784382\"},\n-    {file = \"nbconvert-7.16.2.tar.gz\", hash = \"sha256:8310edd41e1c43947e4ecf16614c61469ebc024898eb808cce0999860fc9fb16\"},\n+    {file = \"nbconvert-7.16.3-py3-none-any.whl\", hash = \"sha256:ddeff14beeeedf3dd0bc506623e41e4507e551736de59df69a91f86700292b3b\"},\n+    {file = \"nbconvert-7.16.3.tar.gz\", hash = \"sha256:a6733b78ce3d47c3f85e504998495b07e6ea9cf9bf6ec1c98dda63ec6ad19142\"},\n ]\n \n [package.dependencies]\n@@ -1439,7 +1439,7 @@ docs = [\"ipykernel\", \"ipython\", \"myst-parser\", \"nbsphinx (>=0.2.12)\", \"pydata-sp\n qtpdf = [\"nbconvert[qtpng]\"]\n qtpng = [\"pyqtwebengine (>=5.15)\"]\n serve = [\"tornado (>=6.1)\"]\n-test = [\"flaky\", \"ipykernel\", \"ipywidgets (>=7.5)\", \"pytest\"]\n+test = [\"flaky\", \"ipykernel\", \"ipywidgets (>=7.5)\", \"pytest (>=7)\"]\n webpdf = [\"playwright\"]\n \n [[package]]\n@@ -1997,17 +1997,17 @@ testing = [\"coverage (>=6.2)\", \"flaky (>=3.5.0)\", \"hypothesis (>=5.7.1)\", \"mypy\n \n [[package]]\n name = \"pytest-mock\"\n-version = \"3.12.0\"\n+version = \"3.14.0\"\n description = \"Thin-wrapper around the mock package for easier use with pytest\"\n optional = false\n python-versions = \">=3.8\"\n files = [\n-    {file = \"pytest-mock-3.12.0.tar.gz\", hash = \"sha256:31a40f038c22cad32287bb43932054451ff5583ff094bca6f675df2f8bc1a6e9\"},\n-    {file = \"pytest_mock-3.12.0-py3-none-any.whl\", hash = \"sha256:0972719a7263072da3a21c7f4773069bcc7486027d7e8e1f81d98a47e701bc4f\"},\n+    {file = \"pytest-mock-3.14.0.tar.gz\", hash = \"sha256:2719255a1efeceadbc056d6bf3df3d1c5015530fb40cf347c0f9afac88410bd0\"},\n+    {file = \"pytest_mock-3.14.0-py3-none-any.whl\", hash = \"sha256:0b72c38033392a5f4621342fe11e9219ac11ec9d375f8e2a0c164539e0d70f6f\"},\n ]\n \n [package.dependencies]\n-pytest = \">=5.0\"\n+pytest = \">=6.2.5\"\n \n [package.extras]\n dev = [\"pre-commit\", \"pytest-asyncio\", \"tox\"]\n@@ -2966,4 +2966,4 @@ extended-testing = [\"jinja2\"]\n [metadata]\n lock-version = \"2.0\"\n python-versions = \">=3.8.1,<4.0\"\n-content-hash = \"ca611429e3dd84ce6dac7ef69d7d9b4da78bf467356946e37016b821e5fe752e\"\n+content-hash = \"a13a0a8454b242106bb681fa74e1f1320a0198f2e07b35d29d985b03a310cf67\""
        },
        {
          "filename": "libs/core/pyproject.toml",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -19,6 +19,7 @@ PyYAML = \">=5.3\"\n requests = \"^2\"\n packaging = \"^23.2\"\n jinja2 = { version = \"^3\", optional = true }\n+defusedxml = \"^0.7\"\n \n [tool.poetry.group.lint]\n optional = true"
        },
        {
          "filename": "libs/core/tests/unit_tests/output_parsers/test_xml_parser.py",
          "status": "modified",
          "additions": 55,
          "deletions": 4,
          "patch": "@@ -1,4 +1,7 @@\n \"\"\"Test XMLOutputParser\"\"\"\n+from typing import AsyncIterator\n+from xml.etree.ElementTree import ParseError\n+\n import pytest\n \n from langchain_core.exceptions import OutputParserException\n@@ -40,19 +43,29 @@\n \"\"\",\n     ],\n )\n-def test_xml_output_parser(result: str) -> None:\n+async def test_xml_output_parser(result: str) -> None:\n     \"\"\"Test XMLOutputParser.\"\"\"\n \n     xml_parser = XMLOutputParser()\n-\n-    xml_result = xml_parser.parse(result)\n-    assert DEF_RESULT_EXPECTED == xml_result\n+    assert DEF_RESULT_EXPECTED == xml_parser.parse(result)\n+    assert DEF_RESULT_EXPECTED == (await xml_parser.aparse(result))\n     assert list(xml_parser.transform(iter(result))) == [\n         {\"foo\": [{\"bar\": [{\"baz\": None}]}]},\n         {\"foo\": [{\"bar\": [{\"baz\": \"slim.shady\"}]}]},\n         {\"foo\": [{\"baz\": \"tag\"}]},\n     ]\n \n+    async def _as_iter(string: str) -> AsyncIterator[str]:\n+        for c in string:\n+            yield c\n+\n+    chunks = [chunk async for chunk in xml_parser.atransform(_as_iter(result))]\n+    assert chunks == [\n+        {\"foo\": [{\"bar\": [{\"baz\": None}]}]},\n+        {\"foo\": [{\"bar\": [{\"baz\": \"slim.shady\"}]}]},\n+        {\"foo\": [{\"baz\": \"tag\"}]},\n+    ]\n+\n \n @pytest.mark.parametrize(\"result\", [\"foo></foo>\", \"<foo></foo\", \"foo></foo\", \"foofoo\"])\n def test_xml_output_parser_fail(result: str) -> None:\n@@ -63,3 +76,41 @@ def test_xml_output_parser_fail(result: str) -> None:\n     with pytest.raises(OutputParserException) as e:\n         xml_parser.parse(result)\n     assert \"Failed to parse\" in str(e)\n+\n+\n+MALICIOUS_XML = \"\"\"<?xml version=\"1.0\"?>\n+<!DOCTYPE lolz [<!ENTITY lol \"lol\"><!ELEMENT lolz (#PCDATA)>\n+ <!ENTITY lol1 \"&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;&lol;\">\n+ <!ENTITY lol2 \"&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;&lol1;\">\n+ <!ENTITY lol3 \"&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;&lol2;\">\n+ <!ENTITY lol4 \"&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;&lol3;\">\n+ <!ENTITY lol5 \"&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;&lol4;\">\n+ <!ENTITY lol6 \"&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;&lol5;\">\n+ <!ENTITY lol7 \"&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;&lol6;\">\n+ <!ENTITY lol8 \"&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;&lol7;\">\n+ <!ENTITY lol9 \"&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;&lol8;\">\n+]>\n+<lolz>&lol9;</lolz>\"\"\"\n+\n+\n+async def tests_billion_laughs_attack() -> None:\n+    parser = XMLOutputParser()\n+    with pytest.raises(OutputParserException):\n+        parser.parse(MALICIOUS_XML)\n+\n+    with pytest.raises(OutputParserException):\n+        await parser.aparse(MALICIOUS_XML)\n+\n+    with pytest.raises(ParseError):\n+        # Right now raises undefined entity error\n+        assert list(parser.transform(iter(MALICIOUS_XML))) == [\n+            {\"foo\": [{\"bar\": [{\"baz\": None}]}]}\n+        ]\n+\n+    async def _as_iter(string: str) -> AsyncIterator[str]:\n+        for c in string:\n+            yield c\n+\n+    with pytest.raises(ParseError):\n+        chunks = [chunk async for chunk in parser.atransform(_as_iter(MALICIOUS_XML))]\n+        assert chunks == [{\"foo\": [{\"bar\": [{\"baz\": None}]}]}]"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 3,
        "max_directory_depth": 5
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "4ab04ad6be0f8f51d22a7df759d7719781fa22f5",
            "date": "2025-01-14T17:55:16Z",
            "author_login": "baskaryan"
          },
          {
            "sha": "d9b856abadef0e7e7338a82f0b2e1239ce3fbd61",
            "date": "2025-01-14T15:23:34Z",
            "author_login": "michaelnchin"
          },
          {
            "sha": "c55af44711ba9180ce8a51a55a385f31023341b5",
            "date": "2025-01-13T23:32:40Z",
            "author_login": "efriis"
          },
          {
            "sha": "cdf3a17e55bd594341c390051dc20c5e5a74b966",
            "date": "2025-01-13T21:25:00Z",
            "author_login": "efriis"
          },
          {
            "sha": "1bf6576709b8c4a4014d5f62cf955c19df1fdf02",
            "date": "2025-01-13T18:28:18Z",
            "author_login": "ccurme"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": null,
    "cvss_vector": null,
    "cwe_id": "CWE-776",
    "description": "A vulnerability in the langchain-ai/langchain repository allows for a Billion Laughs Attack, a type of XML External Entity (XXE) exploitation. By nesting multiple layers of entities within an XML document, an attacker can cause the XML parser to consume excessive CPU and memory resources, leading to a denial of service (DoS). ",
    "attack_vector": null,
    "attack_complexity": null
  },
  "temporal_data": {
    "published_date": "2024-03-26T14:15:08.450",
    "last_modified": "2024-11-21T08:50:37.310",
    "fix_date": "2024-03-25T20:21:52Z"
  },
  "references": [
    {
      "url": "https://github.com/langchain-ai/langchain/commit/727d5023ce88e18e3074ef620a98137d26ff92a3",
      "source": "security@huntr.dev",
      "tags": []
    },
    {
      "url": "https://huntr.com/bounties/4353571f-c70d-4bfd-ac08-3a89cecb45b6",
      "source": "security@huntr.dev",
      "tags": []
    },
    {
      "url": "https://github.com/langchain-ai/langchain/commit/727d5023ce88e18e3074ef620a98137d26ff92a3",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://huntr.com/bounties/4353571f-c70d-4bfd-ac08-3a89cecb45b6",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:07:52.902454",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "langchain",
    "owner": "langchain-ai",
    "created_at": "2022-10-17T02:58:36Z",
    "updated_at": "2025-01-14T13:08:38Z",
    "pushed_at": "2025-01-13T23:32:41Z",
    "size": 376391,
    "stars": 98220,
    "forks": 15956,
    "open_issues": 435,
    "watchers": 98220,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "Jupyter Notebook": 31945259,
      "Python": 19475935,
      "MDX": 56545,
      "Makefile": 55385,
      "Shell": 19562,
      "XSLT": 19446,
      "HTML": 9026,
      "TeX": 2242,
      "Dockerfile": 1311,
      "JavaScript": 471
    },
    "commit_activity": {
      "total_commits_last_year": 7057,
      "avg_commits_per_week": 135.71153846153845,
      "days_active_last_year": 327
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "mit"
    },
    "collected_at": "2025-01-14T13:11:47.805811"
  }
}