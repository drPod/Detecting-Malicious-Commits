{
  "cve_id": "CVE-2024-28233",
  "github_data": {
    "repository": "jupyterhub/jupyterhub",
    "fix_commit": "e2798a088f5ad45340fe79cdf1386198e664f77f",
    "related_commits": [
      "e2798a088f5ad45340fe79cdf1386198e664f77f",
      "e2798a088f5ad45340fe79cdf1386198e664f77f"
    ],
    "patch_url": "https://github.com/jupyterhub/jupyterhub/commit/e2798a088f5ad45340fe79cdf1386198e664f77f.patch",
    "fix_commit_details": {
      "sha": "e2798a088f5ad45340fe79cdf1386198e664f77f",
      "commit_date": "2024-03-20T12:19:29Z",
      "author": {
        "login": "minrk",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Merge pull request from GHSA-7r3h-4ph8-w38g",
        "length": 50,
        "has_description": true,
        "references_issue": false
      },
      "stats": {
        "total": 1266,
        "additions": 1131,
        "deletions": 135
      },
      "files": [
        {
          "filename": ".github/workflows/test.yml",
          "status": "modified",
          "additions": 3,
          "deletions": 0,
          "patch": "@@ -100,6 +100,9 @@ jobs:\n             subset: singleuser\n           - python: \"3.11\"\n             browser: browser\n+          - python: \"3.11\"\n+            subdomain: subdomain\n+            browser: browser\n           - python: \"3.11\"\n             main_dependencies: main_dependencies\n "
        },
        {
          "filename": "docs/source/explanation/websecurity.md",
          "status": "modified",
          "additions": 157,
          "deletions": 21,
          "patch": "@@ -16,7 +16,8 @@ works.\n \n JupyterHub is designed to be a _simple multi-user server for modestly sized\n groups_ of **semi-trusted** users. While the design reflects serving\n-semi-trusted users, JupyterHub can also be suitable for serving **untrusted** users.\n+semi-trusted users, JupyterHub can also be suitable for serving **untrusted** users,\n+but **is not suitable for untrusted users** in its default configuration.\n \n As a result, using JupyterHub with **untrusted** users means more work by the\n administrator, since much care is required to secure a Hub, with extra caution on\n@@ -52,33 +53,67 @@ ensure that:\n     their single-user server;\n   - the modification of the configuration of the notebook server\n     (the `~/.jupyter` or `JUPYTER_CONFIG_DIR` directory).\n+  - unrestricted selection of the base environment (e.g. the image used in container-based Spawners)\n \n If any additional services are run on the same domain as the Hub, the services\n **must never** display user-authored HTML that is neither _sanitized_ nor _sandboxed_\n-(e.g. IFramed) to any user that lacks authentication as the author of a file.\n+to any user that lacks authentication as the author of a file.\n+\n+### Sharing access to servers\n+\n+Because sharing access to servers (via `access:servers` scopes or the sharing feature in JupyterHub 5) by definition means users can serve each other files, enabling sharing is not suitable for untrusted users without also enabling per-user domains.\n+\n+JupyterHub does not enable any sharing by default.\n \n ## Mitigate security issues\n \n The several approaches to mitigating security issues with configuration\n options provided by JupyterHub include:\n \n-### Enable subdomains\n+### Enable user subdomains\n \n JupyterHub provides the ability to run single-user servers on their own\n-subdomains. This means the cross-origin protections between servers has the\n-desired effect, and user servers and the Hub are protected from each other. A\n-user's single-user server will be at `username.jupyter.mydomain.com`. This also\n-requires all user subdomains to point to the same address, which is most easily\n-accomplished with wildcard DNS. Since this spreads the service across multiple\n-domains, you will need wildcard SSL as well. Unfortunately, for many\n-institutional domains, wildcard DNS and SSL are not available. **If you do plan\n-to serve untrusted users, enabling subdomains is highly encouraged**, as it\n-resolves the cross-site issues.\n+domains. This means the cross-origin protections between servers has the\n+desired effect, and user servers and the Hub are protected from each other.\n+\n+**Subdomains are the only way to reliably isolate user servers from each other.**\n+\n+To enable subdomains, set:\n+\n+```python\n+c.JupyterHub.subdomain_host = \"https://jupyter.example.org\"\n+```\n+\n+When subdomains are enabled, each user's single-user server will be at e.g. `https://username.jupyter.example.org`.\n+This also requires all user subdomains to point to the same address,\n+which is most easily accomplished with wildcard DNS, where a single A record points to your server and a wildcard CNAME record points to your A record:\n+\n+```\n+A        jupyter.example.org  192.168.1.123\n+CNAME  *.jupyter.example.org  jupyter.example.org\n+```\n+\n+Since this spreads the service across multiple domains, you will likely need wildcard SSL as well,\n+matching `*.jupyter.example.org`.\n+\n+Unfortunately, for many institutional domains, wildcard DNS and SSL may not be available.\n+\n+We also **strongly encourage** serving JupyterHub and user content on a domain that is _not_ a subdomain of any sensitive content.\n+For reasoning, see [GitHub's discussion of moving user content to github.io from \\*.github.com](https://github.blog/2013-04-09-yummy-cookies-across-domains/).\n+\n+**If you do plan to serve untrusted users, enabling subdomains is highly encouraged**,\n+as it resolves many security issues, which are difficult to unavoidable when JupyterHub is on a single-domain.\n+\n+:::{important}\n+JupyterHub makes no guarantees about protecting users from each other unless subdomains are enabled.\n+\n+If you want to protect users from each other, you **_must_** enable per-user domains.\n+:::\n \n ### Disable user config\n \n If subdomains are unavailable or undesirable, JupyterHub provides a\n-configuration option `Spawner.disable_user_config`, which can be set to prevent\n+configuration option `Spawner.disable_user_config = True`, which can be set to prevent\n the user-owned configuration files from being loaded. After implementing this\n option, `PATH`s and package installation are the other things that the\n admin must enforce.\n@@ -88,21 +123,24 @@ admin must enforce.\n For most Spawners, `PATH` is not something users can influence, but it's important that\n the Spawner should _not_ evaluate shell configuration files prior to launching the server.\n \n-### Isolate packages using virtualenv\n+### Isolate packages in a read-only environment\n \n-Package isolation is most easily handled by running the single-user server in\n-a virtualenv with disabled system-site-packages. The user should not have\n-permission to install packages into this environment.\n+The user must not have permission to install packages into the environment where the singleuser-server runs.\n+On a shared system, package isolation is most easily handled by running the single-user server in\n+a root-owned virtualenv with disabled system-site-packages.\n+The user must not have permission to install packages into this environment.\n+The same principle extends to the images used by container-based deployments.\n+If users can select the images in which their servers run, they can disable all security for their own servers.\n \n-It is important to note that the control over the environment only affects the\n-single-user server, and not the environment(s) in which the user's kernel(s)\n+It is important to note that the control over the environment is only required for the\n+single-user server, and not the environment(s) in which the users' kernel(s)\n may run. Installing additional packages in the kernel environment does not\n pose additional risk to the web application's security.\n \n ### Encrypt internal connections with SSL/TLS\n \n-By default, all communications on the server, between the proxy, hub, and single\n--user notebooks are performed unencrypted. Setting the `internal_ssl` flag in\n+By default, all communications within JupyterHub\u2014between the proxy, hub, and single\n+-user notebooks\u2014are performed unencrypted. Setting the `internal_ssl` flag in\n `jupyterhub_config.py` secures the aforementioned routes. Turning this\n feature on does require that the enabled `Spawner` can use the certificates\n generated by the `Hub` (the default `LocalProcessSpawner` can, for instance).\n@@ -116,6 +154,104 @@ Unix permissions to the communication sockets thereby restricting\n communication to the socket owner. The `internal_ssl` option will eventually\n extend to securing the `tcp` sockets as well.\n \n+### Mitigating same-origin deployments\n+\n+While per-user domains are **required** for robust protection of users from each other,\n+you can mitigate many (but not all) cross-user issues.\n+First, it is critical that users cannot modify their server environments, as described above.\n+Second, it is important that users do not have `access:servers` permission to any server other than their own.\n+\n+If users can access each others' servers, additional security measures must be enabled, some of which come with distinct user-experience costs.\n+\n+Without the [Same-Origin Policy] (SOP) protecting user servers from each other,\n+each user server is considered a trusted origin for requests to each other user server (and the Hub itself).\n+Servers _cannot_ meaningfully distinguish requests originating from other user servers,\n+because SOP implies a great deal of trust, losing many restrictions applied to cross-origin requests.\n+\n+That means pages served from each user server can:\n+\n+1. arbitrarily modify the path in the Referer\n+2. make fully authorized requests with cookies\n+3. access full page contents served from the hub or other servers via popups\n+\n+JupyterHub uses distinct xsrf tokens stored in cookies on each server path to attempt to limit requests across.\n+This has limitations because not all requests are protected by these XSRF tokens,\n+and unless additional measures are taken, the XSRF tokens from other user prefixes may be retrieved.\n+\n+[Same-Origin Policy]: https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy\n+\n+For example:\n+\n+- `Content-Security-Policy` header must prohibit popups and iframes from the same origin.\n+  The following Content-Security-Policy rules are _insecure_ and readily enable users to access each others' servers:\n+\n+  - `frame-ancestors: 'self'`\n+  - `frame-ancestors: '*'`\n+  - `sandbox allow-popups`\n+\n+- Ideally, pages should use the strictest `Content-Security-Policy: sandbox` available,\n+  but this is not feasible in general for JupyterLab pages, which need at least `sandbox allow-same-origin allow-scripts` to work.\n+\n+The default Content-Security-Policy for single-user servers is\n+\n+```\n+frame-ancestors: 'none'\n+```\n+\n+which prohibits iframe embedding, but not pop-ups.\n+\n+A more secure Content-Security-Policy that has some costs to user experience is:\n+\n+```\n+frame-ancestors: 'none'; sandbox allow-same-origin allow-scripts\n+```\n+\n+`allow-popups` is not disabled by default because disabling it breaks legitimate functionality, like \"Open this in a new tab\", and the \"JupyterHub Control Panel\" menu item.\n+To reiterate, the right way to avoid these issues is to enable per-user domains, where none of these concerns come up.\n+\n+Note: even this level of protection requires administrators maintaining full control over the user server environment.\n+If users can modify their server environment, these methods are ineffective, as users can readily disable them.\n+\n+### Cookie tossing\n+\n+Cookie tossing is a technique where another server on a subdomain or peer subdomain can set a cookie\n+which will be read on another domain.\n+This is not relevant unless there are other user-controlled servers on a peer domain.\n+\n+\"Domain-locked\" cookies avoid this issue, but have their own restrictions:\n+\n+- JupyterHub must be served over HTTPS\n+- All secure cookies must be set on `/`, not on sub-paths, which means they are shared by all JupyterHub components in a single-domain deployment.\n+\n+As a result, this option is only recommended when per-user subdomains are enabled,\n+to prevent sending all jupyterhub cookies to all user servers.\n+\n+To enable domain-locked cookies, set:\n+\n+```python\n+c.JupyterHub.cookie_host_prefix_enabled = True\n+```\n+\n+```{versionadded} 4.1\n+\n+```\n+\n+### Forced-login\n+\n+Jupyter servers can share links with `?token=...`.\n+JupyterHub prior to 5.0 will accept this request and persist the token for future requests.\n+This is useful for enabling admins to create 'fully authenticated' links bypassing login.\n+However, it also means users can share their own links that will log other users into their own servers,\n+enabling them to serve each other notebooks and other arbitrary HTML, depending on server configuration.\n+\n+```{versionadded} 4.1\n+Setting environment variable `JUPYTERHUB_ALLOW_TOKEN_IN_URL=0` in the single-user environment can opt out of accepting token auth in URL parameters.\n+```\n+\n+```{versionadded} 5.0\n+Accepting tokens in URLs is disabled by default, and `JUPYTERHUB_ALLOW_TOKEN_IN_URL=1` environment variable must be set to _allow_ token auth in URL parameters.\n+```\n+\n ## Security audits\n \n We recommend that you do periodic reviews of your deployment's security. It's"
        },
        {
          "filename": "docs/source/reference/changelog.md",
          "status": "modified",
          "additions": 51,
          "deletions": 0,
          "patch": "@@ -8,6 +8,57 @@ command line for details.\n \n ## [Unreleased]\n \n+## 4.1\n+\n+### 4.1.0 - 2024-03\n+\n+JupyterHub 4.1 is a security release, fixing [CVE-2024-28233].\n+All JupyterHub deployments are encouraged to upgrade,\n+especially those with other user content on peer domains to JupyterHub.\n+\n+As always, JupyterHub deployments are especially encouraged to enable per-user domains if protecting users from each other is a concern.\n+\n+For more information on securely deploying JupyterHub, see the [web security documentation](web-security).\n+\n+[CVE-2024-28233]: https://github.com/jupyterhub/jupyterhub/security/advisories/GHSA-7r3h-4ph8-w38g\n+\n+([full changelog](https://github.com/jupyterhub/jupyterhub/compare/4.0.2...4.1.0))\n+\n+#### Enhancements made\n+\n+- Backport PR #4628 on branch 4.x (Include LDAP groups in local spawner gids) [#4735](https://github.com/jupyterhub/jupyterhub/pull/4735) ([@minrk](https://github.com/minrk))\n+- Backport PR #4561 on branch 4.x (Improve debugging when waiting for servers) [#4714](https://github.com/jupyterhub/jupyterhub/pull/4714) ([@minrk](https://github.com/minrk))\n+- Backport PR #4563 on branch 4.x (only set 'domain' field on session-id cookie) [#4707](https://github.com/jupyterhub/jupyterhub/pull/4707) ([@minrk](https://github.com/minrk))\n+\n+#### Bugs fixed\n+\n+- Backport PR #4733 on branch 4.x (Catch ValueError while waiting for server to be reachable) [#4734](https://github.com/jupyterhub/jupyterhub/pull/4734) ([@minrk](https://github.com/minrk))\n+- Backport PR #4679 on branch 4.x (Unescape jinja username) [#4705](https://github.com/jupyterhub/jupyterhub/pull/4705) ([@minrk](https://github.com/minrk))\n+- Backport PR #4630: avoid setting unused oauth state cookies on API requests [#4697](https://github.com/jupyterhub/jupyterhub/pull/4697) ([@minrk](https://github.com/minrk))\n+- Backport PR #4632: simplify, avoid errors in parsing accept headers [#4696](https://github.com/jupyterhub/jupyterhub/pull/4696) ([@minrk](https://github.com/minrk))\n+- Backport PR #4677 on branch 4.x (Improve validation, docs for token.expires_in) [#4692](https://github.com/jupyterhub/jupyterhub/pull/4692) ([@minrk](https://github.com/minrk))\n+- Backport PR #4570 on branch 4.x (fix mutation of frozenset in scope intersection) [#4691](https://github.com/jupyterhub/jupyterhub/pull/4691) ([@minrk](https://github.com/minrk))\n+- Backport PR #4562 on branch 4.x (Use `user.stop` to cleanup spawners that stopped while Hub was down) [#4690](https://github.com/jupyterhub/jupyterhub/pull/4690) ([@minrk](https://github.com/minrk))\n+- Backport PR #4542 on branch 4.x (Fix include_stopped_servers in paginated next_url) [#4689](https://github.com/jupyterhub/jupyterhub/pull/4689) ([@minrk](https://github.com/minrk))\n+- Backport PR #4651 on branch 4.x (avoid attempting to patch removed IPythonHandler with notebook v7) [#4688](https://github.com/jupyterhub/jupyterhub/pull/4688) ([@minrk](https://github.com/minrk))\n+- Backport PR #4560 on branch 4.x (singleuser extension: persist token from ?token=... url in cookie) [#4687](https://github.com/jupyterhub/jupyterhub/pull/4687) ([@minrk](https://github.com/minrk))\n+\n+#### Maintenance and upkeep improvements\n+\n+- Backport quay.io publishing [#4698](https://github.com/jupyterhub/jupyterhub/pull/4698) ([@minrk](https://github.com/minrk))\n+- Backport PR #4617: try to improve reliability of test_external_proxy [#4695](https://github.com/jupyterhub/jupyterhub/pull/4695) ([@minrk](https://github.com/minrk))\n+- Backport PR #4618 on branch 4.x (browser test: wait for token request to finish before reloading) [#4694](https://github.com/jupyterhub/jupyterhub/pull/4694) ([@minrk](https://github.com/minrk))\n+- preparing 4.x branch [#4685](https://github.com/jupyterhub/jupyterhub/pull/4685) ([@minrk](https://github.com/minrk), [@consideRatio](https://github.com/consideRatio))\n+\n+#### Contributors to this release\n+\n+The following people contributed discussions, new ideas, code and documentation contributions, and review.\n+See [our definition of contributors](https://github-activity.readthedocs.io/en/latest/#how-does-this-tool-define-contributions-in-the-reports).\n+\n+([GitHub contributors page for this release](https://github.com/jupyterhub/jupyterhub/graphs/contributors?from=2023-08-10&to=2024-03-19&type=c))\n+\n+@Achele ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3AAchele+updated%3A2023-08-10..2024-03-19&type=Issues)) | @akashthedeveloper ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Aakashthedeveloper+updated%3A2023-08-10..2024-03-19&type=Issues)) | @balajialg ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Abalajialg+updated%3A2023-08-10..2024-03-19&type=Issues)) | @BhavyaT-135 ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3ABhavyaT-135+updated%3A2023-08-10..2024-03-19&type=Issues)) | @blink1073 ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Ablink1073+updated%3A2023-08-10..2024-03-19&type=Issues)) | @consideRatio ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3AconsideRatio+updated%3A2023-08-10..2024-03-19&type=Issues)) | @fcollonval ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Afcollonval+updated%3A2023-08-10..2024-03-19&type=Issues)) | @I-Am-D-B ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3AI-Am-D-B+updated%3A2023-08-10..2024-03-19&type=Issues)) | @jakirkham ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Ajakirkham+updated%3A2023-08-10..2024-03-19&type=Issues)) | @ktaletsk ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Aktaletsk+updated%3A2023-08-10..2024-03-19&type=Issues)) | @kzgrzendek ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Akzgrzendek+updated%3A2023-08-10..2024-03-19&type=Issues)) | @lumberbot-app ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Alumberbot-app+updated%3A2023-08-10..2024-03-19&type=Issues)) | @manics ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Amanics+updated%3A2023-08-10..2024-03-19&type=Issues)) | @mbiette ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Ambiette+updated%3A2023-08-10..2024-03-19&type=Issues)) | @minrk ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Aminrk+updated%3A2023-08-10..2024-03-19&type=Issues)) | @rcthomas ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Arcthomas+updated%3A2023-08-10..2024-03-19&type=Issues)) | @ryanlovett ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Aryanlovett+updated%3A2023-08-10..2024-03-19&type=Issues)) | @sgaist ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Asgaist+updated%3A2023-08-10..2024-03-19&type=Issues)) | @shubham0473 ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Ashubham0473+updated%3A2023-08-10..2024-03-19&type=Issues)) | @Temidayo32 ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3ATemidayo32+updated%3A2023-08-10..2024-03-19&type=Issues)) | @willingc ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Awillingc+updated%3A2023-08-10..2024-03-19&type=Issues)) | @yuvipanda ([activity](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyterhub+involves%3Ayuvipanda+updated%3A2023-08-10..2024-03-19&type=Issues))\n+\n ## 4.0\n \n ### 4.0.2 - 2023-08-10"
        },
        {
          "filename": "jupyterhub/_xsrf_utils.py",
          "status": "added",
          "additions": 210,
          "deletions": 0,
          "patch": "@@ -0,0 +1,210 @@\n+\"\"\"utilities for XSRF \n+\n+Extends tornado's xsrf token checks with the following:\n+\n+- only set xsrf cookie on navigation requests (cannot be fetched)\n+\n+This utility file enables the consistent reuse of these functions\n+in both Hub and single-user code\n+\"\"\"\n+\n+import base64\n+import hashlib\n+from datetime import datetime, timedelta, timezone\n+from http.cookies import SimpleCookie\n+\n+from tornado import web\n+from tornado.httputil import format_timestamp\n+from tornado.log import app_log\n+\n+\n+def _get_signed_value_urlsafe(handler, name, b64_value):\n+    \"\"\"Like get_signed_value (used in get_secure_cookie), but for urlsafe values\n+\n+    Decodes urlsafe_base64-encoded signed values\n+\n+    Returns None if any decoding failed\n+    \"\"\"\n+    if b64_value is None:\n+        return None\n+\n+    if isinstance(b64_value, str):\n+        try:\n+            b64_value = b64_value.encode(\"ascii\")\n+        except UnicodeEncodeError:\n+            app_log.warning(\"Invalid value %r\", b64_value)\n+            return None\n+    # re-pad, since we stripped padding in _create_signed_value\n+    remainder = len(b64_value) % 4\n+    if remainder:\n+        b64_value = b64_value + (b'=' * (4 - remainder))\n+    try:\n+        value = base64.urlsafe_b64decode(b64_value)\n+    except ValueError:\n+        app_log.warning(\"Invalid base64 value %r\", b64_value)\n+        return None\n+\n+    return web.decode_signed_value(\n+        handler.application.settings[\"cookie_secret\"],\n+        name,\n+        value,\n+        max_age_days=31,\n+        min_version=2,\n+    )\n+\n+\n+def _create_signed_value_urlsafe(handler, name, value):\n+    \"\"\"Like tornado's create_signed_value (used in set_secure_cookie), but returns urlsafe bytes\"\"\"\n+\n+    signed_value = handler.create_signed_value(name, value)\n+    return base64.urlsafe_b64encode(signed_value).rstrip(b\"=\")\n+\n+\n+def _clear_invalid_xsrf_cookie(handler, cookie_path):\n+    \"\"\"\n+    Clear invalid XSRF cookie\n+\n+    This may an old XSRF token, or one set on / by another application.\n+    Because we cannot trust browsers or tornado to give us the more specific cookie,\n+    try to clear _both_ on / and on our prefix,\n+    then reload the page.\n+    \"\"\"\n+\n+    expired = format_timestamp(datetime.now(timezone.utc) - timedelta(days=366))\n+    cookie = SimpleCookie()\n+    cookie[\"_xsrf\"] = \"\"\n+    morsel = cookie[\"_xsrf\"]\n+    morsel[\"expires\"] = expired\n+    morsel[\"path\"] = \"/\"\n+    # use Set-Cookie directly,\n+    # because tornado's set_cookie and clear_cookie use a single _dict_,\n+    # so we can't clear a cookie on multiple paths and then set it\n+    handler.add_header(\"Set-Cookie\", morsel.OutputString(None))\n+    if cookie_path != \"/\":\n+        # clear it multiple times!\n+        morsel[\"path\"] = cookie_path\n+        handler.add_header(\"Set-Cookie\", morsel.OutputString(None))\n+\n+    if (\n+        handler.request.method.lower() == \"get\"\n+        and handler.request.headers.get(\"Sec-Fetch-Mode\", \"navigate\") == \"navigate\"\n+    ):\n+        # reload current page because any subsequent set_cookie\n+        # will cancel the clearing of the cookie\n+        # this only makes sense on GET requests\n+        handler.redirect(handler.request.uri)\n+        # halt any other processing of the request\n+        raise web.Finish()\n+\n+\n+def get_xsrf_token(handler, cookie_path=\"\"):\n+    \"\"\"Override tornado's xsrf token to add further restrictions\n+\n+    - only set cookie for regular pages (not API requests)\n+    - include login info in xsrf token\n+    - verify signature\n+    \"\"\"\n+    # original: https://github.com/tornadoweb/tornado/blob/v6.4.0/tornado/web.py#L1455\n+    if hasattr(handler, \"_xsrf_token\"):\n+        return handler._xsrf_token\n+\n+    _set_cookie = False\n+    # the raw cookie is the token\n+    xsrf_token = xsrf_cookie = handler.get_cookie(\"_xsrf\")\n+    if xsrf_token:\n+        try:\n+            xsrf_token = xsrf_token.encode(\"ascii\")\n+        except UnicodeEncodeError:\n+            xsrf_token = None\n+\n+    xsrf_id_cookie = _get_signed_value_urlsafe(handler, \"_xsrf\", xsrf_token)\n+    if xsrf_cookie and not xsrf_id_cookie:\n+        # we have a cookie, but it's invalid!\n+        # handle possibility of _xsrf being set multiple times,\n+        # e.g. on / and on /hub/\n+        # this will reload the page if it's a GET request\n+        app_log.warning(\n+            \"Attempting to clear invalid _xsrf cookie %r\", xsrf_cookie[:4] + \"...\"\n+        )\n+        _clear_invalid_xsrf_cookie(handler, cookie_path)\n+\n+    # check the decoded, signed value for validity\n+    xsrf_id = handler._xsrf_token_id\n+    if xsrf_id_cookie != xsrf_id:\n+        # this will usually happen on the first page request after login,\n+        # which changes the inputs to the token id\n+        if xsrf_id_cookie:\n+            app_log.debug(\"xsrf id mismatch %r != %r\", xsrf_id_cookie, xsrf_id)\n+        # generate new value\n+        xsrf_token = _create_signed_value_urlsafe(handler, \"_xsrf\", xsrf_id)\n+        # only set cookie on regular navigation pages\n+        # i.e. not API requests, etc.\n+        # insecure URLs (public hostname/ip, no https)\n+        # don't set Sec-Fetch-Mode.\n+        # consequence of assuming 'navigate': setting a cookie unnecessarily\n+        # consequence of assuming not 'navigate': xsrf never set, nothing works\n+        _set_cookie = (\n+            handler.request.headers.get(\"Sec-Fetch-Mode\", \"navigate\") == \"navigate\"\n+        )\n+\n+    if _set_cookie:\n+        xsrf_cookie_kwargs = {}\n+        xsrf_cookie_kwargs.update(handler.settings.get('xsrf_cookie_kwargs', {}))\n+        xsrf_cookie_kwargs.setdefault(\"path\", cookie_path)\n+        if not handler.current_user:\n+            # limit anonymous xsrf cookies to one hour\n+            xsrf_cookie_kwargs.pop(\"expires\", None)\n+            xsrf_cookie_kwargs.pop(\"expires_days\", None)\n+            xsrf_cookie_kwargs[\"max_age\"] = 3600\n+        app_log.info(\n+            \"Setting new xsrf cookie for %r %r\",\n+            xsrf_id,\n+            xsrf_cookie_kwargs,\n+        )\n+        handler.set_cookie(\"_xsrf\", xsrf_token, **xsrf_cookie_kwargs)\n+    handler._xsrf_token = xsrf_token\n+    return xsrf_token\n+\n+\n+def check_xsrf_cookie(handler):\n+    \"\"\"Check that xsrf cookie matches xsrf token in request\"\"\"\n+    # overrides tornado's implementation\n+    # because we changed what a correct value should be in xsrf_token\n+\n+    token = (\n+        handler.get_argument(\"_xsrf\", None)\n+        or handler.request.headers.get(\"X-Xsrftoken\")\n+        or handler.request.headers.get(\"X-Csrftoken\")\n+    )\n+\n+    if not token:\n+        raise web.HTTPError(\n+            403, f\"'_xsrf' argument missing from {handler.request.method}\"\n+        )\n+\n+    try:\n+        token = token.encode(\"utf8\")\n+    except UnicodeEncodeError:\n+        raise web.HTTPError(403, \"'_xsrf' argument invalid\")\n+\n+    if token != handler.xsrf_token:\n+        raise web.HTTPError(\n+            403, f\"XSRF cookie does not match {handler.request.method.upper()} argument\"\n+        )\n+\n+\n+def _anonymous_xsrf_id(handler):\n+    \"\"\"Generate an appropriate xsrf token id for an anonymous request\n+\n+    Currently uses hash of request ip and user-agent\n+\n+    These are typically used only for the initial login page,\n+    so only need to be valid for a few seconds to a few minutes\n+    (enough to submit a login form with MFA).\n+    \"\"\"\n+    hasher = hashlib.sha256()\n+    hasher.update(handler.request.remote_ip.encode(\"ascii\"))\n+    hasher.update(\n+        handler.request.headers.get(\"User-Agent\", \"\").encode(\"utf8\", \"replace\")\n+    )\n+    return base64.urlsafe_b64encode(hasher.digest()).decode(\"ascii\")"
        },
        {
          "filename": "jupyterhub/apihandlers/base.py",
          "status": "modified",
          "additions": 2,
          "deletions": 9,
          "patch": "@@ -76,15 +76,8 @@ def check_post_content_type(self):\n \n         return True\n \n-    async def prepare(self):\n-        await super().prepare()\n-        # tornado only checks xsrf on non-GET\n-        # we also check xsrf on GETs to API endpoints\n-        # make sure this runs after auth, which happens in super().prepare()\n-        if self.request.method not in {\"HEAD\", \"OPTIONS\"} and self.settings.get(\n-            \"xsrf_cookies\"\n-        ):\n-            self.check_xsrf_cookie()\n+    # we also check xsrf on GETs to API endpoints\n+    _xsrf_safe_methods = {\"HEAD\", \"OPTIONS\"}\n \n     def check_xsrf_cookie(self):\n         if not hasattr(self, '_jupyterhub_user'):"
        },
        {
          "filename": "jupyterhub/app.py",
          "status": "modified",
          "additions": 22,
          "deletions": 0,
          "patch": "@@ -401,6 +401,25 @@ def _validate_config_file(self, proposal):\n         Useful for daemonizing JupyterHub.\n         \"\"\",\n     ).tag(config=True)\n+\n+    cookie_host_prefix_enabled = Bool(\n+        False,\n+        help=\"\"\"Enable `__Host-` prefix on authentication cookies.\n+        \n+        The `__Host-` prefix on JupyterHub cookies provides further\n+        protection against cookie tossing when untrusted servers\n+        may control subdomains of your jupyterhub deployment.\n+        \n+        _However_, it also requires that cookies be set on the path `/`,\n+        which means they are shared by all JupyterHub components,\n+        so a compromised server component will have access to _all_ JupyterHub-related\n+        cookies of the visiting browser.\n+        It is recommended to only combine `__Host-` cookies with per-user domains.\n+\n+        .. versionadded:: 4.1\n+        \"\"\",\n+    ).tag(config=True)\n+\n     cookie_max_age_days = Float(\n         14,\n         help=\"\"\"Number of days for a login cookie to be valid.\n@@ -1898,6 +1917,8 @@ def init_hub(self):\n             hub_args['port'] = self.hub_port\n \n         self.hub = Hub(**hub_args)\n+        if self.cookie_host_prefix_enabled:\n+            self.hub.cookie_name = \"__Host-\" + self.hub.cookie_name\n \n         if not self.subdomain_host:\n             api_prefix = url_path_join(self.hub.base_url, \"api/\")\n@@ -2760,6 +2781,7 @@ def init_tornado_settings(self):\n             base_url=self.base_url,\n             default_url=self.default_url,\n             cookie_secret=self.cookie_secret,\n+            cookie_host_prefix_enabled=self.cookie_host_prefix_enabled,\n             cookie_max_age_days=self.cookie_max_age_days,\n             redirect_to_server=self.redirect_to_server,\n             login_url=login_url,"
        },
        {
          "filename": "jupyterhub/handlers/base.py",
          "status": "modified",
          "additions": 88,
          "deletions": 14,
          "patch": "@@ -24,6 +24,7 @@\n from tornado.web import RequestHandler, addslash\n \n from .. import __version__, orm, roles, scopes\n+from .._xsrf_utils import _anonymous_xsrf_id, check_xsrf_cookie, get_xsrf_token\n from ..metrics import (\n     PROXY_ADD_DURATION_SECONDS,\n     PROXY_DELETE_DURATION_SECONDS,\n@@ -99,7 +100,14 @@ async def prepare(self):\n                 self.log.error(\"Rolling back session due to database error\")\n                 self.db.rollback()\n         self._resolve_roles_and_scopes()\n-        return await maybe_future(super().prepare())\n+        await maybe_future(super().prepare())\n+        # run xsrf check after prepare\n+        # because our version takes auth info into account\n+        if (\n+            self.request.method not in self._xsrf_safe_methods\n+            and self.application.settings.get(\"xsrf_cookies\")\n+        ):\n+            self.check_xsrf_cookie()\n \n     @property\n     def log(self):\n@@ -200,9 +208,13 @@ def content_security_policy(self):\n         \"\"\"The default Content-Security-Policy header\n \n         Can be overridden by defining Content-Security-Policy in settings['headers']\n+\n+        ..versionchanged:: 4.1\n+\n+            Change default frame-ancestors from 'self' to 'none'\n         \"\"\"\n         return '; '.join(\n-            [\"frame-ancestors 'self'\", \"report-uri \" + self.csp_report_uri]\n+            [\"frame-ancestors 'none'\", \"report-uri \" + self.csp_report_uri]\n         )\n \n     def get_content_type(self):\n@@ -212,7 +224,6 @@ def set_default_headers(self):\n         \"\"\"\n         Set any headers passed as tornado_settings['headers'].\n \n-        By default sets Content-Security-Policy of frame-ancestors 'self'.\n         Also responsible for setting content-type header\n         \"\"\"\n         # wrap in HTTPHeaders for case-insensitivity\n@@ -234,17 +245,63 @@ def set_default_headers(self):\n     # Login and cookie-related\n     # ---------------------------------------------------------------\n \n+    _xsrf_safe_methods = {\"GET\", \"HEAD\", \"OPTIONS\"}\n+\n+    @property\n+    def _xsrf_token_id(self):\n+        \"\"\"Value to be signed/encrypted for xsrf token\n+\n+        include login info in xsrf token\n+        this means xsrf tokens are tied to logged-in users,\n+        and change after a user logs in.\n+\n+        While the user is not yet logged in,\n+        an anonymous value is used, to prevent portability.\n+        These anonymous values are short-lived.\n+        \"\"\"\n+        # cases:\n+        # 1. logged in, session id (session_id:user_id)\n+        # 2. logged in, no session id (anonymous_id:user_id)\n+        # 3. not logged in, session id (session_id:anonymous_id)\n+        # 4. no cookies at all, use single anonymous value (:anonymous_id)\n+        session_id = self.get_session_cookie()\n+        if self.current_user:\n+            if isinstance(self.current_user, User):\n+                user_id = self.current_user.cookie_id\n+            else:\n+                # this shouldn't happen, but may if e.g. a Service attempts to fetch a page,\n+                # which usually won't work, but this method should not be what raises\n+                user_id = \"\"\n+            if not session_id:\n+                # no session id, use non-portable anonymous id\n+                session_id = _anonymous_xsrf_id(self)\n+        else:\n+            # not logged in yet, use non-portable anonymous id\n+            user_id = _anonymous_xsrf_id(self)\n+        xsrf_id = f\"{session_id}:{user_id}\".encode(\"utf8\", \"replace\")\n+        return xsrf_id\n+\n+    @property\n+    def xsrf_token(self):\n+        \"\"\"Override tornado's xsrf token with further restrictions\n+\n+        - only set cookie for regular pages\n+        - include login info in xsrf token\n+        - verify signature\n+        \"\"\"\n+        return get_xsrf_token(self, cookie_path=self.hub.base_url)\n+\n     def check_xsrf_cookie(self):\n-        try:\n-            return super().check_xsrf_cookie()\n-        except web.HTTPError as e:\n-            # ensure _jupyterhub_user is defined on rejected requests\n-            if not hasattr(self, \"_jupyterhub_user\"):\n-                self._jupyterhub_user = None\n-            self._resolve_roles_and_scopes()\n-            # rewrite message because we use this on methods other than POST\n-            e.log_message = e.log_message.replace(\"POST\", self.request.method)\n-            raise\n+        \"\"\"Check that xsrf cookie matches xsrf token in request\"\"\"\n+        # overrides tornado's implementation\n+        # because we changed what a correct value should be in xsrf_token\n+\n+        if not hasattr(self, \"_jupyterhub_user\"):\n+            # run too early to check the value\n+            # tornado runs this before 'prepare',\n+            # but we run it again after so auth info is available, which happens in 'prepare'\n+            return None\n+        return check_xsrf_cookie(self)\n \n     @property\n     def admin_users(self):\n@@ -517,6 +574,16 @@ def user_from_username(self, username):\n             user = self._user_from_orm(u)\n         return user\n \n+    def clear_cookie(self, cookie_name, **kwargs):\n+        \"\"\"Clear a cookie\n+\n+        overrides RequestHandler to always handle __Host- prefix correctly\n+        \"\"\"\n+        if cookie_name.startswith(\"__Host-\"):\n+            kwargs[\"path\"] = \"/\"\n+            kwargs[\"secure\"] = True\n+        return super().clear_cookie(cookie_name, **kwargs)\n+\n     def clear_login_cookie(self, name=None):\n         kwargs = {}\n         user = self.get_current_user_cookie()\n@@ -583,6 +650,11 @@ def _set_cookie(self, key, value, encrypted=True, **overrides):\n         kwargs.update(self.settings.get('cookie_options', {}))\n         kwargs.update(overrides)\n \n+        if key.startswith(\"__Host-\"):\n+            # __Host- cookies must be secure and on /\n+            kwargs[\"path\"] = \"/\"\n+            kwargs[\"secure\"] = True\n+\n         if encrypted:\n             set_cookie = self.set_secure_cookie\n         else:\n@@ -612,7 +684,9 @@ def set_session_cookie(self):\n         Session id cookie is *not* encrypted,\n         so other services on this domain can read it.\n         \"\"\"\n-        session_id = uuid.uuid4().hex\n+        if not hasattr(self, \"_session_id\"):\n+            self._session_id = uuid.uuid4().hex\n+        session_id = self._session_id\n         # if using subdomains, set session cookie on the domain,\n         # which allows it to be shared by subdomains.\n         # if domain is unspecified, it is _more_ restricted to only the setting domain"
        },
        {
          "filename": "jupyterhub/services/auth.py",
          "status": "modified",
          "additions": 231,
          "deletions": 13,
          "patch": "@@ -36,6 +36,7 @@\n import time\n import uuid\n import warnings\n+from functools import partial\n from http import HTTPStatus\n from unittest import mock\n from urllib.parse import urlencode\n@@ -46,6 +47,7 @@\n from tornado.web import HTTPError, RequestHandler\n from traitlets import (\n     Any,\n+    Bool,\n     Dict,\n     Instance,\n     Integer,\n@@ -57,8 +59,9 @@\n )\n from traitlets.config import SingletonConfigurable\n \n+from .._xsrf_utils import _anonymous_xsrf_id, check_xsrf_cookie, get_xsrf_token\n from ..scopes import _intersect_expanded_scopes\n-from ..utils import get_browser_protocol, url_path_join\n+from ..utils import _bool_env, get_browser_protocol, url_path_join\n \n \n def check_scopes(required_scopes, scopes):\n@@ -306,6 +309,46 @@ def _default_login_url(self):\n         \"\"\",\n     ).tag(config=True)\n \n+    allow_token_in_url = Bool(\n+        _bool_env(\"JUPYTERHUB_ALLOW_TOKEN_IN_URL\", default=True),\n+        help=\"\"\"Allow requests to pages with ?token=... in the URL\n+        \n+        This allows starting a user session by sharing a URL with credentials,\n+        bypassing authentication with the Hub.\n+        \n+        If False, tokens in URLs will be ignored by the server,\n+        except on websocket requests.\n+        \n+        Has no effect on websocket requests,\n+        which can only reliably authenticate via token in the URL,\n+        as recommended by browser Websocket implementations.\n+\n+        This will default to False in JupyterHub 5.\n+\n+        .. versionadded:: 4.1\n+\n+        .. versionchanged:: 5.0\n+            default changed to False\n+        \"\"\",\n+    ).tag(config=True)\n+\n+    allow_websocket_cookie_auth = Bool(\n+        _bool_env(\"JUPYTERHUB_ALLOW_WEBSOCKET_COOKIE_AUTH\", default=True),\n+        help=\"\"\"Allow websocket requests with only cookie for authentication\n+\n+        Cookie-authenticated websockets cannot be protected from other user servers unless per-user domains are used.\n+        Disabling cookie auth on websockets protects user servers from each other,\n+        but may break some user applications.\n+        Per-user domains eliminate the need to lock this down.\n+        \n+        JupyterLab 4.1.2 and Notebook 6.5.6, 7.1.0 will not work\n+        because they rely on cookie authentication without\n+        API or XSRF tokens.\n+        \n+        .. versionadded:: 4.1\n+        \"\"\",\n+    ).tag(config=True)\n+\n     cookie_options = Dict(\n         help=\"\"\"Additional options to pass when setting cookies.\n \n@@ -324,6 +367,40 @@ def _default_cookie_options(self):\n         else:\n             return {}\n \n+    cookie_host_prefix_enabled = Bool(\n+        False,\n+        help=\"\"\"Enable `__Host-` prefix on authentication cookies.\n+        \n+        The `__Host-` prefix on JupyterHub cookies provides further\n+        protection against cookie tossing when untrusted servers\n+        may control subdomains of your jupyterhub deployment.\n+        \n+        _However_, it also requires that cookies be set on the path `/`,\n+        which means they are shared by all JupyterHub components,\n+        so a compromised server component will have access to _all_ JupyterHub-related\n+        cookies of the visiting browser.\n+        It is recommended to only combine `__Host-` cookies with per-user domains.\n+        \n+        Set via $JUPYTERHUB_COOKIE_HOST_PREFIX_ENABLED\n+        \"\"\",\n+    ).tag(config=True)\n+\n+    @default(\"cookie_host_prefix_enabled\")\n+    def _default_cookie_host_prefix_enabled(self):\n+        return _bool_env(\"JUPYTERHUB_COOKIE_HOST_PREFIX_ENABLED\")\n+\n+    @property\n+    def cookie_path(self):\n+        \"\"\"\n+        Path prefix on which to set cookies\n+\n+        self.base_url, but '/' when cookie_host_prefix_enabled is True\n+        \"\"\"\n+        if self.cookie_host_prefix_enabled:\n+            return \"/\"\n+        else:\n+            return self.base_url\n+\n     cookie_cache_max_age = Integer(help=\"DEPRECATED. Use cache_max_age\")\n \n     @observe('cookie_cache_max_age')\n@@ -586,6 +663,17 @@ def user_for_token(self, token, use_cache=True, session_id='', *, sync=True):\n     auth_header_name = 'Authorization'\n     auth_header_pat = re.compile(r'(?:token|bearer)\\s+(.+)', re.IGNORECASE)\n \n+    def _get_token_url(self, handler):\n+        \"\"\"Get the token from the URL\n+\n+        Always run for websockets,\n+        otherwise run only if self.allow_token_in_url\n+        \"\"\"\n+        fetch_mode = handler.request.headers.get(\"Sec-Fetch-Mode\", \"unspecified\")\n+        if self.allow_token_in_url or fetch_mode == \"websocket\":\n+            return handler.get_argument(\"token\", \"\")\n+        return \"\"\n+\n     def get_token(self, handler, in_cookie=True):\n         \"\"\"Get the token authenticating a request\n \n@@ -598,8 +686,7 @@ def get_token(self, handler, in_cookie=True):\n         - in header: Authorization: token <token>\n         - in cookie (stored after oauth), if in_cookie is True\n         \"\"\"\n-\n-        user_token = handler.get_argument('token', '')\n+        user_token = self._get_token_url(handler)\n         if not user_token:\n             # get it from Authorization header\n             m = self.auth_header_pat.match(\n@@ -646,13 +733,24 @@ def get_user(self, handler, *, sync=True):\n         \"\"\"\n         return self._call_coroutine(sync, self._get_user, handler)\n \n+    def _patch_xsrf(self, handler):\n+        \"\"\"Overridden in HubOAuth\n+\n+        HubAuth base class doesn't handle xsrf,\n+        which is only relevant for cookie-based auth\n+        \"\"\"\n+        return\n+\n     async def _get_user(self, handler):\n         # only allow this to be called once per handler\n         # avoids issues if an error is raised,\n         # since this may be called again when trying to render the error page\n         if hasattr(handler, '_cached_hub_user'):\n             return handler._cached_hub_user\n \n+        # patch XSRF checks, which will apply after user check\n+        self._patch_xsrf(handler)\n+\n         handler._cached_hub_user = user_model = None\n         session_id = self.get_session_id(handler)\n \n@@ -738,7 +836,10 @@ def cookie_name(self):\n         because we don't want to use the same cookie name\n         across OAuth clients.\n         \"\"\"\n-        return self.oauth_client_id\n+        cookie_name = self.oauth_client_id\n+        if self.cookie_host_prefix_enabled:\n+            cookie_name = \"__Host-\" + cookie_name\n+        return cookie_name\n \n     @property\n     def state_cookie_name(self):\n@@ -750,22 +851,103 @@ def state_cookie_name(self):\n \n     def _get_token_cookie(self, handler):\n         \"\"\"Base class doesn't store tokens in cookies\"\"\"\n+\n+        fetch_mode = handler.request.headers.get(\"Sec-Fetch-Mode\", \"unset\")\n+        if fetch_mode == \"websocket\" and not self.allow_websocket_cookie_auth:\n+            # disallow cookie auth on websockets\n+            return None\n+\n         token = handler.get_secure_cookie(self.cookie_name)\n         if token:\n             # decode cookie bytes\n             token = token.decode('ascii', 'replace')\n         return token\n \n+    def _get_xsrf_token_id(self, handler):\n+        \"\"\"Get contents for xsrf token for a given Handler\n+\n+        This is the value to be encrypted & signed in the xsrf token\n+        \"\"\"\n+        token = self._get_token_cookie(handler)\n+        session_id = self.get_session_id(handler)\n+        if token:\n+            token_hash = hashlib.sha256(token.encode(\"ascii\", \"replace\")).hexdigest()\n+            if not session_id:\n+                session_id = _anonymous_xsrf_id(handler)\n+        else:\n+            token_hash = _anonymous_xsrf_id(handler)\n+        return f\"{session_id}:{token_hash}\".encode(\"ascii\", \"replace\")\n+\n+    def _patch_xsrf(self, handler):\n+        \"\"\"Patch handler to inject JuptyerHub xsrf token behavior\"\"\"\n+        handler._xsrf_token_id = self._get_xsrf_token_id(handler)\n+        # override xsrf_token property on class,\n+        # so it's still a getter, not invoked immediately\n+        handler.__class__.xsrf_token = property(\n+            partial(get_xsrf_token, cookie_path=self.base_url)\n+        )\n+        handler.check_xsrf_cookie = partial(self.check_xsrf_cookie, handler)\n+\n+    def check_xsrf_cookie(self, handler):\n+        \"\"\"check_xsrf_cookie patch\n+\n+        Applies JupyterHub check_xsrf_cookie if not token authenticated\n+        \"\"\"\n+        if getattr(handler, '_token_authenticated', False):\n+            return\n+        check_xsrf_cookie(handler)\n+\n+    def _clear_cookie(self, handler, cookie_name, **kwargs):\n+        \"\"\"Clear a cookie, handling __Host- prefix\"\"\"\n+        # Set-Cookie is rejected without 'secure',\n+        # this includes clearing cookies!\n+        if cookie_name.startswith(\"__Host-\"):\n+            kwargs[\"path\"] = \"/\"\n+            kwargs[\"secure\"] = True\n+        return handler.clear_cookie(cookie_name, **kwargs)\n+\n+    def _needs_check_xsrf(self, handler):\n+        \"\"\"Does the given cookie-authenticated request need to check xsrf?\"\"\"\n+        if getattr(handler, \"_token_authenticated\", False):\n+            return False\n+\n+        fetch_mode = handler.request.headers.get(\"Sec-Fetch-Mode\", \"unspecified\")\n+        if fetch_mode in {\"websocket\", \"no-cors\"} or (\n+            fetch_mode in {\"navigate\", \"unspecified\"}\n+            and handler.request.method.lower() in {\"get\", \"head\", \"options\"}\n+        ):\n+            # no xsrf check needed for regular page views or no-cors\n+            # or websockets after allow_websocket_cookie_auth passes\n+            if fetch_mode == \"unspecified\":\n+                self.log.warning(\n+                    f\"Skipping XSRF check for insecure request {handler.request.method} {handler.request.path}\"\n+                )\n+            return False\n+        else:\n+            return True\n+\n     async def _get_user_cookie(self, handler):\n+        # check xsrf if needed\n         token = self._get_token_cookie(handler)\n         session_id = self.get_session_id(handler)\n+        if token and self._needs_check_xsrf(handler):\n+            try:\n+                self.check_xsrf_cookie(handler)\n+            except HTTPError as e:\n+                self.log.error(\n+                    f\"Not accepting cookie auth on {handler.request.method} {handler.request.path}: {e}\"\n+                )\n+                # don't proceed with cookie auth unless xsrf is okay\n+                # don't raise either, because that makes a mess\n+                return None\n+\n         if token:\n             user_model = await self.user_for_token(\n                 token, session_id=session_id, sync=False\n             )\n             if user_model is None:\n                 app_log.warning(\"Token stored in cookie may have expired\")\n-                handler.clear_cookie(self.cookie_name)\n+                self._clear_cookie(handler, self.cookie_name, path=self.cookie_path)\n             return user_model\n \n     # HubOAuth API\n@@ -911,16 +1093,20 @@ def set_state_cookie(self, handler, next_url=None):\n             cookie_name = self.state_cookie_name\n         b64_state = self.generate_state(next_url, **extra_state)\n         kwargs = {\n-            'path': self.base_url,\n+            'path': self.cookie_path,\n             'httponly': True,\n             # Expire oauth state cookie in ten minutes.\n             # Usually this will be cleared by completed login\n             # in less than a few seconds.\n             # OAuth that doesn't complete shouldn't linger too long.\n             'max_age': 600,\n         }\n-        if get_browser_protocol(handler.request) == 'https':\n+        if (\n+            get_browser_protocol(handler.request) == 'https'\n+            or self.cookie_host_prefix_enabled\n+        ):\n             kwargs['secure'] = True\n+\n         # load user cookie overrides\n         kwargs.update(self.cookie_options)\n         handler.set_secure_cookie(cookie_name, b64_state, **kwargs)\n@@ -958,8 +1144,11 @@ def get_state_cookie_name(self, b64_state=''):\n \n     def set_cookie(self, handler, access_token):\n         \"\"\"Set a cookie recording OAuth result\"\"\"\n-        kwargs = {'path': self.base_url, 'httponly': True}\n-        if get_browser_protocol(handler.request) == 'https':\n+        kwargs = {'path': self.cookie_path, 'httponly': True}\n+        if (\n+            get_browser_protocol(handler.request) == 'https'\n+            or self.cookie_host_prefix_enabled\n+        ):\n             kwargs['secure'] = True\n         # load user cookie overrides\n         kwargs.update(self.cookie_options)\n@@ -973,7 +1162,7 @@ def set_cookie(self, handler, access_token):\n \n     def clear_cookie(self, handler):\n         \"\"\"Clear the OAuth cookie\"\"\"\n-        handler.clear_cookie(self.cookie_name, path=self.base_url)\n+        self._clear_cookie(handler, self.cookie_name, path=self.cookie_path)\n \n \n class UserNotAllowed(Exception):\n@@ -1185,7 +1374,7 @@ def get_current_user(self):\n             return\n         try:\n             self._hub_auth_user_cache = self.check_hub_user(user_model)\n-        except UserNotAllowed as e:\n+        except UserNotAllowed:\n             # cache None, in case get_user is called again while processing the error\n             self._hub_auth_user_cache = None\n \n@@ -1207,6 +1396,25 @@ def raise_on_redirect(*args, **kwargs):\n         self.hub_auth._persist_url_token_if_set(self)\n         return self._hub_auth_user_cache\n \n+    @property\n+    def _xsrf_token_id(self):\n+        if hasattr(self, \"__xsrf_token_id\"):\n+            return self.__xsrf_token_id\n+        if not isinstance(self.hub_auth, HubOAuth):\n+            return \"\"\n+        return self.hub_auth._get_xsrf_token_id(self)\n+\n+    @_xsrf_token_id.setter\n+    def _xsrf_token_id(self, value):\n+        self.__xsrf_token_id = value\n+\n+    @property\n+    def xsrf_token(self):\n+        return get_xsrf_token(self, cookie_path=self.hub_auth.base_url)\n+\n+    def check_xsrf_cookie(self):\n+        return self.hub_auth.check_xsrf_cookie(self)\n+\n \n class HubOAuthenticated(HubAuthenticated):\n     \"\"\"Simple subclass of HubAuthenticated using OAuth instead of old shared cookies\"\"\"\n@@ -1241,12 +1449,22 @@ async def get(self):\n         cookie_name = self.hub_auth.get_state_cookie_name(arg_state)\n         cookie_state = self.get_secure_cookie(cookie_name)\n         # clear cookie state now that we've consumed it\n-        self.clear_cookie(cookie_name, path=self.hub_auth.base_url)\n+        clear_kwargs = {}\n+        if self.hub_auth.cookie_host_prefix_enabled:\n+            # Set-Cookie is rejected without 'secure',\n+            # this includes clearing cookies!\n+            clear_kwargs[\"secure\"] = True\n+        self.hub_auth._clear_cookie(self, cookie_name, path=self.hub_auth.cookie_path)\n         if isinstance(cookie_state, bytes):\n             cookie_state = cookie_state.decode('ascii', 'replace')\n         # check that state matches\n         if arg_state != cookie_state:\n-            app_log.warning(\"oauth state %r != %r\", arg_state, cookie_state)\n+            app_log.warning(\n+                \"oauth state argument %r != cookie %s=%r\",\n+                arg_state,\n+                cookie_name,\n+                cookie_state,\n+            )\n             raise HTTPError(403, \"oauth state does not match. Try logging in again.\")\n         next_url = self.hub_auth.get_next_url(cookie_state)\n "
        },
        {
          "filename": "jupyterhub/singleuser/extension.py",
          "status": "modified",
          "additions": 11,
          "deletions": 11,
          "patch": "@@ -44,6 +44,7 @@\n from jupyterhub.log import log_request\n from jupyterhub.services.auth import HubOAuth, HubOAuthCallbackHandler\n from jupyterhub.utils import (\n+    _bool_env,\n     exponential_backoff,\n     isoformat,\n     make_ssl_context,\n@@ -55,17 +56,6 @@\n SINGLEUSER_TEMPLATES_DIR = str(Path(__file__).parent.resolve().joinpath(\"templates\"))\n \n \n-def _bool_env(key):\n-    \"\"\"Cast an environment variable to bool\n-\n-    0, empty, or unset is False; All other values are True.\n-    \"\"\"\n-    if os.environ.get(key, \"\") in {\"\", \"0\"}:\n-        return False\n-    else:\n-        return True\n-\n-\n def _exclude_home(path_list):\n     \"\"\"Filter out any entries in a path list that are in my home directory.\n \n@@ -127,6 +117,9 @@ def _default_hub_auth(self):\n         # HubAuth gets most of its config from the environment\n         return HubOAuth(parent=self)\n \n+    def _patch_xsrf(self, handler):\n+        self.hub_auth._patch_xsrf(handler)\n+\n     def _patch_get_login_url(self, handler):\n         original_get_login_url = handler.get_login_url\n \n@@ -161,6 +154,7 @@ async def get_user(self, handler):\n         if hasattr(handler, \"_jupyterhub_user\"):\n             return handler._jupyterhub_user\n         self._patch_get_login_url(handler)\n+        self._patch_xsrf(handler)\n         user = await self.hub_auth.get_user(handler, sync=False)\n         if user is None:\n             handler._jupyterhub_user = None\n@@ -631,6 +625,9 @@ def initialize(self, args=None):\n         app.web_app.settings[\"page_config_hook\"] = (\n             app.identity_provider.page_config_hook\n         )\n+        # disable xsrf_cookie checks by Tornado, which run too early\n+        # checks in Jupyter Server are unconditional\n+        app.web_app.settings[\"xsrf_cookies\"] = False\n         # if the user has configured a log function in the tornado settings, do not override it\n         if not 'log_function' in app.config.ServerApp.get('tornado_settings', {}):\n             app.web_app.settings[\"log_function\"] = log_request\n@@ -641,6 +638,9 @@ def initialize(self, args=None):\n         # check jupyterhub version\n         app.io_loop.run_sync(self.check_hub_version)\n \n+        # set default CSP to prevent iframe embedding across jupyterhub components\n+        headers.setdefault(\"Content-Security-Policy\", \"frame-ancestors 'none'\")\n+\n         async def _start_activity():\n             self._activity_task = asyncio.ensure_future(self.keep_activity_updated())\n "
        },
        {
          "filename": "jupyterhub/singleuser/mixins.py",
          "status": "modified",
          "additions": 9,
          "deletions": 15,
          "patch": "@@ -44,21 +44,15 @@\n from .._version import __version__, _check_version\n from ..log import log_request\n from ..services.auth import HubOAuth, HubOAuthCallbackHandler, HubOAuthenticated\n-from ..utils import exponential_backoff, isoformat, make_ssl_context, url_path_join\n+from ..utils import (\n+    _bool_env,\n+    exponential_backoff,\n+    isoformat,\n+    make_ssl_context,\n+    url_path_join,\n+)\n from ._disable_user_config import _disable_user_config, _exclude_home\n \n-\n-def _bool_env(key):\n-    \"\"\"Cast an environment variable to bool\n-\n-    0, empty, or unset is False; All other values are True.\n-    \"\"\"\n-    if os.environ.get(key, \"\") in {\"\", \"0\"}:\n-        return False\n-    else:\n-        return True\n-\n-\n # Authenticate requests with the Hub\n \n \n@@ -682,10 +676,10 @@ def init_webapp(self):\n         )\n         headers = s.setdefault('headers', {})\n         headers['X-JupyterHub-Version'] = __version__\n-        # set CSP header directly to workaround bugs in jupyter/notebook 5.0\n+        # set default CSP to prevent iframe embedding across jupyterhub components\n         headers.setdefault(\n             'Content-Security-Policy',\n-            ';'.join([\"frame-ancestors 'self'\", \"report-uri \" + csp_report_uri]),\n+            ';'.join([\"frame-ancestors 'none'\", \"report-uri \" + csp_report_uri]),\n         )\n         super().init_webapp()\n "
        },
        {
          "filename": "jupyterhub/spawner.py",
          "status": "modified",
          "additions": 5,
          "deletions": 0,
          "patch": "@@ -163,6 +163,7 @@ def active(self):\n     hub = Any()\n     orm_spawner = Any()\n     cookie_options = Dict()\n+    cookie_host_prefix_enabled = Bool()\n \n     db = Any()\n \n@@ -970,6 +971,10 @@ def get_env(self):\n         env['JUPYTERHUB_CLIENT_ID'] = self.oauth_client_id\n         if self.cookie_options:\n             env['JUPYTERHUB_COOKIE_OPTIONS'] = json.dumps(self.cookie_options)\n+\n+        env[\"JUPYTERHUB_COOKIE_HOST_PREFIX_ENABLED\"] = str(\n+            int(self.cookie_host_prefix_enabled)\n+        )\n         env['JUPYTERHUB_HOST'] = self.hub.public_host\n         env['JUPYTERHUB_OAUTH_CALLBACK_URL'] = url_path_join(\n             self.user.url, url_escape_path(self.name), 'oauth_callback'"
        },
        {
          "filename": "jupyterhub/tests/browser/test_browser.py",
          "status": "modified",
          "additions": 241,
          "deletions": 12,
          "patch": "@@ -1,6 +1,8 @@\n \"\"\"Tests for the Playwright Python\"\"\"\n \n+import asyncio\n import json\n+import pprint\n import re\n from urllib.parse import parse_qs, urlparse\n \n@@ -10,7 +12,7 @@\n from tornado.httputil import url_concat\n \n from jupyterhub import orm, roles, scopes\n-from jupyterhub.tests.utils import public_host, public_url, ujoin\n+from jupyterhub.tests.utils import async_requests, public_host, public_url, ujoin\n from jupyterhub.utils import url_escape_path, url_path_join\n \n pytestmark = pytest.mark.browser\n@@ -41,7 +43,7 @@ async def test_submit_login_form(app, browser, user_special_chars):\n     login_url = url_path_join(public_host(app), app.hub.base_url, \"login\")\n     await browser.goto(login_url)\n     await login(browser, user.name, password=user.name)\n-    expected_url = ujoin(public_url(app), f\"/user/{user_special_chars.urlname}/\")\n+    expected_url = public_url(app, user)\n     await expect(browser).to_have_url(expected_url)\n \n \n@@ -53,31 +55,31 @@ async def test_submit_login_form(app, browser, user_special_chars):\n             # will encode given parameters for an unauthenticated URL in the next url\n             # the next parameter will contain the app base URL (replaces BASE_URL in tests)\n             'spawn',\n-            [('param', 'value')],\n+            {'param': 'value'},\n             '/hub/login?next={{BASE_URL}}hub%2Fspawn%3Fparam%3Dvalue',\n             '/hub/login?next={{BASE_URL}}hub%2Fspawn%3Fparam%3Dvalue',\n         ),\n         (\n             # login?param=fromlogin&next=encoded(/hub/spawn?param=value)\n             # will drop parameters given to the login page, passing only the next url\n             'login',\n-            [('param', 'fromlogin'), ('next', '/hub/spawn?param=value')],\n-            '/hub/login?param=fromlogin&next=%2Fhub%2Fspawn%3Fparam%3Dvalue',\n-            '/hub/login?next=%2Fhub%2Fspawn%3Fparam%3Dvalue',\n+            {'param': 'fromlogin', 'next': '/hub/spawn?param=value'},\n+            '/hub/login?param=fromlogin&next={{BASE_URL}}hub%2Fspawn%3Fparam%3Dvalue',\n+            '/hub/login?next={{BASE_URL}}hub%2Fspawn%3Fparam%3Dvalue',\n         ),\n         (\n             # login?param=value&anotherparam=anothervalue\n             # will drop parameters given to the login page, and use an empty next url\n             'login',\n-            [('param', 'value'), ('anotherparam', 'anothervalue')],\n+            {'param': 'value', 'anotherparam': 'anothervalue'},\n             '/hub/login?param=value&anotherparam=anothervalue',\n             '/hub/login?next=',\n         ),\n         (\n             # login\n             # simplest case, accessing the login URL, gives an empty next url\n             'login',\n-            [],\n+            {},\n             '/hub/login',\n             '/hub/login?next=',\n         ),\n@@ -95,6 +97,8 @@ async def test_open_url_login(\n     user = user_special_chars.user\n     login_url = url_path_join(public_host(app), app.hub.base_url, url)\n     await browser.goto(login_url)\n+    if params.get(\"next\"):\n+        params[\"next\"] = url_path_join(app.base_url, params[\"next\"])\n     url_new = url_path_join(public_host(app), app.hub.base_url, url_concat(url, params))\n     print(url_new)\n     await browser.goto(url_new)\n@@ -730,12 +734,15 @@ async def test_oauth_page(\n     oauth_client.allowed_scopes = sorted(roles.roles_to_scopes([service_role]))\n     app.db.commit()\n     # open the service url in the browser\n-    service_url = url_path_join(public_url(app, service) + 'owhoami/?arg=x')\n+    service_url = url_path_join(public_url(app, service), 'owhoami/?arg=x')\n     await browser.goto(service_url)\n \n-    expected_redirect_url = url_path_join(\n-        app.base_url + f\"services/{service.name}/oauth_callback\"\n-    )\n+    if app.subdomain_host:\n+        expected_redirect_url = url_path_join(\n+            public_url(app, service), \"oauth_callback\"\n+        )\n+    else:\n+        expected_redirect_url = url_path_join(service.prefix, \"oauth_callback\")\n     expected_client_id = f\"service-{service.name}\"\n \n     # decode the URL\n@@ -1112,3 +1119,225 @@ async def click_stop_button(browser, username):\n     await expect(browser.get_by_role(\"button\", name=\"Spawn Page\")).to_have_count(\n         len(users_list)\n     )\n+\n+\n+@pytest.mark.parametrize(\n+    \"case\",\n+    [\n+        \"fresh\",\n+        \"invalid\",\n+        \"valid-prefix-invalid-root\",\n+    ],\n+)\n+async def test_login_xsrf_initial_cookies(app, browser, case, username):\n+    \"\"\"Test that login works with various initial states for xsrf tokens\n+\n+    Page will be reloaded with correct values\n+    \"\"\"\n+    hub_root = public_host(app)\n+    hub_url = url_path_join(public_host(app), app.hub.base_url)\n+    login_url = url_path_join(\n+        hub_url, url_concat(\"login\", {\"next\": url_path_join(app.base_url, \"/hub/home\")})\n+    )\n+    # start with all cookies cleared\n+    await browser.context.clear_cookies()\n+    if case == \"invalid\":\n+        await browser.context.add_cookies(\n+            [{\"name\": \"_xsrf\", \"value\": \"invalid-hub-prefix\", \"url\": hub_url}]\n+        )\n+    elif case == \"valid-prefix-invalid-root\":\n+        await browser.goto(login_url)\n+        # first visit sets valid xsrf cookie\n+        cookies = await browser.context.cookies()\n+        assert len(cookies) == 1\n+        # second visit is also made with invalid xsrf on `/`\n+        # handling of this behavior is undefined in HTTP itself!\n+        # _either_ the invalid cookie on / is ignored\n+        # _or_ both will be cleared\n+        # currently, this test assumes the observed behavior,\n+        # which is that the invalid cookie on `/` has _higher_ priority\n+        await browser.context.add_cookies(\n+            [{\"name\": \"_xsrf\", \"value\": \"invalid-root\", \"url\": hub_root}]\n+        )\n+        cookies = await browser.context.cookies()\n+        assert len(cookies) == 2\n+\n+    # after visiting page, cookies get re-established\n+    await browser.goto(login_url)\n+    cookies = await browser.context.cookies()\n+    print(cookies)\n+    cookie = cookies[0]\n+    assert cookie['name'] == '_xsrf'\n+    assert cookie[\"path\"] == app.hub.base_url\n+\n+    # next page visit, cookies don't change\n+    await browser.goto(login_url)\n+    cookies_2 = await browser.context.cookies()\n+    assert cookies == cookies_2\n+    # login is successful\n+    await login(browser, username, username)\n+\n+\n+def _cookie_dict(cookie_list):\n+    \"\"\"Convert list of cookies to dict of the form\n+\n+    { 'path': {'key': {cookie} } }\n+    \"\"\"\n+    cookie_dict = {}\n+    for cookie in cookie_list:\n+        path_cookies = cookie_dict.setdefault(cookie['path'], {})\n+        path_cookies[cookie['name']] = cookie\n+    return cookie_dict\n+\n+\n+async def test_singleuser_xsrf(app, browser, user, create_user_with_scopes, full_spawn):\n+    # full login process, checking XSRF handling\n+    # start two servers\n+    target_user = user\n+    target_start = asyncio.ensure_future(target_user.spawn())\n+\n+    browser_user = create_user_with_scopes(\"self\", \"access:servers\")\n+    # login browser_user\n+    login_url = url_path_join(public_host(app), app.hub.base_url, \"login\")\n+    await browser.goto(login_url)\n+    await login(browser, browser_user.name, browser_user.name)\n+    # end up at single-user\n+    await expect(browser).to_have_url(re.compile(rf\".*/user/{browser_user.name}/.*\"))\n+    # wait for target user to start, too\n+    await target_start\n+    await app.proxy.add_user(target_user)\n+\n+    # visit target user, sets credentials for second server\n+    await browser.goto(public_url(app, target_user))\n+    await expect(browser).to_have_url(re.compile(r\".*/oauth2/authorize\"))\n+    auth_button = browser.locator('//input[@type=\"submit\"]')\n+    await expect(auth_button).to_be_enabled()\n+    await auth_button.click()\n+    await expect(browser).to_have_url(re.compile(rf\".*/user/{target_user.name}/.*\"))\n+\n+    # at this point, we are on a page served by target_user,\n+    # logged in as browser_user\n+    # basic check that xsrf isolation works\n+    cookies = await browser.context.cookies()\n+    cookie_dict = _cookie_dict(cookies)\n+    pprint.pprint(cookie_dict)\n+\n+    # we should have xsrf tokens for both singleuser servers and the hub\n+    target_prefix = target_user.prefix\n+    user_prefix = browser_user.prefix\n+    hub_prefix = app.hub.base_url\n+    assert target_prefix in cookie_dict\n+    assert user_prefix in cookie_dict\n+    assert hub_prefix in cookie_dict\n+    target_xsrf = cookie_dict[target_prefix].get(\"_xsrf\", {}).get(\"value\")\n+    assert target_xsrf\n+    user_xsrf = cookie_dict[user_prefix].get(\"_xsrf\", {}).get(\"value\")\n+    assert user_xsrf\n+    hub_xsrf = cookie_dict[hub_prefix].get(\"_xsrf\", {}).get(\"value\")\n+    assert hub_xsrf\n+    assert hub_xsrf != target_xsrf\n+    assert hub_xsrf != user_xsrf\n+    assert target_xsrf != user_xsrf\n+\n+    # we are on a page served by target_user\n+    # check that we can't access\n+\n+    async def fetch_user_page(path, params=None):\n+        url = url_path_join(public_url(app, browser_user), path)\n+        if params:\n+            url = url_concat(url, params)\n+        status = await browser.evaluate(\n+            \"\"\"\n+            async (user_url) => {\n+              try {\n+                response = await fetch(user_url);\n+              } catch (e) {\n+                return 'error';\n+              }\n+              return response.status;\n+            }\n+            \"\"\",\n+            url,\n+        )\n+        return status\n+\n+    if app.subdomain_host:\n+        expected_status = 'error'\n+    else:\n+        expected_status = 403\n+    status = await fetch_user_page(\"/api/contents\")\n+    assert status == expected_status\n+    status = await fetch_user_page(\"/api/contents\", params={\"_xsrf\": target_xsrf})\n+    assert status == expected_status\n+\n+    if not app.subdomain_host:\n+        expected_status = 200\n+    status = await fetch_user_page(\"/api/contents\", params={\"_xsrf\": user_xsrf})\n+    assert status == expected_status\n+\n+    # check that we can't iframe the other user's page\n+    async def iframe(src):\n+        return await browser.evaluate(\n+            \"\"\"\n+            async (src) => {\n+                const frame = document.createElement(\"iframe\");\n+                frame.src = src;\n+                return new Promise((resolve, reject) => {\n+                    frame.addEventListener(\"load\", (event) => {\n+                        if (frame.contentDocument) {\n+                            resolve(\"got document!\");\n+                        } else {\n+                            resolve(\"blocked\")\n+                        }\n+                    });\n+                    setTimeout(() => {\n+                        // some browsers (firefox) never fire load event\n+                        // despite spec appasrently stating it must always do so,\n+                        // even for rejected frames\n+                        resolve(\"timeout\")\n+                    }, 3000)\n+\n+                    document.body.appendChild(frame);\n+                });\n+            }\n+            \"\"\",\n+            src,\n+        )\n+\n+    hub_iframe = await iframe(url_path_join(public_url(app), \"hub/admin\"))\n+    assert hub_iframe in {\"timeout\", \"blocked\"}\n+    user_iframe = await iframe(public_url(app, browser_user))\n+    assert user_iframe in {\"timeout\", \"blocked\"}\n+\n+    # check that server page can still connect to its own kernels\n+    token = target_user.new_api_token(scopes=[\"access:servers!user\"])\n+    url = url_path_join(public_url(app, target_user), \"/api/kernels\")\n+    headers = {\"Authorization\": f\"Bearer {token}\"}\n+    r = await async_requests.post(url, headers=headers)\n+    r.raise_for_status()\n+    kernel = r.json()\n+    kernel_id = kernel[\"id\"]\n+    kernel_url = url_path_join(url, kernel_id)\n+    kernel_ws_url = \"ws\" + url_path_join(kernel_url, \"channels\")[4:]\n+    try:\n+        result = await browser.evaluate(\n+            \"\"\"\n+            async (ws_url) => {\n+                ws = new WebSocket(ws_url);\n+                finished = await new Promise((resolve, reject) => {\n+                    ws.onerror = (err) => {\n+                        reject(err);\n+                    };\n+                    ws.onopen = () => {\n+                        resolve(\"ok\");\n+                    };\n+                });\n+                return finished;\n+            }\n+            \"\"\",\n+            kernel_ws_url,\n+        )\n+    finally:\n+        r = await async_requests.delete(kernel_url, headers=headers)\n+        r.raise_for_status()\n+    assert result == \"ok\""
        },
        {
          "filename": "jupyterhub/tests/mocking.py",
          "status": "modified",
          "additions": 14,
          "deletions": 11,
          "patch": "@@ -43,8 +43,8 @@\n from ..app import JupyterHub\n from ..auth import PAMAuthenticator\n from ..spawner import SimpleLocalProcessSpawner\n-from ..utils import random_port, utcnow\n-from .utils import async_requests, public_url, ssl_setup\n+from ..utils import random_port, url_path_join, utcnow\n+from .utils import AsyncSession, public_url, ssl_setup\n \n \n def mock_authenticate(username, password, service, encoding):\n@@ -356,29 +356,32 @@ def cleanup():\n     async def login_user(self, name):\n         \"\"\"Login a user by name, returning her cookies.\"\"\"\n         base_url = public_url(self)\n-        external_ca = None\n+        s = AsyncSession()\n         if self.internal_ssl:\n-            external_ca = self.external_certs['files']['ca']\n+            s.verify = self.external_certs['files']['ca']\n         login_url = base_url + 'hub/login'\n-        r = await async_requests.get(login_url)\n+        r = await s.get(login_url)\n         r.raise_for_status()\n         xsrf = r.cookies['_xsrf']\n \n-        r = await async_requests.post(\n+        r = await s.post(\n             url_concat(login_url, {\"_xsrf\": xsrf}),\n-            cookies=r.cookies,\n             data={'username': name, 'password': name},\n             allow_redirects=False,\n-            verify=external_ca,\n         )\n         r.raise_for_status()\n-        r.cookies[\"_xsrf\"] = xsrf\n-        assert sorted(r.cookies.keys()) == [\n+        # make second request to get updated xsrf cookie\n+        r2 = await s.get(\n+            url_path_join(base_url, \"hub/home\"),\n+            allow_redirects=False,\n+        )\n+        assert r2.status_code == 200\n+        assert sorted(s.cookies.keys()) == [\n             '_xsrf',\n             'jupyterhub-hub-login',\n             'jupyterhub-session-id',\n         ]\n-        return r.cookies\n+        return s.cookies\n \n \n class InstrumentedSpawner(MockSpawner):"
        },
        {
          "filename": "jupyterhub/tests/test_api.py",
          "status": "modified",
          "additions": 9,
          "deletions": 2,
          "patch": "@@ -96,7 +96,7 @@ async def test_post_content_type(app, content_type, status):\n     assert r.status_code == status\n \n \n-@mark.parametrize(\"xsrf_in_url\", [True, False])\n+@mark.parametrize(\"xsrf_in_url\", [True, False, \"invalid\"])\n @mark.parametrize(\n     \"method, path\",\n     [\n@@ -107,6 +107,13 @@ async def test_post_content_type(app, content_type, status):\n async def test_xsrf_check(app, username, method, path, xsrf_in_url):\n     cookies = await app.login_user(username)\n     xsrf = cookies['_xsrf']\n+    if xsrf_in_url == \"invalid\":\n+        cookies.pop(\"_xsrf\")\n+        # a valid old-style tornado xsrf token is no longer valid\n+        xsrf = cookies['_xsrf'] = (\n+            \"2|7329b149|d837ced983e8aac7468bc7a61ce3d51a|1708610065\"\n+        )\n+\n     url = path.format(username=username)\n     if xsrf_in_url:\n         url = f\"{url}?_xsrf={xsrf}\"\n@@ -117,7 +124,7 @@ async def test_xsrf_check(app, username, method, path, xsrf_in_url):\n         noauth=True,\n         cookies=cookies,\n     )\n-    if xsrf_in_url:\n+    if xsrf_in_url is True:\n         assert r.status_code == 200\n     else:\n         assert r.status_code == 403"
        },
        {
          "filename": "jupyterhub/tests/test_pages.py",
          "status": "modified",
          "additions": 15,
          "deletions": 11,
          "patch": "@@ -683,11 +683,10 @@ async def test_other_user_url(app, username, user, group, create_temp_role, has_\n     ],\n )\n async def test_page_with_token(app, user, url, token_in):\n-    cookies = await app.login_user(user.name)\n     token = user.new_api_token()\n     if token_in == \"url\":\n         url = url_concat(url, {\"token\": token})\n-        headers = None\n+        headers = {}\n     elif token_in == \"header\":\n         headers = {\n             \"Authorization\": f\"token {token}\",\n@@ -732,14 +731,13 @@ async def test_login_strip(app, form_user, auth_user, form_password):\n     \"\"\"Test that login form strips space form usernames, but not passwords\"\"\"\n     form_data = {\"username\": form_user, \"password\": form_password}\n     expected_auth = {\"username\": auth_user, \"password\": form_password}\n-    base_url = public_url(app)\n     called_with = []\n \n     async def mock_authenticate(handler, data):\n         called_with.append(data)\n \n     with mock.patch.object(app.authenticator, 'authenticate', mock_authenticate):\n-        r = await async_requests.get(base_url + 'hub/login')\n+        r = await get_page('login', app)\n         r.raise_for_status()\n         cookies = r.cookies\n         xsrf = cookies['_xsrf']\n@@ -920,17 +918,19 @@ def get(self):\n async def test_auto_login_logout(app):\n     name = 'burnham'\n     cookies = await app.login_user(name)\n+    s = AsyncSession()\n+    s.cookies = cookies\n \n     with mock.patch.dict(\n         app.tornado_settings, {'authenticator': Authenticator(auto_login=True)}\n     ):\n-        r = await async_requests.get(\n+        r = await s.get(\n             public_host(app) + app.tornado_settings['logout_url'], cookies=cookies\n         )\n     r.raise_for_status()\n     logout_url = public_host(app) + app.tornado_settings['logout_url']\n     assert r.url == logout_url\n-    assert r.cookies == {}\n+    assert list(s.cookies.keys()) == [\"_xsrf\"]\n     # don't include logged-out user in page:\n     try:\n         idx = r.text.index(name)\n@@ -944,19 +944,23 @@ async def test_auto_login_logout(app):\n async def test_logout(app):\n     name = 'wash'\n     cookies = await app.login_user(name)\n-    r = await async_requests.get(\n-        public_host(app) + app.tornado_settings['logout_url'], cookies=cookies\n+    s = AsyncSession()\n+    s.cookies = cookies\n+    r = await s.get(\n+        public_host(app) + app.tornado_settings['logout_url'],\n     )\n     r.raise_for_status()\n     login_url = public_host(app) + app.tornado_settings['login_url']\n     assert r.url == login_url\n-    assert r.cookies == {}\n+    assert list(s.cookies.keys()) == [\"_xsrf\"]\n \n \n @pytest.mark.parametrize('shutdown_on_logout', [True, False])\n async def test_shutdown_on_logout(app, shutdown_on_logout):\n     name = 'shutitdown'\n     cookies = await app.login_user(name)\n+    s = AsyncSession()\n+    s.cookies = cookies\n     user = app.users[name]\n \n     # start the user's server\n@@ -976,14 +980,14 @@ async def test_shutdown_on_logout(app, shutdown_on_logout):\n     with mock.patch.dict(\n         app.tornado_settings, {'shutdown_on_logout': shutdown_on_logout}\n     ):\n-        r = await async_requests.get(\n+        r = await s.get(\n             public_host(app) + app.tornado_settings['logout_url'], cookies=cookies\n         )\n         r.raise_for_status()\n \n     login_url = public_host(app) + app.tornado_settings['login_url']\n     assert r.url == login_url\n-    assert r.cookies == {}\n+    assert list(s.cookies.keys()) == [\"_xsrf\"]\n \n     # wait for any pending state to resolve\n     for i in range(50):"
        },
        {
          "filename": "jupyterhub/tests/test_services_auth.py",
          "status": "modified",
          "additions": 4,
          "deletions": 2,
          "patch": "@@ -385,15 +385,17 @@ async def test_oauth_service_roles(\n     # token-authenticated request to HubOAuth\n     token = app.users[name].new_api_token()\n     # token in ?token parameter\n-    r = await async_requests.get(url_concat(url, {'token': token}))\n+    r = await async_requests.get(url_concat(url, {'token': token}), headers=s.headers)\n     r.raise_for_status()\n     reply = r.json()\n     assert reply['name'] == name\n \n     # verify that ?token= requests set a cookie\n     assert len(r.cookies) != 0\n     # ensure cookie works in future requests\n-    r = await async_requests.get(url, cookies=r.cookies, allow_redirects=False)\n+    r = await async_requests.get(\n+        url, cookies=r.cookies, allow_redirects=False, headers=s.headers\n+    )\n     r.raise_for_status()\n     assert r.url == url\n     reply = r.json()"
        },
        {
          "filename": "jupyterhub/tests/test_singleuser.py",
          "status": "modified",
          "additions": 28,
          "deletions": 13,
          "patch": "@@ -74,18 +74,20 @@ async def test_singleuser_auth(\n     spawner = user.spawners[server_name]\n     url = url_path_join(public_url(app, user), server_name)\n \n+    s = AsyncSession()\n+\n     # no cookies, redirects to login page\n-    r = await async_requests.get(url)\n+    r = await s.get(url)\n     r.raise_for_status()\n     assert '/hub/login' in r.url\n \n     # unauthenticated /api/ should 403, not redirect\n     api_url = url_path_join(url, \"api/status\")\n-    r = await async_requests.get(api_url, allow_redirects=False)\n+    r = await s.get(api_url, allow_redirects=False)\n     assert r.status_code == 403\n \n     # with cookies, login successful\n-    r = await async_requests.get(url, cookies=cookies)\n+    r = await s.get(url, cookies=cookies)\n     r.raise_for_status()\n     assert (\n         urlparse(r.url)\n@@ -99,7 +101,7 @@ async def test_singleuser_auth(\n     assert r.status_code == 200\n \n     # logout\n-    r = await async_requests.get(url_path_join(url, 'logout'), cookies=cookies)\n+    r = await s.get(url_path_join(url, 'logout'))\n     assert len(r.cookies) == 0\n \n     # accessing another user's server hits the oauth confirmation page\n@@ -145,6 +147,8 @@ async def test_singleuser_auth(\n async def test_disable_user_config(request, app, tmpdir, full_spawn):\n     # login, start the server\n     cookies = await app.login_user('nandy')\n+    s = AsyncSession()\n+    s.cookies = cookies\n     user = app.users['nandy']\n     # stop spawner, if running:\n     if user.running:\n@@ -169,16 +173,14 @@ async def test_disable_user_config(request, app, tmpdir, full_spawn):\n     url = public_url(app, user)\n \n     # with cookies, login successful\n-    r = await async_requests.get(url, cookies=cookies)\n+    r = await s.get(url)\n     r.raise_for_status()\n     assert r.url.rstrip('/').endswith(\n         url_path_join('/user/nandy', user.spawner.default_url or \"/tree\")\n     )\n     assert r.status_code == 200\n \n-    r = await async_requests.get(\n-        url_path_join(public_url(app, user), 'jupyterhub-test-info'), cookies=cookies\n-    )\n+    r = await s.get(url_path_join(public_url(app, user), 'jupyterhub-test-info'))\n     r.raise_for_status()\n     info = r.json()\n     pprint(info)\n@@ -374,19 +376,31 @@ async def test_nbclassic_control_panel(app, user, full_spawn):\n @pytest.mark.skipif(\n     IS_JUPYVERSE, reason=\"jupyverse doesn't implement token authentication\"\n )\n-async def test_token_url_cookie(app, user, full_spawn):\n+@pytest.mark.parametrize(\"accept_token_in_url\", [\"1\", \"0\", \"\"])\n+async def test_token_url_cookie(app, user, full_spawn, accept_token_in_url):\n+    if accept_token_in_url:\n+        user.spawner.environment[\"JUPYTERHUB_ALLOW_TOKEN_IN_URL\"] = accept_token_in_url\n+    should_accept = accept_token_in_url != \"0\"\n+\n     await user.spawn()\n+    await app.proxy.add_user(user)\n+\n     token = user.new_api_token(scopes=[\"access:servers!user\"])\n     url = url_path_join(public_url(app, user), user.spawner.default_url or \"/tree/\")\n \n     # first request: auth with token in URL\n-    r = await async_requests.get(url + f\"?token={token}\", allow_redirects=False)\n+    s = AsyncSession()\n+    r = await s.get(url + f\"?token={token}\", allow_redirects=False)\n     print(r.url, r.status_code)\n+    if not should_accept:\n+        assert r.status_code == 302\n+        return\n+\n     assert r.status_code == 200\n-    assert r.cookies\n+    assert s.cookies\n     # second request, use cookies set by first response,\n     # no token in URL\n-    r = await async_requests.get(url, cookies=r.cookies, allow_redirects=False)\n+    r = await s.get(url, allow_redirects=False)\n     assert r.status_code == 200\n     await user.stop()\n \n@@ -396,7 +410,8 @@ async def test_api_403_no_cookie(app, user, full_spawn):\n     await user.spawn()\n     await app.proxy.add_user(user)\n     url = url_path_join(public_url(app, user), \"/api/contents/\")\n-    r = await async_requests.get(url, allow_redirects=False)\n+    s = AsyncSession()\n+    r = await s.get(url, allow_redirects=False)\n     # 403, not redirect\n     assert r.status_code == 403\n     # no state cookie set"
        },
        {
          "filename": "jupyterhub/tests/utils.py",
          "status": "modified",
          "additions": 12,
          "deletions": 1,
          "patch": "@@ -42,6 +42,13 @@ def __getattr__(self, name):\n class AsyncSession(requests.Session):\n     \"\"\"requests.Session object that runs in the background thread\"\"\"\n \n+    def __init__(self, **kwargs):\n+        super().__init__(**kwargs)\n+        # session requests are for cookie authentication\n+        # and should look like regular page views,\n+        # so set Sec-Fetch-Mode: navigate\n+        self.headers.setdefault(\"Sec-Fetch-Mode\", \"navigate\")\n+\n     def request(self, *args, **kwargs):\n         return async_requests.executor.submit(super().request, *args, **kwargs)\n \n@@ -157,6 +164,7 @@ async def api_request(\n     else:\n         base_url = public_url(app, path='hub')\n     headers = kwargs.setdefault('headers', {})\n+    headers.setdefault(\"Sec-Fetch-Mode\", \"cors\")\n     if 'Authorization' not in headers and not noauth and 'cookies' not in kwargs:\n         # make a copy to avoid modifying arg in-place\n         kwargs['headers'] = h = {}\n@@ -176,7 +184,7 @@ async def api_request(\n         kwargs['cert'] = (app.internal_ssl_cert, app.internal_ssl_key)\n         kwargs[\"verify\"] = app.internal_ssl_ca\n     resp = await f(url, **kwargs)\n-    assert \"frame-ancestors 'self'\" in resp.headers['Content-Security-Policy']\n+    assert \"frame-ancestors 'none'\" in resp.headers['Content-Security-Policy']\n     assert (\n         ujoin(app.hub.base_url, \"security/csp-report\")\n         in resp.headers['Content-Security-Policy']\n@@ -197,6 +205,9 @@ def get_page(path, app, hub=True, **kw):\n     else:\n         prefix = app.base_url\n     base_url = ujoin(public_host(app), prefix)\n+    # Sec-Fetch-Mode=navigate to look like a regular page view\n+    headers = kw.setdefault(\"headers\", {})\n+    headers.setdefault(\"Sec-Fetch-Mode\", \"navigate\")\n     return async_requests.get(ujoin(base_url, path), **kw)\n \n "
        },
        {
          "filename": "jupyterhub/user.py",
          "status": "modified",
          "additions": 3,
          "deletions": 0,
          "patch": "@@ -461,6 +461,9 @@ def _new_spawner(self, server_name, spawner_class=None, **kwargs):\n             _deprecated_db_session=self.db,\n             oauth_client_id=client_id,\n             cookie_options=self.settings.get('cookie_options', {}),\n+            cookie_host_prefix_enabled=self.settings.get(\n+                \"cookie_host_prefix_enabled\", False\n+            ),\n             trusted_alt_names=trusted_alt_names,\n             user_options=orm_spawner.user_options or {},\n         )"
        },
        {
          "filename": "jupyterhub/utils.py",
          "status": "modified",
          "additions": 16,
          "deletions": 0,
          "patch": "@@ -8,6 +8,7 @@\n import functools\n import hashlib\n import inspect\n+import os\n import random\n import secrets\n import socket\n@@ -30,6 +31,21 @@\n from tornado.log import app_log\n \n \n+def _bool_env(key, default=False):\n+    \"\"\"Cast an environment variable to bool\n+\n+    If unset or empty, return `default`\n+    `0` is False; all other values are True.\n+    \"\"\"\n+    value = os.environ.get(key, \"\")\n+    if value == \"\":\n+        return default\n+    if value.lower() in {\"0\", \"false\"}:\n+        return False\n+    else:\n+        return True\n+\n+\n # Deprecated aliases: no longer needed now that we require 3.7\n def asyncio_all_tasks(loop=None):\n     warnings.warn("
        }
      ],
      "file_patterns": {
        "security_files": 3,
        "config_files": 1,
        "dependency_files": 0,
        "test_files": 8,
        "unique_directories": 10,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "8f9723f0a7f0eb3d2b7481eec9ef08e6de44a54d",
            "date": "2025-01-09T08:21:52Z",
            "author_login": "minrk"
          },
          {
            "sha": "8391d1d5cf4d6431c5ad8cdbca3866a43f103227",
            "date": "2025-01-09T08:21:26Z",
            "author_login": "minrk"
          },
          {
            "sha": "7a76cfd89d43540921a73a4e6227a171fe82283c",
            "date": "2025-01-08T22:47:29Z",
            "author_login": "manics"
          },
          {
            "sha": "4d574123615fff6c9d7fb72439ccc80feb9e71c7",
            "date": "2025-01-08T16:28:06Z",
            "author_login": "agoose77"
          },
          {
            "sha": "3003b8482ad46e9a402495f611db7f1a3f293849",
            "date": "2025-01-07T08:02:48Z",
            "author_login": "minrk"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 8.1,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:N",
    "cwe_id": "CWE-79",
    "description": "JupyterHub is an open source multi-user server for Jupyter notebooks. By tricking a user into visiting a malicious subdomain, the attacker can achieve an XSS directly affecting the former's session. More precisely, in the context of JupyterHub, this XSS could achieve full access to JupyterHub API and user's single-user server. The affected configurations are single-origin JupyterHub deployments and JupyterHub deployments with user-controlled applications running on subdomains or peer subdomains of either the Hub or a single-user server. This vulnerability is fixed in 4.1.0.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-03-27T19:15:48.430",
    "last_modified": "2024-11-21T09:06:03.527",
    "fix_date": "2024-03-20T12:19:29Z"
  },
  "references": [
    {
      "url": "https://github.com/jupyterhub/jupyterhub/commit/e2798a088f5ad45340fe79cdf1386198e664f77f",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://github.com/jupyterhub/jupyterhub/security/advisories/GHSA-7r3h-4ph8-w38g",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://github.com/jupyterhub/jupyterhub/commit/e2798a088f5ad45340fe79cdf1386198e664f77f",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://github.com/jupyterhub/jupyterhub/security/advisories/GHSA-7r3h-4ph8-w38g",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:07:52.915821",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "jupyterhub",
    "owner": "jupyterhub",
    "created_at": "2014-06-12T23:22:10Z",
    "updated_at": "2025-01-14T02:17:19Z",
    "pushed_at": "2025-01-09T08:21:54Z",
    "size": 33681,
    "stars": 7871,
    "forks": 2034,
    "open_issues": 185,
    "watchers": 7871,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "main"
    ],
    "languages": {
      "Python": 1576154,
      "JavaScript": 117662,
      "HTML": 40763,
      "SCSS": 6141,
      "Dockerfile": 5999,
      "CSS": 4430,
      "Shell": 3105,
      "Mako": 494
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "other"
    },
    "collected_at": "2025-01-14T17:08:24.448274"
  }
}