{
  "cve_id": "CVE-2024-3149",
  "github_data": {
    "repository": "mintplex-labs/anything-llm",
    "fix_commit": "f4088d9348fa86dcebe9f97a18d39c0a6e92f15e",
    "related_commits": [
      "f4088d9348fa86dcebe9f97a18d39c0a6e92f15e",
      "f4088d9348fa86dcebe9f97a18d39c0a6e92f15e"
    ],
    "patch_url": "https://github.com/mintplex-labs/anything-llm/commit/f4088d9348fa86dcebe9f97a18d39c0a6e92f15e.patch",
    "fix_commit_details": {
      "sha": "f4088d9348fa86dcebe9f97a18d39c0a6e92f15e",
      "commit_date": "2024-04-01T20:56:35Z",
      "author": {
        "login": "timothycarambat",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "RSA-Signing on server<->collector communication via API (#1005)",
        "length": 169,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 350,
        "additions": 278,
        "deletions": 72
      },
      "files": [
        {
          "filename": ".vscode/settings.json",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -2,6 +2,7 @@\n   \"cSpell.words\": [\n     \"anythingllm\",\n     \"Astra\",\n+    \"comkey\",\n     \"Dockerized\",\n     \"Embeddable\",\n     \"GROQ\",\n@@ -20,4 +21,4 @@\n   ],\n   \"eslint.experimental.useFlatConfig\": true,\n   \"docker.languageserver.formatter.ignoreMultilineInstructions\": true\n-}\n+}\n\\ No newline at end of file"
        },
        {
          "filename": "collector/extensions/index.js",
          "status": "modified",
          "additions": 4,
          "deletions": 3,
          "patch": "@@ -1,9 +1,10 @@\n+const { verifyPayloadIntegrity } = require(\"../middleware/verifyIntegrity\");\n const { reqBody } = require(\"../utils/http\");\n \n function extensions(app) {\n   if (!app) return;\n \n-  app.post(\"/ext/github-repo\", async function (request, response) {\n+  app.post(\"/ext/github-repo\", [verifyPayloadIntegrity], async function (request, response) {\n     try {\n       const loadGithubRepo = require(\"../utils/extensions/GithubRepo\");\n       const { success, reason, data } = await loadGithubRepo(reqBody(request));\n@@ -24,7 +25,7 @@ function extensions(app) {\n   });\n \n   // gets all branches for a specific repo\n-  app.post(\"/ext/github-repo/branches\", async function (request, response) {\n+  app.post(\"/ext/github-repo/branches\", [verifyPayloadIntegrity], async function (request, response) {\n     try {\n       const GithubRepoLoader = require(\"../utils/extensions/GithubRepo/RepoLoader\");\n       const allBranches = await (new GithubRepoLoader(reqBody(request))).getRepoBranches()\n@@ -48,7 +49,7 @@ function extensions(app) {\n     return;\n   });\n \n-  app.post(\"/ext/youtube-transcript\", async function (request, response) {\n+  app.post(\"/ext/youtube-transcript\", [verifyPayloadIntegrity], async function (request, response) {\n     try {\n       const loadYouTubeTranscript = require(\"../utils/extensions/YoutubeTranscript\");\n       const { success, reason, data } = await loadYouTubeTranscript(reqBody(request));"
        },
        {
          "filename": "collector/index.js",
          "status": "modified",
          "additions": 73,
          "deletions": 60,
          "patch": "@@ -13,6 +13,7 @@ const { processLink } = require(\"./processLink\");\n const { wipeCollectorStorage } = require(\"./utils/files\");\n const extensions = require(\"./extensions\");\n const { processRawText } = require(\"./processRawText\");\n+const { verifyPayloadIntegrity } = require(\"./middleware/verifyIntegrity\");\n const app = express();\n \n app.use(cors({ origin: true }));\n@@ -24,71 +25,83 @@ app.use(\n   })\n );\n \n-app.post(\"/process\", async function (request, response) {\n-  const { filename, options = {} } = reqBody(request);\n-  try {\n-    const targetFilename = path\n-      .normalize(filename)\n-      .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\");\n-    const {\n-      success,\n-      reason,\n-      documents = [],\n-    } = await processSingleFile(targetFilename, options);\n-    response\n-      .status(200)\n-      .json({ filename: targetFilename, success, reason, documents });\n-  } catch (e) {\n-    console.error(e);\n-    response.status(200).json({\n-      filename: filename,\n-      success: false,\n-      reason: \"A processing error occurred.\",\n-      documents: [],\n-    });\n+app.post(\n+  \"/process\",\n+  [verifyPayloadIntegrity],\n+  async function (request, response) {\n+    const { filename, options = {} } = reqBody(request);\n+    try {\n+      const targetFilename = path\n+        .normalize(filename)\n+        .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\");\n+      const {\n+        success,\n+        reason,\n+        documents = [],\n+      } = await processSingleFile(targetFilename, options);\n+      response\n+        .status(200)\n+        .json({ filename: targetFilename, success, reason, documents });\n+    } catch (e) {\n+      console.error(e);\n+      response.status(200).json({\n+        filename: filename,\n+        success: false,\n+        reason: \"A processing error occurred.\",\n+        documents: [],\n+      });\n+    }\n+    return;\n   }\n-  return;\n-});\n+);\n \n-app.post(\"/process-link\", async function (request, response) {\n-  const { link } = reqBody(request);\n-  try {\n-    const { success, reason, documents = [] } = await processLink(link);\n-    response.status(200).json({ url: link, success, reason, documents });\n-  } catch (e) {\n-    console.error(e);\n-    response.status(200).json({\n-      url: link,\n-      success: false,\n-      reason: \"A processing error occurred.\",\n-      documents: [],\n-    });\n+app.post(\n+  \"/process-link\",\n+  [verifyPayloadIntegrity],\n+  async function (request, response) {\n+    const { link } = reqBody(request);\n+    try {\n+      const { success, reason, documents = [] } = await processLink(link);\n+      response.status(200).json({ url: link, success, reason, documents });\n+    } catch (e) {\n+      console.error(e);\n+      response.status(200).json({\n+        url: link,\n+        success: false,\n+        reason: \"A processing error occurred.\",\n+        documents: [],\n+      });\n+    }\n+    return;\n   }\n-  return;\n-});\n+);\n \n-app.post(\"/process-raw-text\", async function (request, response) {\n-  const { textContent, metadata } = reqBody(request);\n-  try {\n-    const {\n-      success,\n-      reason,\n-      documents = [],\n-    } = await processRawText(textContent, metadata);\n-    response\n-      .status(200)\n-      .json({ filename: metadata.title, success, reason, documents });\n-  } catch (e) {\n-    console.error(e);\n-    response.status(200).json({\n-      filename: metadata?.title || \"Unknown-doc.txt\",\n-      success: false,\n-      reason: \"A processing error occurred.\",\n-      documents: [],\n-    });\n+app.post(\n+  \"/process-raw-text\",\n+  [verifyPayloadIntegrity],\n+  async function (request, response) {\n+    const { textContent, metadata } = reqBody(request);\n+    try {\n+      const {\n+        success,\n+        reason,\n+        documents = [],\n+      } = await processRawText(textContent, metadata);\n+      response\n+        .status(200)\n+        .json({ filename: metadata.title, success, reason, documents });\n+    } catch (e) {\n+      console.error(e);\n+      response.status(200).json({\n+        filename: metadata?.title || \"Unknown-doc.txt\",\n+        success: false,\n+        reason: \"A processing error occurred.\",\n+        documents: [],\n+      });\n+    }\n+    return;\n   }\n-  return;\n-});\n+);\n \n extensions(app);\n "
        },
        {
          "filename": "collector/middleware/verifyIntegrity.js",
          "status": "added",
          "additions": 21,
          "deletions": 0,
          "patch": "@@ -0,0 +1,21 @@\n+const { CommunicationKey } = require(\"../utils/comKey\");\n+\n+function verifyPayloadIntegrity(request, response, next) {\n+  const comKey = new CommunicationKey();\n+  if (process.env.NODE_ENV === \"development\") {\n+    comKey.log('verifyPayloadIntegrity is skipped in development.')\n+    next();\n+    return;\n+  }\n+\n+  const signature = request.header(\"X-Integrity\");\n+  if (!signature) return response.status(400).json({ msg: 'Failed integrity signature check.' })\n+\n+  const validSignedPayload = comKey.verify(signature, request.body);\n+  if (!validSignedPayload) return response.status(400).json({ msg: 'Failed integrity signature check.' })\n+  next();\n+}\n+\n+module.exports = {\n+  verifyPayloadIntegrity\n+}\n\\ No newline at end of file"
        },
        {
          "filename": "collector/processSingleFile/index.js",
          "status": "modified",
          "additions": 17,
          "deletions": 2,
          "patch": "@@ -4,11 +4,26 @@ const {\n   WATCH_DIRECTORY,\n   SUPPORTED_FILETYPE_CONVERTERS,\n } = require(\"../utils/constants\");\n-const { trashFile, isTextType } = require(\"../utils/files\");\n+const {\n+  trashFile,\n+  isTextType,\n+  normalizePath,\n+  isWithin,\n+} = require(\"../utils/files\");\n const RESERVED_FILES = [\"__HOTDIR__.md\"];\n \n async function processSingleFile(targetFilename, options = {}) {\n-  const fullFilePath = path.resolve(WATCH_DIRECTORY, targetFilename);\n+  const fullFilePath = path.resolve(\n+    WATCH_DIRECTORY,\n+    normalizePath(targetFilename)\n+  );\n+  if (!isWithin(path.resolve(WATCH_DIRECTORY), fullFilePath))\n+    return {\n+      success: false,\n+      reason: \"Filename is a not a valid path to process.\",\n+      documents: [],\n+    };\n+\n   if (RESERVED_FILES.includes(targetFilename))\n     return {\n       success: false,"
        },
        {
          "filename": "collector/utils/comKey/index.js",
          "status": "added",
          "additions": 42,
          "deletions": 0,
          "patch": "@@ -0,0 +1,42 @@\n+const crypto = require(\"crypto\");\n+const fs = require(\"fs\");\n+const path = require(\"path\");\n+\n+const keyPath =\n+  process.env.NODE_ENV === \"development\"\n+    ? path.resolve(__dirname, `../../../server/storage/comkey`)\n+    : path.resolve(process.env.STORAGE_DIR, `comkey`);\n+\n+class CommunicationKey {\n+  #pubKeyName = \"ipc-pub.pem\";\n+  #storageLoc = keyPath;\n+\n+  constructor() {}\n+\n+  log(text, ...args) {\n+    console.log(`\\x1b[36m[CommunicationKeyVerify]\\x1b[0m ${text}`, ...args);\n+  }\n+\n+  #readPublicKey() {\n+    return fs.readFileSync(path.resolve(this.#storageLoc, this.#pubKeyName));\n+  }\n+\n+  // Given a signed payload from private key from /app/server/ this signature should\n+  // decode to match the textData provided. This class does verification only in collector.\n+  // Note: The textData is typically the JSON stringified body sent to the document processor API.\n+  verify(signature = \"\", textData = \"\") {\n+    try {\n+      let data = textData;\n+      if (typeof textData !== \"string\") data = JSON.stringify(data);\n+      return crypto.verify(\n+        \"RSA-SHA256\",\n+        Buffer.from(data),\n+        this.#readPublicKey(),\n+        Buffer.from(signature, \"hex\")\n+      );\n+    } catch {}\n+    return false;\n+  }\n+}\n+\n+module.exports = { CommunicationKey };"
        },
        {
          "filename": "collector/utils/files/index.js",
          "status": "modified",
          "additions": 23,
          "deletions": 0,
          "patch": "@@ -108,10 +108,33 @@ async function wipeCollectorStorage() {\n   return;\n }\n \n+/**\n+ * Checks if a given path is within another path.\n+ * @param {string} outer - The outer path (should be resolved).\n+ * @param {string} inner - The inner path (should be resolved).\n+ * @returns {boolean} - Returns true if the inner path is within the outer path, false otherwise.\n+ */\n+function isWithin(outer, inner) {\n+  if (outer === inner) return false;\n+  const rel = path.relative(outer, inner);\n+  return !rel.startsWith(\"../\") && rel !== \"..\";\n+}\n+\n+function normalizePath(filepath = \"\") {\n+  const result = path\n+    .normalize(filepath.trim())\n+    .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\")\n+    .trim();\n+  if ([\"..\", \".\", \"/\"].includes(result)) throw new Error(\"Invalid path.\");\n+  return result;\n+}\n+\n module.exports = {\n   trashFile,\n   isTextType,\n   createdDate,\n   writeToServerDocuments,\n   wipeCollectorStorage,\n+  normalizePath,\n+  isWithin,\n };"
        },
        {
          "filename": "server/.gitignore",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -3,6 +3,7 @@\n storage/assets/*\n !storage/assets/anything-llm.png\n storage/documents/*\n+storage/comkey/*\n storage/tmp/*\n storage/vector-cache/*.json\n storage/exports"
        },
        {
          "filename": "server/utils/boot/index.js",
          "status": "modified",
          "additions": 3,
          "deletions": 0,
          "patch": "@@ -1,4 +1,5 @@\n const { Telemetry } = require(\"../../models/telemetry\");\n+const { CommunicationKey } = require(\"../comKey\");\n const setupTelemetry = require(\"../telemetry\");\n \n function bootSSL(app, port = 3001) {\n@@ -16,6 +17,7 @@ function bootSSL(app, port = 3001) {\n       .createServer(credentials, app)\n       .listen(port, async () => {\n         await setupTelemetry();\n+        new CommunicationKey(true);\n         console.log(`Primary server in HTTPS mode listening on port ${port}`);\n       })\n       .on(\"error\", catchSigTerms);\n@@ -40,6 +42,7 @@ function bootHTTP(app, port = 3001) {\n   app\n     .listen(port, async () => {\n       await setupTelemetry();\n+      new CommunicationKey(true);\n       console.log(`Primary server in HTTP mode listening on port ${port}`);\n     })\n     .on(\"error\", catchSigTerms);"
        },
        {
          "filename": "server/utils/collectorApi/index.js",
          "status": "modified",
          "additions": 17,
          "deletions": 6,
          "patch": "@@ -5,6 +5,8 @@\n \n class CollectorApi {\n   constructor() {\n+    const { CommunicationKey } = require(\"../comKey\");\n+    this.comkey = new CommunicationKey();\n     this.endpoint = `http://0.0.0.0:${process.env.COLLECTOR_PORT || 8888}`;\n   }\n \n@@ -40,15 +42,19 @@ class CollectorApi {\n \n   async processDocument(filename = \"\") {\n     if (!filename) return false;\n+\n+    const data = JSON.stringify({\n+      filename,\n+      options: this.#attachOptions(),\n+    });\n+\n     return await fetch(`${this.endpoint}/process`, {\n       method: \"POST\",\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(data),\n       },\n-      body: JSON.stringify({\n-        filename,\n-        options: this.#attachOptions(),\n-      }),\n+      body: data,\n     })\n       .then((res) => {\n         if (!res.ok) throw new Error(\"Response could not be completed\");\n@@ -64,12 +70,14 @@ class CollectorApi {\n   async processLink(link = \"\") {\n     if (!link) return false;\n \n+    const data = JSON.stringify({ link });\n     return await fetch(`${this.endpoint}/process-link`, {\n       method: \"POST\",\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(data),\n       },\n-      body: JSON.stringify({ link }),\n+      body: data,\n     })\n       .then((res) => {\n         if (!res.ok) throw new Error(\"Response could not be completed\");\n@@ -83,12 +91,14 @@ class CollectorApi {\n   }\n \n   async processRawText(textContent = \"\", metadata = {}) {\n+    const data = JSON.stringify({ textContent, metadata });\n     return await fetch(`${this.endpoint}/process-raw-text`, {\n       method: \"POST\",\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(data),\n       },\n-      body: JSON.stringify({ textContent, metadata }),\n+      body: data,\n     })\n       .then((res) => {\n         if (!res.ok) throw new Error(\"Response could not be completed\");\n@@ -110,6 +120,7 @@ class CollectorApi {\n       body, // Stringified JSON!\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(body),\n       },\n     })\n       .then((res) => {"
        },
        {
          "filename": "server/utils/comKey/index.js",
          "status": "added",
          "additions": 75,
          "deletions": 0,
          "patch": "@@ -0,0 +1,75 @@\n+const crypto = require(\"crypto\");\n+const fs = require(\"fs\");\n+const path = require(\"path\");\n+const keyPath =\n+  process.env.NODE_ENV === \"development\"\n+    ? path.resolve(__dirname, `../../storage/comkey`)\n+    : path.resolve(process.env.STORAGE_DIR, `comkey`);\n+\n+// What does this class do?\n+// This class generates a hashed version of some text (typically a JSON payload) using a rolling RSA key\n+// that can then be appended as a header value to do integrity checking on a payload. Given the\n+// nature of this class and that keys are rolled constantly, this protects the request\n+// integrity of requests sent to the collector as only the server can sign these requests.\n+// This keeps accidental misconfigurations of AnythingLLM that leaving port 8888 open from\n+// being abused or SSRF'd by users scraping malicious sites who have a loopback embedded in a <script>, for example.\n+// Since each request to the collector must be signed to be valid, unsigned requests directly to the collector\n+// will be dropped and must go through the /server endpoint directly.\n+class CommunicationKey {\n+  #privKeyName = \"ipc-priv.pem\";\n+  #pubKeyName = \"ipc-pub.pem\";\n+  #storageLoc = keyPath;\n+\n+  // Init the class and determine if keys should be rolled.\n+  // This typically occurs on boot up so key is fresh each boot.\n+  constructor(generate = false) {\n+    if (generate) this.#generate();\n+  }\n+\n+  log(text, ...args) {\n+    console.log(`\\x1b[36m[CommunicationKey]\\x1b[0m ${text}`, ...args);\n+  }\n+\n+  #readPrivateKey() {\n+    return fs.readFileSync(path.resolve(this.#storageLoc, this.#privKeyName));\n+  }\n+\n+  #generate() {\n+    const keyPair = crypto.generateKeyPairSync(\"rsa\", {\n+      modulusLength: 2048,\n+      publicKeyEncoding: {\n+        type: \"pkcs1\",\n+        format: \"pem\",\n+      },\n+      privateKeyEncoding: {\n+        type: \"pkcs1\",\n+        format: \"pem\",\n+      },\n+    });\n+\n+    if (!fs.existsSync(this.#storageLoc))\n+      fs.mkdirSync(this.#storageLoc, { recursive: true });\n+    fs.writeFileSync(\n+      `${path.resolve(this.#storageLoc, this.#privKeyName)}`,\n+      keyPair.privateKey\n+    );\n+    fs.writeFileSync(\n+      `${path.resolve(this.#storageLoc, this.#pubKeyName)}`,\n+      keyPair.publicKey\n+    );\n+    this.log(\n+      \"RSA key pair generated for signed payloads within AnythingLLM services.\"\n+    );\n+  }\n+\n+  // This instance of ComKey on server is intended for generation of Priv/Pub key for signing and decoding.\n+  // this resource is shared with /collector/ via a class of the same name in /utils which does decoding/verification only\n+  // while this server class only does signing with the private key.\n+  sign(textData = \"\") {\n+    return crypto\n+      .sign(\"RSA-SHA256\", Buffer.from(textData), this.#readPrivateKey())\n+      .toString(\"hex\");\n+  }\n+}\n+\n+module.exports = { CommunicationKey };"
        }
      ],
      "file_patterns": {
        "security_files": 2,
        "config_files": 1,
        "dependency_files": 0,
        "test_files": 0,
        "unique_directories": 11,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "4d5d8d4dec0e62662c8ec46537038353f45e0e66",
            "date": "2025-01-14T16:20:57Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "21af81085aeb049750942ac5f3b84775cb461693",
            "date": "2025-01-13T21:12:03Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "665e8e5bfe431ad93bed6736d0b450592617d042",
            "date": "2025-01-09T23:39:56Z",
            "author_login": "shatfield4"
          },
          {
            "sha": "865f7eea296e544b2eb1ab8c1f322208eaf5eb05",
            "date": "2025-01-09T21:32:54Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "be886f7d61296a30d5b8a095ca8329f58a0c5a0a",
            "date": "2025-01-09T01:21:30Z",
            "author_login": "root-reindeer-flotilla"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 8.8,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H",
    "cwe_id": "CWE-918",
    "description": "A Server-Side Request Forgery (SSRF) vulnerability exists in the upload link feature of mintplex-labs/anything-llm. This feature, intended for users with manager or admin roles, processes uploaded links through an internal Collector API using a headless browser. An attacker can exploit this by hosting a malicious website and using it to perform actions such as internal port scanning, accessing internal web applications not exposed externally, and interacting with the Collector API. This interaction can lead to unauthorized actions such as arbitrary file deletion and limited Local File Inclusion (LFI), including accessing NGINX access logs which may contain sensitive information.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-06-06T19:16:00.130",
    "last_modified": "2024-11-21T09:29:00.367",
    "fix_date": "2024-04-01T20:56:35Z"
  },
  "references": [
    {
      "url": "https://github.com/mintplex-labs/anything-llm/commit/f4088d9348fa86dcebe9f97a18d39c0a6e92f15e",
      "source": "security@huntr.dev",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.com/bounties/b230d76b-ae2d-440e-a25b-94ffaa7c4ff1",
      "source": "security@huntr.dev",
      "tags": [
        "Exploit",
        "Issue Tracking",
        "Patch",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/mintplex-labs/anything-llm/commit/f4088d9348fa86dcebe9f97a18d39c0a6e92f15e",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.com/bounties/b230d76b-ae2d-440e-a25b-94ffaa7c4ff1",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit",
        "Issue Tracking",
        "Patch",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:08:26.349206",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "anything-llm",
    "owner": "mintplex-labs",
    "created_at": "2023-06-04T02:29:14Z",
    "updated_at": "2025-01-14T13:49:57Z",
    "pushed_at": "2025-01-13T21:12:06Z",
    "size": 42916,
    "stars": 30237,
    "forks": 3030,
    "open_issues": 206,
    "watchers": 30237,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "JavaScript": 3056909,
      "CSS": 73785,
      "Dockerfile": 9030,
      "HTML": 3904,
      "Shell": 1382,
      "HCL": 1211
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "mit"
    },
    "collected_at": "2025-01-14T14:04:33.088245"
  }
}