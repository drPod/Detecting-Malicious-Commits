{
  "cve_id": "CVE-2024-3166",
  "github_data": {
    "repository": "mintplex-labs/anything-llm",
    "fix_commit": "fa27103d032c58904c49b92ee13fabc19a20a5ce",
    "related_commits": [
      "fa27103d032c58904c49b92ee13fabc19a20a5ce",
      "fa27103d032c58904c49b92ee13fabc19a20a5ce"
    ],
    "patch_url": "https://github.com/mintplex-labs/anything-llm/commit/fa27103d032c58904c49b92ee13fabc19a20a5ce.patch",
    "fix_commit_details": {
      "sha": "fa27103d032c58904c49b92ee13fabc19a20a5ce",
      "commit_date": "2024-04-01T21:54:03Z",
      "author": {
        "login": "timothycarambat",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "sync with master",
        "length": 16,
        "has_description": false,
        "references_issue": false
      },
      "stats": {
        "total": 1134,
        "additions": 912,
        "deletions": 222
      },
      "files": [
        {
          "filename": ".vscode/settings.json",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -2,6 +2,7 @@\n   \"cSpell.words\": [\n     \"anythingllm\",\n     \"Astra\",\n+    \"comkey\",\n     \"Dockerized\",\n     \"Embeddable\",\n     \"GROQ\",\n@@ -20,4 +21,4 @@\n   ],\n   \"eslint.experimental.useFlatConfig\": true,\n   \"docker.languageserver.formatter.ignoreMultilineInstructions\": true\n-}\n+}\n\\ No newline at end of file"
        },
        {
          "filename": "collector/extensions/index.js",
          "status": "modified",
          "additions": 4,
          "deletions": 3,
          "patch": "@@ -1,9 +1,10 @@\n+const { verifyPayloadIntegrity } = require(\"../middleware/verifyIntegrity\");\n const { reqBody } = require(\"../utils/http\");\n \n function extensions(app) {\n   if (!app) return;\n \n-  app.post(\"/ext/github-repo\", async function (request, response) {\n+  app.post(\"/ext/github-repo\", [verifyPayloadIntegrity], async function (request, response) {\n     try {\n       const loadGithubRepo = require(\"../utils/extensions/GithubRepo\");\n       const { success, reason, data } = await loadGithubRepo(reqBody(request));\n@@ -24,7 +25,7 @@ function extensions(app) {\n   });\n \n   // gets all branches for a specific repo\n-  app.post(\"/ext/github-repo/branches\", async function (request, response) {\n+  app.post(\"/ext/github-repo/branches\", [verifyPayloadIntegrity], async function (request, response) {\n     try {\n       const GithubRepoLoader = require(\"../utils/extensions/GithubRepo/RepoLoader\");\n       const allBranches = await (new GithubRepoLoader(reqBody(request))).getRepoBranches()\n@@ -48,7 +49,7 @@ function extensions(app) {\n     return;\n   });\n \n-  app.post(\"/ext/youtube-transcript\", async function (request, response) {\n+  app.post(\"/ext/youtube-transcript\", [verifyPayloadIntegrity], async function (request, response) {\n     try {\n       const loadYouTubeTranscript = require(\"../utils/extensions/YoutubeTranscript\");\n       const { success, reason, data } = await loadYouTubeTranscript(reqBody(request));"
        },
        {
          "filename": "collector/index.js",
          "status": "modified",
          "additions": 73,
          "deletions": 60,
          "patch": "@@ -13,6 +13,7 @@ const { processLink } = require(\"./processLink\");\n const { wipeCollectorStorage } = require(\"./utils/files\");\n const extensions = require(\"./extensions\");\n const { processRawText } = require(\"./processRawText\");\n+const { verifyPayloadIntegrity } = require(\"./middleware/verifyIntegrity\");\n const app = express();\n \n app.use(cors({ origin: true }));\n@@ -24,71 +25,83 @@ app.use(\n   })\n );\n \n-app.post(\"/process\", async function (request, response) {\n-  const { filename, options = {} } = reqBody(request);\n-  try {\n-    const targetFilename = path\n-      .normalize(filename)\n-      .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\");\n-    const {\n-      success,\n-      reason,\n-      documents = [],\n-    } = await processSingleFile(targetFilename, options);\n-    response\n-      .status(200)\n-      .json({ filename: targetFilename, success, reason, documents });\n-  } catch (e) {\n-    console.error(e);\n-    response.status(200).json({\n-      filename: filename,\n-      success: false,\n-      reason: \"A processing error occurred.\",\n-      documents: [],\n-    });\n+app.post(\n+  \"/process\",\n+  [verifyPayloadIntegrity],\n+  async function (request, response) {\n+    const { filename, options = {} } = reqBody(request);\n+    try {\n+      const targetFilename = path\n+        .normalize(filename)\n+        .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\");\n+      const {\n+        success,\n+        reason,\n+        documents = [],\n+      } = await processSingleFile(targetFilename, options);\n+      response\n+        .status(200)\n+        .json({ filename: targetFilename, success, reason, documents });\n+    } catch (e) {\n+      console.error(e);\n+      response.status(200).json({\n+        filename: filename,\n+        success: false,\n+        reason: \"A processing error occurred.\",\n+        documents: [],\n+      });\n+    }\n+    return;\n   }\n-  return;\n-});\n+);\n \n-app.post(\"/process-link\", async function (request, response) {\n-  const { link } = reqBody(request);\n-  try {\n-    const { success, reason, documents = [] } = await processLink(link);\n-    response.status(200).json({ url: link, success, reason, documents });\n-  } catch (e) {\n-    console.error(e);\n-    response.status(200).json({\n-      url: link,\n-      success: false,\n-      reason: \"A processing error occurred.\",\n-      documents: [],\n-    });\n+app.post(\n+  \"/process-link\",\n+  [verifyPayloadIntegrity],\n+  async function (request, response) {\n+    const { link } = reqBody(request);\n+    try {\n+      const { success, reason, documents = [] } = await processLink(link);\n+      response.status(200).json({ url: link, success, reason, documents });\n+    } catch (e) {\n+      console.error(e);\n+      response.status(200).json({\n+        url: link,\n+        success: false,\n+        reason: \"A processing error occurred.\",\n+        documents: [],\n+      });\n+    }\n+    return;\n   }\n-  return;\n-});\n+);\n \n-app.post(\"/process-raw-text\", async function (request, response) {\n-  const { textContent, metadata } = reqBody(request);\n-  try {\n-    const {\n-      success,\n-      reason,\n-      documents = [],\n-    } = await processRawText(textContent, metadata);\n-    response\n-      .status(200)\n-      .json({ filename: metadata.title, success, reason, documents });\n-  } catch (e) {\n-    console.error(e);\n-    response.status(200).json({\n-      filename: metadata?.title || \"Unknown-doc.txt\",\n-      success: false,\n-      reason: \"A processing error occurred.\",\n-      documents: [],\n-    });\n+app.post(\n+  \"/process-raw-text\",\n+  [verifyPayloadIntegrity],\n+  async function (request, response) {\n+    const { textContent, metadata } = reqBody(request);\n+    try {\n+      const {\n+        success,\n+        reason,\n+        documents = [],\n+      } = await processRawText(textContent, metadata);\n+      response\n+        .status(200)\n+        .json({ filename: metadata.title, success, reason, documents });\n+    } catch (e) {\n+      console.error(e);\n+      response.status(200).json({\n+        filename: metadata?.title || \"Unknown-doc.txt\",\n+        success: false,\n+        reason: \"A processing error occurred.\",\n+        documents: [],\n+      });\n+    }\n+    return;\n   }\n-  return;\n-});\n+);\n \n extensions(app);\n "
        },
        {
          "filename": "collector/middleware/verifyIntegrity.js",
          "status": "added",
          "additions": 21,
          "deletions": 0,
          "patch": "@@ -0,0 +1,21 @@\n+const { CommunicationKey } = require(\"../utils/comKey\");\n+\n+function verifyPayloadIntegrity(request, response, next) {\n+  const comKey = new CommunicationKey();\n+  if (process.env.NODE_ENV === \"development\") {\n+    comKey.log('verifyPayloadIntegrity is skipped in development.')\n+    next();\n+    return;\n+  }\n+\n+  const signature = request.header(\"X-Integrity\");\n+  if (!signature) return response.status(400).json({ msg: 'Failed integrity signature check.' })\n+\n+  const validSignedPayload = comKey.verify(signature, request.body);\n+  if (!validSignedPayload) return response.status(400).json({ msg: 'Failed integrity signature check.' })\n+  next();\n+}\n+\n+module.exports = {\n+  verifyPayloadIntegrity\n+}\n\\ No newline at end of file"
        },
        {
          "filename": "collector/processSingleFile/index.js",
          "status": "modified",
          "additions": 18,
          "deletions": 2,
          "patch": "@@ -4,11 +4,27 @@ const {\n   WATCH_DIRECTORY,\n   SUPPORTED_FILETYPE_CONVERTERS,\n } = require(\"../utils/constants\");\n-const { trashFile, isTextType } = require(\"../utils/files\");\n+const {\n+  trashFile,\n+  isTextType,\n+  normalizePath,\n+  isWithin,\n+} = require(\"../utils/files\");\n const RESERVED_FILES = [\"__HOTDIR__.md\"];\n \n async function processSingleFile(targetFilename, options = {}) {\n-  const fullFilePath = path.resolve(WATCH_DIRECTORY, targetFilename);\n+  const fullFilePath = path.resolve(\n+    WATCH_DIRECTORY,\n+    normalizePath(targetFilename)\n+  );\n+  if (!isWithin(path.resolve(WATCH_DIRECTORY), fullFilePath)) {\n+    return {\n+      success: false,\n+      reason: \"Filename is a not a valid path to process.\",\n+      documents: [],\n+    };\n+  }\n+\n   if (RESERVED_FILES.includes(targetFilename)) {\n     return {\n       success: false,"
        },
        {
          "filename": "collector/utils/comKey/index.js",
          "status": "added",
          "additions": 42,
          "deletions": 0,
          "patch": "@@ -0,0 +1,42 @@\n+const crypto = require(\"crypto\");\n+const fs = require(\"fs\");\n+const path = require(\"path\");\n+\n+const keyPath =\n+  process.env.NODE_ENV === \"development\"\n+    ? path.resolve(__dirname, `../../../server/storage/comkey`)\n+    : path.resolve(process.env.STORAGE_DIR, `comkey`);\n+\n+class CommunicationKey {\n+  #pubKeyName = \"ipc-pub.pem\";\n+  #storageLoc = keyPath;\n+\n+  constructor() {}\n+\n+  log(text, ...args) {\n+    console.log(`\\x1b[36m[CommunicationKeyVerify]\\x1b[0m ${text}`, ...args);\n+  }\n+\n+  #readPublicKey() {\n+    return fs.readFileSync(path.resolve(this.#storageLoc, this.#pubKeyName));\n+  }\n+\n+  // Given a signed payload from private key from /app/server/ this signature should\n+  // decode to match the textData provided. This class does verification only in collector.\n+  // Note: The textData is typically the JSON stringified body sent to the document processor API.\n+  verify(signature = \"\", textData = \"\") {\n+    try {\n+      let data = textData;\n+      if (typeof textData !== \"string\") data = JSON.stringify(data);\n+      return crypto.verify(\n+        \"RSA-SHA256\",\n+        Buffer.from(data),\n+        this.#readPublicKey(),\n+        Buffer.from(signature, \"hex\")\n+      );\n+    } catch {}\n+    return false;\n+  }\n+}\n+\n+module.exports = { CommunicationKey };"
        },
        {
          "filename": "collector/utils/files/index.js",
          "status": "modified",
          "additions": 23,
          "deletions": 0,
          "patch": "@@ -119,10 +119,33 @@ async function wipeCollectorStorage() {\n   return;\n }\n \n+/**\n+ * Checks if a given path is within another path.\n+ * @param {string} outer - The outer path (should be resolved).\n+ * @param {string} inner - The inner path (should be resolved).\n+ * @returns {boolean} - Returns true if the inner path is within the outer path, false otherwise.\n+ */\n+function isWithin(outer, inner) {\n+  if (outer === inner) return false;\n+  const rel = path.relative(outer, inner);\n+  return !rel.startsWith(\"../\") && rel !== \"..\";\n+}\n+\n+function normalizePath(filepath = \"\") {\n+  const result = path\n+    .normalize(filepath.trim())\n+    .replace(/^(\\.\\.(\\/|\\\\|$))+/, \"\")\n+    .trim();\n+  if ([\"..\", \".\", \"/\"].includes(result)) throw new Error(\"Invalid path.\");\n+  return result;\n+}\n+\n module.exports = {\n   trashFile,\n   isTextType,\n   createdDate,\n   writeToServerDocuments,\n   wipeCollectorStorage,\n+  normalizePath,\n+  isWithin,\n };"
        },
        {
          "filename": "docker/.env.example",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -27,6 +27,7 @@ GID='1000'\n \n # LLM_PROVIDER='lmstudio'\n # LMSTUDIO_BASE_PATH='http://your-server:1234/v1'\n+# LMSTUDIO_MODEL_PREF='Loaded from Chat UI' # this is a bug in LMStudio 0.2.17\n # LMSTUDIO_MODEL_TOKEN_LIMIT=4096\n \n # LLM_PROVIDER='localai'"
        },
        {
          "filename": "docker/HOW_TO_USE_DOCKER.md",
          "status": "modified",
          "additions": 11,
          "deletions": 0,
          "patch": "@@ -109,6 +109,17 @@ container rebuilds or pulls from Docker Hub.\n \n Your docker host will show the image as online once the build process is completed. This will build the app to `http://localhost:3001`.\n \n+## Integrations and one-click setups\n+\n+The integrations below are templates or tooling built by the community to make running the docker experience of AnythingLLM easier.\n+\n+### Use the Midori AI Subsystem to Manage AnythingLLM\n+\n+Follow the setup found on [Midori AI Subsystem Site](https://io.midori-ai.xyz/subsystem/manager/) for your host OS\n+After setting that up install the AnythingLLM docker backend to the Midori AI Subsystem.\n+\n+Once that is done, you are all set!\n+\n ## Common questions and fixes\n \n ### Cannot connect to service running on localhost!"
        },
        {
          "filename": "frontend/src/assets/llmprovider/lmstudio.png",
          "status": "modified",
          "additions": 0,
          "deletions": 0,
          "patch": null
        },
        {
          "filename": "frontend/src/components/LLMSelection/LMStudioOptions/index.jsx",
          "status": "modified",
          "additions": 82,
          "deletions": 2,
          "patch": "@@ -1,8 +1,15 @@\n-import { Info } from \"@phosphor-icons/react\";\n-import paths from \"../../../utils/paths\";\n+import { useEffect, useState } from \"react\";\n import { Link } from \"react-router-dom\";\n+import { Info } from \"@phosphor-icons/react\";\n+import paths from \"@/utils/paths\";\n+import System from \"@/models/system\";\n \n export default function LMStudioOptions({ settings, showAlert = false }) {\n+  const [basePathValue, setBasePathValue] = useState(\n+    settings?.LMStudioBasePath\n+  );\n+  const [basePath, setBasePath] = useState(settings?.LMStudioBasePath);\n+\n   return (\n     <div className=\"w-full flex flex-col\">\n       {showAlert && (\n@@ -36,8 +43,11 @@ export default function LMStudioOptions({ settings, showAlert = false }) {\n             required={true}\n             autoComplete=\"off\"\n             spellCheck={false}\n+            onChange={(e) => setBasePathValue(e.target.value)}\n+            onBlur={() => setBasePath(basePathValue)}\n           />\n         </div>\n+        <LMStudioModelSelection settings={settings} basePath={basePath} />\n         <div className=\"flex flex-col w-60\">\n           <label className=\"text-white text-sm font-semibold block mb-4\">\n             Token context window\n@@ -58,3 +68,73 @@ export default function LMStudioOptions({ settings, showAlert = false }) {\n     </div>\n   );\n }\n+\n+function LMStudioModelSelection({ settings, basePath = null }) {\n+  const [customModels, setCustomModels] = useState([]);\n+  const [loading, setLoading] = useState(true);\n+\n+  useEffect(() => {\n+    async function findCustomModels() {\n+      if (!basePath || !basePath.includes(\"/v1\")) {\n+        setCustomModels([]);\n+        setLoading(false);\n+        return;\n+      }\n+      setLoading(true);\n+      const { models } = await System.customModels(\"lmstudio\", null, basePath);\n+      setCustomModels(models || []);\n+      setLoading(false);\n+    }\n+    findCustomModels();\n+  }, [basePath]);\n+\n+  if (loading || customModels.length == 0) {\n+    return (\n+      <div className=\"flex flex-col w-60\">\n+        <label className=\"text-white text-sm font-semibold block mb-4\">\n+          Chat Model Selection\n+        </label>\n+        <select\n+          name=\"LMStudioModelPref\"\n+          disabled={true}\n+          className=\"bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n+        >\n+          <option disabled={true} selected={true}>\n+            {basePath?.includes(\"/v1\")\n+              ? \"-- loading available models --\"\n+              : \"-- waiting for URL --\"}\n+          </option>\n+        </select>\n+      </div>\n+    );\n+  }\n+\n+  return (\n+    <div className=\"flex flex-col w-60\">\n+      <label className=\"text-white text-sm font-semibold block mb-4\">\n+        Chat Model Selection\n+      </label>\n+      <select\n+        name=\"LMStudioModelPref\"\n+        required={true}\n+        className=\"bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5\"\n+      >\n+        {customModels.length > 0 && (\n+          <optgroup label=\"Your loaded models\">\n+            {customModels.map((model) => {\n+              return (\n+                <option\n+                  key={model.id}\n+                  value={model.id}\n+                  selected={settings.LMStudioModelPref === model.id}\n+                >\n+                  {model.id}\n+                </option>\n+              );\n+            })}\n+          </optgroup>\n+        )}\n+      </select>\n+    </div>\n+  );\n+}"
        },
        {
          "filename": "frontend/src/components/Modals/MangeWorkspace/Documents/Directory/FolderSelectionPopup/index.jsx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -7,7 +7,7 @@ export default function FolderSelectionPopup({ folders, onSelect, onClose }) {\n   };\n \n   return (\n-    <div className=\"absolute bottom-full left-0 mb-2 bg-white rounded-lg shadow-lg\">\n+    <div className=\"absolute bottom-full left-0 mb-2 bg-white rounded-lg shadow-lg max-h-40 overflow-y-auto no-scroll\">\n       <ul className=\"list-none m-1 p-0\">\n         {folders.map((folder) => (\n           <li"
        },
        {
          "filename": "frontend/src/components/Modals/Password/index.jsx",
          "status": "modified",
          "additions": 6,
          "deletions": 4,
          "patch": "@@ -35,7 +35,7 @@ export default function PasswordModal({ mode = \"single\" }) {\n   );\n }\n \n-export function usePasswordModal() {\n+export function usePasswordModal(notry = false) {\n   const [auth, setAuth] = useState({\n     loading: true,\n     requiresAuth: false,\n@@ -48,7 +48,7 @@ export function usePasswordModal() {\n \n       // If the last validity check is still valid\n       // we can skip the loading.\n-      if (!System.needsAuthCheck()) {\n+      if (!System.needsAuthCheck() && notry === false) {\n         setAuth({\n           loading: false,\n           requiresAuth: false,\n@@ -61,7 +61,7 @@ export function usePasswordModal() {\n       if (settings?.MultiUserMode) {\n         const currentToken = window.localStorage.getItem(AUTH_TOKEN);\n         if (!!currentToken) {\n-          const valid = await System.checkAuth(currentToken);\n+          const valid = notry ? false : await System.checkAuth(currentToken);\n           if (!valid) {\n             setAuth({\n               loading: false,\n@@ -103,14 +103,16 @@ export function usePasswordModal() {\n \n         const currentToken = window.localStorage.getItem(AUTH_TOKEN);\n         if (!!currentToken) {\n-          const valid = await System.checkAuth(currentToken);\n+          const valid = notry ? false : await System.checkAuth(currentToken);\n           if (!valid) {\n             setAuth({\n               loading: false,\n               requiresAuth: true,\n               mode: \"single\",\n             });\n             window.localStorage.removeItem(AUTH_TOKEN);\n+            window.localStorage.removeItem(AUTH_USER);\n+            window.localStorage.removeItem(AUTH_TIMESTAMP);\n             return;\n           } else {\n             setAuth({"
        },
        {
          "filename": "frontend/src/components/PrivateRoute/index.jsx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -139,6 +139,6 @@ export default function PrivateRoute({ Component }) {\n       <Component />\n     </AppLayout>\n   ) : (\n-    <Navigate to={paths.login()} />\n+    <Navigate to={paths.login(true)} />\n   );\n }"
        },
        {
          "filename": "frontend/src/components/UserMenu/UserButton/index.jsx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -40,7 +40,7 @@ export default function UserButton() {\n \n   if (mode === null) return null;\n   return (\n-    <div className=\"absolute top-9 right-10 w-fit h-fit z-99\">\n+    <div className=\"absolute top-3 right-4 md:top-9 md:right-10 w-fit h-fit z-99\">\n       <button\n         ref={buttonRef}\n         onClick={() => setShowMenu(!showMenu)}"
        },
        {
          "filename": "frontend/src/models/admin.js",
          "status": "modified",
          "additions": 5,
          "deletions": 1,
          "patch": "@@ -66,8 +66,12 @@ const Admin = {\n   },\n   newInvite: async () => {\n     return await fetch(`${API_BASE()}/admin/invite/new`, {\n-      method: \"GET\",\n+      method: \"POST\",\n       headers: baseHeaders(),\n+      body: JSON.stringify({\n+        role,\n+        workspaceIds,\n+      }),\n     })\n       .then((res) => res.json())\n       .catch((e) => {"
        },
        {
          "filename": "frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx",
          "status": "modified",
          "additions": 91,
          "deletions": 3,
          "patch": "@@ -1,16 +1,23 @@\n import React, { useEffect, useState } from \"react\";\n import { X } from \"@phosphor-icons/react\";\n import Admin from \"@/models/admin\";\n+import Workspace from \"@/models/workspace\";\n \n export default function NewInviteModal({ closeModal }) {\n   const [invite, setInvite] = useState(null);\n   const [error, setError] = useState(null);\n   const [copied, setCopied] = useState(false);\n+  const [workspaces, setWorkspaces] = useState([]);\n+  const [selectedWorkspaceIds, setSelectedWorkspaceIds] = useState([]);\n \n   const handleCreate = async (e) => {\n     setError(null);\n     e.preventDefault();\n-    const { invite: newInvite, error } = await Admin.newInvite();\n+\n+    const { invite: newInvite, error } = await Admin.newInvite({\n+      role: null,\n+      workspaceIds: selectedWorkspaceIds,\n+    });\n     if (!!newInvite) setInvite(newInvite);\n     setError(error);\n   };\n@@ -21,6 +28,16 @@ export default function NewInviteModal({ closeModal }) {\n     );\n     setCopied(true);\n   };\n+\n+  const handleWorkspaceSelection = (workspaceId) => {\n+    if (selectedWorkspaceIds.includes(workspaceId)) {\n+      const updated = selectedWorkspaceIds.filter((id) => id !== workspaceId);\n+      setSelectedWorkspaceIds(updated);\n+      return;\n+    }\n+    setSelectedWorkspaceIds([...selectedWorkspaceIds, workspaceId]);\n+  };\n+\n   useEffect(() => {\n     function resetStatus() {\n       if (!copied) return false;\n@@ -31,6 +48,15 @@ export default function NewInviteModal({ closeModal }) {\n     resetStatus();\n   }, [copied]);\n \n+  useEffect(() => {\n+    async function fetchWorkspaces() {\n+      Workspace.all()\n+        .then((workspaces) => setWorkspaces(workspaces))\n+        .catch(() => setWorkspaces([]));\n+    }\n+    fetchWorkspaces();\n+  }, []);\n+\n   return (\n     <div className=\"relative w-[500px] max-w-2xl max-h-full\">\n       <div className=\"relative bg-main-gradient rounded-lg shadow\">\n@@ -61,11 +87,45 @@ export default function NewInviteModal({ closeModal }) {\n               )}\n               <p className=\"text-white text-xs md:text-sm\">\n                 After creation you will be able to copy the invite and send it\n-                to a new user where they can create an account as a default\n-                user.\n+                to a new user where they can create an account as the{\" \"}\n+                <b>default</b> role and automatically be added to workspaces\n+                selected.\n               </p>\n             </div>\n           </div>\n+\n+          {workspaces.length > 0 && !invite && (\n+            <div className=\"p-6 flex w-full justify-between\">\n+              <div className=\"w-full\">\n+                <div className=\"flex flex-col gap-y-1  mb-2\">\n+                  <label\n+                    htmlFor=\"workspaces\"\n+                    className=\"text-sm font-medium text-white\"\n+                  >\n+                    Auto-add invitee to workspaces\n+                  </label>\n+                  <p className=\"text-white/60 text-xs\">\n+                    You can optionally automatically assign the user to the\n+                    workspaces below by selecting them. By default, the user\n+                    will not have any workspaces visible. You can assign\n+                    workspaces later post-invite acceptance.\n+                  </p>\n+                </div>\n+\n+                <div className=\"flex flex-col gap-y-2\">\n+                  {workspaces.map((workspace) => (\n+                    <WorkspaceOption\n+                      key={workspace.id}\n+                      workspace={workspace}\n+                      selected={selectedWorkspaceIds.includes(workspace.id)}\n+                      toggleSelection={handleWorkspaceSelection}\n+                    />\n+                  ))}\n+                </div>\n+              </div>\n+            </div>\n+          )}\n+\n           <div className=\"flex w-full justify-between items-center p-6 space-x-2 border-t rounded-b border-gray-500/50\">\n             {!invite ? (\n               <>\n@@ -99,3 +159,31 @@ export default function NewInviteModal({ closeModal }) {\n     </div>\n   );\n }\n+\n+function WorkspaceOption({ workspace, selected, toggleSelection }) {\n+  return (\n+    <button\n+      type=\"button\"\n+      onClick={() => toggleSelection(workspace.id)}\n+      className={`transition-all duration-300 w-full h-11 p-2.5 bg-white/10 rounded-lg flex justify-start items-center gap-2.5 cursor-pointer border border-transparent ${\n+        selected ? \"border-white border-opacity-40\" : \"border-none \"\n+      } hover:border-white/60`}\n+    >\n+      <input\n+        type=\"radio\"\n+        name=\"workspace\"\n+        value={workspace.id}\n+        checked={selected}\n+        className=\"hidden\"\n+      />\n+      <div\n+        className={`w-4 h-4 rounded-full border-2 border-white mr-2 ${\n+          selected ? \"bg-white\" : \"\"\n+        }`}\n+      ></div>\n+      <div className=\"text-white text-sm font-medium font-['Plus Jakarta Sans'] leading-tight\">\n+        {workspace.name}\n+      </div>\n+    </button>\n+  );\n+}"
        },
        {
          "filename": "frontend/src/pages/Login/index.jsx",
          "status": "modified",
          "additions": 3,
          "deletions": 1,
          "patch": "@@ -3,9 +3,11 @@ import PasswordModal, { usePasswordModal } from \"@/components/Modals/Password\";\n import { FullScreenLoader } from \"@/components/Preloader\";\n import { Navigate } from \"react-router-dom\";\n import paths from \"@/utils/paths\";\n+import useQuery from \"@/hooks/useQuery\";\n \n export default function Login() {\n-  const { loading, requiresAuth, mode } = usePasswordModal();\n+  const query = useQuery();\n+  const { loading, requiresAuth, mode } = usePasswordModal(!!query.get(\"nt\"));\n   if (loading) return <FullScreenLoader />;\n   if (requiresAuth === false) return <Navigate to={paths.home()} />;\n "
        },
        {
          "filename": "frontend/src/utils/paths.js",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -4,8 +4,8 @@ export default {\n   home: () => {\n     return \"/\";\n   },\n-  login: () => {\n-    return \"/login\";\n+  login: (noTry = false) => {\n+    return `/login${noTry ? \"?nt=1\" : \"\"}`;\n   },\n   onboarding: {\n     home: () => {"
        },
        {
          "filename": "server/.env.example",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -23,6 +23,7 @@ DATABASE_URL=\"file:../storage/anythingllm.db\"\n \n # LLM_PROVIDER='lmstudio'\n # LMSTUDIO_BASE_PATH='http://your-server:1234/v1'\n+# LMSTUDIO_MODEL_PREF='Loaded from Chat UI' # this is a bug in LMStudio 0.2.17\n # LMSTUDIO_MODEL_TOKEN_LIMIT=4096\n \n # LLM_PROVIDER='localai'"
        },
        {
          "filename": "server/.gitignore",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -3,6 +3,7 @@\n storage/assets/*\n !storage/assets/anything-llm.png\n storage/documents/*\n+storage/comkey/*\n storage/tmp/*\n storage/vector-cache/*.json\n storage/exports"
        },
        {
          "filename": "server/endpoints/admin.js",
          "status": "modified",
          "additions": 7,
          "deletions": 2,
          "patch": "@@ -165,13 +165,18 @@ function adminEndpoints(app) {\n     }\n   );\n \n-  app.get(\n+  app.post(\n     \"/admin/invite/new\",\n     [validatedRequest, strictMultiUserRoleValid([ROLES.admin, ROLES.manager])],\n     async (request, response) => {\n       try {\n         const user = await userFromSession(request, response);\n-        const { invite, error } = await Invite.create(user.id);\n+        const body = reqBody(request);\n+        const { invite, error } = await Invite.create({\n+          createdByUserId: user.id,\n+          workspaceIds: body?.workspaceIds || [],\n+        });\n+\n         await EventLogs.logEvent(\n           \"invite_created\",\n           {"
        },
        {
          "filename": "server/endpoints/api/admin/index.js",
          "status": "modified",
          "additions": 16,
          "deletions": 1,
          "patch": "@@ -323,6 +323,18 @@ function apiAdminEndpoints(app) {\n     /*\n     #swagger.tags = ['Admin']\n     #swagger.description = 'Create a new invite code for someone to use to register with instance. Methods are disabled until multi user mode is enabled via the UI.'\n+    #swagger.requestBody = {\n+        description: 'Request body for creation parameters of the invitation',\n+        required: false,\n+        type: 'object',\n+        content: {\n+          \"application/json\": {\n+            example: {\n+              workspaceIds: [1,2,45],\n+            }\n+          }\n+        }\n+      }\n     #swagger.responses[200] = {\n       content: {\n         \"application/json\": {\n@@ -355,7 +367,10 @@ function apiAdminEndpoints(app) {\n         return;\n       }\n \n-      const { invite, error } = await Invite.create();\n+      const body = reqBody(request);\n+      const { invite, error } = await Invite.create({\n+        workspaceIds: body?.workspaceIds ?? [],\n+      });\n       response.status(200).json({ invite, error });\n     } catch (e) {\n       console.error(e);"
        },
        {
          "filename": "server/endpoints/api/document/index.js",
          "status": "modified",
          "additions": 2,
          "deletions": 4,
          "patch": "@@ -1,6 +1,6 @@\n const { Telemetry } = require(\"../../../models/telemetry\");\n const { validApiKey } = require(\"../../../utils/middleware/validApiKey\");\n-const { setupMulter } = require(\"../../../utils/files/multer\");\n+const { handleFileUpload } = require(\"../../../utils/files/multer\");\n const {\n   viewLocalFiles,\n   findDocumentInDocuments,\n@@ -9,7 +9,6 @@ const {\n const { reqBody } = require(\"../../../utils/http\");\n const { EventLogs } = require(\"../../../models/eventLogs\");\n const { CollectorApi } = require(\"../../../utils/collectorApi\");\n-const { handleUploads } = setupMulter();\n const fs = require(\"fs\");\n const path = require(\"path\");\n const { Document } = require(\"../../../models/documents\");\n@@ -23,8 +22,7 @@ function apiDocumentEndpoints(app) {\n \n   app.post(\n     \"/v1/document/upload\",\n-    [validApiKey],\n-    handleUploads.single(\"file\"),\n+    [validApiKey, handleFileUpload],\n     async (request, response) => {\n       /*\n     #swagger.tags = ['Documents']"
        },
        {
          "filename": "server/endpoints/system.js",
          "status": "modified",
          "additions": 15,
          "deletions": 14,
          "patch": "@@ -16,12 +16,11 @@ const {\n   multiUserMode,\n   queryParams,\n } = require(\"../utils/http\");\n-const { setupLogoUploads } = require(\"../utils/files/multer\");\n+const { handleAssetUpload } = require(\"../utils/files/multer\");\n const { v4 } = require(\"uuid\");\n const { SystemSettings } = require(\"../models/systemSettings\");\n const { User } = require(\"../models/user\");\n const { validatedRequest } = require(\"../utils/middleware/validatedRequest\");\n-const { handleLogoUploads } = setupLogoUploads();\n const {\n   getDefaultFilename,\n   determineLogoFilepath,\n@@ -101,7 +100,7 @@ function systemEndpoints(app) {\n \n       if (await SystemSettings.isMultiUserMode()) {\n         const { username, password } = reqBody(request);\n-        const existingUser = await User.get({ username });\n+        const existingUser = await User.get({ username: String(username) });\n \n         if (!existingUser) {\n           await EventLogs.logEvent(\n@@ -121,7 +120,7 @@ function systemEndpoints(app) {\n           return;\n         }\n \n-        if (!bcrypt.compareSync(password, existingUser.password)) {\n+        if (!bcrypt.compareSync(String(password), existingUser.password)) {\n           await EventLogs.logEvent(\n             \"failed_login_invalid_password\",\n             {\n@@ -382,22 +381,21 @@ function systemEndpoints(app) {\n     [validatedRequest],\n     async (request, response) => {\n       try {\n-        const { username, password } = reqBody(request);\n-        const multiUserModeEnabled = await SystemSettings.isMultiUserMode();\n-        if (multiUserModeEnabled) {\n+        if (response.locals.multiUserMode) {\n           response.status(200).json({\n             success: false,\n             error: \"Multi-user mode is already enabled.\",\n           });\n           return;\n         }\n \n+        const { username, password } = reqBody(request);\n         const { user, error } = await User.create({\n           username,\n           password,\n           role: ROLES.admin,\n         });\n-        await SystemSettings.updateSettings({\n+        await SystemSettings._updateSettings({\n           multi_user_mode: true,\n           users_can_delete_workspaces: false,\n           limit_user_messages: false,\n@@ -419,7 +417,7 @@ function systemEndpoints(app) {\n         response.status(200).json({ success: !!user, error });\n       } catch (e) {\n         await User.delete({});\n-        await SystemSettings.updateSettings({\n+        await SystemSettings._updateSettings({\n           multi_user_mode: false,\n         });\n \n@@ -478,10 +476,13 @@ function systemEndpoints(app) {\n \n   app.post(\n     \"/system/upload-logo\",\n-    [validatedRequest, flexUserRoleValid([ROLES.admin, ROLES.manager])],\n-    handleLogoUploads.single(\"logo\"),\n+    [\n+      validatedRequest,\n+      flexUserRoleValid([ROLES.admin, ROLES.manager]),\n+      handleAssetUpload,\n+    ],\n     async (request, response) => {\n-      if (!request.file || !request.file.originalname) {\n+      if (!request?.file || !request?.file.originalname) {\n         return response.status(400).json({ message: \"No logo file provided.\" });\n       }\n \n@@ -496,7 +497,7 @@ function systemEndpoints(app) {\n         const existingLogoFilename = await SystemSettings.currentLogoFilename();\n         await removeCustomLogo(existingLogoFilename);\n \n-        const { success, error } = await SystemSettings.updateSettings({\n+        const { success, error } = await SystemSettings._updateSettings({\n           logo_filename: newFilename,\n         });\n \n@@ -530,7 +531,7 @@ function systemEndpoints(app) {\n       try {\n         const currentLogoFilename = await SystemSettings.currentLogoFilename();\n         await removeCustomLogo(currentLogoFilename);\n-        const { success, error } = await SystemSettings.updateSettings({\n+        const { success, error } = await SystemSettings._updateSettings({\n           logo_filename: LOGO_FILENAME,\n         });\n "
        },
        {
          "filename": "server/endpoints/workspaces.js",
          "status": "modified",
          "additions": 14,
          "deletions": 11,
          "patch": "@@ -1,10 +1,13 @@\n+const path = require(\"path\");\n+const fs = require(\"fs\");\n const { reqBody, multiUserMode, userFromSession } = require(\"../utils/http\");\n+const { normalizePath } = require(\"../utils/files\");\n const { Workspace } = require(\"../models/workspace\");\n const { Document } = require(\"../models/documents\");\n const { DocumentVectors } = require(\"../models/vectors\");\n const { WorkspaceChats } = require(\"../models/workspaceChats\");\n const { getVectorDbClass } = require(\"../utils/helpers\");\n-const { setupMulter } = require(\"../utils/files/multer\");\n+const { handleFileUpload, handlePfpUpload } = require(\"../utils/files/multer\");\n const { validatedRequest } = require(\"../utils/middleware/validatedRequest\");\n const { Telemetry } = require(\"../models/telemetry\");\n const {\n@@ -18,12 +21,6 @@ const {\n const { validWorkspaceSlug } = require(\"../utils/middleware/validWorkspace\");\n const { convertToChatHistory } = require(\"../utils/helpers/chat/responses\");\n const { CollectorApi } = require(\"../utils/collectorApi\");\n-const { handleUploads } = setupMulter();\n-const { setupPfpUploads } = require(\"../utils/files/multer\");\n-const { normalizePath } = require(\"../utils/files\");\n-const { handlePfpUploads } = setupPfpUploads();\n-const path = require(\"path\");\n-const fs = require(\"fs\");\n const {\n   determineWorkspacePfpFilepath,\n   fetchPfp,\n@@ -101,8 +98,11 @@ function workspaceEndpoints(app) {\n \n   app.post(\n     \"/workspace/:slug/upload\",\n-    [validatedRequest, flexUserRoleValid([ROLES.admin, ROLES.manager])],\n-    handleUploads.single(\"file\"),\n+    [\n+      validatedRequest,\n+      flexUserRoleValid([ROLES.admin, ROLES.manager]),\n+      handleFileUpload,\n+    ],\n     async function (request, response) {\n       const Collector = new CollectorApi();\n       const { originalname } = request.file;\n@@ -478,8 +478,11 @@ function workspaceEndpoints(app) {\n \n   app.post(\n     \"/workspace/:slug/upload-pfp\",\n-    [validatedRequest, flexUserRoleValid([ROLES.admin, ROLES.manager])],\n-    handlePfpUploads.single(\"file\"),\n+    [\n+      validatedRequest,\n+      flexUserRoleValid([ROLES.admin, ROLES.manager]),\n+      handlePfpUpload,\n+    ],\n     async function (request, response) {\n       try {\n         const { slug } = request.params;"
        },
        {
          "filename": "server/index.js",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -25,6 +25,7 @@ const { workspaceThreadEndpoints } = require(\"./endpoints/workspaceThreads\");\n const {\n   preloadOllamaService,\n } = require(\"./utils/AiProviders/anythingLLM/utils/preload\");\n+const { CommunicationKey } = require(\"./utils/comKey\");\n const app = express();\n const apiRouter = express.Router();\n const FILE_LIMIT = \"3GB\";\n@@ -62,6 +63,7 @@ app\n   .listen(process.env.SERVER_PORT || 3001, async () => {\n     await setupTelemetry();\n     await preloadOllamaService();\n+    new CommunicationKey(true);\n     console.log(\n       `[${\n         process.env.NODE_ENV || \"development\""
        },
        {
          "filename": "server/models/invite.js",
          "status": "modified",
          "additions": 24,
          "deletions": 2,
          "patch": "@@ -1,3 +1,4 @@\n+const { safeJsonParse } = require(\"../utils/http\");\n const prisma = require(\"../utils/prisma\");\n \n const Invite = {\n@@ -6,12 +7,13 @@ const Invite = {\n     return uuidAPIKey.create().apiKey;\n   },\n \n-  create: async function (createdByUserId = 0) {\n+  create: async function ({ createdByUserId = 0, workspaceIds = [] }) {\n     try {\n       const invite = await prisma.invites.create({\n         data: {\n           code: this.makeCode(),\n           createdBy: createdByUserId,\n+          workspaceIds: JSON.stringify(workspaceIds),\n         },\n       });\n       return { invite, error: null };\n@@ -23,7 +25,7 @@ const Invite = {\n \n   deactivate: async function (inviteId = null) {\n     try {\n-      const invite = await prisma.invites.update({\n+      await prisma.invites.update({\n         where: { id: Number(inviteId) },\n         data: { status: \"disabled\" },\n       });\n@@ -40,6 +42,26 @@ const Invite = {\n         where: { id: Number(inviteId) },\n         data: { status: \"claimed\", claimedBy: user.id },\n       });\n+\n+      try {\n+        if (!!invite?.workspaceIds) {\n+          const { Workspace } = require(\"./workspace\");\n+          const { WorkspaceUser } = require(\"./workspaceUsers\");\n+          const workspaceIds = (await Workspace.where({})).map(\n+            (workspace) => workspace.id\n+          );\n+          const ids = safeJsonParse(invite.workspaceIds)\n+            .map((id) => Number(id))\n+            .filter((id) => workspaceIds.includes(id));\n+          if (ids.length !== 0) await WorkspaceUser.createMany(user.id, ids);\n+        }\n+      } catch (e) {\n+        console.error(\n+          \"Could not add user to workspaces automatically\",\n+          e.message\n+        );\n+      }\n+\n       return { success: true, error: null };\n     } catch (error) {\n       console.error(error.message);"
        },
        {
          "filename": "server/models/systemSettings.js",
          "status": "modified",
          "additions": 40,
          "deletions": 19,
          "patch": "@@ -5,10 +5,11 @@ require(\"dotenv\").config({\n     : `${path.join(__dirname, \".env\")}`,\n });\n \n+const { isValidUrl } = require(\"../utils/http\");\n const prisma = require(\"../utils/prisma\");\n const SystemSettings = {\n+  protectedFields: [\"multi_user_mode\"],\n   supportedFields: [\n-    \"multi_user_mode\",\n     \"users_can_delete_workspaces\",\n     \"limit_user_messages\",\n     \"message_limit\",\n@@ -20,8 +21,10 @@ const SystemSettings = {\n   validations: {\n     footer_data: (updates) => {\n       try {\n-        const array = JSON.parse(updates);\n-        return JSON.stringify(array.slice(0, 3)); // max of 3 items in footer.\n+        const array = JSON.parse(updates)\n+          .filter((setting) => isValidUrl(setting.url))\n+          .slice(0, 3); // max of 3 items in footer.\n+        return JSON.stringify(array);\n       } catch (e) {\n         console.error(`Failed to run validation function on footer_data`);\n         return JSON.stringify([]);\n@@ -139,6 +142,7 @@ const SystemSettings = {\n         ? {\n             LMStudioBasePath: process.env.LMSTUDIO_BASE_PATH,\n             LMStudioTokenLimit: process.env.LMSTUDIO_MODEL_TOKEN_LIMIT,\n+            LMStudioModelPref: process.env.LMSTUDIO_MODEL_PREF,\n \n             // For embedding credentials when lmstudio is selected.\n             OpenAiKey: !!process.env.OPEN_AI_KEY,\n@@ -283,26 +287,43 @@ const SystemSettings = {\n     }\n   },\n \n+  // Can take generic keys and will pre-filter invalid keys\n+  // from the set before sending to the explicit update function\n+  // that will then enforce validations as well.\n   updateSettings: async function (updates = {}) {\n+    const validFields = Object.keys(updates).filter((key) =>\n+      this.supportedFields.includes(key)\n+    );\n+\n+    Object.entries(updates).forEach(([key]) => {\n+      if (validFields.includes(key)) return;\n+      delete updates[key];\n+    });\n+\n+    return this._updateSettings(updates);\n+  },\n+\n+  // Explicit update of settings + key validations.\n+  // Only use this method when directly setting a key value\n+  // that takes no user input for the keys being modified.\n+  _updateSettings: async function (updates = {}) {\n     try {\n-      const updatePromises = Object.keys(updates)\n-        .filter((key) => this.supportedFields.includes(key))\n-        .map((key) => {\n-          const validatedValue = this.validations.hasOwnProperty(key)\n-            ? this.validations[key](updates[key])\n-            : updates[key];\n+      const updatePromises = Object.keys(updates).map((key) => {\n+        const validatedValue = this.validations.hasOwnProperty(key)\n+          ? this.validations[key](updates[key])\n+          : updates[key];\n \n-          return prisma.system_settings.upsert({\n-            where: { label: key },\n-            update: {\n-              value: validatedValue === null ? null : String(validatedValue),\n-            },\n-            create: {\n-              label: key,\n-              value: validatedValue === null ? null : String(validatedValue),\n-            },\n-          });\n+        return prisma.system_settings.upsert({\n+          where: { label: key },\n+          update: {\n+            value: validatedValue === null ? null : String(validatedValue),\n+          },\n+          create: {\n+            label: key,\n+            value: validatedValue === null ? null : String(validatedValue),\n+          },\n         });\n+      });\n \n       await Promise.all(updatePromises);\n       return { success: true, error: null };"
        },
        {
          "filename": "server/models/telemetry.js",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -65,7 +65,7 @@ const Telemetry = {\n \n   setUid: async function () {\n     const newId = v4();\n-    await SystemSettings.updateSettings({ [this.label]: newId });\n+    await SystemSettings._updateSettings({ [this.label]: newId });\n     return newId;\n   },\n "
        },
        {
          "filename": "server/models/welcomeMessages.js",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -34,7 +34,7 @@ const WelcomeMessages = {\n       // We create each message individually because prisma\n       // with sqlite does not support createMany()\n       for (const [index, message] of messages.entries()) {\n-        if (!message.response) continue;\n+        if (!message.response && !message.user) continue;\n         await prisma.welcome_messages.create({\n           data: {\n             user: message.user,"
        },
        {
          "filename": "server/models/workspaceThread.js",
          "status": "modified",
          "additions": 8,
          "deletions": 5,
          "patch": "@@ -25,16 +25,19 @@ const WorkspaceThread = {\n   update: async function (prevThread = null, data = {}) {\n     if (!prevThread) throw new Error(\"No thread id provided for update\");\n \n-    const validKeys = Object.keys(data).filter((key) =>\n-      this.writable.includes(key)\n-    );\n-    if (validKeys.length === 0)\n+    const validData = {};\n+    Object.entries(data).forEach(([key, value]) => {\n+      if (!this.writable.includes(key)) return;\n+      validData[key] = value;\n+    });\n+\n+    if (Object.keys(validData).length === 0)\n       return { thread: prevThread, message: \"No valid fields to update!\" };\n \n     try {\n       const thread = await prisma.workspace_threads.update({\n         where: { id: prevThread.id },\n-        data,\n+        data: validData,\n       });\n       return { thread, message: null };\n     } catch (error) {"
        },
        {
          "filename": "server/prisma/migrations/20240326231053_init/migration.sql",
          "status": "added",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -0,0 +1,2 @@\n+-- AlterTable\n+ALTER TABLE \"invites\" ADD COLUMN \"workspaceIds\" TEXT;"
        },
        {
          "filename": "server/prisma/schema.prisma",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -41,6 +41,7 @@ model invites {\n   code          String   @unique\n   status        String   @default(\"pending\")\n   claimedBy     Int?\n+  workspaceIds  String?\n   createdAt     DateTime @default(now())\n   createdBy     Int\n   lastUpdatedAt DateTime @default(now())\n@@ -100,7 +101,7 @@ model workspaces {\n   chatModel                    String?\n   topN                         Int?                           @default(4)\n   chatMode                     String?                        @default(\"chat\")\n-  pfpFilename     String?\n+  pfpFilename                  String?\n   workspace_users              workspace_users[]\n   documents                    workspace_documents[]\n   workspace_suggested_messages workspace_suggested_messages[]"
        },
        {
          "filename": "server/swagger/openapi.json",
          "status": "modified",
          "additions": 16,
          "deletions": 0,
          "patch": "@@ -489,6 +489,22 @@\n           \"500\": {\n             \"description\": \"Internal Server Error\"\n           }\n+        },\n+        \"requestBody\": {\n+          \"description\": \"Request body for creation parameters of the invitation\",\n+          \"required\": false,\n+          \"type\": \"object\",\n+          \"content\": {\n+            \"application/json\": {\n+              \"example\": {\n+                \"workspaceIds\": [\n+                  1,\n+                  2,\n+                  45\n+                ]\n+              }\n+            }\n+          }\n         }\n       }\n     },"
        },
        {
          "filename": "server/utils/AiProviders/gemini/index.js",
          "status": "modified",
          "additions": 32,
          "deletions": 2,
          "patch": "@@ -87,7 +87,7 @@ class GeminiLLM {\n   formatMessages(messages = []) {\n     // Gemini roles are either user || model.\n     // and all \"content\" is relabeled to \"parts\"\n-    return messages\n+    const allMessages = messages\n       .map((message) => {\n         if (message.role === \"system\")\n           return { role: \"user\", parts: message.content };\n@@ -98,6 +98,16 @@ class GeminiLLM {\n         return null;\n       })\n       .filter((msg) => !!msg);\n+\n+    // Specifically, Google cannot have the last sent message be from a user with no assistant reply\n+    // otherwise it will crash. So if the last item is from the user, it was not completed so pop it off\n+    // the history.\n+    if (\n+      allMessages.length > 0 &&\n+      allMessages[allMessages.length - 1].role === \"user\"\n+    )\n+      allMessages.pop();\n+    return allMessages;\n   }\n \n   async sendChat(chatHistory = [], prompt, workspace = {}, rawHistory = []) {\n@@ -210,7 +220,27 @@ class GeminiLLM {\n       response.on(\"close\", handleAbort);\n \n       for await (const chunk of stream) {\n-        fullText += chunk.text();\n+        let chunkText;\n+        try {\n+          // Due to content sensitivity we cannot always get the function .text();\n+          // https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes#gemini-TASK-samples-nodejs\n+          // and it is not possible to unblock or disable this safety protocol without being allowlisted by Google.\n+          chunkText = chunk.text();\n+        } catch (e) {\n+          chunkText = e.message;\n+          writeResponseChunk(response, {\n+            uuid,\n+            sources: [],\n+            type: \"abort\",\n+            textResponse: null,\n+            close: true,\n+            error: e.message,\n+          });\n+          resolve(e.message);\n+          return;\n+        }\n+\n+        fullText += chunkText;\n         writeResponseChunk(response, {\n           uuid,\n           sources: [],"
        },
        {
          "filename": "server/utils/AiProviders/lmStudio/index.js",
          "status": "modified",
          "additions": 8,
          "deletions": 3,
          "patch": "@@ -13,9 +13,14 @@ class LMStudioLLM {\n       basePath: process.env.LMSTUDIO_BASE_PATH?.replace(/\\/+$/, \"\"), // here is the URL to your LMStudio instance\n     });\n     this.lmstudio = new OpenAIApi(config);\n-    // When using LMStudios inference server - the model param is not required so\n-    // we can stub it here. LMStudio can only run one model at a time.\n-    this.model = \"model-placeholder\";\n+\n+    // Prior to LMStudio 0.2.17 the `model` param was not required and you could pass anything\n+    // into that field and it would work. On 0.2.17 LMStudio introduced multi-model chat\n+    // which now has a bug that reports the server model id as \"Loaded from Chat UI\"\n+    // and any other value will crash inferencing. So until this is patched we will\n+    // try to fetch the `/models` and have the user set it, or just fallback to \"Loaded from Chat UI\"\n+    // which will not impact users with <v0.2.17 and should work as well once the bug is fixed.\n+    this.model = process.env.LMSTUDIO_MODEL_PREF || \"Loaded from Chat UI\";\n     this.limits = {\n       history: this.promptWindowLimit() * 0.15,\n       system: this.promptWindowLimit() * 0.15,"
        },
        {
          "filename": "server/utils/boot/index.js",
          "status": "added",
          "additions": 66,
          "deletions": 0,
          "patch": "@@ -0,0 +1,66 @@\n+const { Telemetry } = require(\"../../models/telemetry\");\n+const { CommunicationKey } = require(\"../comKey\");\n+const setupTelemetry = require(\"../telemetry\");\n+\n+function bootSSL(app, port = 3001) {\n+  try {\n+    console.log(\n+      `\\x1b[33m[SSL BOOT ENABLED]\\x1b[0m Loading the certificate and key for HTTPS mode...`\n+    );\n+    const fs = require(\"fs\");\n+    const https = require(\"https\");\n+    const privateKey = fs.readFileSync(process.env.HTTPS_KEY_PATH);\n+    const certificate = fs.readFileSync(process.env.HTTPS_CERT_PATH);\n+    const credentials = { key: privateKey, cert: certificate };\n+\n+    https\n+      .createServer(credentials, app)\n+      .listen(port, async () => {\n+        await setupTelemetry();\n+        new CommunicationKey(true);\n+        console.log(`Primary server in HTTPS mode listening on port ${port}`);\n+      })\n+      .on(\"error\", catchSigTerms);\n+    return app;\n+  } catch (e) {\n+    console.error(\n+      `\\x1b[31m[SSL BOOT FAILED]\\x1b[0m ${e.message} - falling back to HTTP boot.`,\n+      {\n+        ENABLE_HTTPS: process.env.ENABLE_HTTPS,\n+        HTTPS_KEY_PATH: process.env.HTTPS_KEY_PATH,\n+        HTTPS_CERT_PATH: process.env.HTTPS_CERT_PATH,\n+        stacktrace: e.stack,\n+      }\n+    );\n+    return bootHTTP(app, port);\n+  }\n+}\n+\n+function bootHTTP(app, port = 3001) {\n+  if (!app) throw new Error('No \"app\" defined - crashing!');\n+\n+  app\n+    .listen(port, async () => {\n+      await setupTelemetry();\n+      new CommunicationKey(true);\n+      console.log(`Primary server in HTTP mode listening on port ${port}`);\n+    })\n+    .on(\"error\", catchSigTerms);\n+  return app;\n+}\n+\n+function catchSigTerms() {\n+  process.once(\"SIGUSR2\", function () {\n+    Telemetry.flush();\n+    process.kill(process.pid, \"SIGUSR2\");\n+  });\n+  process.on(\"SIGINT\", function () {\n+    Telemetry.flush();\n+    process.kill(process.pid, \"SIGINT\");\n+  });\n+}\n+\n+module.exports = {\n+  bootHTTP,\n+  bootSSL,\n+};"
        },
        {
          "filename": "server/utils/collectorApi/index.js",
          "status": "modified",
          "additions": 17,
          "deletions": 6,
          "patch": "@@ -5,6 +5,8 @@\n \n class CollectorApi {\n   constructor() {\n+    const { CommunicationKey } = require(\"../comKey\");\n+    this.comkey = new CommunicationKey();\n     this.endpoint = `http://0.0.0.0:${process.env.COLLECTOR_PORT || 8888}`;\n   }\n \n@@ -40,15 +42,19 @@ class CollectorApi {\n \n   async processDocument(filename = \"\") {\n     if (!filename) return false;\n+\n+    const data = JSON.stringify({\n+      filename,\n+      options: this.#attachOptions(),\n+    });\n+\n     return await fetch(`${this.endpoint}/process`, {\n       method: \"POST\",\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(data),\n       },\n-      body: JSON.stringify({\n-        filename,\n-        options: this.#attachOptions(),\n-      }),\n+      body: data,\n     })\n       .then((res) => {\n         if (!res.ok) throw new Error(\"Response could not be completed\");\n@@ -64,12 +70,14 @@ class CollectorApi {\n   async processLink(link = \"\") {\n     if (!link) return false;\n \n+    const data = JSON.stringify({ link });\n     return await fetch(`${this.endpoint}/process-link`, {\n       method: \"POST\",\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(data),\n       },\n-      body: JSON.stringify({ link }),\n+      body: data,\n     })\n       .then((res) => {\n         if (!res.ok) throw new Error(\"Response could not be completed\");\n@@ -83,12 +91,14 @@ class CollectorApi {\n   }\n \n   async processRawText(textContent = \"\", metadata = {}) {\n+    const data = JSON.stringify({ textContent, metadata });\n     return await fetch(`${this.endpoint}/process-raw-text`, {\n       method: \"POST\",\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(data),\n       },\n-      body: JSON.stringify({ textContent, metadata }),\n+      body: data,\n     })\n       .then((res) => {\n         if (!res.ok) throw new Error(\"Response could not be completed\");\n@@ -110,6 +120,7 @@ class CollectorApi {\n       body, // Stringified JSON!\n       headers: {\n         \"Content-Type\": \"application/json\",\n+        \"X-Integrity\": this.comkey.sign(body),\n       },\n     })\n       .then((res) => {"
        },
        {
          "filename": "server/utils/comKey/index.js",
          "status": "added",
          "additions": 75,
          "deletions": 0,
          "patch": "@@ -0,0 +1,75 @@\n+const crypto = require(\"crypto\");\n+const fs = require(\"fs\");\n+const path = require(\"path\");\n+const keyPath =\n+  process.env.NODE_ENV === \"development\"\n+    ? path.resolve(__dirname, `../../storage/comkey`)\n+    : path.resolve(process.env.STORAGE_DIR, `comkey`);\n+\n+// What does this class do?\n+// This class generates a hashed version of some text (typically a JSON payload) using a rolling RSA key\n+// that can then be appended as a header value to do integrity checking on a payload. Given the\n+// nature of this class and that keys are rolled constantly, this protects the request\n+// integrity of requests sent to the collector as only the server can sign these requests.\n+// This keeps accidental misconfigurations of AnythingLLM that leaving port 8888 open from\n+// being abused or SSRF'd by users scraping malicious sites who have a loopback embedded in a <script>, for example.\n+// Since each request to the collector must be signed to be valid, unsigned requests directly to the collector\n+// will be dropped and must go through the /server endpoint directly.\n+class CommunicationKey {\n+  #privKeyName = \"ipc-priv.pem\";\n+  #pubKeyName = \"ipc-pub.pem\";\n+  #storageLoc = keyPath;\n+\n+  // Init the class and determine if keys should be rolled.\n+  // This typically occurs on boot up so key is fresh each boot.\n+  constructor(generate = false) {\n+    if (generate) this.#generate();\n+  }\n+\n+  log(text, ...args) {\n+    console.log(`\\x1b[36m[CommunicationKey]\\x1b[0m ${text}`, ...args);\n+  }\n+\n+  #readPrivateKey() {\n+    return fs.readFileSync(path.resolve(this.#storageLoc, this.#privKeyName));\n+  }\n+\n+  #generate() {\n+    const keyPair = crypto.generateKeyPairSync(\"rsa\", {\n+      modulusLength: 2048,\n+      publicKeyEncoding: {\n+        type: \"pkcs1\",\n+        format: \"pem\",\n+      },\n+      privateKeyEncoding: {\n+        type: \"pkcs1\",\n+        format: \"pem\",\n+      },\n+    });\n+\n+    if (!fs.existsSync(this.#storageLoc))\n+      fs.mkdirSync(this.#storageLoc, { recursive: true });\n+    fs.writeFileSync(\n+      `${path.resolve(this.#storageLoc, this.#privKeyName)}`,\n+      keyPair.privateKey\n+    );\n+    fs.writeFileSync(\n+      `${path.resolve(this.#storageLoc, this.#pubKeyName)}`,\n+      keyPair.publicKey\n+    );\n+    this.log(\n+      \"RSA key pair generated for signed payloads within AnythingLLM services.\"\n+    );\n+  }\n+\n+  // This instance of ComKey on server is intended for generation of Priv/Pub key for signing and decoding.\n+  // this resource is shared with /collector/ via a class of the same name in /utils which does decoding/verification only\n+  // while this server class only does signing with the private key.\n+  sign(textData = \"\") {\n+    return crypto\n+      .sign(\"RSA-SHA256\", Buffer.from(textData), this.#readPrivateKey())\n+      .toString(\"hex\");\n+  }\n+}\n+\n+module.exports = { CommunicationKey };"
        },
        {
          "filename": "server/utils/files/logo.js",
          "status": "modified",
          "additions": 16,
          "deletions": 7,
          "patch": "@@ -3,6 +3,7 @@ const fs = require(\"fs\");\n const { getType } = require(\"mime\");\n const { v4 } = require(\"uuid\");\n const { SystemSettings } = require(\"../../models/systemSettings\");\n+const { normalizePath } = require(\".\");\n const LOGO_FILENAME = \"anything-llm.png\";\n \n function validFilename(newFilename = \"\") {\n@@ -21,7 +22,7 @@ async function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {\n   const defaultFilepath = path.join(basePath, defaultFilename);\n \n   if (currentLogoFilename && validFilename(currentLogoFilename)) {\n-    customLogoPath = path.join(basePath, currentLogoFilename);\n+    customLogoPath = path.join(basePath, normalizePath(currentLogoFilename));\n     return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;\n   }\n \n@@ -52,11 +53,19 @@ async function renameLogoFile(originalFilename = null) {\n   const extname = path.extname(originalFilename) || \".png\";\n   const newFilename = `${v4()}${extname}`;\n   const originalFilepath = process.env.STORAGE_DIR\n-    ? path.join(process.env.STORAGE_DIR, \"assets\", originalFilename)\n-    : path.join(__dirname, `../../storage/assets/${originalFilename}`);\n+    ? path.join(\n+        process.env.STORAGE_DIR,\n+        \"assets\",\n+        normalizePath(originalFilename)\n+      )\n+    : path.join(\n+        __dirname,\n+        `../../storage/assets`,\n+        normalizePath(originalFilename)\n+      );\n   const outputFilepath = process.env.STORAGE_DIR\n-    ? path.join(process.env.STORAGE_DIR, \"assets\", newFilename)\n-    : path.join(__dirname, `../../storage/assets/${newFilename}`);\n+    ? path.join(process.env.STORAGE_DIR, \"assets\", normalizePath(newFilename))\n+    : path.join(__dirname, `../../storage/assets`, normalizePath(newFilename));\n \n   fs.renameSync(originalFilepath, outputFilepath);\n   return newFilename;\n@@ -65,8 +74,8 @@ async function renameLogoFile(originalFilename = null) {\n async function removeCustomLogo(logoFilename = LOGO_FILENAME) {\n   if (!logoFilename || !validFilename(logoFilename)) return false;\n   const logoPath = process.env.STORAGE_DIR\n-    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)\n-    : path.join(__dirname, `../../storage/assets/${logoFilename}`);\n+    ? path.join(process.env.STORAGE_DIR, `assets`, normalizePath(logoFilename))\n+    : path.join(__dirname, `../../storage/assets`, normalizePath(logoFilename));\n   if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);\n   return true;\n }"
        },
        {
          "filename": "server/utils/files/multer.js",
          "status": "modified",
          "additions": 100,
          "deletions": 57,
          "patch": "@@ -2,71 +2,114 @@ const multer = require(\"multer\");\n const path = require(\"path\");\n const fs = require(\"fs\");\n \n-function setupMulter() {\n-  // Handle File uploads for auto-uploading.\n-  const storage = multer.diskStorage({\n-    destination: function (_, __, cb) {\n-      const uploadOutput =\n-        process.env.NODE_ENV === \"development\"\n-          ? path.resolve(__dirname, `../../../collector/hotdir`)\n-          : path.resolve(process.env.STORAGE_DIR, `hotdir`);\n-      cb(null, uploadOutput);\n-    },\n-    filename: function (_, file, cb) {\n-      file.originalname = Buffer.from(file.originalname, \"latin1\").toString(\n-        \"utf8\"\n-      );\n-      cb(null, file.originalname);\n-    },\n-  });\n+// Handle File uploads for auto-uploading.\n+const fileUploadStorage = multer.diskStorage({\n+  destination: function (_, __, cb) {\n+    const uploadOutput =\n+      process.env.NODE_ENV === \"development\"\n+        ? path.resolve(__dirname, `../../../collector/hotdir`)\n+        : path.resolve(process.env.STORAGE_DIR, `../../collector/hotdir`);\n+    cb(null, uploadOutput);\n+  },\n+  filename: function (_, file, cb) {\n+    file.originalname = Buffer.from(file.originalname, \"latin1\").toString(\n+      \"utf8\"\n+    );\n+    cb(null, file.originalname);\n+  },\n+});\n \n-  return { handleUploads: multer({ storage }) };\n-}\n+// Asset storage for logos\n+const assetUploadStorage = multer.diskStorage({\n+  destination: function (_, __, cb) {\n+    const uploadOutput =\n+      process.env.NODE_ENV === \"development\"\n+        ? path.resolve(__dirname, `../../storage/assets`)\n+        : path.resolve(process.env.STORAGE_DIR, \"assets\");\n+    fs.mkdirSync(uploadOutput, { recursive: true });\n+    return cb(null, uploadOutput);\n+  },\n+  filename: function (_, file, cb) {\n+    file.originalname = Buffer.from(file.originalname, \"latin1\").toString(\n+      \"utf8\"\n+    );\n+    cb(null, file.originalname);\n+  },\n+});\n \n-function setupLogoUploads() {\n-  // Handle Logo uploads.\n-  const storage = multer.diskStorage({\n-    destination: function (_, __, cb) {\n-      const uploadOutput =\n-        process.env.NODE_ENV === \"development\"\n-          ? path.resolve(__dirname, `../../storage/assets`)\n-          : path.resolve(process.env.STORAGE_DIR, \"assets\");\n-      fs.mkdirSync(uploadOutput, { recursive: true });\n-      return cb(null, uploadOutput);\n-    },\n-    filename: function (_, file, cb) {\n-      file.originalname = Buffer.from(file.originalname, \"latin1\").toString(\n-        \"utf8\"\n-      );\n-      cb(null, file.originalname);\n-    },\n-  });\n+// Asset sub-storage manager for pfp icons.\n+const pfpUploadStorage = multer.diskStorage({\n+  destination: function (_, __, cb) {\n+    const uploadOutput =\n+      process.env.NODE_ENV === \"development\"\n+        ? path.resolve(__dirname, `../../storage/assets/pfp`)\n+        : path.resolve(process.env.STORAGE_DIR, \"assets/pfp\");\n+    fs.mkdirSync(uploadOutput, { recursive: true });\n+    return cb(null, uploadOutput);\n+  },\n+  filename: function (req, file, cb) {\n+    const randomFileName = `${v4()}${path.extname(file.originalname)}`;\n+    req.randomFileName = randomFileName;\n+    cb(null, randomFileName);\n+  },\n+});\n \n-  return { handleLogoUploads: multer({ storage }) };\n+// Handle Generic file upload as documents\n+function handleFileUpload(request, response, next) {\n+  const upload = multer({ storage: fileUploadStorage }).single(\"file\");\n+  upload(request, response, function (err) {\n+    if (err) {\n+      response\n+        .status(500)\n+        .json({\n+          success: false,\n+          error: `Invalid file upload. ${err.message}`,\n+        })\n+        .end();\n+      return;\n+    }\n+    next();\n+  });\n }\n \n-function setupPfpUploads() {\n-  const storage = multer.diskStorage({\n-    destination: function (_, __, cb) {\n-      const uploadOutput =\n-        process.env.NODE_ENV === \"development\"\n-          ? path.resolve(__dirname, `../../storage/assets/pfp`)\n-          : path.resolve(process.env.STORAGE_DIR, \"assets/pfp\");\n-      fs.mkdirSync(uploadOutput, { recursive: true });\n-      return cb(null, uploadOutput);\n-    },\n-    filename: function (req, file, cb) {\n-      const randomFileName = `${v4()}${path.extname(file.originalname)}`;\n-      req.randomFileName = randomFileName;\n-      cb(null, randomFileName);\n-    },\n+// Handle logo asset uploads\n+function handleAssetUpload(request, response, next) {\n+  const upload = multer({ storage: assetUploadStorage }).single(\"logo\");\n+  upload(request, response, function (err) {\n+    if (err) {\n+      response\n+        .status(500)\n+        .json({\n+          success: false,\n+          error: `Invalid file upload. ${err.message}`,\n+        })\n+        .end();\n+      return;\n+    }\n+    next();\n   });\n+}\n \n-  return { handlePfpUploads: multer({ storage }) };\n+// Handle PFP file upload as logos\n+function handlePfpUpload(request, response, next) {\n+  const upload = multer({ storage: pfpUploadStorage }).single(\"file\");\n+  upload(request, response, function (err) {\n+    if (err) {\n+      response\n+        .status(500)\n+        .json({\n+          success: false,\n+          error: `Invalid file upload. ${err.message}`,\n+        })\n+        .end();\n+      return;\n+    }\n+    next();\n+  });\n }\n \n module.exports = {\n-  setupMulter,\n-  setupLogoUploads,\n-  setupPfpUploads,\n+  handleFileUpload,\n+  handleAssetUpload,\n+  handlePfpUpload,\n };"
        },
        {
          "filename": "server/utils/helpers/customModels.js",
          "status": "modified",
          "additions": 25,
          "deletions": 0,
          "patch": "@@ -11,6 +11,7 @@ const SUPPORT_CUSTOM_MODELS = [\n   \"perplexity\",\n   \"openrouter\",\n   \"anythingllm_ollama\",\n+  \"lmstudio\",\n ];\n \n async function getCustomModels(provider = \"\", apiKey = null, basePath = null) {\n@@ -36,6 +37,8 @@ async function getCustomModels(provider = \"\", apiKey = null, basePath = null) {\n       return await getOpenRouterModels();\n     case \"anythingllm_ollama\":\n       return await getAnythingOllamaModels();\n+    case \"lmstudio\":\n+      return await getLMStudioModels(basePath);\n     default:\n       return { models: [], error: \"Invalid provider for custom models\" };\n   }\n@@ -84,6 +87,28 @@ async function localAIModels(basePath = null, apiKey = null) {\n   return { models, error: null };\n }\n \n+async function getLMStudioModels(basePath = null) {\n+  try {\n+    const { Configuration, OpenAIApi } = require(\"openai\");\n+    const config = new Configuration({\n+      basePath: basePath || process.env.LMSTUDIO_BASE_PATH,\n+    });\n+    const openai = new OpenAIApi(config);\n+    const models = await openai\n+      .listModels()\n+      .then((res) => res.data.data)\n+      .catch((e) => {\n+        console.error(`LMStudio:listModels`, e.message);\n+        return [];\n+      });\n+\n+    return { models, error: null };\n+  } catch (e) {\n+    console.error(`LMStudio:getLMStudioModels`, e.message);\n+    return { models: [], error: \"Could not fetch LMStudio Models\" };\n+  }\n+}\n+\n async function ollamaAIModels(basePath = null) {\n   let url;\n   try {"
        },
        {
          "filename": "server/utils/helpers/updateENV.js",
          "status": "modified",
          "additions": 15,
          "deletions": 3,
          "patch": "@@ -59,6 +59,10 @@ const KEY_MAPPING = {\n     envKey: \"LMSTUDIO_BASE_PATH\",\n     checks: [isNotEmpty, validLLMExternalBasePath, validDockerizedUrl],\n   },\n+  LMStudioModelPref: {\n+    envKey: \"LMSTUDIO_MODEL_PREF\",\n+    checks: [],\n+  },\n   LMStudioTokenLimit: {\n     envKey: \"LMSTUDIO_MODEL_TOKEN_LIMIT\",\n     checks: [nonZero],\n@@ -561,6 +565,16 @@ async function dumpENV() {\n     \"DISABLE_TELEMETRY\",\n   ];\n \n+  // Simple sanitization of each value to prevent ENV injection via newline or quote escaping.\n+  function sanitizeValue(value) {\n+    const offendingChars =\n+      /[\\n\\r\\t\\v\\f\\u0085\\u00a0\\u1680\\u180e\\u2000-\\u200a\\u2028\\u2029\\u202f\\u205f\\u3000\"'`#]/;\n+    const firstOffendingCharIndex = value.search(offendingChars);\n+    if (firstOffendingCharIndex === -1) return value;\n+\n+    return value.substring(0, firstOffendingCharIndex);\n+  }\n+\n   for (const key of protectedKeys) {\n     const envValue = process.env?.[key] || null;\n     if (!envValue) continue;\n@@ -569,9 +583,7 @@ async function dumpENV() {\n \n   var envResult = `# Auto-dump ENV from system call on ${new Date().toTimeString()}\\n`;\n   envResult += Object.entries(frozenEnvs)\n-    .map(([key, value]) => {\n-      return `${key}='${value}'`;\n-    })\n+    .map(([key, value]) => `${key}='${sanitizeValue(value)}'`)\n     .join(\"\\n\");\n \n   const envPath = process.env.STORAGE_DIR"
        },
        {
          "filename": "server/utils/http/index.js",
          "status": "modified",
          "additions": 10,
          "deletions": 0,
          "patch": "@@ -69,6 +69,15 @@ function safeJsonParse(jsonString, fallback = null) {\n   return fallback;\n }\n \n+function isValidUrl(urlString = \"\") {\n+  try {\n+    const url = new URL(urlString);\n+    if (![\"http:\", \"https:\"].includes(url.protocol)) return false;\n+    return true;\n+  } catch (e) {}\n+  return false;\n+}\n+\n module.exports = {\n   reqBody,\n   multiUserMode,\n@@ -78,4 +87,5 @@ module.exports = {\n   userFromSession,\n   parseAuthHeader,\n   safeJsonParse,\n+  isValidUrl,\n };"
        },
        {
          "filename": "server/utils/middleware/validatedRequest.js",
          "status": "modified",
          "additions": 9,
          "deletions": 1,
          "patch": "@@ -38,9 +38,17 @@ async function validatedRequest(request, response, next) {\n \n   const bcrypt = require(\"bcrypt\");\n   const { p } = decodeJWT(token);\n+\n+  if (p === null) {\n+    response.status(401).json({\n+      error: \"Token expired or failed validation.\",\n+    });\n+    return;\n+  }\n+\n   if (!bcrypt.compareSync(p, bcrypt.hashSync(process.env.AUTH_TOKEN, 10))) {\n     response.status(401).json({\n-      error: \"Invalid auth token found.\",\n+      error: \"Invalid auth credentials.\",\n     });\n     return;\n   }"
        }
      ],
      "file_patterns": {
        "security_files": 3,
        "config_files": 5,
        "dependency_files": 0,
        "test_files": 0,
        "unique_directories": 35,
        "max_directory_depth": 8
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "21af81085aeb049750942ac5f3b84775cb461693",
            "date": "2025-01-13T21:12:03Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "665e8e5bfe431ad93bed6736d0b450592617d042",
            "date": "2025-01-09T23:39:56Z",
            "author_login": "shatfield4"
          },
          {
            "sha": "865f7eea296e544b2eb1ab8c1f322208eaf5eb05",
            "date": "2025-01-09T21:32:54Z",
            "author_login": "timothycarambat"
          },
          {
            "sha": "be886f7d61296a30d5b8a095ca8329f58a0c5a0a",
            "date": "2025-01-09T01:21:30Z",
            "author_login": "root-reindeer-flotilla"
          },
          {
            "sha": "487db896c1ce1442e02f7098ad6974ee60b76073",
            "date": "2025-01-07T23:53:34Z",
            "author_login": "timothycarambat"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 9.6,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H",
    "cwe_id": "CWE-79",
    "description": "A Cross-Site Scripting (XSS) vulnerability exists in mintplex-labs/anything-llm, affecting both the desktop application version 1.2.0 and the latest version of the web application. The vulnerability arises from the application's feature to fetch and embed content from websites into workspaces, which can be exploited to execute arbitrary JavaScript code. In the desktop application, this flaw can be escalated to Remote Code Execution (RCE) due to insecure application settings, specifically the enabling of 'nodeIntegration' and the disabling of 'contextIsolation' in Electron's webPreferences. The issue has been addressed in version 1.4.2 of the desktop application.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-06-06T19:16:00.817",
    "last_modified": "2024-11-21T09:29:03.133",
    "fix_date": "2024-04-01T21:54:03Z"
  },
  "references": [
    {
      "url": "https://github.com/mintplex-labs/anything-llm/commit/fa27103d032c58904c49b92ee13fabc19a20a5ce",
      "source": "security@huntr.dev",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.com/bounties/af288bd3-8824-4216-a294-ae9fb444e5db",
      "source": "security@huntr.dev",
      "tags": [
        "Exploit",
        "Third Party Advisory"
      ]
    },
    {
      "url": "https://github.com/mintplex-labs/anything-llm/commit/fa27103d032c58904c49b92ee13fabc19a20a5ce",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.com/bounties/af288bd3-8824-4216-a294-ae9fb444e5db",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": [
        "Exploit",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:08:26.349661",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "anything-llm",
    "owner": "mintplex-labs",
    "created_at": "2023-06-04T02:29:14Z",
    "updated_at": "2025-01-14T13:49:57Z",
    "pushed_at": "2025-01-13T21:12:06Z",
    "size": 42916,
    "stars": 30237,
    "forks": 3030,
    "open_issues": 206,
    "watchers": 30237,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "JavaScript": 3056909,
      "CSS": 73785,
      "Dockerfile": 9030,
      "HTML": 3904,
      "Shell": 1382,
      "HCL": 1211
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "mit"
    },
    "collected_at": "2025-01-14T14:04:33.088245"
  }
}