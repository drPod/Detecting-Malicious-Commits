{
  "cve_id": "CVE-2024-39897",
  "github_data": {
    "repository": "project-zot/zot",
    "fix_commit": "aaee0220e46bdadd12115ac67c19f9d3153eb1df",
    "related_commits": [
      "aaee0220e46bdadd12115ac67c19f9d3153eb1df",
      "aaee0220e46bdadd12115ac67c19f9d3153eb1df"
    ],
    "patch_url": "https://github.com/project-zot/zot/commit/aaee0220e46bdadd12115ac67c19f9d3153eb1df.patch",
    "fix_commit_details": {
      "sha": "aaee0220e46bdadd12115ac67c19f9d3153eb1df",
      "commit_date": "2024-07-08T18:35:44Z",
      "author": {
        "login": "rchincha",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Merge pull request from GHSA-55r9-5mx9-qq7r",
        "length": 772,
        "has_description": true,
        "references_issue": false
      },
      "stats": {
        "total": 502,
        "additions": 492,
        "deletions": 10
      },
      "files": [
        {
          "filename": "pkg/api/controller_test.go",
          "status": "modified",
          "additions": 116,
          "deletions": 0,
          "patch": "@@ -5142,6 +5142,122 @@ func TestGetUsername(t *testing.T) {\n \t})\n }\n \n+func TestAuthorizationMountBlob(t *testing.T) {\n+\tConvey(\"Make a new controller\", t, func() {\n+\t\tport := test.GetFreePort()\n+\t\tbaseURL := test.GetBaseURL(port)\n+\n+\t\tconf := config.New()\n+\t\tconf.HTTP.Port = port\n+\t\t// have two users: one for  user Policy, and another for default policy\n+\t\tusername1, _ := test.GenerateRandomString()\n+\t\tpassword1, _ := test.GenerateRandomString()\n+\t\tusername2, _ := test.GenerateRandomString()\n+\t\tpassword2, _ := test.GenerateRandomString()\n+\t\tusername1 = strings.ToLower(username1)\n+\t\tusername2 = strings.ToLower(username2)\n+\n+\t\tcontent := test.GetCredString(username1, password1) + test.GetCredString(username2, password2)\n+\t\thtpasswdPath := test.MakeHtpasswdFileFromString(content)\n+\t\tdefer os.Remove(htpasswdPath)\n+\n+\t\tconf.HTTP.Auth = &config.AuthConfig{\n+\t\t\tHTPasswd: config.AuthHTPasswd{\n+\t\t\t\tPath: htpasswdPath,\n+\t\t\t},\n+\t\t}\n+\n+\t\tuser1Repo := fmt.Sprintf(\"%s/**\", username1)\n+\t\tuser2Repo := fmt.Sprintf(\"%s/**\", username2)\n+\n+\t\t// config with all policy types, to test that the correct one is applied in each case\n+\t\tconf.HTTP.AccessControl = &config.AccessControlConfig{\n+\t\t\tRepositories: config.Repositories{\n+\t\t\t\tuser1Repo: config.PolicyGroup{\n+\t\t\t\t\tPolicies: []config.Policy{\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tUsers: []string{username1},\n+\t\t\t\t\t\t\tActions: []string{\n+\t\t\t\t\t\t\t\tconstants.ReadPermission,\n+\t\t\t\t\t\t\t\tconstants.CreatePermission,\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t\tuser2Repo: config.PolicyGroup{\n+\t\t\t\t\tPolicies: []config.Policy{\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tUsers: []string{username2},\n+\t\t\t\t\t\t\tActions: []string{\n+\t\t\t\t\t\t\t\tconstants.ReadPermission,\n+\t\t\t\t\t\t\t\tconstants.CreatePermission,\n+\t\t\t\t\t\t\t},\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\n+\t\tdir := t.TempDir()\n+\n+\t\tctlr := api.NewController(conf)\n+\t\tctlr.Config.Storage.RootDirectory = dir\n+\n+\t\tcm := test.NewControllerManager(ctlr)\n+\t\tcm.StartAndWait(port)\n+\t\tdefer cm.StopServer()\n+\n+\t\tuserClient1 := resty.New()\n+\t\tuserClient1.SetBasicAuth(username1, password1)\n+\n+\t\tuserClient2 := resty.New()\n+\t\tuserClient2.SetBasicAuth(username2, password2)\n+\n+\t\timg := CreateImageWith().RandomLayers(1, 2).DefaultConfig().Build()\n+\n+\t\trepoName1 := username1 + \"/\" + \"myrepo\"\n+\t\ttag := \"1.0\"\n+\n+\t\t// upload image with user1 on repoName1\n+\t\terr := UploadImageWithBasicAuth(img, baseURL, repoName1, tag, username1, password1)\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\trepoName2 := username2 + \"/\" + \"myrepo\"\n+\n+\t\tblobDigest := img.Manifest.Layers[0].Digest\n+\n+\t\t/* a HEAD request by user2 on blob digest (found in user1Repo) should return 404\n+\t\tbecause user2 doesn't have permissions to read user1Repo */\n+\t\tresp, err := userClient2.R().Head(baseURL + fmt.Sprintf(\"/v2/%s/blobs/%s\", repoName2, blobDigest))\n+\t\tSo(err, ShouldBeNil)\n+\t\tSo(resp.StatusCode(), ShouldEqual, http.StatusNotFound)\n+\n+\t\tparams := make(map[string]string)\n+\t\tparams[\"mount\"] = blobDigest.String()\n+\n+\t\t// trying to mount a blob which can be found in cache, but user doesn't have permission\n+\t\t// should return 202 instead of 201\n+\t\tresp, err = userClient2.R().SetQueryParams(params).Post(baseURL + \"/v2/\" + repoName2 + \"/blobs/uploads/\")\n+\t\tSo(err, ShouldBeNil)\n+\t\tSo(resp.StatusCode(), ShouldEqual, http.StatusAccepted)\n+\n+\t\t/* a HEAD request by user1 on blob digest (found in user1Repo) should return 200\n+\t\tbecause user1 has permission to read user1Repo */\n+\t\tresp, err = userClient1.R().Head(baseURL + fmt.Sprintf(\"/v2/%s/blobs/%s\", username1+\"/\"+\"mysecondrepo\", blobDigest))\n+\t\tSo(err, ShouldBeNil)\n+\t\tSo(resp.StatusCode(), ShouldEqual, http.StatusOK)\n+\n+\t\t// user2 can upload without dedupe\n+\t\terr = UploadImageWithBasicAuth(img, baseURL, repoName2, tag, username2, password2)\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\t// trying to mount a blob which can be found in cache and user has permission should return 201 instead of 202\n+\t\tresp, err = userClient2.R().SetQueryParams(params).Post(baseURL + \"/v2/\" + repoName2 + \"/blobs/uploads/\")\n+\t\tSo(err, ShouldBeNil)\n+\t\tSo(resp.StatusCode(), ShouldEqual, http.StatusCreated)\n+\t})\n+}\n+\n func TestAuthorizationWithOnlyAnonymousPolicy(t *testing.T) {\n \tConvey(\"Make a new controller\", t, func() {\n \t\tconst TestRepo = \"my-repos/repo\""
        },
        {
          "filename": "pkg/api/routes.go",
          "status": "modified",
          "additions": 74,
          "deletions": 3,
          "patch": "@@ -873,6 +873,37 @@ func (rh *RouteHandler) DeleteManifest(response http.ResponseWriter, request *ht\n \tresponse.WriteHeader(http.StatusAccepted)\n }\n \n+// canMount checks if a user has read permission on cached blobs with this specific digest.\n+// returns true if the user have permission to copy blob from cache.\n+func canMount(userAc *reqCtx.UserAccessControl, imgStore storageTypes.ImageStore, digest godigest.Digest,\n+) (bool, error) {\n+\tcanMount := true\n+\n+\t// authz enabled\n+\tif userAc != nil {\n+\t\tcanMount = false\n+\n+\t\trepos, err := imgStore.GetAllDedupeReposCandidates(digest)\n+\t\tif err != nil {\n+\t\t\t// first write\n+\t\t\treturn false, err\n+\t\t}\n+\n+\t\tif len(repos) == 0 {\n+\t\t\tcanMount = false\n+\t\t}\n+\n+\t\t// check if user can read any repo which contain this blob\n+\t\tfor _, repo := range repos {\n+\t\t\tif userAc.Can(constants.ReadPermission, repo) {\n+\t\t\t\tcanMount = true\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn canMount, nil\n+}\n+\n // CheckBlob godoc\n // @Summary Check image blob/layer\n // @Description Check an image's blob/layer given a digest\n@@ -905,7 +936,31 @@ func (rh *RouteHandler) CheckBlob(response http.ResponseWriter, request *http.Re\n \n \tdigest := godigest.Digest(digestStr)\n \n-\tok, blen, err := imgStore.CheckBlob(name, digest)\n+\tuserAc, err := reqCtx.UserAcFromContext(request.Context())\n+\tif err != nil {\n+\t\tresponse.WriteHeader(http.StatusInternalServerError)\n+\n+\t\treturn\n+\t}\n+\n+\tuserCanMount, err := canMount(userAc, imgStore, digest)\n+\tif err != nil {\n+\t\trh.c.Log.Error().Err(err).Msg(\"unexpected error\")\n+\t}\n+\n+\tvar blen int64\n+\n+\tif userCanMount {\n+\t\tok, blen, err = imgStore.CheckBlob(name, digest)\n+\t} else {\n+\t\tvar lockLatency time.Time\n+\n+\t\timgStore.RLock(&lockLatency)\n+\t\tdefer imgStore.RUnlock(&lockLatency)\n+\n+\t\tok, blen, _, err = imgStore.StatBlob(name, digest)\n+\t}\n+\n \tif err != nil {\n \t\tdetails := zerr.GetDetails(err)\n \t\tif errors.Is(err, zerr.ErrBadBlobDigest) { //nolint:gocritic // errorslint conflicts with gocritic:IfElseChain\n@@ -1191,11 +1246,27 @@ func (rh *RouteHandler) CreateBlobUpload(response http.ResponseWriter, request *\n \t\t}\n \n \t\tmountDigest := godigest.Digest(mountDigests[0])\n+\n+\t\tuserAc, err := reqCtx.UserAcFromContext(request.Context())\n+\t\tif err != nil {\n+\t\t\tresponse.WriteHeader(http.StatusInternalServerError)\n+\n+\t\t\treturn\n+\t\t}\n+\n+\t\tuserCanMount, err := canMount(userAc, imgStore, mountDigest)\n+\t\tif err != nil {\n+\t\t\trh.c.Log.Error().Err(err).Msg(\"unexpected error\")\n+\t\t}\n+\n \t\t// zot does not support cross mounting directly and do a workaround creating using hard link.\n \t\t// check blob looks for actual path (name+mountDigests[0]) first then look for cache and\n \t\t// if found in cache, will do hard link and if fails we will start new upload.\n-\t\t_, _, err := imgStore.CheckBlob(name, mountDigest)\n-\t\tif err != nil {\n+\t\tif userCanMount {\n+\t\t\t_, _, err = imgStore.CheckBlob(name, mountDigest)\n+\t\t}\n+\n+\t\tif err != nil || !userCanMount {\n \t\t\tupload, err := imgStore.NewBlobUpload(name)\n \t\t\tif err != nil {\n \t\t\t\tdetails := zerr.GetDetails(err)"
        },
        {
          "filename": "pkg/storage/cache/boltdb.go",
          "status": "modified",
          "additions": 51,
          "deletions": 0,
          "patch": "@@ -174,6 +174,57 @@ func (d *BoltDBDriver) PutBlob(digest godigest.Digest, path string) error {\n \treturn nil\n }\n \n+func (d *BoltDBDriver) GetAllBlobs(digest godigest.Digest) ([]string, error) {\n+\tvar blobPath strings.Builder\n+\n+\tblobPaths := []string{}\n+\n+\tif err := d.db.View(func(tx *bbolt.Tx) error {\n+\t\troot := tx.Bucket([]byte(constants.BlobsCache))\n+\t\tif root == nil {\n+\t\t\t// this is a serious failure\n+\t\t\terr := zerr.ErrCacheRootBucket\n+\t\t\td.log.Error().Err(err).Msg(\"failed to access root bucket\")\n+\n+\t\t\treturn err\n+\t\t}\n+\n+\t\tbucket := root.Bucket([]byte(digest.String()))\n+\t\tif bucket != nil {\n+\t\t\torigin := bucket.Bucket([]byte(constants.OriginalBucket))\n+\t\t\tblobPath.Write(d.getOne(origin))\n+\t\t\toriginBlob := blobPath.String()\n+\n+\t\t\tblobPaths = append(blobPaths, originBlob)\n+\n+\t\t\tdeduped := bucket.Bucket([]byte(constants.DuplicatesBucket))\n+\t\t\tif deduped != nil {\n+\t\t\t\tcursor := deduped.Cursor()\n+\n+\t\t\t\tfor k, _ := cursor.First(); k != nil; k, _ = cursor.Next() {\n+\t\t\t\t\tvar blobPath strings.Builder\n+\n+\t\t\t\t\tblobPath.Write(k)\n+\n+\t\t\t\t\tduplicateBlob := blobPath.String()\n+\n+\t\t\t\t\tif duplicateBlob != originBlob {\n+\t\t\t\t\t\tblobPaths = append(blobPaths, duplicateBlob)\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\treturn nil\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn zerr.ErrCacheMiss\n+\t}); err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treturn blobPaths, nil\n+}\n+\n func (d *BoltDBDriver) GetBlob(digest godigest.Digest) (string, error) {\n \tvar blobPath strings.Builder\n "
        },
        {
          "filename": "pkg/storage/cache/boltdb_test.go",
          "status": "modified",
          "additions": 43,
          "deletions": 0,
          "patch": "@@ -122,4 +122,47 @@ func TestBoltDBCache(t *testing.T) {\n \t\tSo(err, ShouldNotBeNil)\n \t\tSo(val, ShouldBeEmpty)\n \t})\n+\n+\tConvey(\"Test cache.GetAllBlos()\", t, func() {\n+\t\tdir := t.TempDir()\n+\n+\t\tlog := log.NewLogger(\"debug\", \"\")\n+\t\tSo(log, ShouldNotBeNil)\n+\n+\t\t_, err := storage.Create(\"boltdb\", \"failTypeAssertion\", log)\n+\t\tSo(err, ShouldNotBeNil)\n+\n+\t\tcacheDriver, _ := storage.Create(\"boltdb\", cache.BoltDBDriverParameters{dir, \"cache_test\", false}, log)\n+\t\tSo(cacheDriver, ShouldNotBeNil)\n+\n+\t\terr = cacheDriver.PutBlob(\"digest\", \"first\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\terr = cacheDriver.PutBlob(\"digest\", \"second\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\terr = cacheDriver.PutBlob(\"digest\", \"third\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tblobs, err := cacheDriver.GetAllBlobs(\"digest\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tSo(blobs, ShouldResemble, []string{\"first\", \"second\", \"third\"})\n+\n+\t\terr = cacheDriver.DeleteBlob(\"digest\", \"first\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tblobs, err = cacheDriver.GetAllBlobs(\"digest\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tSo(blobs, ShouldResemble, []string{\"second\", \"third\"})\n+\n+\t\terr = cacheDriver.DeleteBlob(\"digest\", \"third\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tblobs, err = cacheDriver.GetAllBlobs(\"digest\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tSo(blobs, ShouldResemble, []string{\"second\"})\n+\t})\n }"
        },
        {
          "filename": "pkg/storage/cache/cacheinterface.go",
          "status": "modified",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -11,6 +11,8 @@ type Cache interface {\n \t// Retrieves the blob matching provided digest.\n \tGetBlob(digest godigest.Digest) (string, error)\n \n+\tGetAllBlobs(digest godigest.Digest) ([]string, error)\n+\n \t// Uploads blob to cachedb.\n \tPutBlob(digest godigest.Digest, path string) error\n "
        },
        {
          "filename": "pkg/storage/cache/dynamodb.go",
          "status": "modified",
          "additions": 36,
          "deletions": 0,
          "patch": "@@ -141,6 +141,42 @@ func (d *DynamoDBDriver) GetBlob(digest godigest.Digest) (string, error) {\n \treturn out.OriginalBlobPath, nil\n }\n \n+func (d *DynamoDBDriver) GetAllBlobs(digest godigest.Digest) ([]string, error) {\n+\tblobPaths := []string{}\n+\n+\tresp, err := d.client.GetItem(context.TODO(), &dynamodb.GetItemInput{\n+\t\tTableName: aws.String(d.tableName),\n+\t\tKey: map[string]types.AttributeValue{\n+\t\t\t\"Digest\": &types.AttributeValueMemberS{Value: digest.String()},\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\td.log.Error().Err(err).Str(\"tableName\", d.tableName).Msg(\"failed to get blob\")\n+\n+\t\treturn nil, err\n+\t}\n+\n+\tout := Blob{}\n+\n+\tif resp.Item == nil {\n+\t\td.log.Debug().Err(zerr.ErrCacheMiss).Str(\"digest\", string(digest)).Msg(\"failed to find blob in cache\")\n+\n+\t\treturn nil, zerr.ErrCacheMiss\n+\t}\n+\n+\t_ = attributevalue.UnmarshalMap(resp.Item, &out)\n+\n+\tblobPaths = append(blobPaths, out.OriginalBlobPath)\n+\n+\tfor _, item := range out.DuplicateBlobPath {\n+\t\tif item != out.OriginalBlobPath {\n+\t\t\tblobPaths = append(blobPaths, item)\n+\t\t}\n+\t}\n+\n+\treturn blobPaths, nil\n+}\n+\n func (d *DynamoDBDriver) PutBlob(digest godigest.Digest, path string) error {\n \tif path == \"\" {\n \t\td.log.Error().Err(zerr.ErrEmptyValue).Str(\"digest\", digest.String())."
        },
        {
          "filename": "pkg/storage/cache/dynamodb_test.go",
          "status": "modified",
          "additions": 42,
          "deletions": 0,
          "patch": "@@ -144,6 +144,48 @@ func TestDynamoDB(t *testing.T) {\n \t\tSo(err, ShouldNotBeNil)\n \t\tSo(val, ShouldBeEmpty)\n \t})\n+\n+\tConvey(\"Test dynamoDB\", t, func(c C) {\n+\t\tlog := log.NewLogger(\"debug\", \"\")\n+\n+\t\tcacheDriver, err := storage.Create(\"dynamodb\", cache.DynamoDBDriverParameters{\n+\t\t\tEndpoint:  os.Getenv(\"DYNAMODBMOCK_ENDPOINT\"),\n+\t\t\tTableName: \"BlobTable\",\n+\t\t\tRegion:    \"us-east-2\",\n+\t\t}, log)\n+\t\tSo(cacheDriver, ShouldNotBeNil)\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\terr = cacheDriver.PutBlob(\"digest\", \"first\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\terr = cacheDriver.PutBlob(\"digest\", \"second\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\terr = cacheDriver.PutBlob(\"digest\", \"third\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tblobs, err := cacheDriver.GetAllBlobs(\"digest\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tSo(blobs, ShouldResemble, []string{\"first\", \"second\", \"third\"})\n+\n+\t\terr = cacheDriver.DeleteBlob(\"digest\", \"first\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tblobs, err = cacheDriver.GetAllBlobs(\"digest\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tSo(blobs, ShouldResemble, []string{\"second\", \"third\"})\n+\n+\t\terr = cacheDriver.DeleteBlob(\"digest\", \"third\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tblobs, err = cacheDriver.GetAllBlobs(\"digest\")\n+\t\tSo(err, ShouldBeNil)\n+\n+\t\tSo(blobs, ShouldResemble, []string{\"second\"})\n+\t})\n }\n \n func TestDynamoDBError(t *testing.T) {"
        },
        {
          "filename": "pkg/storage/imagestore/imagestore.go",
          "status": "modified",
          "additions": 31,
          "deletions": 0,
          "patch": "@@ -1114,6 +1114,37 @@ func (is *ImageStore) BlobPath(repo string, digest godigest.Digest) string {\n \treturn path.Join(is.rootDir, repo, \"blobs\", digest.Algorithm().String(), digest.Encoded())\n }\n \n+func (is *ImageStore) GetAllDedupeReposCandidates(digest godigest.Digest) ([]string, error) {\n+\tvar lockLatency time.Time\n+\n+\tif err := digest.Validate(); err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tis.RLock(&lockLatency)\n+\tdefer is.RUnlock(&lockLatency)\n+\n+\tblobsPaths, err := is.cache.GetAllBlobs(digest)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trepos := []string{}\n+\n+\tfor _, blobPath := range blobsPaths {\n+\t\t// these can be both full paths or relative paths depending on the cache options\n+\t\tif !is.cache.UsesRelativePaths() && path.IsAbs(blobPath) {\n+\t\t\tblobPath, _ = filepath.Rel(is.rootDir, blobPath)\n+\t\t}\n+\n+\t\tblobsDirIndex := strings.LastIndex(blobPath, \"/blobs/\")\n+\n+\t\trepos = append(repos, blobPath[:blobsDirIndex])\n+\t}\n+\n+\treturn repos, nil\n+}\n+\n /*\n \tCheckBlob verifies a blob and returns true if the blob is correct\n "
        },
        {
          "filename": "pkg/storage/storage_test.go",
          "status": "modified",
          "additions": 70,
          "deletions": 0,
          "patch": "@@ -10,6 +10,7 @@ import (\n \t\"io\"\n \t\"os\"\n \t\"path\"\n+\t\"slices\"\n \t\"strings\"\n \t\"sync\"\n \t\"testing\"\n@@ -132,6 +133,75 @@ func TestStorageNew(t *testing.T) {\n \t})\n }\n \n+func TestGetAllDedupeReposCandidates(t *testing.T) {\n+\tfor _, testcase := range testCases {\n+\t\ttestcase := testcase\n+\t\tt.Run(testcase.testCaseName, func(t *testing.T) {\n+\t\t\tvar imgStore storageTypes.ImageStore\n+\t\t\tif testcase.storageType == storageConstants.S3StorageDriverName {\n+\t\t\t\ttskip.SkipS3(t)\n+\n+\t\t\t\tuuid, err := guuid.NewV4()\n+\t\t\t\tif err != nil {\n+\t\t\t\t\tpanic(err)\n+\t\t\t\t}\n+\n+\t\t\t\ttestDir := path.Join(\"/oci-repo-test\", uuid.String())\n+\t\t\t\ttdir := t.TempDir()\n+\n+\t\t\t\tvar store driver.StorageDriver\n+\t\t\t\tstore, imgStore, _ = createObjectsStore(testDir, tdir)\n+\t\t\t\tdefer cleanupStorage(store, testDir)\n+\t\t\t} else {\n+\t\t\t\tdir := t.TempDir()\n+\n+\t\t\t\tlog := zlog.Logger{Logger: zerolog.New(os.Stdout)}\n+\t\t\t\tmetrics := monitoring.NewMetricsServer(false, log)\n+\t\t\t\tcacheDriver, _ := storage.Create(\"boltdb\", cache.BoltDBDriverParameters{\n+\t\t\t\t\tRootDir:     dir,\n+\t\t\t\t\tName:        \"cache\",\n+\t\t\t\t\tUseRelPaths: true,\n+\t\t\t\t}, log)\n+\n+\t\t\t\tdriver := local.New(true)\n+\n+\t\t\t\timgStore = imagestore.NewImageStore(dir, dir, true, true, log, metrics, nil, driver, cacheDriver)\n+\t\t\t}\n+\n+\t\t\tConvey(\"Push repos with deduped blobs\", t, func(c C) {\n+\t\t\t\trepoNames := []string{\n+\t\t\t\t\t\"first\",\n+\t\t\t\t\t\"second\",\n+\t\t\t\t\t\"repo/a\",\n+\t\t\t\t\t\"repo/a/b/c/d/e/f\",\n+\t\t\t\t\t\"repo/repo-b/blobs\",\n+\t\t\t\t\t\"foo/bar/baz\",\n+\t\t\t\t\t\"blobs/foo/bar/blobs\",\n+\t\t\t\t\t\"blobs\",\n+\t\t\t\t\t\"blobs/foo\",\n+\t\t\t\t}\n+\n+\t\t\t\tstoreController := storage.StoreController{DefaultStore: imgStore}\n+\n+\t\t\t\timage := CreateRandomImage()\n+\n+\t\t\t\tfor _, repoName := range repoNames {\n+\t\t\t\t\terr := WriteImageToFileSystem(image, repoName, tag, storeController)\n+\t\t\t\t\tSo(err, ShouldBeNil)\n+\t\t\t\t}\n+\n+\t\t\t\trandomBlobDigest := image.Manifest.Layers[0].Digest\n+\n+\t\t\t\trepos, err := imgStore.GetAllDedupeReposCandidates(randomBlobDigest)\n+\t\t\t\tSo(err, ShouldBeNil)\n+\t\t\t\tslices.Sort(repoNames)\n+\t\t\t\tslices.Sort(repos)\n+\t\t\t\tSo(repoNames, ShouldResemble, repos)\n+\t\t\t})\n+\t\t})\n+\t}\n+}\n+\n func TestStorageAPIs(t *testing.T) {\n \tfor _, testcase := range testCases {\n \t\ttestcase := testcase"
        },
        {
          "filename": "pkg/storage/types/types.go",
          "status": "modified",
          "additions": 1,
          "deletions": 0,
          "patch": "@@ -63,6 +63,7 @@ type ImageStore interface { //nolint:interfacebloat\n \tGetAllBlobs(repo string) ([]string, error)\n \tPopulateStorageMetrics(interval time.Duration, sch *scheduler.Scheduler)\n \tVerifyBlobDigestValue(repo string, digest godigest.Digest) error\n+\tGetAllDedupeReposCandidates(digest godigest.Digest) ([]string, error)\n }\n \n type Driver interface { //nolint:interfacebloat"
        },
        {
          "filename": "pkg/test/mocks/cache_mock.go",
          "status": "modified",
          "additions": 10,
          "deletions": 0,
          "patch": "@@ -6,6 +6,8 @@ type CacheMock struct {\n \t// Returns the human-readable \"name\" of the driver.\n \tNameFn func() string\n \n+\tGetAllBlobsFn func(digest godigest.Digest) ([]string, error)\n+\n \t// Retrieves the blob matching provided digest.\n \tGetBlobFn func(digest godigest.Digest) (string, error)\n \n@@ -68,3 +70,11 @@ func (cacheMock CacheMock) DeleteBlob(digest godigest.Digest, path string) error\n \n \treturn nil\n }\n+\n+func (cacheMock CacheMock) GetAllBlobs(digest godigest.Digest) ([]string, error) {\n+\tif cacheMock.GetAllBlobsFn != nil {\n+\t\treturn cacheMock.GetAllBlobsFn(digest)\n+\t}\n+\n+\treturn []string{}, nil\n+}"
        },
        {
          "filename": "pkg/test/mocks/image_store_mock.go",
          "status": "modified",
          "additions": 16,
          "deletions": 7,
          "patch": "@@ -50,13 +50,14 @@ type MockedImageStore struct {\n \tRunDedupeBlobsFn     func(interval time.Duration, sch *scheduler.Scheduler)\n \tRunDedupeForDigestFn func(ctx context.Context, digest godigest.Digest, dedupe bool,\n \t\tduplicateBlobs []string) error\n-\tGetNextDigestWithBlobPathsFn func(repos []string, lastDigests []godigest.Digest) (godigest.Digest, []string, error)\n-\tGetAllBlobsFn                func(repo string) ([]string, error)\n-\tCleanupRepoFn                func(repo string, blobs []godigest.Digest, removeRepo bool) (int, error)\n-\tPutIndexContentFn            func(repo string, index ispec.Index) error\n-\tPopulateStorageMetricsFn     func(interval time.Duration, sch *scheduler.Scheduler)\n-\tStatIndexFn                  func(repo string) (bool, int64, time.Time, error)\n-\tVerifyBlobDigestValueFn      func(repo string, digest godigest.Digest) error\n+\tGetNextDigestWithBlobPathsFn  func(repos []string, lastDigests []godigest.Digest) (godigest.Digest, []string, error)\n+\tGetAllBlobsFn                 func(repo string) ([]string, error)\n+\tCleanupRepoFn                 func(repo string, blobs []godigest.Digest, removeRepo bool) (int, error)\n+\tPutIndexContentFn             func(repo string, index ispec.Index) error\n+\tPopulateStorageMetricsFn      func(interval time.Duration, sch *scheduler.Scheduler)\n+\tStatIndexFn                   func(repo string) (bool, int64, time.Time, error)\n+\tVerifyBlobDigestValueFn       func(repo string, digest godigest.Digest) error\n+\tGetAllDedupeReposCandidatesFn func(digest godigest.Digest) ([]string, error)\n }\n \n func (is MockedImageStore) StatIndex(repo string) (bool, int64, time.Time, error) {\n@@ -419,3 +420,11 @@ func (is MockedImageStore) VerifyBlobDigestValue(repo string, digest godigest.Di\n \n \treturn nil\n }\n+\n+func (is MockedImageStore) GetAllDedupeReposCandidates(digest godigest.Digest) ([]string, error) {\n+\tif is.GetAllBlobsFn != nil {\n+\t\treturn is.GetAllDedupeReposCandidatesFn(digest)\n+\t}\n+\n+\treturn []string{}, nil\n+}"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 6,
        "unique_directories": 6,
        "max_directory_depth": 3
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "97fd43e2b0a7964e15f35aed95cd54f879f138bb",
            "date": "2025-01-14T06:36:30Z",
            "author_login": "rchincha"
          },
          {
            "sha": "7f593b8896d25fb0a7302f0823fa0b5379782e85",
            "date": "2025-01-13T09:20:29Z",
            "author_login": "rchincha"
          },
          {
            "sha": "e410f3952c792b20eb63beac051e0082e58384d5",
            "date": "2025-01-04T00:47:33Z",
            "author_login": "rchincha"
          },
          {
            "sha": "ab43515c888e6f7e80f9daa44985e2090771be49",
            "date": "2024-12-26T10:17:34Z",
            "author_login": "rchincha"
          },
          {
            "sha": "6ca9c662603da5d814d8ceea2f491e1c97da13e2",
            "date": "2024-12-24T05:10:23Z",
            "author_login": "rchincha"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 4.3,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N",
    "cwe_id": "CWE-639",
    "description": "zot is an OCI image registry. Prior to 2.1.0, the cache driver `GetBlob()` allows read access to any blob without access control check. If a Zot `accessControl` policy allows users read access to some repositories but restricts read access to other repositories and `dedupe` is enabled (it is enabled by default), then an attacker who knows the name of an image and the digest of a blob (that they do not have read access to), they may maliciously read it via a second repository they do have read access to. \n This attack is possible because [`ImageStore.CheckBlob()` calls `checkCacheBlob()`](https://github.com/project-zot/zot/blob/v2.1.0-rc2/pkg/storage/imagestore/imagestore.go#L1158-L1159) to find the blob a global cache by searching for the digest. If it is found, it is copied to the user requested repository with `copyBlob()`. The attack may be mitigated by configuring \"dedupe\": false in the \"storage\" settings. The vulnerability is fixed in 2.1.0.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-07-09T19:15:12.953",
    "last_modified": "2024-11-21T09:28:31.350",
    "fix_date": "2024-07-08T18:35:44Z"
  },
  "references": [
    {
      "url": "https://github.com/project-zot/zot/commit/aaee0220e46bdadd12115ac67c19f9d3153eb1df",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://github.com/project-zot/zot/security/advisories/GHSA-55r9-5mx9-qq7r",
      "source": "security-advisories@github.com",
      "tags": []
    },
    {
      "url": "https://github.com/project-zot/zot/commit/aaee0220e46bdadd12115ac67c19f9d3153eb1df",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://github.com/project-zot/zot/security/advisories/GHSA-55r9-5mx9-qq7r",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:08:31.458334",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "zot",
    "owner": "project-zot",
    "created_at": "2019-06-21T21:40:58Z",
    "updated_at": "2025-01-14T15:32:42Z",
    "pushed_at": "2025-01-14T06:37:47Z",
    "size": 9676,
    "stars": 1019,
    "forks": 106,
    "open_issues": 119,
    "watchers": 1019,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "main"
    ],
    "languages": {
      "Go": 4034709,
      "Shell": 205368,
      "Makefile": 25380,
      "Dockerfile": 1216,
      "Java": 109
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "apache-2.0"
    },
    "collected_at": "2025-01-14T16:18:36.610316"
  }
}