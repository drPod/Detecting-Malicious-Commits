{
  "cve_id": "CVE-2024-4181",
  "github_data": {
    "repository": "run-llama/llama_index",
    "fix_commit": "d73715eaf0642705583e7897c78b9c8dd2d3a7ba",
    "related_commits": [
      "d73715eaf0642705583e7897c78b9c8dd2d3a7ba",
      "d73715eaf0642705583e7897c78b9c8dd2d3a7ba"
    ],
    "patch_url": null
  },
  "vulnerability_details": {
    "cvss_score": null,
    "cvss_vector": null,
    "cwe_id": "CWE-94",
    "description": "A command injection vulnerability exists in the RunGptLLM class of the llama_index library, version 0.9.47, used by the RunGpt framework from JinaAI to connect to Language Learning Models (LLMs). The vulnerability arises from the improper use of the eval function, allowing a malicious or compromised LLM hosting provider to execute arbitrary commands on the client's machine. This issue was fixed in version 0.10.13. The exploitation of this vulnerability could lead to a hosting provider gaining full control over client machines.",
    "attack_vector": null,
    "attack_complexity": null
  },
  "temporal_data": {
    "published_date": "2024-05-16T09:15:15.553",
    "last_modified": "2024-11-21T09:42:20.630",
    "fix_date": null
  },
  "references": [
    {
      "url": "https://github.com/run-llama/llama_index/commit/d73715eaf0642705583e7897c78b9c8dd2d3a7ba",
      "source": "security@huntr.dev",
      "tags": []
    },
    {
      "url": "https://huntr.com/bounties/1a204520-598a-434e-b13d-0d34f2a5ddc1",
      "source": "security@huntr.dev",
      "tags": []
    },
    {
      "url": "https://github.com/run-llama/llama_index/commit/d73715eaf0642705583e7897c78b9c8dd2d3a7ba",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://huntr.com/bounties/1a204520-598a-434e-b13d-0d34f2a5ddc1",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:08:24.245146",
    "processing_status": "raw"
  }
}