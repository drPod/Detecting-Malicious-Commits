{
  "cve_id": "CVE-2024-49768",
  "github_data": {
    "repository": "Pylons/waitress",
    "fix_commit": "e4359018537af376cf24bd13616d861e2fb76f65",
    "related_commits": [
      "e4359018537af376cf24bd13616d861e2fb76f65"
    ],
    "patch_url": "https://github.com/Pylons/waitress/commit/e4359018537af376cf24bd13616d861e2fb76f65.patch",
    "fix_commit_details": {
      "sha": "e4359018537af376cf24bd13616d861e2fb76f65",
      "commit_date": "2024-10-29T00:05:50Z",
      "author": {
        "login": "digitalresistor",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "Merge commit from fork",
        "length": 91,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 137,
        "additions": 122,
        "deletions": 15
      },
      "files": [
        {
          "filename": "docs/arguments.rst",
          "status": "modified",
          "additions": 14,
          "deletions": 0,
          "patch": "@@ -314,3 +314,17 @@ url_prefix\n     be stripped of the prefix.\n \n     Default: ``''``\n+\n+channel_request_lookahead\n+    Sets the amount of requests we can continue to read from the socket, while\n+    we are processing current requests. The default value won't allow any\n+    lookahead, increase it above ``0`` to enable.\n+\n+    When enabled this inserts a callable ``waitress.client_disconnected`` into\n+    the environment that allows the task to check if the client disconnected\n+    while waiting for the response at strategic points in the execution and to\n+    cancel the operation.\n+\n+    Default: ``0``\n+\n+    .. versionadded:: 2.0.0"
        },
        {
          "filename": "src/waitress/channel.py",
          "status": "modified",
          "additions": 10,
          "deletions": 1,
          "patch": "@@ -140,7 +140,7 @@ def readable(self):\n         # 1. We're not already about to close the connection.\n         # 2. We're not waiting to flush remaining data before closing the\n         #    connection\n-        # 3. There are not too many tasks already queued\n+        # 3. There are not too many tasks already queued (if lookahead is enabled)\n         # 4. There's no data in the output buffer that needs to be sent\n         #    before we potentially create a new task.\n \n@@ -196,6 +196,15 @@ def received(self, data):\n             return False\n \n         with self.requests_lock:\n+            # Don't bother processing anymore data if this connection is about\n+            # to close. This may happen if readable() returned True, on the\n+            # main thread before the service thread set the close_when_flushed\n+            # flag, and we read data but our service thread is attempting to\n+            # shut down the connection due to an error. We want to make sure we\n+            # do this while holding the request_lock so that we can't race\n+            if self.will_close or self.close_when_flushed:\n+                return False\n+\n             while data:\n                 if self.request is None:\n                     self.request = self.parser_class(self.adj)"
        },
        {
          "filename": "tests/test_channel.py",
          "status": "modified",
          "additions": 98,
          "deletions": 14,
          "patch": "@@ -18,7 +18,7 @@ def _makeOneWithMap(self, adj=None):\n         map = {}\n         inst = self._makeOne(sock, \"127.0.0.1\", adj, map=map)\n         inst.outbuf_lock = DummyLock()\n-        return inst, sock, map\n+        return inst, sock.local(), map\n \n     def test_ctor(self):\n         inst, _, map = self._makeOneWithMap()\n@@ -218,7 +218,7 @@ def test_write_soon_nonempty_byte(self):\n         def send(_):\n             return 0\n \n-        sock.send = send\n+        sock.remote.send = send\n \n         wrote = inst.write_soon(b\"a\")\n         self.assertEqual(wrote, 1)\n@@ -236,7 +236,7 @@ def test_write_soon_filewrapper(self):\n         def send(_):\n             return 0\n \n-        sock.send = send\n+        sock.remote.send = send\n \n         outbufs = inst.outbufs\n         wrote = inst.write_soon(wrapper)\n@@ -270,7 +270,7 @@ def test_write_soon_rotates_outbuf_on_overflow(self):\n         def send(_):\n             return 0\n \n-        sock.send = send\n+        sock.remote.send = send\n \n         inst.adj.outbuf_high_watermark = 3\n         inst.current_outbuf_count = 4\n@@ -286,7 +286,7 @@ def test_write_soon_waits_on_backpressure(self):\n         def send(_):\n             return 0\n \n-        sock.send = send\n+        sock.remote.send = send\n \n         inst.adj.outbuf_high_watermark = 3\n         inst.total_outbufs_len = 4\n@@ -315,7 +315,7 @@ def send(_):\n             inst.connected = False\n             raise Exception()\n \n-        sock.send = send\n+        sock.remote.send = send\n \n         inst.adj.outbuf_high_watermark = 3\n         inst.total_outbufs_len = 4\n@@ -345,7 +345,7 @@ def send(_):\n             inst.connected = False\n             raise Exception()\n \n-        sock.send = send\n+        sock.remote.send = send\n \n         wrote = inst.write_soon(b\"xyz\")\n         self.assertEqual(wrote, 3)\n@@ -376,7 +376,7 @@ def test_handle_write_no_notify_after_flush(self):\n         inst.total_outbufs_len = len(inst.outbufs[0])\n         inst.adj.send_bytes = 1\n         inst.adj.outbuf_high_watermark = 2\n-        sock.send = lambda x, do_close=True: False\n+        sock.remote.send = lambda x, do_close=True: False\n         inst.will_close = False\n         inst.last_activity = 0\n         result = inst.handle_write()\n@@ -400,7 +400,7 @@ def test__flush_some_full_outbuf_socket_returns_nonzero(self):\n \n     def test__flush_some_full_outbuf_socket_returns_zero(self):\n         inst, sock, map = self._makeOneWithMap()\n-        sock.send = lambda x: False\n+        sock.remote.send = lambda x: False\n         inst.outbufs[0].append(b\"abc\")\n         inst.total_outbufs_len = sum(len(x) for x in inst.outbufs)\n         result = inst._flush_some()\n@@ -805,11 +805,12 @@ def app_check_disconnect(self, environ, start_response):\n         )\n         return [body]\n \n-    def _make_app_with_lookahead(self):\n+    def _make_app_with_lookahead(self, recv_bytes=8192):\n         \"\"\"\n         Setup a channel with lookahead and store it and the socket in self\n         \"\"\"\n         adj = DummyAdjustments()\n+        adj.recv_bytes = recv_bytes\n         adj.channel_request_lookahead = 5\n         channel, sock, map = self._makeOneWithMap(adj=adj)\n         channel.server.application = self.app_check_disconnect\n@@ -901,13 +902,66 @@ def test_lookahead_continue(self):\n         self.assertEqual(data.split(\"\\r\\n\")[-1], \"finished\")\n         self.assertEqual(self.request_body, b\"x\")\n \n+    def test_lookahead_bad_request_drop_extra_data(self):\n+        \"\"\"\n+        Send two requests, the first one being bad, split on the recv_bytes\n+        limit, then emulate a race that could happen whereby we read data from\n+        the socket while the service thread is cleaning up due to an error\n+        processing the request.\n+        \"\"\"\n+\n+        invalid_request = [\n+            \"GET / HTTP/1.1\",\n+            \"Host: localhost:8080\",\n+            \"Content-length: -1\",\n+            \"\",\n+        ]\n+\n+        invalid_request_len = len(\"\".join([x + \"\\r\\n\" for x in invalid_request]))\n+\n+        second_request = [\n+            \"POST / HTTP/1.1\",\n+            \"Host: localhost:8080\",\n+            \"Content-Length: 1\",\n+            \"\",\n+            \"x\",\n+        ]\n+\n+        full_request = invalid_request + second_request\n+\n+        self._make_app_with_lookahead(recv_bytes=invalid_request_len)\n+        self._send(*full_request)\n+        self.channel.handle_read()\n+        self.assertEqual(len(self.channel.requests), 1)\n+        self.channel.server.tasks[0].service()\n+        self.assertTrue(self.channel.close_when_flushed)\n+        # Read all of the next request\n+        self.channel.handle_read()\n+        self.channel.handle_read()\n+        # Validate that there is no more data to be read\n+        self.assertEqual(self.sock.remote.local_sent, b\"\")\n+        # Validate that we dropped the data from the second read, and did not\n+        # create a new request\n+        self.assertEqual(len(self.channel.requests), 0)\n+        data = self.sock.recv(256).decode(\"ascii\")\n+        self.assertFalse(self.channel.readable())\n+        self.assertTrue(self.channel.writable())\n+\n+        # Handle the write, which will close the socket\n+        self.channel.handle_write()\n+        self.assertTrue(self.sock.closed)\n+\n+        data = self.sock.recv(256)\n+        self.assertEqual(len(data), 0)\n+\n \n class DummySock:\n     blocking = False\n     closed = False\n \n     def __init__(self):\n-        self.sent = b\"\"\n+        self.local_sent = b\"\"\n+        self.remote_sent = b\"\"\n \n     def setblocking(self, *arg):\n         self.blocking = True\n@@ -925,14 +979,44 @@ def close(self):\n         self.closed = True\n \n     def send(self, data):\n-        self.sent += data\n+        self.remote_sent += data\n         return len(data)\n \n     def recv(self, buffer_size):\n-        result = self.sent[:buffer_size]\n-        self.sent = self.sent[buffer_size:]\n+        result = self.local_sent[:buffer_size]\n+        self.local_sent = self.local_sent[buffer_size:]\n         return result\n \n+    def local(self):\n+        outer = self\n+\n+        class LocalDummySock:\n+            def send(self, data):\n+                outer.local_sent += data\n+                return len(data)\n+\n+            def recv(self, buffer_size):\n+                result = outer.remote_sent[:buffer_size]\n+                outer.remote_sent = outer.remote_sent[buffer_size:]\n+                return result\n+\n+            def close(self):\n+                outer.closed = True\n+\n+            @property\n+            def sent(self):\n+                return outer.remote_sent\n+\n+            @property\n+            def closed(self):\n+                return outer.closed\n+\n+            @property\n+            def remote(self):\n+                return outer\n+\n+        return LocalDummySock()\n+\n \n class DummyLock:\n     notified = False"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 3,
        "max_directory_depth": 2
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "fc592e804a1aed87654c1ad21337dad86582c71f",
            "date": "2024-11-25T01:07:27Z",
            "author_login": "mmerickel"
          },
          {
            "sha": "7a19337321c43b81076da20bc9c4e2e077a7e01c",
            "date": "2024-11-24T19:55:09Z",
            "author_login": "kgaughan"
          },
          {
            "sha": "2a1524a9b5786459786a4b86e5b2f09d1041e53d",
            "date": "2024-11-23T19:40:01Z",
            "author_login": "kgaughan"
          },
          {
            "sha": "b11ae729cc51ca2998a1ad9b4992b34f34ac95e7",
            "date": "2024-11-16T19:46:41Z",
            "author_login": "digitalresistor"
          },
          {
            "sha": "38ffad094b785168aba197f6b6d8df5de713cc2b",
            "date": "2024-11-16T19:39:00Z",
            "author_login": "digitalresistor"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 9.1,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:N",
    "cwe_id": "CWE-367",
    "description": "Waitress is a Web Server Gateway Interface server for Python 2 and 3. A remote client may send a request that is exactly recv_bytes (defaults to 8192) long, followed by a secondary request using HTTP pipelining. When request lookahead is disabled (default) we won't read any more requests, and when the first request fails due to a parsing error, we simply close the connection. However when request lookahead is enabled, it is possible to process and receive the first request, start sending the error message back to the client while we read the next request and queue it. This will allow the secondary request to be serviced by the worker thread while the connection should be closed. Waitress 3.0.1 fixes the race condition. As a workaround, disable channel_request_lookahead, this is set to 0 by default disabling this feature.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-10-29T15:15:11.440",
    "last_modified": "2024-11-07T17:28:02.853",
    "fix_date": "2024-10-29T00:05:50Z"
  },
  "references": [
    {
      "url": "https://github.com/Pylons/waitress/commit/e4359018537af376cf24bd13616d861e2fb76f65",
      "source": "security-advisories@github.com",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/Pylons/waitress/security/advisories/GHSA-9298-4cf8-g4wj",
      "source": "security-advisories@github.com",
      "tags": [
        "Vendor Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:09:27.106397",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "waitress",
    "owner": "Pylons",
    "created_at": "2011-12-17T06:58:21Z",
    "updated_at": "2025-01-11T21:17:13Z",
    "pushed_at": "2024-11-25T01:07:27Z",
    "size": 1868,
    "stars": 1467,
    "forks": 178,
    "open_issues": 16,
    "watchers": 1467,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "main"
    ],
    "languages": {
      "Python": 495340
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "other"
    },
    "collected_at": "2025-01-14T15:00:04.687602"
  }
}