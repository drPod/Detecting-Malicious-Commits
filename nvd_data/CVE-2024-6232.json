{
  "cve_id": "CVE-2024-6232",
  "github_data": {
    "repository": "python/cpython",
    "fix_commit": "4eaf4891c12589e3c7bdad5f5b076e4c8392dd06",
    "related_commits": [
      "4eaf4891c12589e3c7bdad5f5b076e4c8392dd06",
      "743acbe872485dc18df4d8ab2dc7895187f062c4",
      "7d1f50cd92ff7e10a1c15a8f591dde8a6843a64d",
      "b4225ca91547aa97ed3aca391614afbb255bc877",
      "d449caf8a179e3b954268b3a88eb9170be3c8fbf",
      "ed3a49ea734ada357ff4442996fd4ae71d253373"
    ],
    "patch_url": "https://github.com/python/cpython/commit/4eaf4891c12589e3c7bdad5f5b076e4c8392dd06.patch",
    "fix_commit_details": {
      "sha": "4eaf4891c12589e3c7bdad5f5b076e4c8392dd06",
      "commit_date": "2024-08-31T22:35:24Z",
      "author": {
        "login": "miss-islington",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "[3.12] gh-121285: Remove backtracking when parsing tarfile headers (GH-121286) (GH-123543)",
        "length": 558,
        "has_description": true,
        "references_issue": false
      },
      "stats": {
        "total": 147,
        "additions": 112,
        "deletions": 35
      },
      "files": [
        {
          "filename": "Lib/tarfile.py",
          "status": "modified",
          "additions": 68,
          "deletions": 35,
          "patch": "@@ -843,6 +843,9 @@ def data_filter(member, dest_path):\n # Sentinel for replace() defaults, meaning \"don't change the attribute\"\n _KEEP = object()\n \n+# Header length is digits followed by a space.\n+_header_length_prefix_re = re.compile(br\"([0-9]{1,20}) \")\n+\n class TarInfo(object):\n     \"\"\"Informational class which holds the details about an\n        archive member given by a tar header block.\n@@ -1412,55 +1415,76 @@ def _proc_pax(self, tarfile):\n         else:\n             pax_headers = tarfile.pax_headers.copy()\n \n-        # Check if the pax header contains a hdrcharset field. This tells us\n-        # the encoding of the path, linkpath, uname and gname fields. Normally,\n-        # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n-        # implementations are allowed to store them as raw binary strings if\n-        # the translation to UTF-8 fails.\n-        match = re.search(br\"\\d+ hdrcharset=([^\\n]+)\\n\", buf)\n-        if match is not None:\n-            pax_headers[\"hdrcharset\"] = match.group(1).decode(\"utf-8\")\n-\n-        # For the time being, we don't care about anything other than \"BINARY\".\n-        # The only other value that is currently allowed by the standard is\n-        # \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n-        hdrcharset = pax_headers.get(\"hdrcharset\")\n-        if hdrcharset == \"BINARY\":\n-            encoding = tarfile.encoding\n-        else:\n-            encoding = \"utf-8\"\n-\n         # Parse pax header information. A record looks like that:\n         # \"%d %s=%s\\n\" % (length, keyword, value). length is the size\n         # of the complete record including the length field itself and\n-        # the newline. keyword and value are both UTF-8 encoded strings.\n-        regex = re.compile(br\"(\\d+) ([^=]+)=\")\n+        # the newline.\n         pos = 0\n-        while match := regex.match(buf, pos):\n-            length, keyword = match.groups()\n-            length = int(length)\n-            if length == 0:\n+        encoding = None\n+        raw_headers = []\n+        while len(buf) > pos and buf[pos] != 0x00:\n+            if not (match := _header_length_prefix_re.match(buf, pos)):\n+                raise InvalidHeaderError(\"invalid header\")\n+            try:\n+                length = int(match.group(1))\n+            except ValueError:\n+                raise InvalidHeaderError(\"invalid header\")\n+            # Headers must be at least 5 bytes, shortest being '5 x=\\n'.\n+            # Value is allowed to be empty.\n+            if length < 5:\n+                raise InvalidHeaderError(\"invalid header\")\n+            if pos + length > len(buf):\n+                raise InvalidHeaderError(\"invalid header\")\n+\n+            header_value_end_offset = match.start(1) + length - 1  # Last byte of the header\n+            keyword_and_value = buf[match.end(1) + 1:header_value_end_offset]\n+            raw_keyword, equals, raw_value = keyword_and_value.partition(b\"=\")\n+\n+            # Check the framing of the header. The last character must be '\\n' (0x0A)\n+            if not raw_keyword or equals != b\"=\" or buf[header_value_end_offset] != 0x0A:\n                 raise InvalidHeaderError(\"invalid header\")\n-            value = buf[match.end(2) + 1:match.start(1) + length - 1]\n+            raw_headers.append((length, raw_keyword, raw_value))\n+\n+            # Check if the pax header contains a hdrcharset field. This tells us\n+            # the encoding of the path, linkpath, uname and gname fields. Normally,\n+            # these fields are UTF-8 encoded but since POSIX.1-2008 tar\n+            # implementations are allowed to store them as raw binary strings if\n+            # the translation to UTF-8 fails. For the time being, we don't care about\n+            # anything other than \"BINARY\". The only other value that is currently\n+            # allowed by the standard is \"ISO-IR 10646 2000 UTF-8\" in other words UTF-8.\n+            # Note that we only follow the initial 'hdrcharset' setting to preserve\n+            # the initial behavior of the 'tarfile' module.\n+            if raw_keyword == b\"hdrcharset\" and encoding is None:\n+                if raw_value == b\"BINARY\":\n+                    encoding = tarfile.encoding\n+                else:  # This branch ensures only the first 'hdrcharset' header is used.\n+                    encoding = \"utf-8\"\n \n+            pos += length\n+\n+        # If no explicit hdrcharset is set, we use UTF-8 as a default.\n+        if encoding is None:\n+            encoding = \"utf-8\"\n+\n+        # After parsing the raw headers we can decode them to text.\n+        for length, raw_keyword, raw_value in raw_headers:\n             # Normally, we could just use \"utf-8\" as the encoding and \"strict\"\n             # as the error handler, but we better not take the risk. For\n             # example, GNU tar <= 1.23 is known to store filenames it cannot\n             # translate to UTF-8 as raw strings (unfortunately without a\n             # hdrcharset=BINARY header).\n             # We first try the strict standard encoding, and if that fails we\n             # fall back on the user's encoding and error handler.\n-            keyword = self._decode_pax_field(keyword, \"utf-8\", \"utf-8\",\n+            keyword = self._decode_pax_field(raw_keyword, \"utf-8\", \"utf-8\",\n                     tarfile.errors)\n             if keyword in PAX_NAME_FIELDS:\n-                value = self._decode_pax_field(value, encoding, tarfile.encoding,\n+                value = self._decode_pax_field(raw_value, encoding, tarfile.encoding,\n                         tarfile.errors)\n             else:\n-                value = self._decode_pax_field(value, \"utf-8\", \"utf-8\",\n+                value = self._decode_pax_field(raw_value, \"utf-8\", \"utf-8\",\n                         tarfile.errors)\n \n             pax_headers[keyword] = value\n-            pos += length\n \n         # Fetch the next header.\n         try:\n@@ -1475,7 +1499,7 @@ def _proc_pax(self, tarfile):\n \n         elif \"GNU.sparse.size\" in pax_headers:\n             # GNU extended sparse format version 0.0.\n-            self._proc_gnusparse_00(next, pax_headers, buf)\n+            self._proc_gnusparse_00(next, raw_headers)\n \n         elif pax_headers.get(\"GNU.sparse.major\") == \"1\" and pax_headers.get(\"GNU.sparse.minor\") == \"0\":\n             # GNU extended sparse format version 1.0.\n@@ -1497,15 +1521,24 @@ def _proc_pax(self, tarfile):\n \n         return next\n \n-    def _proc_gnusparse_00(self, next, pax_headers, buf):\n+    def _proc_gnusparse_00(self, next, raw_headers):\n         \"\"\"Process a GNU tar extended sparse header, version 0.0.\n         \"\"\"\n         offsets = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.offset=(\\d+)\\n\", buf):\n-            offsets.append(int(match.group(1)))\n         numbytes = []\n-        for match in re.finditer(br\"\\d+ GNU.sparse.numbytes=(\\d+)\\n\", buf):\n-            numbytes.append(int(match.group(1)))\n+        for _, keyword, value in raw_headers:\n+            if keyword == b\"GNU.sparse.offset\":\n+                try:\n+                    offsets.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n+            elif keyword == b\"GNU.sparse.numbytes\":\n+                try:\n+                    numbytes.append(int(value.decode()))\n+                except ValueError:\n+                    raise InvalidHeaderError(\"invalid header\")\n+\n         next.sparse = list(zip(offsets, numbytes))\n \n     def _proc_gnusparse_01(self, next, pax_headers):"
        },
        {
          "filename": "Lib/test/test_tarfile.py",
          "status": "modified",
          "additions": 42,
          "deletions": 0,
          "patch": "@@ -1237,6 +1237,48 @@ def test_pax_number_fields(self):\n         finally:\n             tar.close()\n \n+    def test_pax_header_bad_formats(self):\n+        # The fields from the pax header have priority over the\n+        # TarInfo.\n+        pax_header_replacements = (\n+            b\" foo=bar\\n\",\n+            b\"0 \\n\",\n+            b\"1 \\n\",\n+            b\"2 \\n\",\n+            b\"3 =\\n\",\n+            b\"4 =a\\n\",\n+            b\"1000000 foo=bar\\n\",\n+            b\"0 foo=bar\\n\",\n+            b\"-12 foo=bar\\n\",\n+            b\"000000000000000000000000036 foo=bar\\n\",\n+        )\n+        pax_headers = {\"foo\": \"bar\"}\n+\n+        for replacement in pax_header_replacements:\n+            with self.subTest(header=replacement):\n+                tar = tarfile.open(tmpname, \"w\", format=tarfile.PAX_FORMAT,\n+                                   encoding=\"iso8859-1\")\n+                try:\n+                    t = tarfile.TarInfo()\n+                    t.name = \"pax\"  # non-ASCII\n+                    t.uid = 1\n+                    t.pax_headers = pax_headers\n+                    tar.addfile(t)\n+                finally:\n+                    tar.close()\n+\n+                with open(tmpname, \"rb\") as f:\n+                    data = f.read()\n+                    self.assertIn(b\"11 foo=bar\\n\", data)\n+                    data = data.replace(b\"11 foo=bar\\n\", replacement)\n+\n+                with open(tmpname, \"wb\") as f:\n+                    f.truncate()\n+                    f.write(data)\n+\n+                with self.assertRaisesRegex(tarfile.ReadError, r\"method tar: ReadError\\('invalid header'\\)\"):\n+                    tarfile.open(tmpname, encoding=\"iso8859-1\")\n+\n \n class WriteTestBase(TarTest):\n     # Put all write tests in here that are supposed to be tested"
        },
        {
          "filename": "Misc/NEWS.d/next/Security/2024-07-02-13-39-20.gh-issue-121285.hrl-yI.rst",
          "status": "added",
          "additions": 2,
          "deletions": 0,
          "patch": "@@ -0,0 +1,2 @@\n+Remove backtracking from tarfile header parsing for ``hdrcharset``, PAX, and\n+GNU sparse headers."
        }
      ],
      "file_patterns": {
        "security_files": 1,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 1,
        "unique_directories": 3,
        "max_directory_depth": 4
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "f7ceb317aec498823555885a4b7fed5e0244f300",
            "date": "2025-01-14T20:40:45Z",
            "author_login": "serhiy-storchaka"
          },
          {
            "sha": "b5ee0258bf5bb60a5a5a65c64717853e06b64808",
            "date": "2025-01-14T19:56:11Z",
            "author_login": "mpage"
          },
          {
            "sha": "1c13c56a34fc4c4d8969f0b6dc93d5208a50d61b",
            "date": "2025-01-14T19:43:42Z",
            "author_login": "nascheme"
          },
          {
            "sha": "d906bde250d59c396d8dab92285b832c66cdec27",
            "date": "2025-01-14T16:07:37Z",
            "author_login": "picnixz"
          },
          {
            "sha": "d786ac7f584f23c3206f4c86032bdabe83c17b51",
            "date": "2025-01-14T15:31:13Z",
            "author_login": "vstinner"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.5,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-1333",
    "description": "There is a MEDIUM severity vulnerability affecting CPython.\n\n\n\n\n\nRegular expressions that allowed excessive backtracking during tarfile.TarFile header parsing are vulnerable to ReDoS via specifically-crafted tar archives.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-09-03T13:15:05.363",
    "last_modified": "2024-11-21T09:49:14.903",
    "fix_date": "2024-08-31T22:35:24Z"
  },
  "references": [
    {
      "url": "https://github.com/python/cpython/commit/4eaf4891c12589e3c7bdad5f5b076e4c8392dd06",
      "source": "cna@python.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/python/cpython/commit/743acbe872485dc18df4d8ab2dc7895187f062c4",
      "source": "cna@python.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/python/cpython/commit/7d1f50cd92ff7e10a1c15a8f591dde8a6843a64d",
      "source": "cna@python.org",
      "tags": []
    },
    {
      "url": "https://github.com/python/cpython/commit/b4225ca91547aa97ed3aca391614afbb255bc877",
      "source": "cna@python.org",
      "tags": []
    },
    {
      "url": "https://github.com/python/cpython/commit/d449caf8a179e3b954268b3a88eb9170be3c8fbf",
      "source": "cna@python.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/python/cpython/commit/ed3a49ea734ada357ff4442996fd4ae71d253373",
      "source": "cna@python.org",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://github.com/python/cpython/issues/121285",
      "source": "cna@python.org",
      "tags": [
        "Exploit",
        "Issue Tracking",
        "Patch"
      ]
    },
    {
      "url": "https://github.com/python/cpython/pull/121286",
      "source": "cna@python.org",
      "tags": [
        "Issue Tracking",
        "Patch"
      ]
    },
    {
      "url": "https://mail.python.org/archives/list/security-announce@python.org/thread/JRYFTPRHZRTLMZLWQEUHZSJXNHM4ACTY/",
      "source": "cna@python.org",
      "tags": [
        "Vendor Advisory"
      ]
    },
    {
      "url": "http://www.openwall.com/lists/oss-security/2024/09/03/5",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    },
    {
      "url": "https://security.netapp.com/advisory/ntap-20241018-0007/",
      "source": "af854a3a-2127-422b-91ae-364da2661108",
      "tags": []
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:08:37.423675",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "cpython",
    "owner": "python",
    "created_at": "2017-02-10T19:23:51Z",
    "updated_at": "2025-01-14T11:40:35Z",
    "pushed_at": "2025-01-14T11:26:26Z",
    "size": 657526,
    "stars": 64721,
    "forks": 30871,
    "open_issues": 8974,
    "watchers": 64721,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [
      "3.9",
      "3.10",
      "3.11",
      "3.12",
      "3.13",
      "main"
    ],
    "languages": {
      "Python": 35947988,
      "C": 20215174,
      "C++": 463381,
      "M4": 257753,
      "HTML": 206335,
      "Batchfile": 78178,
      "Shell": 71664,
      "Roff": 45666,
      "Makefile": 36295,
      "Objective-C": 33051,
      "Common Lisp": 24579,
      "PLSQL": 22886,
      "PowerShell": 20323,
      "Rich Text Format": 6905,
      "JavaScript": 4245,
      "Kotlin": 3800,
      "Assembly": 2552,
      "DTrace": 2196,
      "CSS": 1325,
      "XSLT": 1174,
      "CMake": 327,
      "VBScript": 70
    },
    "commit_activity": {
      "total_commits_last_year": 5718,
      "avg_commits_per_week": 109.96153846153847,
      "days_active_last_year": 357
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": true,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "other"
    },
    "collected_at": "2025-01-14T13:09:03.245623"
  }
}