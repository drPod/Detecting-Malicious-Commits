{
  "cve_id": "CVE-2024-7807",
  "github_data": {
    "repository": "gaizhenbiao/chuanhuchatgpt",
    "fix_commit": "919222d285d73b9dcd71fb34de379eef8c90d175",
    "related_commits": [
      "919222d285d73b9dcd71fb34de379eef8c90d175"
    ],
    "patch_url": "https://github.com/gaizhenbiao/chuanhuchatgpt/commit/919222d285d73b9dcd71fb34de379eef8c90d175.patch",
    "fix_commit_details": {
      "sha": "919222d285d73b9dcd71fb34de379eef8c90d175",
      "commit_date": "2024-09-18T02:50:44Z",
      "author": {
        "login": "GaiZhenbiao",
        "type": "User",
        "stats": null
      },
      "commit_message": {
        "title": "bugfix: Raise error if multipart boundry is invalid.",
        "length": 52,
        "has_description": false,
        "references_issue": true
      },
      "stats": {
        "total": 406,
        "additions": 404,
        "deletions": 2
      },
      "files": [
        {
          "filename": "modules/overwrites.py",
          "status": "modified",
          "additions": 404,
          "deletions": 2,
          "patch": "@@ -1,8 +1,9 @@\n from __future__ import annotations\n \n-import inspect\n-\n import gradio as gr\n+import multipart\n+from multipart.multipart import MultipartState, CR, LF, HYPHEN, COLON, lower_char, LOWER_A, LOWER_Z, SPACE, FLAG_PART_BOUNDARY, FLAG_LAST_BOUNDARY, join_bytes\n+from multipart.exceptions import MultipartParseError\n from gradio.components.chatbot import ChatbotData, FileMessage\n from gradio.data_classes import FileData\n from gradio_client import utils as client_utils\n@@ -83,6 +84,406 @@ def wrapper(self, *args, **kwargs):\n \n     return wrapper\n \n+def multipart_internal_write(self, data: bytes, length: int) -> int:\n+        # Get values from locals.\n+        boundary = self.boundary\n+\n+        # Get our state, flags and index.  These are persisted between calls to\n+        # this function.\n+        state = self.state\n+        index = self.index\n+        flags = self.flags\n+\n+        # Our index defaults to 0.\n+        i = 0\n+\n+        # Set a mark.\n+        def set_mark(name):\n+            self.marks[name] = i\n+\n+        # Remove a mark.\n+        def delete_mark(name, reset=False):\n+            self.marks.pop(name, None)\n+\n+        # Helper function that makes calling a callback with data easier. The\n+        # 'remaining' parameter will callback from the marked value until the\n+        # end of the buffer, and reset the mark, instead of deleting it.  This\n+        # is used at the end of the function to call our callbacks with any\n+        # remaining data in this chunk.\n+        def data_callback(name, remaining=False):\n+            marked_index = self.marks.get(name)\n+            if marked_index is None:\n+                return\n+\n+            # If we're getting remaining data, we ignore the current i value\n+            # and just call with the remaining data.\n+            if remaining:\n+                self.callback(name, data, marked_index, length)\n+                self.marks[name] = 0\n+\n+            # Otherwise, we call it from the mark to the current byte we're\n+            # processing.\n+            else:\n+                self.callback(name, data, marked_index, i)\n+                self.marks.pop(name, None)\n+\n+        # For each byte...\n+        # Add a counter for bytes consumed in the END state\n+        end_state_counter = 0\n+        while i < length:\n+            c = data[i]\n+\n+            if state == MultipartState.START:\n+                # Skip leading newlines\n+                if c == CR or c == LF:\n+                    i += 1\n+                    self.logger.debug(\"Skipping leading CR/LF at %d\", i)\n+                    continue\n+\n+                # index is used as in index into our boundary.  Set to 0.\n+                index = 0\n+\n+                # Move to the next state, but decrement i so that we re-process\n+                # this character.\n+                state = MultipartState.START_BOUNDARY\n+                i -= 1\n+\n+            elif state == MultipartState.START_BOUNDARY:\n+                # Check to ensure that the last 2 characters in our boundary\n+                # are CRLF.\n+                if index == len(boundary) - 2:\n+                    if c != CR:\n+                        # Error!\n+                        msg = \"Did not find CR at end of boundary (%d)\" % (i,)\n+                        self.logger.warning(msg)\n+                        e = MultipartParseError(msg)\n+                        e.offset = i\n+                        raise e\n+\n+                    index += 1\n+\n+                elif index == len(boundary) - 2 + 1:\n+                    if c != LF:\n+                        msg = \"Did not find LF at end of boundary (%d)\" % (i,)\n+                        self.logger.warning(msg)\n+                        e = MultipartParseError(msg)\n+                        e.offset = i\n+                        raise e\n+\n+                    # The index is now used for indexing into our boundary.\n+                    index = 0\n+\n+                    # Callback for the start of a part.\n+                    self.callback(\"part_begin\")\n+\n+                    # Move to the next character and state.\n+                    state = MultipartState.HEADER_FIELD_START\n+\n+                else:\n+                    # Check to ensure our boundary matches\n+                    if c != boundary[index + 2]:\n+                        msg = \"Did not find boundary character %r at index \" \"%d\" % (c, index + 2)\n+                        self.logger.warning(msg)\n+                        e = MultipartParseError(msg)\n+                        e.offset = i\n+                        raise e\n+\n+                    # Increment index into boundary and continue.\n+                    index += 1\n+\n+            elif state == MultipartState.HEADER_FIELD_START:\n+                # Mark the start of a header field here, reset the index, and\n+                # continue parsing our header field.\n+                index = 0\n+\n+                # Set a mark of our header field.\n+                set_mark(\"header_field\")\n+\n+                # Move to parsing header fields.\n+                state = MultipartState.HEADER_FIELD\n+                i -= 1\n+\n+            elif state == MultipartState.HEADER_FIELD:\n+                # If we've reached a CR at the beginning of a header, it means\n+                # that we've reached the second of 2 newlines, and so there are\n+                # no more headers to parse.\n+                if c == CR:\n+                    delete_mark(\"header_field\")\n+                    state = MultipartState.HEADERS_ALMOST_DONE\n+                    i += 1\n+                    continue\n+\n+                # Increment our index in the header.\n+                index += 1\n+\n+                # Do nothing if we encounter a hyphen.\n+                if c == HYPHEN:\n+                    pass\n+\n+                # If we've reached a colon, we're done with this header.\n+                elif c == COLON:\n+                    # A 0-length header is an error.\n+                    if index == 1:\n+                        msg = \"Found 0-length header at %d\" % (i,)\n+                        self.logger.warning(msg)\n+                        e = MultipartParseError(msg)\n+                        e.offset = i\n+                        raise e\n+\n+                    # Call our callback with the header field.\n+                    data_callback(\"header_field\")\n+\n+                    # Move to parsing the header value.\n+                    state = MultipartState.HEADER_VALUE_START\n+\n+                else:\n+                    # Lower-case this character, and ensure that it is in fact\n+                    # a valid letter.  If not, it's an error.\n+                    cl = lower_char(c)\n+                    if cl < LOWER_A or cl > LOWER_Z:\n+                        msg = \"Found non-alphanumeric character %r in \" \"header at %d\" % (c, i)\n+                        self.logger.warning(msg)\n+                        e = MultipartParseError(msg)\n+                        e.offset = i\n+                        raise e\n+\n+            elif state == MultipartState.HEADER_VALUE_START:\n+                # Skip leading spaces.\n+                if c == SPACE:\n+                    i += 1\n+                    continue\n+\n+                # Mark the start of the header value.\n+                set_mark(\"header_value\")\n+\n+                # Move to the header-value state, reprocessing this character.\n+                state = MultipartState.HEADER_VALUE\n+                i -= 1\n+\n+            elif state == MultipartState.HEADER_VALUE:\n+                # If we've got a CR, we're nearly done our headers.  Otherwise,\n+                # we do nothing and just move past this character.\n+                if c == CR:\n+                    data_callback(\"header_value\")\n+                    self.callback(\"header_end\")\n+                    state = MultipartState.HEADER_VALUE_ALMOST_DONE\n+\n+            elif state == MultipartState.HEADER_VALUE_ALMOST_DONE:\n+                # The last character should be a LF.  If not, it's an error.\n+                if c != LF:\n+                    msg = \"Did not find LF character at end of header \" \"(found %r)\" % (c,)\n+                    self.logger.warning(msg)\n+                    e = MultipartParseError(msg)\n+                    e.offset = i\n+                    raise e\n+\n+                # Move back to the start of another header.  Note that if that\n+                # state detects ANOTHER newline, it'll trigger the end of our\n+                # headers.\n+                state = MultipartState.HEADER_FIELD_START\n+\n+            elif state == MultipartState.HEADERS_ALMOST_DONE:\n+                # We're almost done our headers.  This is reached when we parse\n+                # a CR at the beginning of a header, so our next character\n+                # should be a LF, or it's an error.\n+                if c != LF:\n+                    msg = f\"Did not find LF at end of headers (found {c!r})\"\n+                    self.logger.warning(msg)\n+                    e = MultipartParseError(msg)\n+                    e.offset = i\n+                    raise e\n+\n+                self.callback(\"headers_finished\")\n+                state = MultipartState.PART_DATA_START\n+\n+            elif state == MultipartState.PART_DATA_START:\n+                # Mark the start of our part data.\n+                set_mark(\"part_data\")\n+\n+                # Start processing part data, including this character.\n+                state = MultipartState.PART_DATA\n+                i -= 1\n+\n+            elif state == MultipartState.PART_DATA:\n+                # We're processing our part data right now.  During this, we\n+                # need to efficiently search for our boundary, since any data\n+                # on any number of lines can be a part of the current data.\n+                # We use the Boyer-Moore-Horspool algorithm to efficiently\n+                # search through the remainder of the buffer looking for our\n+                # boundary.\n+\n+                # Save the current value of our index.  We use this in case we\n+                # find part of a boundary, but it doesn't match fully.\n+                prev_index = index\n+\n+                # Set up variables.\n+                boundary_length = len(boundary)\n+                boundary_end = boundary_length - 1\n+                data_length = length\n+                boundary_chars = self.boundary_chars\n+\n+                # If our index is 0, we're starting a new part, so start our\n+                # search.\n+                if index == 0:\n+                    # Search forward until we either hit the end of our buffer,\n+                    # or reach a character that's in our boundary.\n+                    i += boundary_end\n+                    while i < data_length - 1 and data[i] not in boundary_chars:\n+                        i += boundary_length\n+\n+                    # Reset i back the length of our boundary, which is the\n+                    # earliest possible location that could be our match (i.e.\n+                    # if we've just broken out of our loop since we saw the\n+                    # last character in our boundary)\n+                    i -= boundary_end\n+                    c = data[i]\n+\n+                # Now, we have a couple of cases here.  If our index is before\n+                # the end of the boundary...\n+                if index < boundary_length:\n+                    # If the character matches...\n+                    if boundary[index] == c:\n+                        # If we found a match for our boundary, we send the\n+                        # existing data.\n+                        if index == 0:\n+                            data_callback(\"part_data\")\n+\n+                        # The current character matches, so continue!\n+                        index += 1\n+                    else:\n+                        index = 0\n+\n+                # Our index is equal to the length of our boundary!\n+                elif index == boundary_length:\n+                    # First we increment it.\n+                    index += 1\n+\n+                    # Now, if we've reached a newline, we need to set this as\n+                    # the potential end of our boundary.\n+                    if c == CR:\n+                        flags |= FLAG_PART_BOUNDARY\n+\n+                    # Otherwise, if this is a hyphen, we might be at the last\n+                    # of all boundaries.\n+                    elif c == HYPHEN:\n+                        flags |= FLAG_LAST_BOUNDARY\n+\n+                    # Otherwise, we reset our index, since this isn't either a\n+                    # newline or a hyphen.\n+                    else:\n+                        index = 0\n+\n+                # Our index is right after the part boundary, which should be\n+                # a LF.\n+                elif index == boundary_length + 1:\n+                    # If we're at a part boundary (i.e. we've seen a CR\n+                    # character already)...\n+                    if flags & FLAG_PART_BOUNDARY:\n+                        # We need a LF character next.\n+                        if c == LF:\n+                            # Unset the part boundary flag.\n+                            flags &= ~FLAG_PART_BOUNDARY\n+\n+                            # Callback indicating that we've reached the end of\n+                            # a part, and are starting a new one.\n+                            self.callback(\"part_end\")\n+                            self.callback(\"part_begin\")\n+\n+                            # Move to parsing new headers.\n+                            index = 0\n+                            state = MultipartState.HEADER_FIELD_START\n+                            i += 1\n+                            continue\n+\n+                        # We didn't find an LF character, so no match.  Reset\n+                        # our index and clear our flag.\n+                        index = 0\n+                        flags &= ~FLAG_PART_BOUNDARY\n+\n+                    # Otherwise, if we're at the last boundary (i.e. we've\n+                    # seen a hyphen already)...\n+                    elif flags & FLAG_LAST_BOUNDARY:\n+                        # We need a second hyphen here.\n+                        if c == HYPHEN:\n+                            # Callback to end the current part, and then the\n+                            # message.\n+                            self.callback(\"part_end\")\n+                            self.callback(\"end\")\n+                            state = MultipartState.END\n+                        else:\n+                            # No match, so reset index.\n+                            index = 0\n+\n+                # If we have an index, we need to keep this byte for later, in\n+                # case we can't match the full boundary.\n+                if index > 0:\n+                    self.lookbehind[index - 1] = c\n+\n+                # Otherwise, our index is 0.  If the previous index is not, it\n+                # means we reset something, and we need to take the data we\n+                # thought was part of our boundary and send it along as actual\n+                # data.\n+                elif prev_index > 0:\n+                    # Callback to write the saved data.\n+                    lb_data = join_bytes(self.lookbehind)\n+                    self.callback(\"part_data\", lb_data, 0, prev_index)\n+\n+                    # Overwrite our previous index.\n+                    prev_index = 0\n+\n+                    # Re-set our mark for part data.\n+                    set_mark(\"part_data\")\n+\n+                    # Re-consider the current character, since this could be\n+                    # the start of the boundary itself.\n+                    i -= 1\n+\n+            elif state == MultipartState.END:\n+                # Count bytes consumed in the end state\n+                if c not in (CR, LF):\n+                    self.logger.warning(\"Consuming a byte '0x%x' in the end state\", c)\n+                    end_state_counter += 1\n+\n+                    # It seems that raising an error is the best way to stop the parser\n+                    # Raise an error when consuming more than 10 bytes in the end state\n+                    # Raising an error immediately seems fine, but to be cautious, let\u2019s raise an error when more than 10 bytes are consumed\n+                    if end_state_counter > 10:\n+                        raise MultipartParseError(\"Consumed more than 10 bytes in the end state\")\n+                else:\n+                    # Reset the counter for CR or LF\n+                    end_state_counter = 0\n+\n+            else:  # pragma: no cover (error case)\n+                # We got into a strange state somehow!  Just stop processing.\n+                msg = \"Reached an unknown state %d at %d\" % (state, i)\n+                self.logger.warning(msg)\n+                e = MultipartParseError(msg)\n+                e.offset = i\n+                raise e\n+\n+            # Move to the next byte.\n+            i += 1\n+\n+        # We call our callbacks with any remaining data.  Note that we pass\n+        # the 'remaining' flag, which sets the mark back to 0 instead of\n+        # deleting it, if it's found.  This is because, if the mark is found\n+        # at this point, we assume that there's data for one of these things\n+        # that has been parsed, but not yet emitted.  And, as such, it implies\n+        # that we haven't yet reached the end of this 'thing'.  So, by setting\n+        # the mark to 0, we cause any data callbacks that take place in future\n+        # calls to this function to start from the beginning of that buffer.\n+        data_callback(\"header_field\", True)\n+        data_callback(\"header_value\", True)\n+        data_callback(\"part_data\", True)\n+\n+        # Save values to locals.\n+        self.state = state\n+        self.index = index\n+        self.flags = flags\n+\n+        # Return our data length to indicate no errors, and that we processed\n+        # all of it.\n+        return length\n \n def patch_gradio():\n     gr.components.Component.__init__ = init_with_class_name_as_elem_classes(\n@@ -95,3 +496,4 @@ def patch_gradio():\n \n     gr.Chatbot._postprocess_chat_messages = postprocess_chat_messages\n     gr.Chatbot.postprocess = postprocess\n+    multipart.MultipartParser._internal_write = multipart_internal_write"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 0,
        "dependency_files": 0,
        "test_files": 0,
        "unique_directories": 1,
        "max_directory_depth": 1
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "3747cdbb95f9395146f29da7dcdc31c82cc23717",
            "date": "2024-12-12T14:54:00Z",
            "author_login": "GaiZhenbiao"
          },
          {
            "sha": "33869648f2a97759ec48cac475f7bc890b10e981",
            "date": "2024-11-16T06:20:15Z",
            "author_login": "Keldos-Li"
          },
          {
            "sha": "fb97fd65aee852248cfcf0d88f44e81304f58109",
            "date": "2024-11-13T16:17:40Z",
            "author_login": "Keldos-Li"
          },
          {
            "sha": "d1ca9f33c531ceaccd62dd73b819c9246c44813c",
            "date": "2024-11-13T16:08:51Z",
            "author_login": "Keldos-Li"
          },
          {
            "sha": "0752e6ec84434838de4cf00e6a38919a01cf0c33",
            "date": "2024-10-22T07:02:06Z",
            "author_login": "Keldos-Li"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 7.5,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H",
    "cwe_id": "CWE-770",
    "description": "A vulnerability in gaizhenbiao/chuanhuchatgpt version 20240628 allows for a Denial of Service (DOS) attack. When uploading a file, if an attacker appends a large number of characters to the end of a multipart boundary, the system will continuously process each character, rendering ChuanhuChatGPT inaccessible. This uncontrolled resource consumption can lead to prolonged unavailability of the service, disrupting operations and causing potential data inaccessibility and loss of productivity.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-10-29T13:15:10.360",
    "last_modified": "2025-01-09T18:15:29.543",
    "fix_date": "2024-09-18T02:50:44Z"
  },
  "references": [
    {
      "url": "https://github.com/gaizhenbiao/chuanhuchatgpt/commit/919222d285d73b9dcd71fb34de379eef8c90d175",
      "source": "security@huntr.dev",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.com/bounties/db67276d-36ee-4487-9165-b621c67ef8a3",
      "source": "security@huntr.dev",
      "tags": [
        "Exploit"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:09:27.105420",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "ChuanhuChatGPT",
    "owner": "gaizhenbiao",
    "created_at": "2023-03-02T13:37:13Z",
    "updated_at": "2025-01-14T08:24:11Z",
    "pushed_at": "2024-12-12T15:01:12Z",
    "size": 3223,
    "stars": 15343,
    "forks": 2288,
    "open_issues": 127,
    "watchers": 15343,
    "has_security_policy": false,
    "default_branch": "main",
    "protected_branches": [],
    "languages": {
      "Python": 433757,
      "JavaScript": 92092,
      "CSS": 63899,
      "HTML": 52103,
      "Shell": 1338,
      "Dockerfile": 1275,
      "Batchfile": 464
    },
    "commit_activity": {
      "total_commits_last_year": 0,
      "avg_commits_per_week": 0,
      "days_active_last_year": 0
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": true,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "gpl-3.0"
    },
    "collected_at": "2025-01-14T13:28:37.886262"
  }
}