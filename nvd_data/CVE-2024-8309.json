{
  "cve_id": "CVE-2024-8309",
  "github_data": {
    "repository": "langchain-ai/langchain",
    "fix_commit": "c2a3021bb0c5f54649d380b42a0684ca5778c255",
    "related_commits": [
      "c2a3021bb0c5f54649d380b42a0684ca5778c255"
    ],
    "patch_url": "https://github.com/langchain-ai/langchain/commit/c2a3021bb0c5f54649d380b42a0684ca5778c255.patch",
    "fix_commit_details": {
      "sha": "c2a3021bb0c5f54649d380b42a0684ca5778c255",
      "commit_date": "2024-09-13T21:38:45Z",
      "author": {
        "login": "efriis",
        "type": "User",
        "stats": {
          "total_commits": 1435,
          "average_weekly_commits": 12.264957264957266,
          "total_additions": 0,
          "total_deletions": 0,
          "weeks_active": 71
        }
      },
      "commit_message": {
        "title": "multiple: pydantic 2 compatibility, v0.3 (#26443)",
        "length": 862,
        "has_description": true,
        "references_issue": true
      },
      "stats": {
        "total": 69738,
        "additions": 38823,
        "deletions": 30915
      },
      "files": [
        {
          "filename": ".github/scripts/check_diff.py",
          "status": "modified",
          "additions": 85,
          "deletions": 20,
          "patch": "@@ -2,10 +2,12 @@\n import json\n import os\n import sys\n-import tomllib\n from collections import defaultdict\n from typing import Dict, List, Set\n from pathlib import Path\n+import tomllib\n+\n+from get_min_versions import get_min_version_from_toml\n \n \n LANGCHAIN_DIRS = [\n@@ -16,6 +18,12 @@\n     \"libs/experimental\",\n ]\n \n+# when set to True, we are ignoring core dependents\n+# in order to be able to get CI to pass for each individual\n+# package that depends on core\n+# e.g. if you touch core, we don't then add textsplitters/etc to CI\n+IGNORE_CORE_DEPENDENTS = False\n+\n # ignored partners are removed from dependents\n # but still run if directly edited\n IGNORED_PARTNERS = [\n@@ -99,44 +107,96 @@ def add_dependents(dirs_to_eval: Set[str], dependents: dict) -> List[str]:\n \n \n def _get_configs_for_single_dir(job: str, dir_: str) -> List[Dict[str, str]]:\n-    if dir_ == \"libs/core\":\n-        return [\n-            {\"working-directory\": dir_, \"python-version\": f\"3.{v}\"}\n-            for v in range(8, 13)\n-        ]\n-    min_python = \"3.8\"\n-    max_python = \"3.12\"\n+    if job == \"test-pydantic\":\n+        return _get_pydantic_test_configs(dir_)\n \n+    if dir_ == \"libs/core\":\n+        py_versions = [\"3.9\", \"3.10\", \"3.11\", \"3.12\"]\n     # custom logic for specific directories\n-    if dir_ == \"libs/partners/milvus\":\n+    elif dir_ == \"libs/partners/milvus\":\n         # milvus poetry doesn't allow 3.12 because they\n         # declare deps in funny way\n-        max_python = \"3.11\"\n+        py_versions = [\"3.9\", \"3.11\"]\n \n-    if dir_ in [\"libs/community\", \"libs/langchain\"] and job == \"extended-tests\":\n+    elif dir_ in [\"libs/community\", \"libs/langchain\"] and job == \"extended-tests\":\n         # community extended test resolution in 3.12 is slow\n         # even in uv\n-        max_python = \"3.11\"\n+        py_versions = [\"3.9\", \"3.11\"]\n \n-    if dir_ == \"libs/community\" and job == \"compile-integration-tests\":\n+    elif dir_ == \"libs/community\" and job == \"compile-integration-tests\":\n         # community integration deps are slow in 3.12\n-        max_python = \"3.11\"\n+        py_versions = [\"3.9\", \"3.11\"]\n+    else:\n+        py_versions = [\"3.9\", \"3.12\"]\n \n-    return [\n-        {\"working-directory\": dir_, \"python-version\": min_python},\n-        {\"working-directory\": dir_, \"python-version\": max_python},\n+    return [{\"working-directory\": dir_, \"python-version\": py_v} for py_v in py_versions]\n+\n+\n+def _get_pydantic_test_configs(\n+    dir_: str, *, python_version: str = \"3.11\"\n+) -> List[Dict[str, str]]:\n+    with open(\"./libs/core/poetry.lock\", \"rb\") as f:\n+        core_poetry_lock_data = tomllib.load(f)\n+    for package in core_poetry_lock_data[\"package\"]:\n+        if package[\"name\"] == \"pydantic\":\n+            core_max_pydantic_minor = package[\"version\"].split(\".\")[1]\n+            break\n+\n+    with open(f\"./{dir_}/poetry.lock\", \"rb\") as f:\n+        dir_poetry_lock_data = tomllib.load(f)\n+\n+    for package in dir_poetry_lock_data[\"package\"]:\n+        if package[\"name\"] == \"pydantic\":\n+            dir_max_pydantic_minor = package[\"version\"].split(\".\")[1]\n+            break\n+\n+    core_min_pydantic_version = get_min_version_from_toml(\n+        \"./libs/core/pyproject.toml\", \"release\", python_version, include=[\"pydantic\"]\n+    )[\"pydantic\"]\n+    core_min_pydantic_minor = core_min_pydantic_version.split(\".\")[1] if \".\" in core_min_pydantic_version else \"0\"\n+    dir_min_pydantic_version = (\n+        get_min_version_from_toml(\n+            f\"./{dir_}/pyproject.toml\", \"release\", python_version, include=[\"pydantic\"]\n+        )\n+        .get(\"pydantic\", \"0.0.0\")\n+    )\n+    dir_min_pydantic_minor = dir_min_pydantic_version.split(\".\")[1] if \".\" in dir_min_pydantic_version else \"0\"\n+\n+    custom_mins = {\n+        # depends on pydantic-settings 2.4 which requires pydantic 2.7\n+        \"libs/community\": 7,\n+    }\n+\n+    max_pydantic_minor = min(\n+        int(dir_max_pydantic_minor),\n+        int(core_max_pydantic_minor),\n+    )\n+    min_pydantic_minor = max(\n+        int(dir_min_pydantic_minor),\n+        int(core_min_pydantic_minor),\n+        custom_mins.get(dir_, 0),\n+    )\n+\n+    configs = [\n+        {\n+            \"working-directory\": dir_,\n+            \"pydantic-version\": f\"2.{v}.0\",\n+            \"python-version\": python_version,\n+        }\n+        for v in range(min_pydantic_minor, max_pydantic_minor + 1)\n     ]\n+    return configs\n \n \n def _get_configs_for_multi_dirs(\n-    job: str, dirs_to_run: List[str], dependents: dict\n+    job: str, dirs_to_run: Dict[str, Set[str]], dependents: dict\n ) -> List[Dict[str, str]]:\n     if job == \"lint\":\n         dirs = add_dependents(\n             dirs_to_run[\"lint\"] | dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"],\n             dependents,\n         )\n-    elif job in [\"test\", \"compile-integration-tests\", \"dependencies\"]:\n+    elif job in [\"test\", \"compile-integration-tests\", \"dependencies\", \"test-pydantic\"]:\n         dirs = add_dependents(\n             dirs_to_run[\"test\"] | dirs_to_run[\"extended-test\"], dependents\n         )\n@@ -165,6 +225,7 @@ def _get_configs_for_multi_dirs(\n         dirs_to_run[\"lint\"] = all_package_dirs()\n         dirs_to_run[\"test\"] = all_package_dirs()\n         dirs_to_run[\"extended-test\"] = set(LANGCHAIN_DIRS)\n+\n     for file in files:\n         if any(\n             file.startswith(dir_)\n@@ -182,8 +243,12 @@ def _get_configs_for_multi_dirs(\n         if any(file.startswith(dir_) for dir_ in LANGCHAIN_DIRS):\n             # add that dir and all dirs after in LANGCHAIN_DIRS\n             # for extended testing\n+\n             found = False\n             for dir_ in LANGCHAIN_DIRS:\n+                if dir_ == \"libs/core\" and IGNORE_CORE_DEPENDENTS:\n+                    dirs_to_run[\"extended-test\"].add(dir_)\n+                    continue\n                 if file.startswith(dir_):\n                     found = True\n                 if found:\n@@ -224,7 +289,6 @@ def _get_configs_for_multi_dirs(\n \n     # we now have dirs_by_job\n     # todo: clean this up\n-\n     map_job_to_configs = {\n         job: _get_configs_for_multi_dirs(job, dirs_to_run, dependents)\n         for job in [\n@@ -233,6 +297,7 @@ def _get_configs_for_multi_dirs(\n             \"extended-tests\",\n             \"compile-integration-tests\",\n             \"dependencies\",\n+            \"test-pydantic\",\n         ]\n     }\n     map_job_to_configs[\"test-doc-imports\"] = ("
        },
        {
          "filename": ".github/scripts/check_prerelease_dependencies.py",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -11,7 +11,7 @@\n \n     # see if we're releasing an rc\n     version = toml_data[\"tool\"][\"poetry\"][\"version\"]\n-    releasing_rc = \"rc\" in version\n+    releasing_rc = \"rc\" in version or \"dev\" in version\n \n     # if not, iterate through dependencies and make sure none allow prereleases\n     if not releasing_rc:"
        },
        {
          "filename": ".github/scripts/get_min_versions.py",
          "status": "modified",
          "additions": 40,
          "deletions": 2,
          "patch": "@@ -1,4 +1,5 @@\n import sys\n+from typing import Optional\n \n if sys.version_info >= (3, 11):\n     import tomllib\n@@ -7,6 +8,9 @@\n     import tomli as tomllib\n \n from packaging.version import parse as parse_version\n+from packaging.specifiers import SpecifierSet\n+from packaging.version import Version\n+\n import re\n \n MIN_VERSION_LIBS = [\n@@ -15,6 +19,7 @@\n     \"langchain\",\n     \"langchain-text-splitters\",\n     \"SQLAlchemy\",\n+    \"pydantic\",\n ]\n \n SKIP_IF_PULL_REQUEST = [\"langchain-core\"]\n@@ -45,7 +50,13 @@ def get_min_version(version: str) -> str:\n     raise ValueError(f\"Unrecognized version format: {version}\")\n \n \n-def get_min_version_from_toml(toml_path: str, versions_for: str):\n+def get_min_version_from_toml(\n+    toml_path: str,\n+    versions_for: str,\n+    python_version: str,\n+    *,\n+    include: Optional[list] = None,\n+):\n     # Parse the TOML file\n     with open(toml_path, \"rb\") as file:\n         toml_data = tomllib.load(file)\n@@ -64,11 +75,20 @@ def get_min_version_from_toml(toml_path: str, versions_for: str):\n             continue\n         # Check if the lib is present in the dependencies\n         if lib in dependencies:\n+            if include and lib not in include:\n+                continue\n             # Get the version string\n             version_string = dependencies[lib]\n \n             if isinstance(version_string, dict):\n                 version_string = version_string[\"version\"]\n+            if isinstance(version_string, list):\n+                version_string = [\n+                    vs\n+                    for vs in version_string\n+                    if check_python_version(python_version, vs[\"python\"])\n+                ][0][\"version\"]\n+\n \n             # Use parse_version to get the minimum supported version from version_string\n             min_version = get_min_version(version_string)\n@@ -79,13 +99,31 @@ def get_min_version_from_toml(toml_path: str, versions_for: str):\n     return min_versions\n \n \n+def check_python_version(version_string, constraint_string):\n+    \"\"\"\n+    Check if the given Python version matches the given constraints.\n+\n+    :param version_string: A string representing the Python version (e.g. \"3.8.5\").\n+    :param constraint_string: A string representing the package's Python version constraints (e.g. \">=3.6, <4.0\").\n+    :return: True if the version matches the constraints, False otherwise.\n+    \"\"\"\n+    try:\n+        version = Version(version_string)\n+        constraints = SpecifierSet(constraint_string)\n+        return version in constraints\n+    except Exception as e:\n+        print(f\"Error: {e}\")\n+        return False\n+\n+\n if __name__ == \"__main__\":\n     # Get the TOML file path from the command line argument\n     toml_file = sys.argv[1]\n     versions_for = sys.argv[2]\n+    python_version = sys.argv[3]\n     assert versions_for in [\"release\", \"pull_request\"]\n \n     # Call the function to get the minimum versions\n-    min_versions = get_min_version_from_toml(toml_file, versions_for)\n+    min_versions = get_min_version_from_toml(toml_file, versions_for, python_version)\n \n     print(\" \".join([f\"{lib}=={version}\" for lib, version in min_versions.items()]))"
        },
        {
          "filename": ".github/workflows/_dependencies.yml",
          "status": "removed",
          "additions": 0,
          "deletions": 114,
          "patch": "@@ -1,114 +0,0 @@\n-name: dependencies\n-\n-on:\n-  workflow_call:\n-    inputs:\n-      working-directory:\n-        required: true\n-        type: string\n-        description: \"From which folder this pipeline executes\"\n-      langchain-location:\n-        required: false\n-        type: string\n-        description: \"Relative path to the langchain library folder\"\n-      python-version:\n-        required: true\n-        type: string\n-        description: \"Python version to use\"\n-\n-env:\n-  POETRY_VERSION: \"1.7.1\"\n-\n-jobs:\n-  build:\n-    defaults:\n-      run:\n-        working-directory: ${{ inputs.working-directory }}\n-    runs-on: ubuntu-latest\n-    name: dependency checks ${{ inputs.python-version }}\n-    steps:\n-      - uses: actions/checkout@v4\n-\n-      - name: Set up Python ${{ inputs.python-version }} + Poetry ${{ env.POETRY_VERSION }}\n-        uses: \"./.github/actions/poetry_setup\"\n-        with:\n-          python-version: ${{ inputs.python-version }}\n-          poetry-version: ${{ env.POETRY_VERSION }}\n-          working-directory: ${{ inputs.working-directory }}\n-          cache-key: pydantic-cross-compat\n-\n-      - name: Install dependencies\n-        shell: bash\n-        run: poetry install\n-\n-      - name: Check imports with base dependencies\n-        shell: bash\n-        run: poetry run make check_imports\n-\n-      - name: Install test dependencies\n-        shell: bash\n-        run: poetry install --with test\n-\n-      - name: Install langchain editable\n-        working-directory: ${{ inputs.working-directory }}\n-        if: ${{ inputs.langchain-location }}\n-        env:\n-          LANGCHAIN_LOCATION: ${{ inputs.langchain-location }}\n-        run: |\n-          poetry run pip install -e \"$LANGCHAIN_LOCATION\"\n-\n-      - name: Install the opposite major version of pydantic\n-        # If normal tests use pydantic v1, here we'll use v2, and vice versa.\n-        shell: bash\n-        # airbyte currently doesn't support pydantic v2\n-        if: ${{ !startsWith(inputs.working-directory, 'libs/partners/airbyte') }}\n-        run: |\n-          # Determine the major part of pydantic version\n-          REGULAR_VERSION=$(poetry run python -c \"import pydantic; print(pydantic.__version__)\" | cut -d. -f1)\n-\n-          if [[ \"$REGULAR_VERSION\" == \"1\" ]]; then\n-            PYDANTIC_DEP=\">=2.1,<3\"\n-            TEST_WITH_VERSION=\"2\"\n-          elif [[ \"$REGULAR_VERSION\" == \"2\" ]]; then\n-            PYDANTIC_DEP=\"<2\"\n-            TEST_WITH_VERSION=\"1\"\n-          else\n-            echo \"Unexpected pydantic major version '$REGULAR_VERSION', cannot determine which version to use for cross-compatibility test.\"\n-            exit 1\n-          fi\n-\n-          # Install via `pip` instead of `poetry add` to avoid changing lockfile,\n-          # which would prevent caching from working: the cache would get saved\n-          # to a different key than where it gets loaded from.\n-          poetry run pip install \"pydantic${PYDANTIC_DEP}\"\n-\n-          # Ensure that the correct pydantic is installed now.\n-          echo \"Checking pydantic version... Expecting ${TEST_WITH_VERSION}\"\n-\n-          # Determine the major part of pydantic version\n-          CURRENT_VERSION=$(poetry run python -c \"import pydantic; print(pydantic.__version__)\" | cut -d. -f1)\n-\n-          # Check that the major part of pydantic version is as expected, if not\n-          # raise an error\n-          if [[ \"$CURRENT_VERSION\" != \"$TEST_WITH_VERSION\" ]]; then\n-            echo \"Error: expected pydantic version ${CURRENT_VERSION} to have been installed, but found: ${TEST_WITH_VERSION}\"\n-            exit 1\n-          fi\n-          echo \"Found pydantic version ${CURRENT_VERSION}, as expected\"\n-      - name: Run pydantic compatibility tests\n-        # airbyte currently doesn't support pydantic v2\n-        if: ${{ !startsWith(inputs.working-directory, 'libs/partners/airbyte') }}\n-        shell: bash\n-        run: make test\n-\n-      - name: Ensure the tests did not create any additional files\n-        shell: bash\n-        run: |\n-          set -eu\n-\n-          STATUS=\"$(git status)\"\n-          echo \"$STATUS\"\n-\n-          # grep will exit non-zero if the target message isn't found,\n-          # and `set -e` above will cause the step to fail.\n-          echo \"$STATUS\" | grep 'nothing to commit, working tree clean'"
        },
        {
          "filename": ".github/workflows/_lint.yml",
          "status": "modified",
          "additions": 0,
          "deletions": 12,
          "patch": "@@ -7,10 +7,6 @@ on:\n         required: true\n         type: string\n         description: \"From which folder this pipeline executes\"\n-      langchain-location:\n-        required: false\n-        type: string\n-        description: \"Relative path to the langchain library folder\"\n       python-version:\n         required: true\n         type: string\n@@ -63,14 +59,6 @@ jobs:\n         run: |\n           poetry install --with lint,typing\n \n-      - name: Install langchain editable\n-        working-directory: ${{ inputs.working-directory }}\n-        if: ${{ inputs.langchain-location }}\n-        env:\n-          LANGCHAIN_LOCATION: ${{ inputs.langchain-location }}\n-        run: |\n-          poetry run pip install -e \"$LANGCHAIN_LOCATION\"\n-\n       - name: Get .mypy_cache to speed up mypy\n         uses: actions/cache@v4\n         env:"
        },
        {
          "filename": ".github/workflows/_release.yml",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -164,6 +164,7 @@ jobs:\n \n       - name: Set up Python + Poetry ${{ env.POETRY_VERSION }}\n         uses: \"./.github/actions/poetry_setup\"\n+        id: setup-python\n         with:\n           python-version: ${{ env.PYTHON_VERSION }}\n           poetry-version: ${{ env.POETRY_VERSION }}\n@@ -231,7 +232,7 @@ jobs:\n         id: min-version\n         run: |\n           poetry run pip install packaging\n-          min_versions=\"$(poetry run python $GITHUB_WORKSPACE/.github/scripts/get_min_versions.py pyproject.toml release)\"\n+          min_versions=\"$(poetry run python $GITHUB_WORKSPACE/.github/scripts/get_min_versions.py pyproject.toml release ${{ steps.setup-python.outputs.installed-python-version }})\"\n           echo \"min-versions=$min_versions\" >> \"$GITHUB_OUTPUT\"\n           echo \"min-versions=$min_versions\"\n "
        },
        {
          "filename": ".github/workflows/_test.yml",
          "status": "modified",
          "additions": 18,
          "deletions": 26,
          "patch": "@@ -7,10 +7,6 @@ on:\n         required: true\n         type: string\n         description: \"From which folder this pipeline executes\"\n-      langchain-location:\n-        required: false\n-        type: string\n-        description: \"Relative path to the langchain library folder\"\n       python-version:\n         required: true\n         type: string\n@@ -31,47 +27,30 @@ jobs:\n \n       - name: Set up Python ${{ inputs.python-version }} + Poetry ${{ env.POETRY_VERSION }}\n         uses: \"./.github/actions/poetry_setup\"\n+        id: setup-python\n         with:\n           python-version: ${{ inputs.python-version }}\n           poetry-version: ${{ env.POETRY_VERSION }}\n           working-directory: ${{ inputs.working-directory }}\n           cache-key: core\n-\n       - name: Install dependencies\n         shell: bash\n         run: poetry install --with test\n \n-      - name: Install langchain editable\n-        working-directory: ${{ inputs.working-directory }}\n-        if: ${{ inputs.langchain-location }}\n-        env:\n-          LANGCHAIN_LOCATION: ${{ inputs.langchain-location }}\n-        run: |\n-          poetry run pip install -e \"$LANGCHAIN_LOCATION\"\n-\n       - name: Run core tests\n         shell: bash\n         run: |\n           make test\n \n-      - name: Ensure the tests did not create any additional files\n-        shell: bash\n-        run: |\n-          set -eu\n-\n-          STATUS=\"$(git status)\"\n-          echo \"$STATUS\"\n-\n-          # grep will exit non-zero if the target message isn't found,\n-          # and `set -e` above will cause the step to fail.\n-          echo \"$STATUS\" | grep 'nothing to commit, working tree clean'\n-          \n       - name: Get minimum versions\n         working-directory: ${{ inputs.working-directory }}\n         id: min-version\n+        shell: bash\n         run: |\n           poetry run pip install packaging tomli\n-          min_versions=\"$(poetry run python $GITHUB_WORKSPACE/.github/scripts/get_min_versions.py pyproject.toml pull_request)\"\n+          echo \"Python version ${{ steps.setup-python.outputs.installed-python-version }}\"\n+          python_version=\"$(poetry run python --version | awk '{print $2}')\"\n+          min_versions=\"$(poetry run python $GITHUB_WORKSPACE/.github/scripts/get_min_versions.py pyproject.toml pull_request $python_version)\"\n           echo \"min-versions=$min_versions\" >> \"$GITHUB_OUTPUT\"\n           echo \"min-versions=$min_versions\"\n \n@@ -83,3 +62,16 @@ jobs:\n           poetry run pip install --force-reinstall $MIN_VERSIONS --editable .\n           make tests\n         working-directory: ${{ inputs.working-directory }}\n+\n+      - name: Ensure the tests did not create any additional files\n+        shell: bash\n+        run: |\n+          set -eu\n+\n+          STATUS=\"$(git status)\"\n+          echo \"$STATUS\"\n+\n+          # grep will exit non-zero if the target message isn't found,\n+          # and `set -e` above will cause the step to fail.\n+          echo \"$STATUS\" | grep 'nothing to commit, working tree clean'\n+          "
        },
        {
          "filename": ".github/workflows/_test_pydantic.yml",
          "status": "added",
          "additions": 64,
          "deletions": 0,
          "patch": "@@ -0,0 +1,64 @@\n+name: test pydantic intermediate versions\n+\n+on:\n+  workflow_call:\n+    inputs:\n+      working-directory:\n+        required: true\n+        type: string\n+        description: \"From which folder this pipeline executes\"\n+      python-version:\n+        required: false\n+        type: string\n+        description: \"Python version to use\"\n+        default: \"3.11\"\n+      pydantic-version:\n+        required: true\n+        type: string\n+        description: \"Pydantic version to test.\"\n+\n+env:\n+  POETRY_VERSION: \"1.7.1\"\n+\n+jobs:\n+  build:\n+    defaults:\n+      run:\n+        working-directory: ${{ inputs.working-directory }}\n+    runs-on: ubuntu-latest\n+    name: \"make test # pydantic: ~=${{ inputs.pydantic-version }}, python: ${{ inputs.python-version }}, \"\n+    steps:\n+      - uses: actions/checkout@v4\n+\n+      - name: Set up Python ${{ inputs.python-version }} + Poetry ${{ env.POETRY_VERSION }}\n+        uses: \"./.github/actions/poetry_setup\"\n+        with:\n+          python-version: ${{ inputs.python-version }}\n+          poetry-version: ${{ env.POETRY_VERSION }}\n+          working-directory: ${{ inputs.working-directory }}\n+          cache-key: core\n+\n+      - name: Install dependencies\n+        shell: bash\n+        run: poetry install --with test\n+\n+      - name: Overwrite pydantic version\n+        shell: bash\n+        run: poetry run pip install pydantic~=${{ inputs.pydantic-version }}\n+\n+      - name: Run core tests\n+        shell: bash\n+        run: |\n+          make test\n+\n+      - name: Ensure the tests did not create any additional files\n+        shell: bash\n+        run: |\n+          set -eu\n+\n+          STATUS=\"$(git status)\"\n+          echo \"$STATUS\"\n+\n+          # grep will exit non-zero if the target message isn't found,\n+          # and `set -e` above will cause the step to fail.\n+          echo \"$STATUS\" | grep 'nothing to commit, working tree clean'\n\\ No newline at end of file"
        },
        {
          "filename": ".github/workflows/check_diffs.yml",
          "status": "modified",
          "additions": 22,
          "deletions": 14,
          "patch": "@@ -31,6 +31,7 @@ jobs:\n         uses: Ana06/get-changed-files@v2.2.0\n       - id: set-matrix\n         run: |\n+          python -m pip install packaging\n           python .github/scripts/check_diff.py ${{ steps.files.outputs.all }} >> $GITHUB_OUTPUT\n     outputs:\n       lint: ${{ steps.set-matrix.outputs.lint }}\n@@ -39,13 +40,15 @@ jobs:\n       compile-integration-tests: ${{ steps.set-matrix.outputs.compile-integration-tests }}\n       dependencies: ${{ steps.set-matrix.outputs.dependencies }}\n       test-doc-imports: ${{ steps.set-matrix.outputs.test-doc-imports }}\n+      test-pydantic: ${{ steps.set-matrix.outputs.test-pydantic }}\n   lint:\n     name: cd ${{ matrix.job-configs.working-directory }}\n     needs: [ build ]\n     if: ${{ needs.build.outputs.lint != '[]' }}\n     strategy:\n       matrix:\n         job-configs: ${{ fromJson(needs.build.outputs.lint) }}\n+      fail-fast: false\n     uses: ./.github/workflows/_lint.yml\n     with:\n       working-directory: ${{ matrix.job-configs.working-directory }}\n@@ -59,18 +62,34 @@ jobs:\n     strategy:\n       matrix:\n         job-configs: ${{ fromJson(needs.build.outputs.test) }}\n+      fail-fast: false\n     uses: ./.github/workflows/_test.yml\n     with:\n       working-directory: ${{ matrix.job-configs.working-directory }}\n       python-version: ${{ matrix.job-configs.python-version }}\n     secrets: inherit\n \n+  test-pydantic:\n+    name: cd ${{ matrix.job-configs.working-directory }}\n+    needs: [ build ]\n+    if: ${{ needs.build.outputs.test-pydantic != '[]' }}\n+    strategy:\n+      matrix:\n+        job-configs: ${{ fromJson(needs.build.outputs.test-pydantic) }}\n+      fail-fast: false\n+    uses: ./.github/workflows/_test_pydantic.yml\n+    with:\n+      working-directory: ${{ matrix.job-configs.working-directory }}\n+      pydantic-version: ${{ matrix.job-configs.pydantic-version }}\n+    secrets: inherit\n+\n   test-doc-imports:\n     needs: [ build ]\n     if: ${{ needs.build.outputs.test-doc-imports != '[]' }}\n     strategy:\n       matrix:\n         job-configs: ${{ fromJson(needs.build.outputs.test-doc-imports) }}\n+      fail-fast: false\n     uses: ./.github/workflows/_test_doc_imports.yml\n     secrets: inherit\n     with:\n@@ -83,25 +102,13 @@ jobs:\n     strategy:\n       matrix:\n         job-configs: ${{ fromJson(needs.build.outputs.compile-integration-tests) }}\n+      fail-fast: false\n     uses: ./.github/workflows/_compile_integration_test.yml\n     with:\n       working-directory: ${{ matrix.job-configs.working-directory }}\n       python-version: ${{ matrix.job-configs.python-version }}\n     secrets: inherit\n \n-  dependencies:\n-    name: cd ${{ matrix.job-configs.working-directory }}\n-    needs: [ build ]\n-    if: ${{ needs.build.outputs.dependencies != '[]' }}\n-    strategy:\n-      matrix:\n-        job-configs: ${{ fromJson(needs.build.outputs.dependencies) }}\n-    uses: ./.github/workflows/_dependencies.yml\n-    with:\n-      working-directory: ${{ matrix.job-configs.working-directory }}\n-      python-version: ${{ matrix.job-configs.python-version }}\n-    secrets: inherit\n-\n   extended-tests:\n     name: \"cd ${{ matrix.job-configs.working-directory }} / make extended_tests #${{ matrix.job-configs.python-version }}\"\n     needs: [ build ]\n@@ -110,6 +117,7 @@ jobs:\n       matrix:\n         # note different variable for extended test dirs\n         job-configs: ${{ fromJson(needs.build.outputs.extended-tests) }}\n+      fail-fast: false\n     runs-on: ubuntu-latest\n     defaults:\n       run:\n@@ -149,7 +157,7 @@ jobs:\n           echo \"$STATUS\" | grep 'nothing to commit, working tree clean'\n   ci_success:\n     name: \"CI Success\"\n-    needs: [build, lint, test, compile-integration-tests, dependencies, extended-tests, test-doc-imports]\n+    needs: [build, lint, test, compile-integration-tests, extended-tests, test-doc-imports, test-pydantic]\n     if: |\n       always()\n     runs-on: ubuntu-latest"
        },
        {
          "filename": ".github/workflows/codespell.yml",
          "status": "modified",
          "additions": 1,
          "deletions": 2,
          "patch": "@@ -3,9 +3,8 @@ name: CI / cd . / make spell_check\n \n on:\n   push:\n-    branches: [master, v0.1]\n+    branches: [master, v0.1, v0.2]\n   pull_request:\n-    branches: [master, v0.1]\n \n permissions:\n   contents: read"
        },
        {
          "filename": ".github/workflows/scheduled_test.yml",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -17,7 +17,7 @@ jobs:\n       fail-fast: false\n       matrix:\n         python-version:\n-          - \"3.8\"\n+          - \"3.9\"\n           - \"3.11\"\n         working-directory:\n           - \"libs/partners/openai\""
        },
        {
          "filename": "Makefile",
          "status": "modified",
          "additions": 0,
          "deletions": 1,
          "patch": "@@ -36,7 +36,6 @@ api_docs_build:\n API_PKG ?= text-splitters\n \n api_docs_quick_preview:\n-\tpoetry run pip install \"pydantic<2\"\n \tpoetry run python docs/api_reference/create_api_rst.py $(API_PKG)\n \tcd docs/api_reference && poetry run make html\n \tpoetry run python docs/api_reference/scripts/custom_formatter.py docs/api_reference/_build/html/"
        },
        {
          "filename": "cookbook/code-analysis-deeplake.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -90,7 +90,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"# Please manually enter OpenAI Key\"\n    ]\n   },"
        },
        {
          "filename": "docs/Makefile",
          "status": "modified",
          "additions": 2,
          "deletions": 6,
          "patch": "@@ -33,8 +33,8 @@ install-py-deps:\n \tpython3 -m venv .venv\n \t$(PYTHON) -m pip install --upgrade pip\n \t$(PYTHON) -m pip install --upgrade uv\n-\t$(PYTHON) -m uv pip install -r vercel_requirements.txt\n-\t$(PYTHON) -m uv pip install --editable $(PARTNER_DEPS_LIST)\n+\t$(PYTHON) -m uv pip install --pre -r vercel_requirements.txt\n+\t$(PYTHON) -m uv pip install --pre --editable $(PARTNER_DEPS_LIST)\n \n generate-files:\n \tmkdir -p $(INTERMEDIATE_DIR)\n@@ -86,10 +86,6 @@ vercel-build: install-vercel-deps build generate-references\n \tmv langchain-api-docs-build/api_reference_build/html/* static/api_reference/\n \trm -rf langchain-api-docs-build\n \tNODE_OPTIONS=\"--max-old-space-size=5000\" yarn run docusaurus build\n-\tmv build v0.2\n-\tmkdir build\n-\tmv v0.2 build\n-\tmv build/v0.2/404.html build\n \n start:\n \tcd $(OUTPUT_NEW_DIR) && yarn && yarn start --port=$(PORT)"
        },
        {
          "filename": "docs/api_reference/guide_imports.json",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": null
        },
        {
          "filename": "docs/api_reference/requirements.txt",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -1,5 +1,5 @@\n-autodoc_pydantic>=1,<2\n-sphinx<=7\n+autodoc_pydantic>=2,<3\n+sphinx>=8,<9\n myst-parser>=3\n sphinx-autobuild>=2024\n pydata-sphinx-theme>=0.15\n@@ -8,4 +8,4 @@ myst-nb>=1.1.1\n pyyaml\n sphinx-design\n sphinx-copybutton\n-beautifulsoup4\n\\ No newline at end of file\n+beautifulsoup4"
        },
        {
          "filename": "docs/api_reference/scripts/custom_formatter.py",
          "status": "modified",
          "additions": 4,
          "deletions": 1,
          "patch": "@@ -17,7 +17,10 @@ def process_toc_h3_elements(html_content: str) -> str:\n \n     # Process each element\n     for element in toc_h3_elements:\n-        element = element.a.code.span\n+        try:\n+            element = element.a.code.span\n+        except Exception:\n+            continue\n         # Get the text content of the element\n         content = element.get_text()\n "
        },
        {
          "filename": "docs/api_reference/templates/pydantic.rst",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -15,7 +15,7 @@\n     :member-order: groupwise\n     :show-inheritance: True\n     :special-members: __call__\n-    :exclude-members: construct, copy, dict, from_orm, parse_file, parse_obj, parse_raw, schema, schema_json, update_forward_refs, validate, json, is_lc_serializable, to_json, to_json_not_implemented, lc_secrets, lc_attributes, lc_id, get_lc_namespace\n+    :exclude-members: construct, copy, dict, from_orm, parse_file, parse_obj, parse_raw, schema, schema_json, update_forward_refs, validate, json, is_lc_serializable, to_json, to_json_not_implemented, lc_secrets, lc_attributes, lc_id, get_lc_namespace, model_construct, model_copy, model_dump, model_dump_json, model_parametrized_name, model_post_init, model_rebuild, model_validate, model_validate_json, model_validate_strings, model_extra, model_fields_set, model_json_schema\n \n \n     {% block attributes %}"
        },
        {
          "filename": "docs/api_reference/templates/runnable_pydantic.rst",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -15,7 +15,7 @@\n     :member-order: groupwise\n     :show-inheritance: True\n     :special-members: __call__\n-    :exclude-members: construct, copy, dict, from_orm, parse_file, parse_obj, parse_raw, schema, schema_json, update_forward_refs, validate, json, is_lc_serializable, to_json_not_implemented, lc_secrets, lc_attributes, lc_id, get_lc_namespace, astream_log, transform, atransform, get_output_schema, get_prompts, config_schema, map, pick, pipe, with_listeners, with_alisteners, with_config, with_fallbacks, with_types, with_retry, InputType, OutputType, config_specs, output_schema, get_input_schema, get_graph, get_name, input_schema, name, bind, assign, as_tool\n+    :exclude-members: construct, copy, dict, from_orm, parse_file, parse_obj, parse_raw, schema, schema_json, update_forward_refs, validate, json, is_lc_serializable, to_json_not_implemented, lc_secrets, lc_attributes, lc_id, get_lc_namespace, astream_log, transform, atransform, get_output_schema, get_prompts, config_schema, map, pick, pipe, with_listeners, with_alisteners, with_config, with_fallbacks, with_types, with_retry, InputType, OutputType, config_specs, output_schema, get_input_schema, get_graph, get_name, input_schema, name, bind, assign, as_tool, get_config_jsonschema, get_input_jsonschema, get_output_jsonschema, model_construct, model_copy, model_dump, model_dump_json, model_parametrized_name, model_post_init, model_rebuild, model_validate, model_validate_json, model_validate_strings, to_json, model_extra, model_fields_set, model_json_schema\n \n     .. NOTE:: {{objname}} implements the standard :py:class:`Runnable Interface <langchain_core.runnables.base.Runnable>`. \ud83c\udfc3\n "
        },
        {
          "filename": "docs/docs/additional_resources/arxiv_references.mdx",
          "status": "modified",
          "additions": 36,
          "deletions": 36,
          "patch": "@@ -13,45 +13,45 @@ From the opposite direction, scientists use `LangChain` in research and referenc\n \n | arXiv id / Title | Authors | Published date \ud83d\udd3b | LangChain Documentation|\n |------------------|---------|-------------------|------------------------|\n-| `2403.14403v2` [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](http://arxiv.org/abs/2403.14403v2) | Soyeong Jeong, Jinheon Baek, Sukmin Cho,  et al. | 2024&#8209;03&#8209;21 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+| `2403.14403v2` [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](http://arxiv.org/abs/2403.14403v2) | Soyeong Jeong, Jinheon Baek, Sukmin Cho,  et al. | 2024&#8209;03&#8209;21 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts)\n | `2402.03620v1` [Self-Discover: Large Language Models Self-Compose Reasoning Structures](http://arxiv.org/abs/2402.03620v1) | Pei Zhou, Jay Pujara, Xiang Ren,  et al. | 2024&#8209;02&#8209;06 | `Cookbook:` [Self-Discover](https://github.com/langchain-ai/langchain/blob/master/cookbook/self-discover.ipynb)\n-| `2402.03367v2` [RAG-Fusion: a New Take on Retrieval-Augmented Generation](http://arxiv.org/abs/2402.03367v2) | Zackary Rackauckas | 2024&#8209;01&#8209;31 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+| `2402.03367v2` [RAG-Fusion: a New Take on Retrieval-Augmented Generation](http://arxiv.org/abs/2402.03367v2) | Zackary Rackauckas | 2024&#8209;01&#8209;31 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts)\n | `2401.18059v1` [RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval](http://arxiv.org/abs/2401.18059v1) | Parth Sarthi, Salman Abdullah, Aditi Tuli,  et al. | 2024&#8209;01&#8209;31 | `Cookbook:` [Raptor](https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb)\n-| `2401.15884v2` [Corrective Retrieval Augmented Generation](http://arxiv.org/abs/2401.15884v2) | Shi-Qi Yan, Jia-Chen Gu, Yun Zhu,  et al. | 2024&#8209;01&#8209;29 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts), `Cookbook:` [Langgraph Crag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_crag.ipynb)\n-| `2401.08500v1` [Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering](http://arxiv.org/abs/2401.08500v1) | Tal Ridnik, Dedy Kredo, Itamar Friedman | 2024&#8209;01&#8209;16 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+| `2401.15884v2` [Corrective Retrieval Augmented Generation](http://arxiv.org/abs/2401.15884v2) | Shi-Qi Yan, Jia-Chen Gu, Yun Zhu,  et al. | 2024&#8209;01&#8209;29 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts), `Cookbook:` [Langgraph Crag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_crag.ipynb)\n+| `2401.08500v1` [Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering](http://arxiv.org/abs/2401.08500v1) | Tal Ridnik, Dedy Kredo, Itamar Friedman | 2024&#8209;01&#8209;16 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts)\n | `2401.04088v1` [Mixtral of Experts](http://arxiv.org/abs/2401.04088v1) | Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux,  et al. | 2024&#8209;01&#8209;08 | `Cookbook:` [Together Ai](https://github.com/langchain-ai/langchain/blob/master/cookbook/together_ai.ipynb)\n | `2312.06648v2` [Dense X Retrieval: What Retrieval Granularity Should We Use?](http://arxiv.org/abs/2312.06648v2) | Tong Chen, Hongwei Wang, Sihao Chen,  et al. | 2023&#8209;12&#8209;11 | `Template:` [propositional-retrieval](https://python.langchain.com/docs/templates/propositional-retrieval)\n | `2311.09210v1` [Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models](http://arxiv.org/abs/2311.09210v1) | Wenhao Yu, Hongming Zhang, Xiaoman Pan,  et al. | 2023&#8209;11&#8209;15 | `Template:` [chain-of-note-wiki](https://python.langchain.com/docs/templates/chain-of-note-wiki)\n-| `2310.11511v1` [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](http://arxiv.org/abs/2310.11511v1) | Akari Asai, Zeqiu Wu, Yizhong Wang,  et al. | 2023&#8209;10&#8209;17 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts), `Cookbook:` [Langgraph Self Rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_self_rag.ipynb)\n-| `2310.06117v2` [Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models](http://arxiv.org/abs/2310.06117v2) | Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,  et al. | 2023&#8209;10&#8209;09 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts), `Template:` [stepback-qa-prompting](https://python.langchain.com/docs/templates/stepback-qa-prompting), `Cookbook:` [Stepback-Qa](https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb)\n+| `2310.11511v1` [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](http://arxiv.org/abs/2310.11511v1) | Akari Asai, Zeqiu Wu, Yizhong Wang,  et al. | 2023&#8209;10&#8209;17 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts), `Cookbook:` [Langgraph Self Rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_self_rag.ipynb)\n+| `2310.06117v2` [Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models](http://arxiv.org/abs/2310.06117v2) | Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,  et al. | 2023&#8209;10&#8209;09 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts), `Template:` [stepback-qa-prompting](https://python.langchain.com/docs/templates/stepback-qa-prompting), `Cookbook:` [Stepback-Qa](https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb)\n | `2307.15337v3` [Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation](http://arxiv.org/abs/2307.15337v3) | Xuefei Ning, Zinan Lin, Zixuan Zhou,  et al. | 2023&#8209;07&#8209;28 | `Template:` [skeleton-of-thought](https://python.langchain.com/docs/templates/skeleton-of-thought)\n | `2307.09288v2` [Llama 2: Open Foundation and Fine-Tuned Chat Models](http://arxiv.org/abs/2307.09288v2) | Hugo Touvron, Louis Martin, Kevin Stone,  et al. | 2023&#8209;07&#8209;18 | `Cookbook:` [Semi Structured Rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb)\n-| `2307.03172v3` [Lost in the Middle: How Language Models Use Long Contexts](http://arxiv.org/abs/2307.03172v3) | Nelson F. Liu, Kevin Lin, John Hewitt,  et al. | 2023&#8209;07&#8209;06 | `Docs:` [docs/how_to/long_context_reorder](https://python.langchain.com/v0.2/docs/how_to/long_context_reorder)\n+| `2307.03172v3` [Lost in the Middle: How Language Models Use Long Contexts](http://arxiv.org/abs/2307.03172v3) | Nelson F. Liu, Kevin Lin, John Hewitt,  et al. | 2023&#8209;07&#8209;06 | `Docs:` [docs/how_to/long_context_reorder](https://python.langchain.com/docs/how_to/long_context_reorder)\n | `2305.14283v3` [Query Rewriting for Retrieval-Augmented Large Language Models](http://arxiv.org/abs/2305.14283v3) | Xinbei Ma, Yeyun Gong, Pengcheng He,  et al. | 2023&#8209;05&#8209;23 | `Template:` [rewrite-retrieve-read](https://python.langchain.com/docs/templates/rewrite-retrieve-read), `Cookbook:` [Rewrite](https://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb)\n | `2305.08291v1` [Large Language Model Guided Tree-of-Thought](http://arxiv.org/abs/2305.08291v1) | Jieyi Long | 2023&#8209;05&#8209;15 | `API:` [langchain_experimental.tot](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.tot), `Cookbook:` [Tree Of Thought](https://github.com/langchain-ai/langchain/blob/master/cookbook/tree_of_thought.ipynb)\n | `2305.04091v3` [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](http://arxiv.org/abs/2305.04091v3) | Lei Wang, Wanyu Xu, Yihuai Lan,  et al. | 2023&#8209;05&#8209;06 | `Cookbook:` [Plan And Execute Agent](https://github.com/langchain-ai/langchain/blob/master/cookbook/plan_and_execute_agent.ipynb)\n-| `2305.02156v1` [Zero-Shot Listwise Document Reranking with a Large Language Model](http://arxiv.org/abs/2305.02156v1) | Xueguang Ma, Xinyu Zhang, Ronak Pradeep,  et al. | 2023&#8209;05&#8209;03 | `Docs:` [docs/how_to/contextual_compression](https://python.langchain.com/v0.2/docs/how_to/contextual_compression), `API:` [langchain...LLMListwiseRerank](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html#langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank)\n+| `2305.02156v1` [Zero-Shot Listwise Document Reranking with a Large Language Model](http://arxiv.org/abs/2305.02156v1) | Xueguang Ma, Xinyu Zhang, Ronak Pradeep,  et al. | 2023&#8209;05&#8209;03 | `Docs:` [docs/how_to/contextual_compression](https://python.langchain.com/docs/how_to/contextual_compression), `API:` [langchain...LLMListwiseRerank](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html#langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank)\n | `2304.08485v2` [Visual Instruction Tuning](http://arxiv.org/abs/2304.08485v2) | Haotian Liu, Chunyuan Li, Qingyang Wu,  et al. | 2023&#8209;04&#8209;17 | `Cookbook:` [Semi Structured Multi Modal Rag Llama2](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb), [Semi Structured And Multi Modal Rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb)\n | `2304.03442v2` [Generative Agents: Interactive Simulacra of Human Behavior](http://arxiv.org/abs/2304.03442v2) | Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai,  et al. | 2023&#8209;04&#8209;07 | `Cookbook:` [Generative Agents Interactive Simulacra Of Human Behavior](https://github.com/langchain-ai/langchain/blob/master/cookbook/generative_agents_interactive_simulacra_of_human_behavior.ipynb), [Multiagent Bidding](https://github.com/langchain-ai/langchain/blob/master/cookbook/multiagent_bidding.ipynb)\n | `2303.17760v2` [CAMEL: Communicative Agents for \"Mind\" Exploration of Large Language Model Society](http://arxiv.org/abs/2303.17760v2) | Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani,  et al. | 2023&#8209;03&#8209;31 | `Cookbook:` [Camel Role Playing](https://github.com/langchain-ai/langchain/blob/master/cookbook/camel_role_playing.ipynb)\n | `2303.17580v4` [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](http://arxiv.org/abs/2303.17580v4) | Yongliang Shen, Kaitao Song, Xu Tan,  et al. | 2023&#8209;03&#8209;30 | `API:` [langchain_experimental.autonomous_agents](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.autonomous_agents), `Cookbook:` [Hugginggpt](https://github.com/langchain-ai/langchain/blob/master/cookbook/hugginggpt.ipynb)\n | `2301.10226v4` [A Watermark for Large Language Models](http://arxiv.org/abs/2301.10226v4) | John Kirchenbauer, Jonas Geiping, Yuxin Wen,  et al. | 2023&#8209;01&#8209;24 | `API:` [langchain_community...OCIModelDeploymentTGI](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI.html#langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI), [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint)\n-| `2212.10496v1` [Precise Zero-Shot Dense Retrieval without Relevance Labels](http://arxiv.org/abs/2212.10496v1) | Luyu Gao, Xueguang Ma, Jimmy Lin,  et al. | 2022&#8209;12&#8209;20 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts), `API:` [langchain...HypotheticalDocumentEmbedder](https://api.python.langchain.com/en/latest/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html#langchain.chains.hyde.base.HypotheticalDocumentEmbedder), `Template:` [hyde](https://python.langchain.com/docs/templates/hyde), `Cookbook:` [Hypothetical Document Embeddings](https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb)\n-| `2212.08073v1` [Constitutional AI: Harmlessness from AI Feedback](http://arxiv.org/abs/2212.08073v1) | Yuntao Bai, Saurav Kadavath, Sandipan Kundu,  et al. | 2022&#8209;12&#8209;15 | `Docs:` [docs/versions/migrating_chains/constitutional_chain](https://python.langchain.com/v0.2/docs/versions/migrating_chains/constitutional_chain)\n+| `2212.10496v1` [Precise Zero-Shot Dense Retrieval without Relevance Labels](http://arxiv.org/abs/2212.10496v1) | Luyu Gao, Xueguang Ma, Jimmy Lin,  et al. | 2022&#8209;12&#8209;20 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts), `API:` [langchain...HypotheticalDocumentEmbedder](https://api.python.langchain.com/en/latest/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html#langchain.chains.hyde.base.HypotheticalDocumentEmbedder), `Template:` [hyde](https://python.langchain.com/docs/templates/hyde), `Cookbook:` [Hypothetical Document Embeddings](https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb)\n+| `2212.08073v1` [Constitutional AI: Harmlessness from AI Feedback](http://arxiv.org/abs/2212.08073v1) | Yuntao Bai, Saurav Kadavath, Sandipan Kundu,  et al. | 2022&#8209;12&#8209;15 | `Docs:` [docs/versions/migrating_chains/constitutional_chain](https://python.langchain.com/docs/versions/migrating_chains/constitutional_chain)\n | `2212.07425v3` [Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments](http://arxiv.org/abs/2212.07425v3) | Zhivar Sourati, Vishnu Priya Prasanna Venkatesh, Darshan Deshpande,  et al. | 2022&#8209;12&#8209;12 | `API:` [langchain_experimental.fallacy_removal](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.fallacy_removal)\n | `2211.13892v2` [Complementary Explanations for Effective In-Context Learning](http://arxiv.org/abs/2211.13892v2) | Xi Ye, Srinivasan Iyer, Asli Celikyilmaz,  et al. | 2022&#8209;11&#8209;25 | `API:` [langchain_core...MaxMarginalRelevanceExampleSelector](https://api.python.langchain.com/en/latest/example_selectors/langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector.html#langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector)\n | `2211.10435v2` [PAL: Program-aided Language Models](http://arxiv.org/abs/2211.10435v2) | Luyu Gao, Aman Madaan, Shuyan Zhou,  et al. | 2022&#8209;11&#8209;18 | `API:` [langchain_experimental.pal_chain](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.pal_chain), [langchain_experimental...PALChain](https://api.python.langchain.com/en/latest/pal_chain/langchain_experimental.pal_chain.base.PALChain.html#langchain_experimental.pal_chain.base.PALChain), `Cookbook:` [Program Aided Language Model](https://github.com/langchain-ai/langchain/blob/master/cookbook/program_aided_language_model.ipynb)\n-| `2210.11934v2` [An Analysis of Fusion Functions for Hybrid Retrieval](http://arxiv.org/abs/2210.11934v2) | Sebastian Bruch, Siyu Gai, Amir Ingber | 2022&#8209;10&#8209;21 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n-| `2210.03629v3` [ReAct: Synergizing Reasoning and Acting in Language Models](http://arxiv.org/abs/2210.03629v3) | Shunyu Yao, Jeffrey Zhao, Dian Yu,  et al. | 2022&#8209;10&#8209;06 | `Docs:` [docs/integrations/tools/ionic_shopping](https://python.langchain.com/v0.2/docs/integrations/tools/ionic_shopping), [docs/integrations/providers/cohere](https://python.langchain.com/v0.2/docs/integrations/providers/cohere), [docs/concepts](https://python.langchain.com/v0.2/docs/concepts), `API:` [langchain...create_react_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent), [langchain...TrajectoryEvalChain](https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html#langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain)\n-| `2209.10785v2` [Deep Lake: a Lakehouse for Deep Learning](http://arxiv.org/abs/2209.10785v2) | Sasun Hambardzumyan, Abhinav Tuli, Levon Ghukasyan,  et al. | 2022&#8209;09&#8209;22 | `Docs:` [docs/integrations/providers/activeloop_deeplake](https://python.langchain.com/v0.2/docs/integrations/providers/activeloop_deeplake)\n-| `2205.13147v4` [Matryoshka Representation Learning](http://arxiv.org/abs/2205.13147v4) | Aditya Kusupati, Gantavya Bhatt, Aniket Rege,  et al. | 2022&#8209;05&#8209;26 | `Docs:` [docs/integrations/providers/snowflake](https://python.langchain.com/v0.2/docs/integrations/providers/snowflake)\n+| `2210.11934v2` [An Analysis of Fusion Functions for Hybrid Retrieval](http://arxiv.org/abs/2210.11934v2) | Sebastian Bruch, Siyu Gai, Amir Ingber | 2022&#8209;10&#8209;21 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts)\n+| `2210.03629v3` [ReAct: Synergizing Reasoning and Acting in Language Models](http://arxiv.org/abs/2210.03629v3) | Shunyu Yao, Jeffrey Zhao, Dian Yu,  et al. | 2022&#8209;10&#8209;06 | `Docs:` [docs/integrations/tools/ionic_shopping](https://python.langchain.com/docs/integrations/tools/ionic_shopping), [docs/integrations/providers/cohere](https://python.langchain.com/docs/integrations/providers/cohere), [docs/concepts](https://python.langchain.com/docs/concepts), `API:` [langchain...create_react_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent), [langchain...TrajectoryEvalChain](https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html#langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain)\n+| `2209.10785v2` [Deep Lake: a Lakehouse for Deep Learning](http://arxiv.org/abs/2209.10785v2) | Sasun Hambardzumyan, Abhinav Tuli, Levon Ghukasyan,  et al. | 2022&#8209;09&#8209;22 | `Docs:` [docs/integrations/providers/activeloop_deeplake](https://python.langchain.com/docs/integrations/providers/activeloop_deeplake)\n+| `2205.13147v4` [Matryoshka Representation Learning](http://arxiv.org/abs/2205.13147v4) | Aditya Kusupati, Gantavya Bhatt, Aniket Rege,  et al. | 2022&#8209;05&#8209;26 | `Docs:` [docs/integrations/providers/snowflake](https://python.langchain.com/docs/integrations/providers/snowflake)\n | `2205.12654v1` [Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages](http://arxiv.org/abs/2205.12654v1) | Kevin Heffernan, Onur \u00c7elebi, Holger Schwenk | 2022&#8209;05&#8209;25 | `API:` [langchain_community...LaserEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.laser.LaserEmbeddings.html#langchain_community.embeddings.laser.LaserEmbeddings)\n-| `2204.00498v1` [Evaluating the Text-to-SQL Capabilities of Large Language Models](http://arxiv.org/abs/2204.00498v1) | Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau | 2022&#8209;03&#8209;15 | `Docs:` [docs/tutorials/sql_qa](https://python.langchain.com/v0.2/docs/tutorials/sql_qa), `API:` [langchain_community...SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), [langchain_community...SparkSQL](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.spark_sql.SparkSQL.html#langchain_community.utilities.spark_sql.SparkSQL)\n+| `2204.00498v1` [Evaluating the Text-to-SQL Capabilities of Large Language Models](http://arxiv.org/abs/2204.00498v1) | Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau | 2022&#8209;03&#8209;15 | `Docs:` [docs/tutorials/sql_qa](https://python.langchain.com/docs/tutorials/sql_qa), `API:` [langchain_community...SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), [langchain_community...SparkSQL](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.spark_sql.SparkSQL.html#langchain_community.utilities.spark_sql.SparkSQL)\n | `2202.00666v5` [Locally Typical Sampling](http://arxiv.org/abs/2202.00666v5) | Clara Meister, Tiago Pimentel, Gian Wiher,  et al. | 2022&#8209;02&#8209;01 | `API:` [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint)\n-| `2112.01488v3` [ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction](http://arxiv.org/abs/2112.01488v3) | Keshav Santhanam, Omar Khattab, Jon Saad-Falcon,  et al. | 2021&#8209;12&#8209;02 | `Docs:` [docs/integrations/retrievers/ragatouille](https://python.langchain.com/v0.2/docs/integrations/retrievers/ragatouille), [docs/integrations/providers/ragatouille](https://python.langchain.com/v0.2/docs/integrations/providers/ragatouille), [docs/concepts](https://python.langchain.com/v0.2/docs/concepts), [docs/integrations/providers/dspy](https://python.langchain.com/v0.2/docs/integrations/providers/dspy)\n+| `2112.01488v3` [ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction](http://arxiv.org/abs/2112.01488v3) | Keshav Santhanam, Omar Khattab, Jon Saad-Falcon,  et al. | 2021&#8209;12&#8209;02 | `Docs:` [docs/integrations/retrievers/ragatouille](https://python.langchain.com/docs/integrations/retrievers/ragatouille), [docs/integrations/providers/ragatouille](https://python.langchain.com/docs/integrations/providers/ragatouille), [docs/concepts](https://python.langchain.com/docs/concepts), [docs/integrations/providers/dspy](https://python.langchain.com/docs/integrations/providers/dspy)\n | `2103.00020v1` [Learning Transferable Visual Models From Natural Language Supervision](http://arxiv.org/abs/2103.00020v1) | Alec Radford, Jong Wook Kim, Chris Hallacy,  et al. | 2021&#8209;02&#8209;26 | `API:` [langchain_experimental.open_clip](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.open_clip)\n-| `2005.14165v4` [Language Models are Few-Shot Learners](http://arxiv.org/abs/2005.14165v4) | Tom B. Brown, Benjamin Mann, Nick Ryder,  et al. | 2020&#8209;05&#8209;28 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n-| `2005.11401v4` [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](http://arxiv.org/abs/2005.11401v4) | Patrick Lewis, Ethan Perez, Aleksandra Piktus,  et al. | 2020&#8209;05&#8209;22 | `Docs:` [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+| `2005.14165v4` [Language Models are Few-Shot Learners](http://arxiv.org/abs/2005.14165v4) | Tom B. Brown, Benjamin Mann, Nick Ryder,  et al. | 2020&#8209;05&#8209;28 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts)\n+| `2005.11401v4` [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](http://arxiv.org/abs/2005.11401v4) | Patrick Lewis, Ethan Perez, Aleksandra Piktus,  et al. | 2020&#8209;05&#8209;22 | `Docs:` [docs/concepts](https://python.langchain.com/docs/concepts)\n | `1909.05858v2` [CTRL: A Conditional Transformer Language Model for Controllable Generation](http://arxiv.org/abs/1909.05858v2) | Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney,  et al. | 2019&#8209;09&#8209;11 | `API:` [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint)\n \n ## Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity\n@@ -60,7 +60,7 @@ From the opposite direction, scientists use `LangChain` in research and referenc\n - **arXiv id:** [2403.14403v2](http://arxiv.org/abs/2403.14403v2)  **Published Date:** 2024-03-21\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n \n **Abstract:** Retrieval-Augmented Large Language Models (LLMs), which incorporate the\n non-parametric knowledge from external knowledge bases into LLMs, have emerged\n@@ -113,7 +113,7 @@ commonalities with human reasoning patterns.\n - **arXiv id:** [2402.03367v2](http://arxiv.org/abs/2402.03367v2)  **Published Date:** 2024-01-31\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n \n **Abstract:** Infineon has identified a need for engineers, account managers, and customers\n to rapidly obtain product information. This problem is traditionally addressed\n@@ -159,7 +159,7 @@ benchmark by 20% in absolute accuracy.\n - **arXiv id:** [2401.15884v2](http://arxiv.org/abs/2401.15884v2)  **Published Date:** 2024-01-29\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n    - **Cookbook:** [langgraph_crag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_crag.ipynb)\n \n **Abstract:** Large language models (LLMs) inevitably exhibit hallucinations since the\n@@ -187,7 +187,7 @@ performance of RAG-based approaches.\n - **arXiv id:** [2401.08500v1](http://arxiv.org/abs/2401.08500v1)  **Published Date:** 2024-01-16\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n \n **Abstract:** Code generation problems differ from common natural language problems - they\n require matching the exact syntax of the target language, identifying happy\n@@ -293,7 +293,7 @@ outside the pre-training knowledge scope.\n - **arXiv id:** [2310.11511v1](http://arxiv.org/abs/2310.11511v1)  **Published Date:** 2023-10-17\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n    - **Cookbook:** [langgraph_self_rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_self_rag.ipynb)\n \n **Abstract:** Despite their remarkable capabilities, large language models (LLMs) often\n@@ -324,7 +324,7 @@ to these models.\n - **arXiv id:** [2310.06117v2](http://arxiv.org/abs/2310.06117v2)  **Published Date:** 2023-10-09\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n    - **Template:** [stepback-qa-prompting](https://python.langchain.com/docs/templates/stepback-qa-prompting)\n    - **Cookbook:** [stepback-qa](https://github.com/langchain-ai/langchain/blob/master/cookbook/stepback-qa.ipynb)\n \n@@ -384,7 +384,7 @@ contribute to the responsible development of LLMs.\n - **arXiv id:** [2307.03172v3](http://arxiv.org/abs/2307.03172v3)  **Published Date:** 2023-07-06\n - **LangChain:**\n \n-   - **Documentation:** [docs/how_to/long_context_reorder](https://python.langchain.com/v0.2/docs/how_to/long_context_reorder)\n+   - **Documentation:** [docs/how_to/long_context_reorder](https://python.langchain.com/docs/how_to/long_context_reorder)\n \n **Abstract:** While recent language models have the ability to take long contexts as input,\n relatively little is known about how well they use longer context. We analyze\n@@ -490,7 +490,7 @@ https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.\n - **arXiv id:** [2305.02156v1](http://arxiv.org/abs/2305.02156v1)  **Published Date:** 2023-05-03\n - **LangChain:**\n \n-   - **Documentation:** [docs/how_to/contextual_compression](https://python.langchain.com/v0.2/docs/how_to/contextual_compression)\n+   - **Documentation:** [docs/how_to/contextual_compression](https://python.langchain.com/docs/how_to/contextual_compression)\n    - **API Reference:** [langchain...LLMListwiseRerank](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html#langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank)\n \n **Abstract:** Supervised ranking methods based on bi-encoder or cross-encoder architectures\n@@ -649,7 +649,7 @@ family, and discuss robustness and security.\n - **arXiv id:** [2212.10496v1](http://arxiv.org/abs/2212.10496v1)  **Published Date:** 2022-12-20\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n    - **API Reference:** [langchain...HypotheticalDocumentEmbedder](https://api.python.langchain.com/en/latest/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html#langchain.chains.hyde.base.HypotheticalDocumentEmbedder)\n    - **Template:** [hyde](https://python.langchain.com/docs/templates/hyde)\n    - **Cookbook:** [hypothetical_document_embeddings](https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb)\n@@ -678,7 +678,7 @@ search, QA, fact verification) and languages~(e.g. sw, ko, ja).\n - **arXiv id:** [2212.08073v1](http://arxiv.org/abs/2212.08073v1)  **Published Date:** 2022-12-15\n - **LangChain:**\n \n-   - **Documentation:** [docs/versions/migrating_chains/constitutional_chain](https://python.langchain.com/v0.2/docs/versions/migrating_chains/constitutional_chain)\n+   - **Documentation:** [docs/versions/migrating_chains/constitutional_chain](https://python.langchain.com/docs/versions/migrating_chains/constitutional_chain)\n \n **Abstract:** As AI systems become more capable, we would like to enlist their help to\n supervise other AIs. We experiment with methods for training a harmless AI\n@@ -792,7 +792,7 @@ publicly available at http://reasonwithpal.com/ .\n - **arXiv id:** [2210.11934v2](http://arxiv.org/abs/2210.11934v2)  **Published Date:** 2022-10-21\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n \n **Abstract:** We study hybrid search in text retrieval where lexical and semantic search\n are fused together with the intuition that the two are complementary in how\n@@ -811,7 +811,7 @@ training examples to tune its only parameter to a target domain.\n - **arXiv id:** [2210.03629v3](http://arxiv.org/abs/2210.03629v3)  **Published Date:** 2022-10-06\n - **LangChain:**\n \n-   - **Documentation:** [docs/integrations/tools/ionic_shopping](https://python.langchain.com/v0.2/docs/integrations/tools/ionic_shopping), [docs/integrations/providers/cohere](https://python.langchain.com/v0.2/docs/integrations/providers/cohere), [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/integrations/tools/ionic_shopping](https://python.langchain.com/docs/integrations/tools/ionic_shopping), [docs/integrations/providers/cohere](https://python.langchain.com/docs/integrations/providers/cohere), [docs/concepts](https://python.langchain.com/docs/concepts)\n    - **API Reference:** [langchain...create_react_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent), [langchain...TrajectoryEvalChain](https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html#langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain)\n \n **Abstract:** While large language models (LLMs) have demonstrated impressive capabilities\n@@ -843,7 +843,7 @@ Project site with code: https://react-lm.github.io\n - **arXiv id:** [2209.10785v2](http://arxiv.org/abs/2209.10785v2)  **Published Date:** 2022-09-22\n - **LangChain:**\n \n-   - **Documentation:** [docs/integrations/providers/activeloop_deeplake](https://python.langchain.com/v0.2/docs/integrations/providers/activeloop_deeplake)\n+   - **Documentation:** [docs/integrations/providers/activeloop_deeplake](https://python.langchain.com/docs/integrations/providers/activeloop_deeplake)\n \n **Abstract:** Traditional data lakes provide critical data infrastructure for analytical\n workloads by enabling time travel, running SQL queries, ingesting data with\n@@ -868,7 +868,7 @@ TensorFlow, JAX, and integrate with numerous MLOps tools.\n - **arXiv id:** [2205.13147v4](http://arxiv.org/abs/2205.13147v4)  **Published Date:** 2022-05-26\n - **LangChain:**\n \n-   - **Documentation:** [docs/integrations/providers/snowflake](https://python.langchain.com/v0.2/docs/integrations/providers/snowflake)\n+   - **Documentation:** [docs/integrations/providers/snowflake](https://python.langchain.com/docs/integrations/providers/snowflake)\n \n **Abstract:** Learned representations are a central component in modern ML systems, serving\n a multitude of downstream tasks. When training such representations, it is\n@@ -925,7 +925,7 @@ encoders, mine bitexts, and validate the bitexts by training NMT systems.\n - **arXiv id:** [2204.00498v1](http://arxiv.org/abs/2204.00498v1)  **Published Date:** 2022-03-15\n - **LangChain:**\n \n-   - **Documentation:** [docs/tutorials/sql_qa](https://python.langchain.com/v0.2/docs/tutorials/sql_qa)\n+   - **Documentation:** [docs/tutorials/sql_qa](https://python.langchain.com/docs/tutorials/sql_qa)\n    - **API Reference:** [langchain_community...SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), [langchain_community...SparkSQL](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.spark_sql.SparkSQL.html#langchain_community.utilities.spark_sql.SparkSQL)\n \n **Abstract:** We perform an empirical evaluation of Text-to-SQL capabilities of the Codex\n@@ -971,7 +971,7 @@ reducing degenerate repetitions.\n - **arXiv id:** [2112.01488v3](http://arxiv.org/abs/2112.01488v3)  **Published Date:** 2021-12-02\n - **LangChain:**\n \n-   - **Documentation:** [docs/integrations/retrievers/ragatouille](https://python.langchain.com/v0.2/docs/integrations/retrievers/ragatouille), [docs/integrations/providers/ragatouille](https://python.langchain.com/v0.2/docs/integrations/providers/ragatouille), [docs/concepts](https://python.langchain.com/v0.2/docs/concepts), [docs/integrations/providers/dspy](https://python.langchain.com/v0.2/docs/integrations/providers/dspy)\n+   - **Documentation:** [docs/integrations/retrievers/ragatouille](https://python.langchain.com/docs/integrations/retrievers/ragatouille), [docs/integrations/providers/ragatouille](https://python.langchain.com/docs/integrations/providers/ragatouille), [docs/concepts](https://python.langchain.com/docs/concepts), [docs/integrations/providers/dspy](https://python.langchain.com/docs/integrations/providers/dspy)\n \n **Abstract:** Neural information retrieval (IR) has greatly advanced search and other\n knowledge-intensive language tasks. While many neural IR methods encode queries\n@@ -1022,7 +1022,7 @@ https://github.com/OpenAI/CLIP.\n - **arXiv id:** [2005.14165v4](http://arxiv.org/abs/2005.14165v4)  **Published Date:** 2020-05-28\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n \n **Abstract:** Recent work has demonstrated substantial gains on many NLP tasks and\n benchmarks by pre-training on a large corpus of text followed by fine-tuning on\n@@ -1055,7 +1055,7 @@ and of GPT-3 in general.\n - **arXiv id:** [2005.11401v4](http://arxiv.org/abs/2005.11401v4)  **Published Date:** 2020-05-22\n - **LangChain:**\n \n-   - **Documentation:** [docs/concepts](https://python.langchain.com/v0.2/docs/concepts)\n+   - **Documentation:** [docs/concepts](https://python.langchain.com/docs/concepts)\n \n **Abstract:** Large pre-trained language models have been shown to store factual knowledge\n in their parameters, and achieve state-of-the-art results when fine-tuned on"
        },
        {
          "filename": "docs/docs/concepts.mdx",
          "status": "modified",
          "additions": 22,
          "deletions": 22,
          "patch": "@@ -97,7 +97,7 @@ For guides on how to do specific tasks with LCEL, check out [the relevant how-to\n ### Runnable interface\n <span data-heading-keywords=\"invoke,runnable\"></span>\n \n-To make it as easy as possible to create custom chains, we've implemented a [\"Runnable\"](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) protocol. Many LangChain components implement the `Runnable` protocol, including chat models, LLMs, output parsers, retrievers, prompt templates, and more. There are also several useful primitives for working with runnables, which you can read about below.\n+To make it as easy as possible to create custom chains, we've implemented a [\"Runnable\"](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) protocol. Many LangChain components implement the `Runnable` protocol, including chat models, LLMs, output parsers, retrievers, prompt templates, and more. There are also several useful primitives for working with runnables, which you can read about below.\n \n This is a standard interface, which makes it easy to define custom chains as well as invoke them in a standard way.\n The standard interface includes:\n@@ -380,17 +380,17 @@ LangChain has lots of different types of output parsers. This is a list of outpu\n \n | Name            | Supports Streaming | Has Format Instructions       | Calls LLM | Input Type                       | Output Type          | Description                                                                                                                                                                                                                                              |\n |-----------------|--------------------|-------------------------------|-----------|----------------------------------|----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n-| [JSON](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html#langchain_core.output_parsers.json.JsonOutputParser)            | \u2705                  | \u2705                             |           | `str` \\| `Message`               | JSON object          | Returns a JSON object as specified. You can specify a Pydantic model and it will return JSON for that model. Probably the most reliable output parser for getting structured data that does NOT use function calling.                                    |\n-| [XML](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.xml.XMLOutputParser.html#langchain_core.output_parsers.xml.XMLOutputParser)            | \u2705                  | \u2705                             |           | `str` \\| `Message`                 | `dict`               | Returns a dictionary of tags. Use when XML output is needed. Use with models that are good at writing XML (like Anthropic's).                                                                                                                            |\n-| [CSV](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.list.CommaSeparatedListOutputParser.html#langchain_core.output_parsers.list.CommaSeparatedListOutputParser)           | \u2705                  | \u2705                             |           | `str` \\| `Message`                 | `List[str]`          | Returns a list of comma separated values.                                                                                                                                                                                                                |\n-| [OutputFixing](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html#langchain.output_parsers.fix.OutputFixingParser)    |                    |                               | \u2705         | `str` \\| `Message`                 |                      | Wraps another output parser. If that output parser errors, then this will pass the error message and the bad output to an LLM and ask it to fix the output.                                                                                              |\n-| [RetryWithError](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.retry.RetryWithErrorOutputParser.html#langchain.output_parsers.retry.RetryWithErrorOutputParser)  |                    |                               | \u2705         | `str` \\| `Message`                 |                      | Wraps another output parser. If that output parser errors, then this will pass the original inputs, the bad output, and the error message to an LLM and ask it to fix it. Compared to OutputFixingParser, this one also sends the original instructions. |\n-| [Pydantic](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html#langchain_core.output_parsers.pydantic.PydanticOutputParser)        |                    | \u2705                             |           | `str` \\| `Message`                 | `pydantic.BaseModel` | Takes a user defined Pydantic model and returns data in that format.                                                                                                                                                                                     |\n-| [YAML](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html#langchain.output_parsers.yaml.YamlOutputParser)        |                    | \u2705                             |           | `str` \\| `Message`                 | `pydantic.BaseModel` | Takes a user defined Pydantic model and returns data in that format. Uses YAML to encode it.                                                                                                                                                                                    |\n-| [PandasDataFrame](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser.html#langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser) |                    | \u2705                             |           | `str` \\| `Message`                 | `dict`               | Useful for doing operations with pandas DataFrames.                                                                                                                                                                                                      |\n-| [Enum](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.enum.EnumOutputParser.html#langchain.output_parsers.enum.EnumOutputParser)            |                    | \u2705                             |           | `str` \\| `Message`                 | `Enum`               | Parses response into one of the provided enum values.                                                                                                                                                                                                    |\n-| [Datetime](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.datetime.DatetimeOutputParser.html#langchain.output_parsers.datetime.DatetimeOutputParser)        |                    | \u2705                             |           | `str` \\| `Message`                 | `datetime.datetime`  | Parses response into a datetime string.                                                                                                                                                                                                                  |\n-| [Structured](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.structured.StructuredOutputParser.html#langchain.output_parsers.structured.StructuredOutputParser)      |                    | \u2705                             |           | `str` \\| `Message`                 | `Dict[str, str]`     | An output parser that returns structured information. It is less powerful than other output parsers since it only allows for fields to be strings. This can be useful when you are working with smaller LLMs.                                            |\n+| [JSON](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html#langchain_core.output_parsers.json.JsonOutputParser)            | \u2705                  | \u2705                             |           | `str` \\| `Message`               | JSON object          | Returns a JSON object as specified. You can specify a Pydantic model and it will return JSON for that model. Probably the most reliable output parser for getting structured data that does NOT use function calling.                                    |\n+| [XML](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.xml.XMLOutputParser.html#langchain_core.output_parsers.xml.XMLOutputParser)            | \u2705                  | \u2705                             |           | `str` \\| `Message`                 | `dict`               | Returns a dictionary of tags. Use when XML output is needed. Use with models that are good at writing XML (like Anthropic's).                                                                                                                            |\n+| [CSV](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.list.CommaSeparatedListOutputParser.html#langchain_core.output_parsers.list.CommaSeparatedListOutputParser)           | \u2705                  | \u2705                             |           | `str` \\| `Message`                 | `List[str]`          | Returns a list of comma separated values.                                                                                                                                                                                                                |\n+| [OutputFixing](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html#langchain.output_parsers.fix.OutputFixingParser)    |                    |                               | \u2705         | `str` \\| `Message`                 |                      | Wraps another output parser. If that output parser errors, then this will pass the error message and the bad output to an LLM and ask it to fix the output.                                                                                              |\n+| [RetryWithError](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.retry.RetryWithErrorOutputParser.html#langchain.output_parsers.retry.RetryWithErrorOutputParser)  |                    |                               | \u2705         | `str` \\| `Message`                 |                      | Wraps another output parser. If that output parser errors, then this will pass the original inputs, the bad output, and the error message to an LLM and ask it to fix it. Compared to OutputFixingParser, this one also sends the original instructions. |\n+| [Pydantic](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html#langchain_core.output_parsers.pydantic.PydanticOutputParser)        |                    | \u2705                             |           | `str` \\| `Message`                 | `pydantic.BaseModel` | Takes a user defined Pydantic model and returns data in that format.                                                                                                                                                                                     |\n+| [YAML](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html#langchain.output_parsers.yaml.YamlOutputParser)        |                    | \u2705                             |           | `str` \\| `Message`                 | `pydantic.BaseModel` | Takes a user defined Pydantic model and returns data in that format. Uses YAML to encode it.                                                                                                                                                                                    |\n+| [PandasDataFrame](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser.html#langchain.output_parsers.pandas_dataframe.PandasDataFrameOutputParser) |                    | \u2705                             |           | `str` \\| `Message`                 | `dict`               | Useful for doing operations with pandas DataFrames.                                                                                                                                                                                                      |\n+| [Enum](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.enum.EnumOutputParser.html#langchain.output_parsers.enum.EnumOutputParser)            |                    | \u2705                             |           | `str` \\| `Message`                 | `Enum`               | Parses response into one of the provided enum values.                                                                                                                                                                                                    |\n+| [Datetime](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.datetime.DatetimeOutputParser.html#langchain.output_parsers.datetime.DatetimeOutputParser)        |                    | \u2705                             |           | `str` \\| `Message`                 | `datetime.datetime`  | Parses response into a datetime string.                                                                                                                                                                                                                  |\n+| [Structured](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.structured.StructuredOutputParser.html#langchain.output_parsers.structured.StructuredOutputParser)      |                    | \u2705                             |           | `str` \\| `Message`                 | `Dict[str, str]`     | An output parser that returns structured information. It is less powerful than other output parsers since it only allows for fields to be strings. This can be useful when you are working with smaller LLMs.                                            |\n \n For specifics on how to use output parsers, see the [relevant how-to guides here](/docs/how_to/#output-parsers).\n \n@@ -501,7 +501,7 @@ For specifics on how to use retrievers, see the [relevant how-to guides here](/d\n For some techniques, such as [indexing and retrieval with multiple vectors per document](/docs/how_to/multi_vector/) or\n [caching embeddings](/docs/how_to/caching_embeddings/), having a form of key-value (KV) storage is helpful.\n \n-LangChain includes a [`BaseStore`](https://python.langchain.com/v0.2/api_reference/core/stores/langchain_core.stores.BaseStore.html) interface,\n+LangChain includes a [`BaseStore`](https://python.langchain.com/api_reference/core/stores/langchain_core.stores.BaseStore.html) interface,\n which allows for storage of arbitrary data. However, LangChain components that require KV-storage accept a\n more specific `BaseStore[str, bytes]` instance that stores binary data (referred to as a `ByteStore`), and internally take care of\n encoding and decoding data for their specific needs.\n@@ -510,7 +510,7 @@ This means that as a user, you only need to think about one type of store rather\n \n #### Interface\n \n-All [`BaseStores`](https://python.langchain.com/v0.2/api_reference/core/stores/langchain_core.stores.BaseStore.html) support the following interface. Note that the interface allows\n+All [`BaseStores`](https://python.langchain.com/api_reference/core/stores/langchain_core.stores.BaseStore.html) support the following interface. Note that the interface allows\n for modifying **multiple** key-value pairs at once:\n \n - `mget(key: Sequence[str]) -> List[Optional[bytes]]`: get the contents of multiple keys, returning `None` if the key does not exist\n@@ -708,10 +708,10 @@ You can subscribe to these events by using the `callbacks` argument available th\n \n Callback handlers can either be `sync` or `async`:\n \n-* Sync callback handlers implement the [BaseCallbackHandler](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html) interface.\n-* Async callback handlers implement the [AsyncCallbackHandler](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.base.AsyncCallbackHandler.html) interface.\n+* Sync callback handlers implement the [BaseCallbackHandler](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html) interface.\n+* Async callback handlers implement the [AsyncCallbackHandler](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.AsyncCallbackHandler.html) interface.\n \n-During run-time LangChain configures an appropriate callback manager (e.g., [CallbackManager](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.manager.CallbackManager.html) or [AsyncCallbackManager](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.manager.AsyncCallbackManager.html) which will be responsible for calling the appropriate method on each \"registered\" callback handler when the event is triggered.\n+During run-time LangChain configures an appropriate callback manager (e.g., [CallbackManager](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.manager.CallbackManager.html) or [AsyncCallbackManager](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.manager.AsyncCallbackManager.html) which will be responsible for calling the appropriate method on each \"registered\" callback handler when the event is triggered.\n \n #### Passing callbacks\n \n@@ -779,7 +779,7 @@ For models (or other components) that don't support streaming natively, this ite\n you could still use the same general pattern when calling them. Using `.stream()` will also automatically call the model in streaming mode\n without the need to provide additional config.\n \n-The type of each outputted chunk depends on the type of component - for example, chat models yield [`AIMessageChunks`](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html).\n+The type of each outputted chunk depends on the type of component - for example, chat models yield [`AIMessageChunks`](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html).\n Because this method is part of [LangChain Expression Language](/docs/concepts/#langchain-expression-language-lcel),\n you can handle formatting differences from different outputs using an [output parser](/docs/concepts/#output-parsers) to transform\n each yielded chunk.\n@@ -827,10 +827,10 @@ including a table listing available events.\n #### Callbacks\n \n The lowest level way to stream outputs from LLMs in LangChain is via the [callbacks](/docs/concepts/#callbacks) system. You can pass a\n-callback handler that handles the [`on_llm_new_token`](https://python.langchain.com/v0.2/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_new_token) event into LangChain components. When that component is invoked, any\n+callback handler that handles the [`on_llm_new_token`](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_new_token) event into LangChain components. When that component is invoked, any\n [LLM](/docs/concepts/#llms) or [chat model](/docs/concepts/#chat-models) contained in the component calls\n the callback with the generated token. Within the callback, you could pipe the tokens into some other destination, e.g. a HTTP response.\n-You can also handle the [`on_llm_end`](https://python.langchain.com/v0.2/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_end) event to perform any necessary cleanup.\n+You can also handle the [`on_llm_end`](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_end) event to perform any necessary cleanup.\n \n You can see [this how-to section](/docs/how_to/#callbacks) for more specifics on using callbacks.\n \n@@ -945,7 +945,7 @@ Here's an example:\n ```python\n from typing import Optional\n \n-from langchain_core.pydantic_v1 import BaseModel, Field\n+from pydantic import BaseModel, Field\n \n \n class Joke(BaseModel):\n@@ -1062,7 +1062,7 @@ a `tool_calls` field containing `args` that match the desired shape.\n There are several acceptable formats you can use to bind tools to a model in LangChain. Here's one example:\n \n ```python\n-from langchain_core.pydantic_v1 import BaseModel, Field\n+from pydantic import BaseModel, Field\n from langchain_openai import ChatOpenAI\n \n class ResponseFormatter(BaseModel):"
        },
        {
          "filename": "docs/docs/contributing/documentation/setup.mdx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -12,7 +12,7 @@ It covers a wide array of topics, including tutorials, use cases, integrations,\n and more, offering extensive guidance on building with LangChain.\n The content for this documentation lives in the `/docs` directory of the monorepo.\n 2. In-code Documentation: This is documentation of the codebase itself, which is also\n-used to generate the externally facing [API Reference](https://python.langchain.com/v0.2/api_reference/langchain/index.html).\n+used to generate the externally facing [API Reference](https://python.langchain.com/api_reference/langchain/index.html).\n The content for the API reference is autogenerated by scanning the docstrings in the codebase. For this reason we ask that\n developers document their code well.\n "
        },
        {
          "filename": "docs/docs/contributing/repo_structure.mdx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -50,7 +50,7 @@ There are other files in the root directory level, but their presence should be\n ## Documentation\n \n The `/docs` directory contains the content for the documentation that is shown\n-at https://python.langchain.com/ and the associated API Reference https://python.langchain.com/v0.2/api_reference/langchain/index.html.\n+at https://python.langchain.com/ and the associated API Reference https://python.langchain.com/api_reference/langchain/index.html.\n \n See the [documentation](/docs/contributing/documentation/) guidelines to learn how to contribute to the documentation.\n "
        },
        {
          "filename": "docs/docs/how_to/HTML_header_metadata_splitter.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -13,7 +13,7 @@\n     \"# How to split by HTML header \\n\",\n     \"## Description and motivation\\n\",\n     \"\\n\",\n-    \"[HTMLHeaderTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/html/langchain_text_splitters.html.HTMLHeaderTextSplitter.html) is a \\\"structure-aware\\\" chunker that splits text at the HTML element level and adds metadata for each header \\\"relevant\\\" to any given chunk. It can return chunks element by element or combine elements with the same metadata, with the objectives of (a) keeping related text grouped (more or less) semantically and (b) preserving context-rich information encoded in document structures. It can be used with other text splitters as part of a chunking pipeline.\\n\",\n+    \"[HTMLHeaderTextSplitter](https://python.langchain.com/api_reference/text_splitters/html/langchain_text_splitters.html.HTMLHeaderTextSplitter.html) is a \\\"structure-aware\\\" chunker that splits text at the HTML element level and adds metadata for each header \\\"relevant\\\" to any given chunk. It can return chunks element by element or combine elements with the same metadata, with the objectives of (a) keeping related text grouped (more or less) semantically and (b) preserving context-rich information encoded in document structures. It can be used with other text splitters as part of a chunking pipeline.\\n\",\n     \"\\n\",\n     \"It is analogous to the [MarkdownHeaderTextSplitter](/docs/how_to/markdown_header_metadata_splitter) for markdown files.\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/MultiQueryRetriever.ipynb",
          "status": "modified",
          "additions": 64,
          "deletions": 14,
          "patch": "@@ -9,7 +9,7 @@\n     \"\\n\",\n     \"Distance-based vector database retrieval embeds (represents) queries in high-dimensional space and finds similar embedded documents based on a distance metric. But, retrieval may produce different results with subtle changes in query wording, or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems, but can be tedious.\\n\",\n     \"\\n\",\n-    \"The [MultiQueryRetriever](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html) automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the `MultiQueryRetriever` can mitigate some of the limitations of the distance-based retrieval and get a richer set of results.\\n\",\n+    \"The [MultiQueryRetriever](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html) automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the `MultiQueryRetriever` can mitigate some of the limitations of the distance-based retrieval and get a richer set of results.\\n\",\n     \"\\n\",\n     \"Let's build a vectorstore using the [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/) blog post by Lilian Weng from the [RAG tutorial](/docs/tutorials/rag):\"\n    ]\n@@ -18,8 +18,23 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n    \"id\": \"994d6c74\",\n-   \"metadata\": {},\n-   \"outputs\": [],\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:08:00.190093Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:08:00.189665Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:08:05.438015Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:08:05.437685Z\"\n+    }\n+   },\n+   \"outputs\": [\n+    {\n+     \"name\": \"stderr\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"USER_AGENT environment variable not set, consider setting it to identify your requests.\\n\"\n+     ]\n+    }\n+   ],\n    \"source\": [\n     \"# Build a sample vectorDB\\n\",\n     \"from langchain_chroma import Chroma\\n\",\n@@ -54,7 +69,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 2,\n    \"id\": \"edbca101\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:08:05.439930Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:08:05.439810Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:08:05.553766Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:08:05.553520Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain.retrievers.multi_query import MultiQueryRetriever\\n\",\n@@ -71,7 +93,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 3,\n    \"id\": \"9e6d3b69\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:08:05.555359Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:08:05.555262Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:08:05.557046Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:08:05.556825Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# Set logging for the queries\\n\",\n@@ -85,13 +114,20 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 4,\n    \"id\": \"bc93dc2b-9407-48b0-9f9a-338247e7eb69\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:08:05.558176Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:08:05.558100Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:08:07.250342Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:08:07.249711Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stderr\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"INFO:langchain.retrievers.multi_query:Generated queries: ['1. How can Task Decomposition be achieved through different methods?', '2. What strategies are commonly used for Task Decomposition?', '3. What are the various techniques for breaking down tasks in Task Decomposition?']\\n\"\n+      \"INFO:langchain.retrievers.multi_query:Generated queries: ['1. How can Task Decomposition be achieved through different methods?', '2. What strategies are commonly used for Task Decomposition?', '3. What are the various ways to break down tasks in Task Decomposition?']\\n\"\n      ]\n     },\n     {\n@@ -125,9 +161,9 @@\n    \"source\": [\n     \"#### Supplying your own prompt\\n\",\n     \"\\n\",\n-    \"Under the hood, `MultiQueryRetriever` generates queries using a specific [prompt](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html). To customize this prompt:\\n\",\n+    \"Under the hood, `MultiQueryRetriever` generates queries using a specific [prompt](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html). To customize this prompt:\\n\",\n     \"\\n\",\n-    \"1. Make a [PromptTemplate](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html) with an input variable for the question;\\n\",\n+    \"1. Make a [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html) with an input variable for the question;\\n\",\n     \"2. Implement an [output parser](/docs/concepts#output-parsers) like the one below to split the result into a list of queries.\\n\",\n     \"\\n\",\n     \"The prompt and output parser together must support the generation of a list of queries.\"\n@@ -137,14 +173,21 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 5,\n    \"id\": \"d9afb0ca\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:08:07.253875Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:08:07.253600Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:08:07.277848Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:08:07.277487Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List\\n\",\n     \"\\n\",\n     \"from langchain_core.output_parsers import BaseOutputParser\\n\",\n     \"from langchain_core.prompts import PromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"# Output parser will split the LLM result into a list of queries\\n\",\n@@ -180,13 +223,20 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 6,\n    \"id\": \"59c75c56-dbd7-4887-b9ba-0b5b21069f51\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:08:07.280001Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:08:07.279861Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:08:09.579525Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:08:09.578837Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stderr\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide insights on regression from the course material?', '2. How is regression discussed in the course content?', '3. What information does the course offer about regression?', '4. In what way is regression covered in the course?', '5. What are the teachings of the course regarding regression?']\\n\"\n+      \"INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide insights on regression from the course material?', '2. How is regression discussed in the course content?', '3. What information does the course offer regarding regression?', '4. In what way is regression covered in the course?', \\\"5. What are the course's teachings on regression?\\\"]\\n\"\n      ]\n     },\n     {\n@@ -228,7 +278,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.4\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/add_scores_retriever.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -7,15 +7,15 @@\n    \"source\": [\n     \"# How to add scores to retriever results\\n\",\n     \"\\n\",\n-    \"Retrievers will return sequences of [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) objects, which by default include no information about the process that retrieved them (e.g., a similarity score against a query). Here we demonstrate how to add retrieval scores to the `.metadata` of documents:\\n\",\n+    \"Retrievers will return sequences of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects, which by default include no information about the process that retrieved them (e.g., a similarity score against a query). Here we demonstrate how to add retrieval scores to the `.metadata` of documents:\\n\",\n     \"1. From [vectorstore retrievers](/docs/how_to/vectorstore_retriever);\\n\",\n     \"2. From higher-order LangChain retrievers, such as [SelfQueryRetriever](/docs/how_to/self_query) or [MultiVectorRetriever](/docs/how_to/multi_vector).\\n\",\n     \"\\n\",\n     \"For (1), we will implement a short wrapper function around the corresponding vector store. For (2), we will update a method of the corresponding class.\\n\",\n     \"\\n\",\n     \"## Create vector store\\n\",\n     \"\\n\",\n-    \"First we populate a vector store with some data. We will use a [PineconeVectorStore](https://python.langchain.com/v0.2/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html), but this guide is compatible with any LangChain vector store that implements a `.similarity_search_with_score` method.\"\n+    \"First we populate a vector store with some data. We will use a [PineconeVectorStore](https://python.langchain.com/api_reference/pinecone/vectorstores/langchain_pinecone.vectorstores.PineconeVectorStore.html), but this guide is compatible with any LangChain vector store that implements a `.similarity_search_with_score` method.\"\n    ]\n   },\n   {\n@@ -263,7 +263,7 @@\n     \"\\n\",\n     \"To propagate similarity scores through this retriever, we can again subclass `MultiVectorRetriever` and override a method. This time we will override `_get_relevant_documents`.\\n\",\n     \"\\n\",\n-    \"First, we prepare some fake data. We generate fake \\\"whole documents\\\" and store them in a document store; here we will use a simple [InMemoryStore](https://python.langchain.com/v0.2/api_reference/core/stores/langchain_core.stores.InMemoryBaseStore.html).\"\n+    \"First, we prepare some fake data. We generate fake \\\"whole documents\\\" and store them in a document store; here we will use a simple [InMemoryStore](https://python.langchain.com/api_reference/core/stores/langchain_core.stores.InMemoryBaseStore.html).\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/assign.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -27,7 +27,7 @@\n     \"\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"An alternate way of [passing data through](/docs/how_to/passthrough) steps of a chain is to leave the current values of the chain state unchanged while assigning a new value under a given key. The [`RunnablePassthrough.assign()`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html#langchain_core.runnables.passthrough.RunnablePassthrough.assign) static method takes an input value and adds the extra arguments passed to the assign function.\\n\",\n+    \"An alternate way of [passing data through](/docs/how_to/passthrough) steps of a chain is to leave the current values of the chain state unchanged while assigning a new value under a given key. The [`RunnablePassthrough.assign()`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html#langchain_core.runnables.passthrough.RunnablePassthrough.assign) static method takes an input value and adds the extra arguments passed to the assign function.\\n\",\n     \"\\n\",\n     \"This is useful in the common [LangChain Expression Language](/docs/concepts/#langchain-expression-language) pattern of additively creating a dictionary to use as input to a later step.\\n\",\n     \"\\n\",\n@@ -45,7 +45,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/binding.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 4,
          "patch": "@@ -27,7 +27,7 @@\n     \"\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"Sometimes we want to invoke a [`Runnable`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) within a [RunnableSequence](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableSequence.html) with constant arguments that are not part of the output of the preceding Runnable in the sequence, and which are not part of the user input. We can use the [`Runnable.bind()`](https://python.langchain.com/v0.2/api_reference/langchain_core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.bind) method to set these arguments ahead of time.\\n\",\n+    \"Sometimes we want to invoke a [`Runnable`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) within a [RunnableSequence](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableSequence.html) with constant arguments that are not part of the output of the preceding Runnable in the sequence, and which are not part of the user input. We can use the [`Runnable.bind()`](https://python.langchain.com/api_reference/langchain_core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.bind) method to set these arguments ahead of time.\\n\",\n     \"\\n\",\n     \"## Binding stop sequences\\n\",\n     \"\\n\",\n@@ -49,7 +49,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {\n@@ -183,7 +184,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_z0OU2CytqENVrRTI6T8DkI3u', 'function': {'arguments': '{\\\"location\\\": \\\"San Francisco, CA\\\", \\\"unit\\\": \\\"celsius\\\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_ft96IJBh0cMKkQWrZjNg4bsw', 'function': {'arguments': '{\\\"location\\\": \\\"New York, NY\\\", \\\"unit\\\": \\\"celsius\\\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_tfbtGgCLmuBuWgZLvpPwvUMH', 'function': {'arguments': '{\\\"location\\\": \\\"Los Angeles, CA\\\", \\\"unit\\\": \\\"celsius\\\"}', 'name': 'get_current_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 85, 'total_tokens': 169}, 'model_name': 'gpt-3.5-turbo-1106', 'system_fingerprint': 'fp_77a673219d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d57ad5fa-b52a-4822-bc3e-74f838697e18-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'San Francisco, CA', 'unit': 'celsius'}, 'id': 'call_z0OU2CytqENVrRTI6T8DkI3u'}, {'name': 'get_current_weather', 'args': {'location': 'New York, NY', 'unit': 'celsius'}, 'id': 'call_ft96IJBh0cMKkQWrZjNg4bsw'}, {'name': 'get_current_weather', 'args': {'location': 'Los Angeles, CA', 'unit': 'celsius'}, 'id': 'call_tfbtGgCLmuBuWgZLvpPwvUMH'}])\"\n+       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_z0OU2CytqENVrRTI6T8DkI3u', 'function': {'arguments': '{\\\"location\\\": \\\"San Francisco, CA\\\", \\\"unit\\\": \\\"celsius\\\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_ft96IJBh0cMKkQWrZjNg4bsw', 'function': {'arguments': '{\\\"location\\\": \\\"New York, NY\\\", \\\"unit\\\": \\\"celsius\\\"}', 'name': 'get_current_weather'}, 'type': 'function'}, {'id': 'call_tfbtGgCLmuBuWgZLvpPwvUMH', 'function': {'arguments': '{\\\"location\\\": \\\"Los Angeles, CA\\\", \\\"unit\\\": \\\"celsius\\\"}', 'name': 'get_current_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 85, 'total_tokens': 169}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_77a673219d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d57ad5fa-b52a-4822-bc3e-74f838697e18-0', tool_calls=[{'name': 'get_current_weather', 'args': {'location': 'San Francisco, CA', 'unit': 'celsius'}, 'id': 'call_z0OU2CytqENVrRTI6T8DkI3u'}, {'name': 'get_current_weather', 'args': {'location': 'New York, NY', 'unit': 'celsius'}, 'id': 'call_ft96IJBh0cMKkQWrZjNg4bsw'}, {'name': 'get_current_weather', 'args': {'location': 'Los Angeles, CA', 'unit': 'celsius'}, 'id': 'call_tfbtGgCLmuBuWgZLvpPwvUMH'}])\"\n       ]\n      },\n      \"execution_count\": 5,\n@@ -192,7 +193,7 @@\n     }\n    ],\n    \"source\": [\n-    \"model = ChatOpenAI(model=\\\"gpt-3.5-turbo-1106\\\").bind(tools=tools)\\n\",\n+    \"model = ChatOpenAI(model=\\\"gpt-4o-mini\\\").bind(tools=tools)\\n\",\n     \"model.invoke(\\\"What's the weather in SF, NYC and LA?\\\")\"\n    ]\n   },"
        },
        {
          "filename": "docs/docs/how_to/callbacks_async.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -14,7 +14,7 @@\n     \"- [Custom callback handlers](/docs/how_to/custom_callbacks)\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"If you are planning to use the async APIs, it is recommended to use and extend [`AsyncCallbackHandler`](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.base.AsyncCallbackHandler.html) to avoid blocking the event.\\n\",\n+    \"If you are planning to use the async APIs, it is recommended to use and extend [`AsyncCallbackHandler`](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.AsyncCallbackHandler.html) to avoid blocking the event.\\n\",\n     \"\\n\",\n     \"\\n\",\n     \":::{.callout-warning}\\n\","
        },
        {
          "filename": "docs/docs/how_to/callbacks_attach.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -17,7 +17,7 @@\n     \"\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"If you are composing a chain of runnables and want to reuse callbacks across multiple executions, you can attach callbacks with the [`.with_config()`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config) method. This saves you the need to pass callbacks in each time you invoke the chain.\\n\",\n+    \"If you are composing a chain of runnables and want to reuse callbacks across multiple executions, you can attach callbacks with the [`.with_config()`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config) method. This saves you the need to pass callbacks in each time you invoke the chain.\\n\",\n     \"\\n\",\n     \":::{.callout-important}\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/callbacks_runtime.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -15,7 +15,7 @@\n     \"\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"In many cases, it is advantageous to pass in handlers instead when running the object. When we pass through [`CallbackHandlers`](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain-core-callbacks-base-basecallbackhandler) using the `callbacks` keyword arg when executing an run, those callbacks will be issued by all nested objects involved in the execution. For example, when a handler is passed through to an Agent, it will be used for all callbacks related to the agent and all the objects involved in the agent's execution, in this case, the Tools and LLM.\\n\",\n+    \"In many cases, it is advantageous to pass in handlers instead when running the object. When we pass through [`CallbackHandlers`](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain-core-callbacks-base-basecallbackhandler) using the `callbacks` keyword arg when executing an run, those callbacks will be issued by all nested objects involved in the execution. For example, when a handler is passed through to an Agent, it will be used for all callbacks related to the agent and all the objects involved in the agent's execution, in this case, the Tools and LLM.\\n\",\n     \"\\n\",\n     \"This prevents us from having to manually attach the handlers to each individual nested object. Here's an example:\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/character_text_splitter.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -28,7 +28,7 @@\n     \"\\n\",\n     \"To obtain the string content directly, use `.split_text`.\\n\",\n     \"\\n\",\n-    \"To create LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) objects (e.g., for use in downstream tasks), use `.create_documents`.\"\n+    \"To create LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects (e.g., for use in downstream tasks), use `.create_documents`.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/chat_model_caching.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -50,7 +50,8 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n     \"llm = ChatOpenAI()\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/chat_models_universal_init.ipynb",
          "status": "modified",
          "additions": 143,
          "deletions": 39,
          "patch": "@@ -11,7 +11,7 @@\n     \"\\n\",\n     \":::tip Supported models\\n\",\n     \"\\n\",\n-    \"See the [init_chat_model()](https://python.langchain.com/v0.2/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html) API reference for a full list of supported integrations.\\n\",\n+    \"See the [init_chat_model()](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html) API reference for a full list of supported integrations.\\n\",\n     \"\\n\",\n     \"Make sure you have the integration packages installed for any model providers you want to support. E.g. you should have `langchain-openai` installed to init an OpenAI model.\\n\",\n     \"\\n\",\n@@ -26,10 +26,32 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 1,\n    \"id\": \"165b0de6-9ae3-4e3d-aa98-4fc8a97c4a06\",\n-   \"metadata\": {},\n-   \"outputs\": [],\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:32.858670Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:32.858278Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:33.009452Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:33.007022Z\"\n+    }\n+   },\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"zsh:1: 0.2.8 not found\\r\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n+     ]\n+    }\n+   ],\n    \"source\": [\n     \"%pip install -qU langchain>=0.2.8 langchain-openai langchain-anthropic langchain-google-vertexai\"\n    ]\n@@ -44,19 +66,48 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 2,\n    \"id\": \"79e14913-803c-4382-9009-5c6af3d75d35\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:33.015729Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:33.015241Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:39.391716Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:39.390438Z\"\n+    }\n+   },\n    \"outputs\": [\n+    {\n+     \"name\": \"stderr\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"/var/folders/4j/2rz3865x6qg07tx43146py8h0000gn/T/ipykernel_95293/571506279.py:4: LangChainBetaWarning: The function `init_chat_model` is in beta. It is actively being worked on, so the API may change.\\n\",\n+      \"  gpt_4o = init_chat_model(\\\"gpt-4o\\\", model_provider=\\\"openai\\\", temperature=0)\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"GPT-4o: I'm an AI created by OpenAI, and I don't have a personal name. How can I assist you today?\\n\",\n+      \"\\n\"\n+     ]\n+    },\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"GPT-4o: I'm an AI created by OpenAI, and I don't have a personal name. You can call me Assistant! How can I help you today?\\n\",\n-      \"\\n\",\n       \"Claude Opus: My name is Claude. It's nice to meet you!\\n\",\n+      \"\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Gemini 1.5: I am a large language model, trained by Google. \\n\",\n       \"\\n\",\n-      \"Gemini 1.5: I am a large language model, trained by Google. I do not have a name. \\n\",\n+      \"I don't have a name like a person does. You can call me Bard if you like! \ud83d\ude0a \\n\",\n       \"\\n\",\n       \"\\n\"\n      ]\n@@ -89,14 +140,21 @@\n    \"source\": [\n     \"## Inferring model provider\\n\",\n     \"\\n\",\n-    \"For common and distinct model names `init_chat_model()` will attempt to infer the model provider. See the [API reference](https://python.langchain.com/v0.2/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html) for a full list of inference behavior. E.g. any model that starts with `gpt-3...` or `gpt-4...` will be inferred as using model provider `openai`.\"\n+    \"For common and distinct model names `init_chat_model()` will attempt to infer the model provider. See the [API reference](https://python.langchain.com/api_reference/langchain/chat_models/langchain.chat_models.base.init_chat_model.html) for a full list of inference behavior. E.g. any model that starts with `gpt-3...` or `gpt-4...` will be inferred as using model provider `openai`.\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 3,\n    \"id\": \"0378ccc6-95bc-4d50-be50-fccc193f0a71\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:39.396908Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:39.396563Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:39.444959Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:39.444646Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"gpt_4o = init_chat_model(\\\"gpt-4o\\\", temperature=0)\\n\",\n@@ -116,17 +174,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 4,\n    \"id\": \"6c037f27-12d7-4e83-811e-4245c0e3ba58\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:39.446901Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:39.446773Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:40.301906Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:40.300918Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content=\\\"I'm an AI language model created by OpenAI, and I don't have a personal name. You can call me Assistant or any other name you prefer! How can I assist you today?\\\", response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 11, 'total_tokens': 48}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_d576307f90', 'finish_reason': 'stop', 'logprobs': None}, id='run-5428ab5c-b5c0-46de-9946-5d4ca40dbdc8-0', usage_metadata={'input_tokens': 11, 'output_tokens': 37, 'total_tokens': 48})\"\n+       \"AIMessage(content=\\\"I'm an AI created by OpenAI, and I don't have a personal name. How can I assist you today?\\\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 11, 'total_tokens': 34}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-b41df187-4627-490d-af3c-1c96282d3eb0-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34})\"\n       ]\n      },\n-     \"execution_count\": 5,\n+     \"execution_count\": 4,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -141,17 +206,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 5,\n    \"id\": \"321e3036-abd2-4e1f-bcc6-606efd036954\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:40.316030Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:40.315628Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:41.199134Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:41.198173Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content=\\\"My name is Claude. It's nice to meet you!\\\", response_metadata={'id': 'msg_012XvotUJ3kGLXJUWKBVxJUi', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 11, 'output_tokens': 15}}, id='run-1ad1eefe-f1c6-4244-8bc6-90e2cb7ee554-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})\"\n+       \"AIMessage(content=\\\"My name is Claude. It's nice to meet you!\\\", additional_kwargs={}, response_metadata={'id': 'msg_01Fx9P74A7syoFkwE73CdMMY', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 11, 'output_tokens': 15}}, id='run-a0fd2bbd-3b7e-46bf-8d69-a48c7e60b03c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})\"\n       ]\n      },\n-     \"execution_count\": 6,\n+     \"execution_count\": 5,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -174,17 +246,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 9,\n+   \"execution_count\": 6,\n    \"id\": \"814a2289-d0db-401e-b555-d5116112b413\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:41.203346Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:41.203004Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:41.891450Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:41.890539Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content=\\\"I'm an AI language model created by OpenAI, and I don't have a personal name. You can call me Assistant or any other name you prefer! How can I assist you today?\\\", response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 11, 'total_tokens': 48}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_ce0793330f', 'finish_reason': 'stop', 'logprobs': None}, id='run-3923e328-7715-4cd6-b215-98e4b6bf7c9d-0', usage_metadata={'input_tokens': 11, 'output_tokens': 37, 'total_tokens': 48})\"\n+       \"AIMessage(content=\\\"I'm an AI created by OpenAI, and I don't have a personal name. How can I assist you today?\\\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 11, 'total_tokens': 34}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-3380f977-4b89-4f44-bc02-b64043b3166f-0', usage_metadata={'input_tokens': 11, 'output_tokens': 23, 'total_tokens': 34})\"\n       ]\n      },\n-     \"execution_count\": 9,\n+     \"execution_count\": 6,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -202,17 +281,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 10,\n+   \"execution_count\": 7,\n    \"id\": \"6c8755ba-c001-4f5a-a497-be3f1db83244\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:41.896413Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:41.895967Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:42.767565Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:42.766619Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content=\\\"My name is Claude. It's nice to meet you!\\\", response_metadata={'id': 'msg_01RyYR64DoMPNCfHeNnroMXm', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 11, 'output_tokens': 15}}, id='run-22446159-3723-43e6-88df-b84797e7751d-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})\"\n+       \"AIMessage(content=\\\"My name is Claude. It's nice to meet you!\\\", additional_kwargs={}, response_metadata={'id': 'msg_01EFKSWpmsn2PSYPQa4cNHWb', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 11, 'output_tokens': 15}}, id='run-3c58f47c-41b9-4e56-92e7-fb9602e3787c-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26})\"\n       ]\n      },\n-     \"execution_count\": 10,\n+     \"execution_count\": 7,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -242,28 +328,37 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 7,\n+   \"execution_count\": 8,\n    \"id\": \"067dabee-1050-4110-ae24-c48eba01e13b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:42.771941Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:42.771606Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:43.909206Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:43.908496Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[{'name': 'GetPopulation',\\n\",\n        \"  'args': {'location': 'Los Angeles, CA'},\\n\",\n-       \"  'id': 'call_sYT3PFMufHGWJD32Hi2CTNUP'},\\n\",\n+       \"  'id': 'call_Ga9m8FAArIyEjItHmztPYA22',\\n\",\n+       \"  'type': 'tool_call'},\\n\",\n        \" {'name': 'GetPopulation',\\n\",\n        \"  'args': {'location': 'New York, NY'},\\n\",\n-       \"  'id': 'call_j1qjhxRnD3ffQmRyqjlI1Lnk'}]\"\n+       \"  'id': 'call_jh2dEvBaAHRaw5JUDthOs7rt',\\n\",\n+       \"  'type': 'tool_call'}]\"\n       ]\n      },\n-     \"execution_count\": 7,\n+     \"execution_count\": 8,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n    ],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class GetWeather(BaseModel):\\n\",\n@@ -288,22 +383,31 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 8,\n+   \"execution_count\": 9,\n    \"id\": \"e57dfe9f-cd24-4e37-9ce9-ccf8daf78f89\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:22:43.912746Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:22:43.912447Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:22:46.437049Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:22:46.436093Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[{'name': 'GetPopulation',\\n\",\n        \"  'args': {'location': 'Los Angeles, CA'},\\n\",\n-       \"  'id': 'toolu_01CxEHxKtVbLBrvzFS7GQ5xR'},\\n\",\n+       \"  'id': 'toolu_01JMufPf4F4t2zLj7miFeqXp',\\n\",\n+       \"  'type': 'tool_call'},\\n\",\n        \" {'name': 'GetPopulation',\\n\",\n        \"  'args': {'location': 'New York City, NY'},\\n\",\n-       \"  'id': 'toolu_013A79qt5toWSsKunFBDZd5S'}]\"\n+       \"  'id': 'toolu_01RQBHcE8kEEbYTuuS8WqY1u',\\n\",\n+       \"  'type': 'tool_call'}]\"\n       ]\n      },\n-     \"execution_count\": 8,\n+     \"execution_count\": 9,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }"
        },
        {
          "filename": "docs/docs/how_to/chat_streaming.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -18,7 +18,7 @@\n     \"# How to stream chat model responses\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"All [chat models](https://python.langchain.com/v0.2/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html) implement the [Runnable interface](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable), which comes with a **default** implementations of standard runnable methods (i.e. `ainvoke`, `batch`, `abatch`, `stream`, `astream`, `astream_events`).\\n\",\n+    \"All [chat models](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html) implement the [Runnable interface](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable), which comes with a **default** implementations of standard runnable methods (i.e. `ainvoke`, `batch`, `abatch`, `stream`, `astream`, `astream_events`).\\n\",\n     \"\\n\",\n     \"The **default** streaming implementation provides an`Iterator` (or `AsyncIterator` for asynchronous streaming) that yields a single value: the final output from the underlying chat model provider.\\n\",\n     \"\\n\",\n@@ -120,7 +120,7 @@\n    \"source\": [\n     \"## Astream events\\n\",\n     \"\\n\",\n-    \"Chat models also support the standard [astream events](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) method.\\n\",\n+    \"Chat models also support the standard [astream events](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) method.\\n\",\n     \"\\n\",\n     \"This method is useful if you're streaming output from a larger LLM application that contains multiple steps (e.g., an LLM chain composed of a prompt, llm and parser).\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/chat_token_usage_tracking.ipynb",
          "status": "modified",
          "additions": 10,
          "deletions": 10,
          "patch": "@@ -42,7 +42,7 @@\n     \"\\n\",\n     \"A number of model providers return token usage information as part of the chat generation response. When available, this information will be included on the `AIMessage` objects produced by the corresponding model.\\n\",\n     \"\\n\",\n-    \"LangChain `AIMessage` objects include a [usage_metadata](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.usage_metadata) attribute. When populated, this attribute will be a [UsageMetadata](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.UsageMetadata.html) dictionary with standard keys (e.g., `\\\"input_tokens\\\"` and `\\\"output_tokens\\\"`).\\n\",\n+    \"LangChain `AIMessage` objects include a [usage_metadata](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.usage_metadata) attribute. When populated, this attribute will be a [UsageMetadata](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.UsageMetadata.html) dictionary with standard keys (e.g., `\\\"input_tokens\\\"` and `\\\"output_tokens\\\"`).\\n\",\n     \"\\n\",\n     \"Examples:\\n\",\n     \"\\n\",\n@@ -71,7 +71,7 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\\n\",\n     \"openai_response = llm.invoke(\\\"hello\\\")\\n\",\n     \"openai_response.usage_metadata\"\n    ]\n@@ -118,7 +118,7 @@\n    \"source\": [\n     \"### Using AIMessage.response_metadata\\n\",\n     \"\\n\",\n-    \"Metadata from the model response is also included in the AIMessage [response_metadata](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.response_metadata) attribute. These data are typically not standardized. Note that different providers adopt different conventions for representing token counts:\"\n+    \"Metadata from the model response is also included in the AIMessage [response_metadata](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.response_metadata) attribute. These data are typically not standardized. Note that different providers adopt different conventions for representing token counts:\"\n    ]\n   },\n   {\n@@ -153,7 +153,7 @@\n     \"\\n\",\n     \"#### OpenAI\\n\",\n     \"\\n\",\n-    \"For example, OpenAI will return a message [chunk](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html) at the end of a stream with token usage information. This behavior is supported by `langchain-openai >= 0.1.9` and can be enabled by setting `stream_usage=True`. This attribute can also be set when `ChatOpenAI` is instantiated.\\n\",\n+    \"For example, OpenAI will return a message [chunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html) at the end of a stream with token usage information. This behavior is supported by `langchain-openai >= 0.1.9` and can be enabled by setting `stream_usage=True`. This attribute can also be set when `ChatOpenAI` is instantiated.\\n\",\n     \"\\n\",\n     \"```{=mdx}\\n\",\n     \":::note\\n\",\n@@ -182,13 +182,13 @@\n       \"content=' you' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\\n\",\n       \"content=' today' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\\n\",\n       \"content='?' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\\n\",\n-      \"content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'} id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\\n\",\n+      \"content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini'} id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\\n\",\n       \"content='' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623' usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17}\\n\"\n      ]\n     }\n    ],\n    \"source\": [\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\\n\",\n     \"\\n\",\n     \"aggregate = None\\n\",\n     \"for chunk in llm.stream(\\\"hello\\\", stream_usage=True):\\n\",\n@@ -252,7 +252,7 @@\n       \"content=' you' id='run-8e758550-94b0-4cca-a298-57482793c25d'\\n\",\n       \"content=' today' id='run-8e758550-94b0-4cca-a298-57482793c25d'\\n\",\n       \"content='?' id='run-8e758550-94b0-4cca-a298-57482793c25d'\\n\",\n-      \"content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'} id='run-8e758550-94b0-4cca-a298-57482793c25d'\\n\"\n+      \"content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini'} id='run-8e758550-94b0-4cca-a298-57482793c25d'\\n\"\n      ]\n     }\n    ],\n@@ -289,7 +289,7 @@\n     }\n    ],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Joke(BaseModel):\\n\",\n@@ -300,7 +300,7 @@\n     \"\\n\",\n     \"\\n\",\n     \"llm = ChatOpenAI(\\n\",\n-    \"    model=\\\"gpt-3.5-turbo-0125\\\",\\n\",\n+    \"    model=\\\"gpt-4o-mini\\\",\\n\",\n     \"    stream_usage=True,\\n\",\n     \")\\n\",\n     \"# Under the hood, .with_structured_output binds tools to the\\n\",\n@@ -362,7 +362,7 @@\n     \"from langchain_community.callbacks.manager import get_openai_callback\\n\",\n     \"\\n\",\n     \"llm = ChatOpenAI(\\n\",\n-    \"    model=\\\"gpt-3.5-turbo-0125\\\",\\n\",\n+    \"    model=\\\"gpt-4o-mini\\\",\\n\",\n     \"    temperature=0,\\n\",\n     \"    stream_usage=True,\\n\",\n     \")\\n\","
        },
        {
          "filename": "docs/docs/how_to/chatbots_memory.ipynb",
          "status": "modified",
          "additions": 10,
          "deletions": 10,
          "patch": "@@ -77,7 +77,7 @@\n    \"source\": [\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"chat = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\"\n+    \"chat = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\"\n    ]\n   },\n   {\n@@ -140,7 +140,7 @@\n     \"\\n\",\n     \"## Chat history\\n\",\n     \"\\n\",\n-    \"It's perfectly fine to store and pass messages directly as an array, but we can use LangChain's built-in [message history class](https://python.langchain.com/v0.2/api_reference/langchain/index.html#module-langchain.memory) to store and load messages as well. Instances of this class are responsible for storing and loading chat messages from persistent storage. LangChain integrates with many providers - you can see a [list of integrations here](/docs/integrations/memory) - but for this demo we will use an ephemeral demo class.\\n\",\n+    \"It's perfectly fine to store and pass messages directly as an array, but we can use LangChain's built-in [message history class](https://python.langchain.com/api_reference/langchain/index.html#module-langchain.memory) to store and load messages as well. Instances of this class are responsible for storing and loading chat messages from persistent storage. LangChain integrates with many providers - you can see a [list of integrations here](/docs/integrations/memory) - but for this demo we will use an ephemeral demo class.\\n\",\n     \"\\n\",\n     \"Here's an example of the API:\"\n    ]\n@@ -191,7 +191,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='You just asked me to translate the sentence \\\"I love programming\\\" from English to French.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 61, 'total_tokens': 79}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5cbb21c2-9c30-4031-8ea8-bfc497989535-0', usage_metadata={'input_tokens': 61, 'output_tokens': 18, 'total_tokens': 79})\"\n+       \"AIMessage(content='You just asked me to translate the sentence \\\"I love programming\\\" from English to French.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 61, 'total_tokens': 79}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5cbb21c2-9c30-4031-8ea8-bfc497989535-0', usage_metadata={'input_tokens': 61, 'output_tokens': 18, 'total_tokens': 79})\"\n       ]\n      },\n      \"execution_count\": 5,\n@@ -312,7 +312,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='\\\"J\\\\'adore la programmation.\\\"', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 39, 'total_tokens': 48}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-648b0822-b0bb-47a2-8e7d-7d34744be8f2-0', usage_metadata={'input_tokens': 39, 'output_tokens': 9, 'total_tokens': 48})\"\n+       \"AIMessage(content='\\\"J\\\\'adore la programmation.\\\"', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 39, 'total_tokens': 48}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-648b0822-b0bb-47a2-8e7d-7d34744be8f2-0', usage_metadata={'input_tokens': 39, 'output_tokens': 9, 'total_tokens': 48})\"\n       ]\n      },\n      \"execution_count\": 8,\n@@ -342,7 +342,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='You asked me to translate the sentence \\\"I love programming\\\" from English to French.', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 63, 'total_tokens': 80}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5950435c-1dc2-43a6-836f-f989fd62c95e-0', usage_metadata={'input_tokens': 63, 'output_tokens': 17, 'total_tokens': 80})\"\n+       \"AIMessage(content='You asked me to translate the sentence \\\"I love programming\\\" from English to French.', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 63, 'total_tokens': 80}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5950435c-1dc2-43a6-836f-f989fd62c95e-0', usage_metadata={'input_tokens': 63, 'output_tokens': 17, 'total_tokens': 80})\"\n       ]\n      },\n      \"execution_count\": 9,\n@@ -421,7 +421,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='Your name is Nemo.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 66, 'total_tokens': 72}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8aabef8-631a-4238-a39b-701e881fbe47-0', usage_metadata={'input_tokens': 66, 'output_tokens': 6, 'total_tokens': 72})\"\n+       \"AIMessage(content='Your name is Nemo.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 66, 'total_tokens': 72}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8aabef8-631a-4238-a39b-701e881fbe47-0', usage_metadata={'input_tokens': 66, 'output_tokens': 6, 'total_tokens': 72})\"\n       ]\n      },\n      \"execution_count\": 22,\n@@ -501,7 +501,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='P. Sherman is a fictional character from the animated movie \\\"Finding Nemo\\\" who lives at 42 Wallaby Way, Sydney.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 53, 'total_tokens': 80}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5642ef3a-fdbe-43cf-a575-d1785976a1b9-0', usage_metadata={'input_tokens': 53, 'output_tokens': 27, 'total_tokens': 80})\"\n+       \"AIMessage(content='P. Sherman is a fictional character from the animated movie \\\"Finding Nemo\\\" who lives at 42 Wallaby Way, Sydney.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 53, 'total_tokens': 80}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5642ef3a-fdbe-43cf-a575-d1785976a1b9-0', usage_metadata={'input_tokens': 53, 'output_tokens': 27, 'total_tokens': 80})\"\n       ]\n      },\n      \"execution_count\": 24,\n@@ -529,9 +529,9 @@\n        \" HumanMessage(content='How are you today?'),\\n\",\n        \" AIMessage(content='Fine thanks!'),\\n\",\n        \" HumanMessage(content=\\\"What's my name?\\\"),\\n\",\n-       \" AIMessage(content='Your name is Nemo.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 66, 'total_tokens': 72}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8aabef8-631a-4238-a39b-701e881fbe47-0', usage_metadata={'input_tokens': 66, 'output_tokens': 6, 'total_tokens': 72}),\\n\",\n+       \" AIMessage(content='Your name is Nemo.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 66, 'total_tokens': 72}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f8aabef8-631a-4238-a39b-701e881fbe47-0', usage_metadata={'input_tokens': 66, 'output_tokens': 6, 'total_tokens': 72}),\\n\",\n        \" HumanMessage(content='Where does P. Sherman live?'),\\n\",\n-       \" AIMessage(content='P. Sherman is a fictional character from the animated movie \\\"Finding Nemo\\\" who lives at 42 Wallaby Way, Sydney.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 53, 'total_tokens': 80}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5642ef3a-fdbe-43cf-a575-d1785976a1b9-0', usage_metadata={'input_tokens': 53, 'output_tokens': 27, 'total_tokens': 80})]\"\n+       \" AIMessage(content='P. Sherman is a fictional character from the animated movie \\\"Finding Nemo\\\" who lives at 42 Wallaby Way, Sydney.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 53, 'total_tokens': 80}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5642ef3a-fdbe-43cf-a575-d1785976a1b9-0', usage_metadata={'input_tokens': 53, 'output_tokens': 27, 'total_tokens': 80})]\"\n       ]\n      },\n      \"execution_count\": 25,\n@@ -565,7 +565,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content=\\\"I'm sorry, but I don't have access to your personal information, so I don't know your name. How else may I assist you today?\\\", response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 74, 'total_tokens': 105}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0ab03495-1f7c-4151-9070-56d2d1c565ff-0', usage_metadata={'input_tokens': 74, 'output_tokens': 31, 'total_tokens': 105})\"\n+       \"AIMessage(content=\\\"I'm sorry, but I don't have access to your personal information, so I don't know your name. How else may I assist you today?\\\", response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 74, 'total_tokens': 105}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0ab03495-1f7c-4151-9070-56d2d1c565ff-0', usage_metadata={'input_tokens': 74, 'output_tokens': 31, 'total_tokens': 105})\"\n       ]\n      },\n      \"execution_count\": 27,"
        },
        {
          "filename": "docs/docs/how_to/chatbots_retrieval.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -71,7 +71,7 @@\n    \"source\": [\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"chat = ChatOpenAI(model=\\\"gpt-3.5-turbo-1106\\\", temperature=0.2)\"\n+    \"chat = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0.2)\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/chatbots_tools.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -70,7 +70,7 @@\n     \"\\n\",\n     \"# Choose the LLM that will drive the agent\\n\",\n     \"# Only certain models support this\\n\",\n-    \"chat = ChatOpenAI(model=\\\"gpt-3.5-turbo-1106\\\", temperature=0)\"\n+    \"chat = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/code_splitter.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -7,7 +7,7 @@\n    \"source\": [\n     \"# How to split code\\n\",\n     \"\\n\",\n-    \"[RecursiveCharacterTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html) includes pre-built lists of separators that are useful for splitting text in a specific programming language.\\n\",\n+    \"[RecursiveCharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html) includes pre-built lists of separators that are useful for splitting text in a specific programming language.\\n\",\n     \"\\n\",\n     \"Supported languages are stored in the `langchain_text_splitters.Language` enum. They include:\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/configure.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 3,
          "patch": "@@ -58,7 +58,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {\n@@ -99,7 +100,7 @@\n    \"id\": \"b0f74589\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Above, we defined `temperature` as a [`ConfigurableField`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField) that we can set at runtime. To do so, we use the [`with_config`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config) method like this:\"\n+    \"Above, we defined `temperature` as a [`ConfigurableField`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.utils.ConfigurableField.html#langchain_core.runnables.utils.ConfigurableField) that we can set at runtime. To do so, we use the [`with_config`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config) method like this:\"\n    ]\n   },\n   {\n@@ -281,7 +282,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\"\n+    \"if \\\"ANTHROPIC_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/contextual_compression.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -227,7 +227,7 @@\n    \"source\": [\n     \"### `LLMListwiseRerank`\\n\",\n     \"\\n\",\n-    \"[LLMListwiseRerank](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) uses [zero-shot listwise document reranking](https://arxiv.org/pdf/2305.02156) and functions similarly to `LLMChainFilter` as a robust but more expensive option. It is recommended to use a more powerful LLM.\\n\",\n+    \"[LLMListwiseRerank](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) uses [zero-shot listwise document reranking](https://arxiv.org/pdf/2305.02156) and functions similarly to `LLMChainFilter` as a robust but more expensive option. It is recommended to use a more powerful LLM.\\n\",\n     \"\\n\",\n     \"Note that `LLMListwiseRerank` requires a model with the [with_structured_output](/docs/integrations/chat/) method implemented.\"\n    ]\n@@ -258,7 +258,7 @@\n     \"from langchain.retrievers.document_compressors import LLMListwiseRerank\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"\\n\",\n     \"_filter = LLMListwiseRerank.from_llm(llm, top_n=1)\\n\",\n     \"compression_retriever = ContextualCompressionRetriever(\\n\","
        },
        {
          "filename": "docs/docs/how_to/convert_runnable_to_tool.ipynb",
          "status": "modified",
          "additions": 11,
          "deletions": 11,
          "patch": "@@ -42,13 +42,13 @@\n    \"source\": [\n     \"LangChain [tools](/docs/concepts#tools) are interfaces that an agent, chain, or chat model can use to interact with the world. See [here](/docs/how_to/#tools) for how-to guides covering tool-calling, built-in tools, custom tools, and more information.\\n\",\n     \"\\n\",\n-    \"LangChain tools-- instances of [BaseTool](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.BaseTool.html)-- are [Runnables](/docs/concepts/#runnable-interface) with additional constraints that enable them to be invoked effectively by language models:\\n\",\n+    \"LangChain tools-- instances of [BaseTool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.BaseTool.html)-- are [Runnables](/docs/concepts/#runnable-interface) with additional constraints that enable them to be invoked effectively by language models:\\n\",\n     \"\\n\",\n     \"- Their inputs are constrained to be serializable, specifically strings and Python `dict` objects;\\n\",\n     \"- They contain names and descriptions indicating how and when they should be used;\\n\",\n-    \"- They may contain a detailed [args_schema](https://python.langchain.com/v0.2/docs/how_to/custom_tools/) for their arguments. That is, while a tool (as a `Runnable`) might accept a single `dict` input, the specific keys and type information needed to populate a dict should be specified in the `args_schema`.\\n\",\n+    \"- They may contain a detailed [args_schema](https://python.langchain.com/docs/how_to/custom_tools/) for their arguments. That is, while a tool (as a `Runnable`) might accept a single `dict` input, the specific keys and type information needed to populate a dict should be specified in the `args_schema`.\\n\",\n     \"\\n\",\n-    \"Runnables that accept string or `dict` input can be converted to tools using the [as_tool](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.as_tool) method, which allows for the specification of names, descriptions, and additional schema information for arguments.\"\n+    \"Runnables that accept string or `dict` input can be converted to tools using the [as_tool](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.as_tool) method, which allows for the specification of names, descriptions, and additional schema information for arguments.\"\n    ]\n   },\n   {\n@@ -180,7 +180,7 @@\n    \"id\": \"32b1a992-8997-4c98-8eb2-c9fe9431b799\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Alternatively, the schema can be fully specified by directly passing the desired [args_schema](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool.args_schema) for the tool:\"\n+    \"Alternatively, the schema can be fully specified by directly passing the desired [args_schema](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool.args_schema) for the tool:\"\n    ]\n   },\n   {\n@@ -190,7 +190,7 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class GSchema(BaseModel):\\n\",\n@@ -285,7 +285,7 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -331,7 +331,7 @@\n    \"id\": \"9ba737ac-43a2-4a6f-b855-5bd0305017f1\",\n    \"metadata\": {},\n    \"source\": [\n-    \"We next create use a simple pre-built [LangGraph agent](https://python.langchain.com/v0.2/docs/tutorials/agents/) and provide it the tool:\"\n+    \"We next create use a simple pre-built [LangGraph agent](https://python.langchain.com/docs/tutorials/agents/) and provide it the tool:\"\n    ]\n   },\n   {\n@@ -362,11 +362,11 @@\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_W8cnfOjwqEn4cFcg19LN9mYD', 'function': {'arguments': '{\\\"__arg1\\\":\\\"dogs\\\"}', 'name': 'pet_info_retriever'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 60, 'total_tokens': 79}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d7f81de9-1fb7-4caf-81ed-16dcdb0b2ab4-0', tool_calls=[{'name': 'pet_info_retriever', 'args': {'__arg1': 'dogs'}, 'id': 'call_W8cnfOjwqEn4cFcg19LN9mYD'}], usage_metadata={'input_tokens': 60, 'output_tokens': 19, 'total_tokens': 79})]}}\\n\",\n+      \"{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_W8cnfOjwqEn4cFcg19LN9mYD', 'function': {'arguments': '{\\\"__arg1\\\":\\\"dogs\\\"}', 'name': 'pet_info_retriever'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 60, 'total_tokens': 79}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d7f81de9-1fb7-4caf-81ed-16dcdb0b2ab4-0', tool_calls=[{'name': 'pet_info_retriever', 'args': {'__arg1': 'dogs'}, 'id': 'call_W8cnfOjwqEn4cFcg19LN9mYD'}], usage_metadata={'input_tokens': 60, 'output_tokens': 19, 'total_tokens': 79})]}}\\n\",\n       \"----\\n\",\n       \"{'tools': {'messages': [ToolMessage(content=\\\"[Document(id='86f835fe-4bbe-4ec6-aeb4-489a8b541707', page_content='Dogs are great companions, known for their loyalty and friendliness.')]\\\", name='pet_info_retriever', tool_call_id='call_W8cnfOjwqEn4cFcg19LN9mYD')]}}\\n\",\n       \"----\\n\",\n-      \"{'agent': {'messages': [AIMessage(content='Dogs are known for being great companions, known for their loyalty and friendliness.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9ca5847a-a5eb-44c0-a774-84cc2c5bbc5b-0', usage_metadata={'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152})]}}\\n\",\n+      \"{'agent': {'messages': [AIMessage(content='Dogs are known for being great companions, known for their loyalty and friendliness.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 134, 'total_tokens': 152}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9ca5847a-a5eb-44c0-a774-84cc2c5bbc5b-0', usage_metadata={'input_tokens': 134, 'output_tokens': 18, 'total_tokens': 152})]}}\\n\",\n       \"----\\n\"\n      ]\n     }\n@@ -497,11 +497,11 @@\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_17iLPWvOD23zqwd1QVQ00Y63', 'function': {'arguments': '{\\\"question\\\":\\\"What are dogs known for according to pirates?\\\",\\\"answer_style\\\":\\\"quote\\\"}', 'name': 'pet_expert'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 59, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7fef44f3-7bba-4e63-8c51-2ad9c5e65e2e-0', tool_calls=[{'name': 'pet_expert', 'args': {'question': 'What are dogs known for according to pirates?', 'answer_style': 'quote'}, 'id': 'call_17iLPWvOD23zqwd1QVQ00Y63'}], usage_metadata={'input_tokens': 59, 'output_tokens': 28, 'total_tokens': 87})]}}\\n\",\n+      \"{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_17iLPWvOD23zqwd1QVQ00Y63', 'function': {'arguments': '{\\\"question\\\":\\\"What are dogs known for according to pirates?\\\",\\\"answer_style\\\":\\\"quote\\\"}', 'name': 'pet_expert'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 59, 'total_tokens': 87}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7fef44f3-7bba-4e63-8c51-2ad9c5e65e2e-0', tool_calls=[{'name': 'pet_expert', 'args': {'question': 'What are dogs known for according to pirates?', 'answer_style': 'quote'}, 'id': 'call_17iLPWvOD23zqwd1QVQ00Y63'}], usage_metadata={'input_tokens': 59, 'output_tokens': 28, 'total_tokens': 87})]}}\\n\",\n       \"----\\n\",\n       \"{'tools': {'messages': [ToolMessage(content='\\\"Dogs are known for their loyalty and friendliness, making them great companions for pirates on long sea voyages.\\\"', name='pet_expert', tool_call_id='call_17iLPWvOD23zqwd1QVQ00Y63')]}}\\n\",\n       \"----\\n\",\n-      \"{'agent': {'messages': [AIMessage(content='According to pirates, dogs are known for their loyalty and friendliness, making them great companions for pirates on long sea voyages.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 119, 'total_tokens': 146}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5a30edc3-7be0-4743-b980-ca2f8cad9b8d-0', usage_metadata={'input_tokens': 119, 'output_tokens': 27, 'total_tokens': 146})]}}\\n\",\n+      \"{'agent': {'messages': [AIMessage(content='According to pirates, dogs are known for their loyalty and friendliness, making them great companions for pirates on long sea voyages.', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 119, 'total_tokens': 146}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5a30edc3-7be0-4743-b980-ca2f8cad9b8d-0', usage_metadata={'input_tokens': 119, 'output_tokens': 27, 'total_tokens': 146})]}}\\n\",\n       \"----\\n\"\n      ]\n     }"
        },
        {
          "filename": "docs/docs/how_to/custom_callbacks.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -16,7 +16,7 @@\n     \"\\n\",\n     \"LangChain has some built-in callback handlers, but you will often want to create your own handlers with custom logic.\\n\",\n     \"\\n\",\n-    \"To create a custom callback handler, we need to determine the [event(s)](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain-core-callbacks-base-basecallbackhandler) we want our callback handler to handle as well as what we want our callback handler to do when the event is triggered. Then all we need to do is attach the callback handler to the object, for example via [the constructor](/docs/how_to/callbacks_constructor) or [at runtime](/docs/how_to/callbacks_runtime).\\n\",\n+    \"To create a custom callback handler, we need to determine the [event(s)](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain-core-callbacks-base-basecallbackhandler) we want our callback handler to handle as well as what we want our callback handler to do when the event is triggered. Then all we need to do is attach the callback handler to the object, for example via [the constructor](/docs/how_to/callbacks_constructor) or [at runtime](/docs/how_to/callbacks_runtime).\\n\",\n     \"\\n\",\n     \"In the example below, we'll implement streaming with a custom handler.\\n\",\n     \"\\n\",\n@@ -107,7 +107,7 @@\n    \"cell_type\": \"markdown\",\n    \"metadata\": {},\n    \"source\": [\n-    \"You can see [this reference page](https://python.langchain.com/v0.2/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain-core-callbacks-base-basecallbackhandler) for a list of events you can handle. Note that the `handle_chain_*` events run for most LCEL runnables.\\n\",\n+    \"You can see [this reference page](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain-core-callbacks-base-basecallbackhandler) for a list of events you can handle. Note that the `handle_chain_*` events run for most LCEL runnables.\\n\",\n     \"\\n\",\n     \"## Next steps\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/custom_chat_model.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -16,7 +16,7 @@\n     \"\\n\",\n     \"In this guide, we'll learn how to create a custom chat model using LangChain abstractions.\\n\",\n     \"\\n\",\n-    \"Wrapping your LLM with the standard [`BaseChatModel`](https://python.langchain.com/v0.2/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html) interface allow you to use your LLM in existing LangChain programs with minimal code modifications!\\n\",\n+    \"Wrapping your LLM with the standard [`BaseChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html) interface allow you to use your LLM in existing LangChain programs with minimal code modifications!\\n\",\n     \"\\n\",\n     \"As an bonus, your LLM will automatically become a LangChain `Runnable` and will benefit from some optimizations out of the box (e.g., batch via a threadpool), async support, the `astream_events` API, etc.\\n\",\n     \"\\n\",\n@@ -503,7 +503,7 @@\n     \"\\n\",\n     \"Documentation:\\n\",\n     \"\\n\",\n-    \"* The model contains doc-strings for all initialization arguments, as these will be surfaced in the [APIReference](https://python.langchain.com/v0.2/api_reference/langchain/index.html).\\n\",\n+    \"* The model contains doc-strings for all initialization arguments, as these will be surfaced in the [APIReference](https://python.langchain.com/api_reference/langchain/index.html).\\n\",\n     \"* The class doc-string for the model contains a link to the model API if the model is powered by a service.\\n\",\n     \"\\n\",\n     \"Tests:\\n\","
        },
        {
          "filename": "docs/docs/how_to/custom_llm.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -402,7 +402,7 @@\n     \"\\n\",\n     \"Documentation:\\n\",\n     \"\\n\",\n-    \"* The model contains doc-strings for all initialization arguments, as these will be surfaced in the [APIReference](https://python.langchain.com/v0.2/api_reference/langchain/index.html).\\n\",\n+    \"* The model contains doc-strings for all initialization arguments, as these will be surfaced in the [APIReference](https://python.langchain.com/api_reference/langchain/index.html).\\n\",\n     \"* The class doc-string for the model contains a link to the model API if the model is powered by a service.\\n\",\n     \"\\n\",\n     \"Tests:\\n\","
        },
        {
          "filename": "docs/docs/how_to/custom_retriever.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -270,7 +270,7 @@\n     \"\\n\",\n     \"Documentation:\\n\",\n     \"\\n\",\n-    \"* The retriever contains doc-strings for all initialization arguments, as these will be surfaced in the [API Reference](https://python.langchain.com/v0.2/api_reference/langchain/index.html).\\n\",\n+    \"* The retriever contains doc-strings for all initialization arguments, as these will be surfaced in the [API Reference](https://python.langchain.com/api_reference/langchain/index.html).\\n\",\n     \"* The class doc-string for the model contains a link to any relevant APIs used for the retriever (e.g., if the retriever is retrieving from wikipedia, it'll be good to link to the wikipedia API!)\\n\",\n     \"\\n\",\n     \"Tests:\\n\","
        },
        {
          "filename": "docs/docs/how_to/custom_tools.ipynb",
          "status": "modified",
          "additions": 241,
          "deletions": 77,
          "patch": "@@ -13,16 +13,16 @@\n     \"|---------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n\",\n     \"| name          | str                             | Must be unique within a set of tools provided to an LLM or agent.                                                                                                              |\\n\",\n     \"| description   | str                             | Describes what the tool does. Used as context by the LLM or agent.                                                                                                             |\\n\",\n-    \"| args_schema   | langchain.pydantic_v1.BaseModel | Optional but recommended, and required if using callback handlers. It can be used to provide more information (e.g., few-shot examples) or validation for expected parameters. |\\n\",\n+    \"| args_schema   | pydantic.BaseModel | Optional but recommended, and required if using callback handlers. It can be used to provide more information (e.g., few-shot examples) or validation for expected parameters. |\\n\",\n     \"| return_direct | boolean                         | Only relevant for agents. When True, after invoking the given tool, the agent will stop and return the result direcly to the user.                                             |\\n\",\n     \"\\n\",\n     \"LangChain supports the creation of tools from:\\n\",\n     \"\\n\",\n     \"1. Functions;\\n\",\n     \"2. LangChain [Runnables](/docs/concepts#runnable-interface);\\n\",\n-    \"3. By sub-classing from [BaseTool](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.BaseTool.html) -- This is the most flexible method, it provides the largest degree of control, at the expense of more effort and code.\\n\",\n+    \"3. By sub-classing from [BaseTool](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.BaseTool.html) -- This is the most flexible method, it provides the largest degree of control, at the expense of more effort and code.\\n\",\n     \"\\n\",\n-    \"Creating tools from functions may be sufficient for most use cases, and can be done via a simple [@tool decorator](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.tool.html#langchain_core.tools.tool). If more configuration is needed-- e.g., specification of both sync and async implementations-- one can also use the [StructuredTool.from_function](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.StructuredTool.html#langchain_core.tools.StructuredTool.from_function) class method.\\n\",\n+    \"Creating tools from functions may be sufficient for most use cases, and can be done via a simple [@tool decorator](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.tool.html#langchain_core.tools.tool). If more configuration is needed-- e.g., specification of both sync and async implementations-- one can also use the [StructuredTool.from_function](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.StructuredTool.html#langchain_core.tools.StructuredTool.from_function) class method.\\n\",\n     \"\\n\",\n     \"In this guide we provide an overview of these methods.\\n\",\n     \"\\n\",\n@@ -48,7 +48,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n    \"id\": \"cc7005cd-072f-4d37-8453-6297468e5192\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:52.645451Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:52.645081Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.030958Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.030669Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -88,7 +95,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 2,\n    \"id\": \"0c0991db-b997-4611-be37-4346e660506b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.032544Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.032420Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.035349Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.035123Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.tools import tool\\n\",\n@@ -112,22 +126,29 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 3,\n    \"id\": \"5626423f-053e-4a66-adca-1d794d835397\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.036658Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.036574Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.041154Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.040964Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'multiply_by_maxSchema',\\n\",\n-       \" 'description': 'Multiply a by the maximum of b.',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'a': {'title': 'A',\\n\",\n-       \"   'description': 'scale factor',\\n\",\n+       \"{'description': 'Multiply a by the maximum of b.',\\n\",\n+       \" 'properties': {'a': {'description': 'scale factor',\\n\",\n+       \"   'title': 'A',\\n\",\n        \"   'type': 'string'},\\n\",\n-       \"  'b': {'title': 'B',\\n\",\n-       \"   'description': 'list of ints over which to take maximum',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'integer'}}},\\n\",\n-       \" 'required': ['a', 'b']}\"\n+       \"  'b': {'description': 'list of ints over which to take maximum',\\n\",\n+       \"   'items': {'type': 'integer'},\\n\",\n+       \"   'title': 'B',\\n\",\n+       \"   'type': 'array'}},\\n\",\n+       \" 'required': ['a', 'b'],\\n\",\n+       \" 'title': 'multiply_by_maxSchema',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n      \"execution_count\": 3,\n@@ -163,21 +184,28 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 4,\n    \"id\": \"9216d03a-f6ea-4216-b7e1-0661823a4c0b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.042516Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.042427Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.045217Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.045010Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n       \"multiplication-tool\\n\",\n       \"Multiply two numbers.\\n\",\n-      \"{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\\n\",\n+      \"{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\\n\",\n       \"True\\n\"\n      ]\n     }\n    ],\n    \"source\": [\n-    \"from langchain.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class CalculatorInput(BaseModel):\\n\",\n@@ -218,19 +246,26 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 5,\n    \"id\": \"336f5538-956e-47d5-9bde-b732559f9e61\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.046526Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.046456Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.050045Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.049836Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'fooSchema',\\n\",\n-       \" 'description': 'The foo.',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'bar': {'title': 'Bar',\\n\",\n-       \"   'description': 'The bar.',\\n\",\n+       \"{'description': 'The foo.',\\n\",\n+       \" 'properties': {'bar': {'description': 'The bar.',\\n\",\n+       \"   'title': 'Bar',\\n\",\n        \"   'type': 'string'},\\n\",\n-       \"  'baz': {'title': 'Baz', 'description': 'The baz.', 'type': 'integer'}},\\n\",\n-       \" 'required': ['bar', 'baz']}\"\n+       \"  'baz': {'description': 'The baz.', 'title': 'Baz', 'type': 'integer'}},\\n\",\n+       \" 'required': ['bar', 'baz'],\\n\",\n+       \" 'title': 'fooSchema',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n      \"execution_count\": 5,\n@@ -259,7 +294,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \":::{.callout-caution}\\n\",\n-    \"By default, `@tool(parse_docstring=True)` will raise `ValueError` if the docstring does not parse correctly. See [API Reference](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.tool.html) for detail and examples.\\n\",\n+    \"By default, `@tool(parse_docstring=True)` will raise `ValueError` if the docstring does not parse correctly. See [API Reference](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.tool.html) for detail and examples.\\n\",\n     \":::\"\n    ]\n   },\n@@ -277,7 +312,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 6,\n    \"id\": \"564fbe6f-11df-402d-b135-ef6ff25e1e63\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.051302Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.051218Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.059704Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.059490Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -320,7 +362,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 7,\n    \"id\": \"6bc055d4-1fbe-4db5-8881-9c382eba6b1b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.060971Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.060883Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.064615Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.064408Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -329,7 +378,7 @@\n       \"6\\n\",\n       \"Calculator\\n\",\n       \"multiply numbers\\n\",\n-      \"{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\\n\"\n+      \"{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\\n\"\n      ]\n     }\n    ],\n@@ -366,24 +415,39 @@\n    \"source\": [\n     \"## Creating tools from Runnables\\n\",\n     \"\\n\",\n-    \"LangChain [Runnables](/docs/concepts#runnable-interface) that accept string or `dict` input can be converted to tools using the [as_tool](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.as_tool) method, which allows for the specification of names, descriptions, and additional schema information for arguments.\\n\",\n+    \"LangChain [Runnables](/docs/concepts#runnable-interface) that accept string or `dict` input can be converted to tools using the [as_tool](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.as_tool) method, which allows for the specification of names, descriptions, and additional schema information for arguments.\\n\",\n     \"\\n\",\n     \"Example usage:\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 9,\n+   \"execution_count\": 8,\n    \"id\": \"8ef593c5-cf72-4c10-bfc9-7d21874a0c24\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.065797Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.065733Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.130458Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.130229Z\"\n+    }\n+   },\n    \"outputs\": [\n+    {\n+     \"name\": \"stderr\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"/var/folders/4j/2rz3865x6qg07tx43146py8h0000gn/T/ipykernel_95770/2548361071.py:14: LangChainBetaWarning: This API is in beta and may change in the future.\\n\",\n+      \"  as_tool = chain.as_tool(\\n\"\n+     ]\n+    },\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"{'answer_style': {'title': 'Answer Style', 'type': 'string'}}\"\n       ]\n      },\n-     \"execution_count\": 9,\n+     \"execution_count\": 8,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -428,29 +492,38 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 10,\n+   \"execution_count\": 9,\n    \"id\": \"1dad8f8e\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.131904Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.131803Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.136797Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.136563Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import Optional, Type\\n\",\n     \"\\n\",\n-    \"from langchain.pydantic_v1 import BaseModel\\n\",\n     \"from langchain_core.callbacks import (\\n\",\n     \"    AsyncCallbackManagerForToolRun,\\n\",\n     \"    CallbackManagerForToolRun,\\n\",\n     \")\\n\",\n     \"from langchain_core.tools import BaseTool\\n\",\n+    \"from pydantic import BaseModel\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class CalculatorInput(BaseModel):\\n\",\n     \"    a: int = Field(description=\\\"first number\\\")\\n\",\n     \"    b: int = Field(description=\\\"second number\\\")\\n\",\n     \"\\n\",\n     \"\\n\",\n+    \"# Note: It's important that every field has type hints. BaseTool is a\\n\",\n+    \"# Pydantic class and not having type hints can lead to unexpected behavior.\\n\",\n     \"class CustomCalculatorTool(BaseTool):\\n\",\n-    \"    name = \\\"Calculator\\\"\\n\",\n-    \"    description = \\\"useful for when you need to answer questions about math\\\"\\n\",\n+    \"    name: str = \\\"Calculator\\\"\\n\",\n+    \"    description: str = \\\"useful for when you need to answer questions about math\\\"\\n\",\n     \"    args_schema: Type[BaseModel] = CalculatorInput\\n\",\n     \"    return_direct: bool = True\\n\",\n     \"\\n\",\n@@ -477,17 +550,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 11,\n+   \"execution_count\": 10,\n    \"id\": \"bb551c33\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.138074Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.138007Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.141360Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.141158Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n       \"Calculator\\n\",\n       \"useful for when you need to answer questions about math\\n\",\n-      \"{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\\n\",\n+      \"{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}\\n\",\n       \"True\\n\",\n       \"6\\n\",\n       \"6\\n\"\n@@ -512,7 +592,7 @@\n    \"source\": [\n     \"## How to create async tools\\n\",\n     \"\\n\",\n-    \"LangChain Tools implement the [Runnable interface \ud83c\udfc3](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html).\\n\",\n+    \"LangChain Tools implement the [Runnable interface \ud83c\udfc3](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html).\\n\",\n     \"\\n\",\n     \"All Runnables expose the `invoke` and `ainvoke` methods (as well as other methods like `batch`, `abatch`, `astream` etc).\\n\",\n     \"\\n\",\n@@ -528,9 +608,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 12,\n+   \"execution_count\": 11,\n    \"id\": \"6615cb77-fd4c-4676-8965-f92cc71d4944\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.142587Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.142504Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.147205Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.146995Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -560,9 +647,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 13,\n+   \"execution_count\": 12,\n    \"id\": \"bb2af583-eadd-41f4-a645-bf8748bd3dcd\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.148383Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.148307Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.152684Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.152486Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -605,9 +699,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 14,\n+   \"execution_count\": 13,\n    \"id\": \"4ad0932c-8610-4278-8c57-f9218f654c8a\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.153849Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.153773Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.158312Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.158130Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -650,9 +751,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 15,\n+   \"execution_count\": 14,\n    \"id\": \"7094c0e8-6192-4870-a942-aad5b5ae48fd\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.159440Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.159364Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.160922Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.160712Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.tools import ToolException\\n\",\n@@ -673,17 +781,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 16,\n+   \"execution_count\": 15,\n    \"id\": \"b4d22022-b105-4ccc-a15b-412cb9ea3097\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.162046Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.161968Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.165236Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.165052Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"'Error: There is no city by the name of foobar.'\"\n       ]\n      },\n-     \"execution_count\": 16,\n+     \"execution_count\": 15,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -707,17 +822,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 17,\n+   \"execution_count\": 16,\n    \"id\": \"3fad1728-d367-4e1b-9b54-3172981271cf\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.166372Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.166294Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.169739Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.169553Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"\\\"There is no such city, but it's probably above 0K there!\\\"\"\n       ]\n      },\n-     \"execution_count\": 17,\n+     \"execution_count\": 16,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -741,17 +863,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 18,\n+   \"execution_count\": 17,\n    \"id\": \"ebfe7c1f-318d-4e58-99e1-f31e69473c46\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.170937Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.170859Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.174498Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.174304Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"'The following errors occurred during tool execution: `Error: There is no city by the name of foobar.`'\"\n       ]\n      },\n-     \"execution_count\": 18,\n+     \"execution_count\": 17,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -778,7 +907,7 @@\n     \"\\n\",\n     \"Sometimes there are artifacts of a tool's execution that we want to make accessible to downstream components in our chain or agent, but that we don't want to expose to the model itself. For example if a tool returns custom objects like Documents, we may want to pass some view or metadata about this output to the model without passing the raw output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.\\n\",\n     \"\\n\",\n-    \"The Tool and [ToolMessage](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) interfaces make it possible to distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact).\\n\",\n+    \"The Tool and [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) interfaces make it possible to distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact).\\n\",\n     \"\\n\",\n     \":::info Requires ``langchain-core >= 0.2.19``\\n\",\n     \"\\n\",\n@@ -791,9 +920,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": 18,\n    \"id\": \"14905425-0334-43a0-9de9-5bcf622ede0e\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.175683Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.175605Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.178798Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.178601Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import random\\n\",\n@@ -820,17 +956,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 9,\n+   \"execution_count\": 19,\n    \"id\": \"0f2e1528-404b-46e6-b87c-f0957c4b9217\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.179881Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.179807Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.182100Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.181940Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"'Successfully generated array of 10 random ints in [0, 9].'\"\n       ]\n      },\n-     \"execution_count\": 9,\n+     \"execution_count\": 19,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -849,17 +992,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 20,\n    \"id\": \"cc197777-26eb-46b3-a83b-c2ce116c6311\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.183238Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.183170Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.185752Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.185567Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"ToolMessage(content='Successfully generated array of 10 random ints in [0, 9].', name='generate_random_ints', tool_call_id='123', artifact=[1, 4, 2, 5, 3, 9, 0, 4, 7, 7])\"\n+       \"ToolMessage(content='Successfully generated array of 10 random ints in [0, 9].', name='generate_random_ints', tool_call_id='123', artifact=[4, 8, 2, 4, 1, 0, 9, 5, 8, 1])\"\n       ]\n      },\n-     \"execution_count\": 3,\n+     \"execution_count\": 20,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -885,9 +1035,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 21,\n    \"id\": \"fe1a09d1-378b-4b91-bb5e-0697c3d7eb92\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.186884Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.186803Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.190718Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.190494Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.tools import BaseTool\\n\",\n@@ -917,17 +1074,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 8,\n+   \"execution_count\": 22,\n    \"id\": \"8c3d16f6-1c4a-48ab-b05a-38547c592e79\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:25:53.191872Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:25:53.191794Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:25:53.194396Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:25:53.194184Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"ToolMessage(content='Generated 3 floats in [0.1, 3.3333], rounded to 4 decimals.', name='generate_random_floats', tool_call_id='123', artifact=[1.4277, 0.7578, 2.4871])\"\n+       \"ToolMessage(content='Generated 3 floats in [0.1, 3.3333], rounded to 4 decimals.', name='generate_random_floats', tool_call_id='123', artifact=[1.5566, 0.5134, 2.7914])\"\n       ]\n      },\n-     \"execution_count\": 8,\n+     \"execution_count\": 22,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }"
        },
        {
          "filename": "docs/docs/how_to/document_loader_csv.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -9,7 +9,7 @@\n     \"\\n\",\n     \"A [comma-separated values (CSV)](https://en.wikipedia.org/wiki/Comma-separated_values) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.\\n\",\n     \"\\n\",\n-    \"LangChain implements a [CSV Loader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html) that will load CSV files into a sequence of [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects. Each row of the CSV file is translated to one document.\"\n+    \"LangChain implements a [CSV Loader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.csv_loader.CSVLoader.html) that will load CSV files into a sequence of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects. Each row of the CSV file is translated to one document.\"\n    ]\n   },\n   {\n@@ -88,7 +88,7 @@\n    \"source\": [\n     \"## Specify a column to identify the document source\\n\",\n     \"\\n\",\n-    \"The `\\\"source\\\"` key on [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) metadata can be set using a column of the CSV. Use the `source_column` argument to specify a source for the document created from each row. Otherwise `file_path` will be used as the source for all documents created from the CSV file.\\n\",\n+    \"The `\\\"source\\\"` key on [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) metadata can be set using a column of the CSV. Use the `source_column` argument to specify a source for the document created from each row. Otherwise `file_path` will be used as the source for all documents created from the CSV file.\\n\",\n     \"\\n\",\n     \"This is useful when using documents loaded from CSV files for chains that answer questions using sources.\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/document_loader_directory.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -7,7 +7,7 @@\n    \"source\": [\n     \"# How to load documents from a directory\\n\",\n     \"\\n\",\n-    \"LangChain's [DirectoryLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.directory.DirectoryLoader.html) implements functionality for reading files from disk into LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects. Here we demonstrate:\\n\",\n+    \"LangChain's [DirectoryLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.directory.DirectoryLoader.html) implements functionality for reading files from disk into LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects. Here we demonstrate:\\n\",\n     \"\\n\",\n     \"- How to load from a filesystem, including use of wildcard patterns;\\n\",\n     \"- How to use multithreading for file I/O;\\n\",\n@@ -134,7 +134,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"## Change loader class\\n\",\n-    \"By default this uses the `UnstructuredLoader` class. To customize the loader, specify the loader class in the `loader_cls` kwarg. Below we show an example using [TextLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.text.TextLoader.html):\"\n+    \"By default this uses the `UnstructuredLoader` class. To customize the loader, specify the loader class in the `loader_cls` kwarg. Below we show an example using [TextLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.text.TextLoader.html):\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/document_loader_html.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -9,7 +9,7 @@\n     \"\\n\",\n     \"The HyperText Markup Language or [HTML](https://en.wikipedia.org/wiki/HTML) is the standard markup language for documents designed to be displayed in a web browser.\\n\",\n     \"\\n\",\n-    \"This covers how to load `HTML` documents into a LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects that we can use downstream.\\n\",\n+    \"This covers how to load `HTML` documents into a LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects that we can use downstream.\\n\",\n     \"\\n\",\n     \"Parsing HTML files often requires specialized tools. Here we demonstrate parsing via [Unstructured](https://unstructured-io.github.io/unstructured/) and [BeautifulSoup4](https://beautiful-soup-4.readthedocs.io/en/latest/), which can be installed via pip. Head over to the integrations page to find integrations with additional services, such as [Azure AI Document Intelligence](/docs/integrations/document_loaders/azure_document_intelligence) or [FireCrawl](/docs/integrations/document_loaders/firecrawl).\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/document_loader_json.mdx",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -4,8 +4,8 @@\n \n [JSON Lines](https://jsonlines.org/) is a file format where each line is a valid JSON value.\n \n-LangChain implements a [JSONLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html) \n-to convert JSON and JSONL data into LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) \n+LangChain implements a [JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html) \n+to convert JSON and JSONL data into LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) \n objects. It uses a specified [jq schema](https://en.wikipedia.org/wiki/Jq_(programming_language)) to parse the JSON files, allowing for the extraction of specific fields into the content \n and metadata of the LangChain Document.\n "
        },
        {
          "filename": "docs/docs/how_to/document_loader_markdown.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -9,14 +9,14 @@\n     \"\\n\",\n     \"[Markdown](https://en.wikipedia.org/wiki/Markdown) is a lightweight markup language for creating formatted text using a plain-text editor.\\n\",\n     \"\\n\",\n-    \"Here we cover how to load `Markdown` documents into LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects that we can use downstream.\\n\",\n+    \"Here we cover how to load `Markdown` documents into LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) objects that we can use downstream.\\n\",\n     \"\\n\",\n     \"We will cover:\\n\",\n     \"\\n\",\n     \"- Basic usage;\\n\",\n     \"- Parsing of Markdown into elements such as titles, list items, and text.\\n\",\n     \"\\n\",\n-    \"LangChain implements an [UnstructuredMarkdownLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html) object which requires the [Unstructured](https://unstructured-io.github.io/unstructured/) package. First we install it:\"\n+    \"LangChain implements an [UnstructuredMarkdownLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html) object which requires the [Unstructured](https://unstructured-io.github.io/unstructured/) package. First we install it:\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/document_loader_office_file.mdx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -3,7 +3,7 @@\n The [Microsoft Office](https://www.office.com/) suite of productivity software includes Microsoft Word, Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, and Microsoft OneNote. It is available for Microsoft Windows and macOS operating systems. It is also available on Android and iOS.\n \n This covers how to load commonly used file formats including `DOCX`, `XLSX` and `PPTX` documents into a LangChain \n-[Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document)\n+[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document)\n object that we can use downstream.\n \n "
        },
        {
          "filename": "docs/docs/how_to/document_loader_pdf.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 3,
          "patch": "@@ -9,7 +9,7 @@\n     \"\\n\",\n     \"[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\\n\",\n     \"\\n\",\n-    \"This guide covers how to load `PDF` documents into the LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) format that we use downstream.\\n\",\n+    \"This guide covers how to load `PDF` documents into the LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) format that we use downstream.\\n\",\n     \"\\n\",\n     \"LangChain integrates with a host of PDF parsers. Some are simple and relatively low-level; others will support OCR and image-processing, or perform advanced document layout analysis. The right choice will depend on your application. Below we enumerate the possibilities.\\n\",\n     \"\\n\",\n@@ -90,7 +90,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {\n@@ -182,7 +183,7 @@\n    \"source\": [\n     \"## Using other PDF loaders\\n\",\n     \"\\n\",\n-    \"For a list of other PDF loaders to use, please see [this table](https://python.langchain.com/v0.2/docs/integrations/document_loaders/#pdfs)\"\n+    \"For a list of other PDF loaders to use, please see [this table](https://python.langchain.com/docs/integrations/document_loaders/#pdfs)\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/how_to/ensemble_retriever.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -6,15 +6,15 @@\n    \"source\": [\n     \"# How to combine results from multiple retrievers\\n\",\n     \"\\n\",\n-    \"The [EnsembleRetriever](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.ensemble.EnsembleRetriever.html) supports ensembling of results from multiple retrievers. It is initialized with a list of [BaseRetriever](https://python.langchain.com/v0.2/api_reference/core/retrievers/langchain_core.retrievers.BaseRetriever.html) objects. EnsembleRetrievers rerank the results of the constituent retrievers based on the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\\n\",\n+    \"The [EnsembleRetriever](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.ensemble.EnsembleRetriever.html) supports ensembling of results from multiple retrievers. It is initialized with a list of [BaseRetriever](https://python.langchain.com/api_reference/core/retrievers/langchain_core.retrievers.BaseRetriever.html) objects. EnsembleRetrievers rerank the results of the constituent retrievers based on the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\\n\",\n     \"\\n\",\n     \"By leveraging the strengths of different algorithms, the `EnsembleRetriever` can achieve better performance than any single algorithm. \\n\",\n     \"\\n\",\n     \"The most common pattern is to combine a sparse retriever (like BM25) with a dense retriever (like embedding similarity), because their strengths are complementary. It is also known as \\\"hybrid search\\\". The sparse retriever is good at finding relevant documents based on keywords, while the dense retriever is good at finding relevant documents based on semantic similarity.\\n\",\n     \"\\n\",\n     \"## Basic usage\\n\",\n     \"\\n\",\n-    \"Below we demonstrate ensembling of a [BM25Retriever](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.bm25.BM25Retriever.html) with a retriever derived from the [FAISS vector store](https://python.langchain.com/v0.2/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html).\"\n+    \"Below we demonstrate ensembling of a [BM25Retriever](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.bm25.BM25Retriever.html) with a retriever derived from the [FAISS vector store](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html).\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/extraction_examples.ipynb",
          "status": "modified",
          "additions": 173,
          "deletions": 48,
          "patch": "@@ -16,11 +16,11 @@\n     \"also with JSON more or prompt based techniques.\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"LangChain implements a [tool-call attribute](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.tool_calls) on messages from LLMs that include tool calls. See our [how-to guide on tool calling](/docs/how_to/tool_calling) for more detail. To build reference examples for data extraction, we build a chat history containing a sequence of: \\n\",\n+    \"LangChain implements a [tool-call attribute](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.tool_calls) on messages from LLMs that include tool calls. See our [how-to guide on tool calling](/docs/how_to/tool_calling) for more detail. To build reference examples for data extraction, we build a chat history containing a sequence of: \\n\",\n     \"\\n\",\n-    \"- [HumanMessage](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) containing example inputs;\\n\",\n-    \"- [AIMessage](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html) containing example tool calls;\\n\",\n-    \"- [ToolMessage](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) containing example tool outputs.\\n\",\n+    \"- [HumanMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.human.HumanMessage.html) containing example inputs;\\n\",\n+    \"- [AIMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html) containing example tool calls;\\n\",\n+    \"- [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) containing example tool outputs.\\n\",\n     \"\\n\",\n     \"LangChain adopts this convention for structuring tool calls into conversation across LLM model providers.\\n\",\n     \"\\n\",\n@@ -29,9 +29,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 2,\n+   \"execution_count\": 1,\n    \"id\": \"89579144-bcb3-490a-8036-86a0a6bcd56b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:41.780410Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:41.780102Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.147112Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.146838Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\n\",\n@@ -67,17 +74,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 2,\n    \"id\": \"610c3025-ea63-4cd7-88bd-c8cbcb4d8a3f\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.148746Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.148621Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.162044Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.161794Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"ChatPromptValue(messages=[SystemMessage(content=\\\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\\\"), HumanMessage(content='testing 1 2 3'), HumanMessage(content='this is some text')])\"\n+       \"ChatPromptValue(messages=[SystemMessage(content=\\\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\\\", additional_kwargs={}, response_metadata={}), HumanMessage(content='testing 1 2 3', additional_kwargs={}, response_metadata={}), HumanMessage(content='this is some text', additional_kwargs={}, response_metadata={})])\"\n       ]\n      },\n-     \"execution_count\": 3,\n+     \"execution_count\": 2,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -104,15 +118,22 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 3,\n    \"id\": \"d875a49a-d2cb-4b9e-b5bf-41073bc3905c\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.163477Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.163391Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.324449Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.324206Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List, Optional\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Person(BaseModel):\\n\",\n@@ -162,9 +183,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 4,\n    \"id\": \"08356810-77ce-4e68-99d9-faa0326f2cee\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.326100Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.326016Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.329260Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.329014Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import uuid\\n\",\n@@ -177,7 +205,7 @@\n     \"    SystemMessage,\\n\",\n     \"    ToolMessage,\\n\",\n     \")\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Example(TypedDict):\\n\",\n@@ -238,9 +266,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 5,\n    \"id\": \"7f59a745-5c81-4011-a4c5-a33ec1eca7ef\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.330580Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.330488Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.332813Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.332598Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"examples = [\\n\",\n@@ -273,22 +308,29 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 7,\n+   \"execution_count\": 6,\n    \"id\": \"976bb7b8-09c4-4a3e-80df-49a483705c08\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.333955Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.333876Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.336841Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.336635Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"system: content=\\\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\\\"\\n\",\n-      \"human: content=\\\"The ocean is vast and blue. It's more than 20,000 feet deep. There are many fish in it.\\\"\\n\",\n-      \"ai: content='' tool_calls=[{'name': 'Person', 'args': {'name': None, 'hair_color': None, 'height_in_meters': None}, 'id': 'b843ba77-4c9c-48ef-92a4-54e534f24521'}]\\n\",\n-      \"tool: content='You have correctly called this tool.' tool_call_id='b843ba77-4c9c-48ef-92a4-54e534f24521'\\n\",\n-      \"human: content='Fiona traveled far from France to Spain.'\\n\",\n-      \"ai: content='' tool_calls=[{'name': 'Person', 'args': {'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}, 'id': '46f00d6b-50e5-4482-9406-b07bb10340f6'}]\\n\",\n-      \"tool: content='You have correctly called this tool.' tool_call_id='46f00d6b-50e5-4482-9406-b07bb10340f6'\\n\",\n-      \"human: content='this is some text'\\n\"\n+      \"system: content=\\\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\\\" additional_kwargs={} response_metadata={}\\n\",\n+      \"human: content=\\\"The ocean is vast and blue. It's more than 20,000 feet deep. There are many fish in it.\\\" additional_kwargs={} response_metadata={}\\n\",\n+      \"ai: content='' additional_kwargs={} response_metadata={} tool_calls=[{'name': 'Data', 'args': {'people': []}, 'id': '240159b1-1405-4107-a07c-3c6b91b3d5b7', 'type': 'tool_call'}]\\n\",\n+      \"tool: content='You have correctly called this tool.' tool_call_id='240159b1-1405-4107-a07c-3c6b91b3d5b7'\\n\",\n+      \"human: content='Fiona traveled far from France to Spain.' additional_kwargs={} response_metadata={}\\n\",\n+      \"ai: content='' additional_kwargs={} response_metadata={} tool_calls=[{'name': 'Data', 'args': {'people': [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]}, 'id': '3fc521e4-d1d2-4c20-bf40-e3d72f1068da', 'type': 'tool_call'}]\\n\",\n+      \"tool: content='You have correctly called this tool.' tool_call_id='3fc521e4-d1d2-4c20-bf40-e3d72f1068da'\\n\",\n+      \"human: content='this is some text' additional_kwargs={} response_metadata={}\\n\"\n      ]\n     }\n    ],\n@@ -320,9 +362,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 8,\n+   \"execution_count\": 7,\n    \"id\": \"df2e1ee1-69e8-4c4d-b349-95f2e320317b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.338001Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.337915Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.349121Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.348908Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# | output: false\\n\",\n@@ -343,9 +392,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 9,\n+   \"execution_count\": 8,\n    \"id\": \"dbfea43d-769b-42e9-a76f-ce722f7d6f93\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.350335Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.350264Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:42.424894Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:42.424623Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"runnable = prompt | llm.with_structured_output(\\n\",\n@@ -367,18 +423,49 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 10,\n+   \"execution_count\": 9,\n    \"id\": \"66545cab-af2a-40a4-9dc9-b4110458b7d3\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:42.426258Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:42.426187Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:46.151633Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:46.150690Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"people=[Person(name='earth', hair_color='null', height_in_meters='null')]\\n\",\n-      \"people=[Person(name='earth', hair_color='null', height_in_meters='null')]\\n\",\n-      \"people=[]\\n\",\n-      \"people=[Person(name='earth', hair_color='null', height_in_meters='null')]\\n\",\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n       \"people=[]\\n\"\n      ]\n     }\n@@ -401,18 +488,49 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 11,\n+   \"execution_count\": 10,\n    \"id\": \"1c09d805-ec16-4123-aef9-6a5b59499b5c\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:46.155346Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:46.155110Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:51.810359Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:51.809636Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"people=[]\\n\",\n-      \"people=[]\\n\",\n-      \"people=[]\\n\",\n-      \"people=[]\\n\",\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"people=[]\\n\"\n+     ]\n+    },\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n       \"people=[]\\n\"\n      ]\n     }\n@@ -435,17 +553,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 12,\n+   \"execution_count\": 11,\n    \"id\": \"a9b7a762-1b75-4f9f-b9d9-6732dd05802c\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:26:51.813309Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:26:51.813150Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:26:53.474153Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:26:53.473522Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"Data(people=[Person(name='Harrison', hair_color='black', height_in_meters=None)])\"\n       ]\n      },\n-     \"execution_count\": 12,\n+     \"execution_count\": 11,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -476,7 +601,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.4\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/extraction_long_text.ipynb",
          "status": "modified",
          "additions": 146,
          "deletions": 31,
          "patch": "@@ -23,16 +23,56 @@\n    \"id\": \"57969139-ad0a-487e-97d8-cb30e2af9742\",\n    \"metadata\": {},\n    \"source\": [\n-    \"## Set up\\n\",\n+    \"## Setup\\n\",\n     \"\\n\",\n-    \"We need some example data! Let's download an article about [cars from wikipedia](https://en.wikipedia.org/wiki/Car) and load it as a LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html).\"\n+    \"First we'll install the dependencies needed for this guide:\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n-   \"id\": \"84460db2-36e1-4037-bfa6-2a11883c2ba5\",\n+   \"id\": \"a3b4d838-5be4-4207-8a4a-9ef5624c48f2\",\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:19.850767Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:19.850427Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:21.432233Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:21.431606Z\"\n+    }\n+   },\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n+     ]\n+    }\n+   ],\n+   \"source\": [\n+    \"%pip install -qU langchain-community lxml faiss-cpu langchain-openai\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"ac000b03-33fc-414f-8f2c-3850df621a35\",\n    \"metadata\": {},\n+   \"source\": [\n+    \"Now we need some example data! Let's download an article about [cars from wikipedia](https://en.wikipedia.org/wiki/Car) and load it as a LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html).\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 2,\n+   \"id\": \"84460db2-36e1-4037-bfa6-2a11883c2ba5\",\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:21.434882Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:21.434571Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:22.214545Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:22.214253Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import re\\n\",\n@@ -55,15 +95,22 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 2,\n+   \"execution_count\": 3,\n    \"id\": \"fcb6917b-123d-4630-a0ce-ed8b293d482d\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:22.216143Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:22.216039Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:22.218117Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:22.217854Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"79174\\n\"\n+      \"80427\\n\"\n      ]\n     }\n    ],\n@@ -87,13 +134,20 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 4,\n    \"id\": \"a3b288ed-87a6-4af0-aac8-20921dc370d4\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:22.219468Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:22.219395Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:22.340594Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:22.340319Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List, Optional\\n\",\n     \"\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class KeyDevelopment(BaseModel):\\n\",\n@@ -156,7 +210,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 5,\n    \"id\": \"109f4f05-d0ff-431d-93d9-8f5aa34979a6\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:22.342277Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:22.342171Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:22.532302Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:22.532034Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# | output: false\\n\",\n@@ -171,7 +232,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 6,\n    \"id\": \"aa4ae224-6d3d-4fe2-b210-7db19a9fe580\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:22.533795Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:22.533708Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:22.610573Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:22.610307Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"extractor = prompt | llm.with_structured_output(\\n\",\n@@ -194,7 +262,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 7,\n    \"id\": \"27b8a373-14b3-45ea-8bf5-9749122ad927\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:22.612123Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:22.612052Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:22.753493Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:22.753179Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_text_splitters import TokenTextSplitter\\n\",\n@@ -214,7 +289,7 @@\n    \"id\": \"5b43d7e0-3c85-4d97-86c7-e8c984b60b0a\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Use [batch](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) functionality to run the extraction in **parallel** across each chunk! \\n\",\n+    \"Use [batch](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) functionality to run the extraction in **parallel** across each chunk! \\n\",\n     \"\\n\",\n     \":::{.callout-tip}\\n\",\n     \"You can often use .batch() to parallelize the extractions! `.batch` uses a threadpool under the hood to help you parallelize workloads.\\n\",\n@@ -227,7 +302,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 8,\n    \"id\": \"6ba766b5-8d6c-48e6-8d69-f391a66b65d2\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:22.755067Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:22.754987Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:36.691130Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:36.690500Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# Limit just to the first 3 chunks\\n\",\n@@ -254,21 +336,27 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 9,\n    \"id\": \"c3f77470-ce6c-477f-8957-650913218632\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:36.694799Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:36.694458Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:36.701416Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:36.700993Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"[KeyDevelopment(year=1966, description='The Toyota Corolla began production, becoming the best-selling series of automobile in history.', evidence='The Toyota Corolla, which has been in production since 1966, is the best-selling series of automobile in history.'),\\n\",\n-       \" KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first steam-powered road vehicle.', evidence='The French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769.'),\\n\",\n-       \" KeyDevelopment(year=1808, description='Fran\u00e7ois Isaac de Rivaz designed and constructed the first internal combustion-powered automobile.', evidence='the Swiss inventor Fran\u00e7ois Isaac de Rivaz designed and constructed the first internal combustion-powered automobile in 1808.'),\\n\",\n-       \" KeyDevelopment(year=1886, description='Carl Benz patented his Benz Patent-Motorwagen, inventing the modern car.', evidence='The modern car\u2014a practical, marketable automobile for everyday use\u2014was invented in 1886, when the German inventor Carl Benz patented his Benz Patent-Motorwagen.'),\\n\",\n-       \" KeyDevelopment(year=1908, description='Ford Model T, one of the first cars affordable by the masses, began production.', evidence='One of the first cars affordable by the masses was the Ford Model T, begun in 1908, an American car manufactured by the Ford Motor Company.'),\\n\",\n-       \" KeyDevelopment(year=1888, description=\\\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\\\", evidence=\\\"In August 1888, Bertha Benz, the wife of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\\\"),\\n\",\n+       \"[KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first full-scale, self-propelled mechanical vehicle, a steam-powered tricycle.', evidence='Nicolas-Joseph Cugnot is widely credited with building the first full-scale, self-propelled mechanical vehicle in about 1769; he created a steam-powered tricycle.'),\\n\",\n+       \" KeyDevelopment(year=1807, description=\\\"Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine.\\\", evidence=\\\"In 1807, Nic\u00e9phore Ni\u00e9pce and his brother Claude created what was probably the world's first internal combustion engine (which they called a Pyr\u00e9olophore), but installed it in a boat on the river Saone in France.\\\"),\\n\",\n+       \" KeyDevelopment(year=1886, description='Carl Benz patented the Benz Patent-Motorwagen, marking the birth of the modern car.', evidence='In November 1881, French inventor Gustave Trouv\u00e9 demonstrated a three-wheeled car powered by electricity at the International Exposition of Electricity. Although several other German engineers (including Gottlieb Daimler, Wilhelm Maybach, and Siegfried Marcus) were working on cars at about the same time, the year 1886 is regarded as the birth year of the modern car\u2014a practical, marketable automobile for everyday use\u2014when the German Carl Benz patented his Benz Patent-Motorwagen; he is generally acknowledged as the inventor of the car.'),\\n\",\n+       \" KeyDevelopment(year=1886, description='Carl Benz began promotion of his vehicle, marking the introduction of the first commercially available automobile.', evidence='Benz began promotion of the vehicle on 3 July 1886.'),\\n\",\n+       \" KeyDevelopment(year=1888, description=\\\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\\\", evidence=\\\"In August 1888, Bertha Benz, the wife and business partner of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\\\"),\\n\",\n        \" KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\\n\",\n-       \" KeyDevelopment(year=1897, description='Nesselsdorfer Wagenbau produced the Pr\u00e4sident automobil, one of the first factory-made cars in the world.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Pr\u00e4sident automobil.'),\\n\",\n-       \" KeyDevelopment(year=1890, description='Daimler Motoren Gesellschaft (DMG) was founded by Daimler and Maybach in Cannstatt.', evidence='Daimler and Maybach founded Daimler Motoren Gesellschaft (DMG) in Cannstatt in 1890.'),\\n\",\n-       \" KeyDevelopment(year=1891, description='Auguste Doriot and Louis Rigoulot completed the longest trip by a petrol-driven vehicle with a Daimler powered Peugeot Type 3.', evidence='In 1891, Auguste Doriot and his Peugeot colleague Louis Rigoulot completed the longest trip by a petrol-driven vehicle when their self-designed and built Daimler powered Peugeot Type 3 completed 2,100 kilometres (1,300 mi) from Valentigney to Paris and Brest and back again.')]\"\n+       \" KeyDevelopment(year=1897, description='The first motor car in central Europe and one of the first factory-made cars in the world, the Pr\u00e4sident automobil, was produced by Nesselsdorfer Wagenbau.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Pr\u00e4sident automobil.'),\\n\",\n+       \" KeyDevelopment(year=1901, description='Ransom Olds started large-scale, production-line manufacturing of affordable cars at his Oldsmobile factory in Lansing, Michigan.', evidence='Large-scale, production-line manufacturing of affordable cars was started by Ransom Olds in 1901 at his Oldsmobile factory in Lansing, Michigan.'),\\n\",\n+       \" KeyDevelopment(year=1913, description=\\\"Henry Ford introduced the world's first moving assembly line for cars at the Highland Park Ford Plant.\\\", evidence=\\\"This concept was greatly expanded by Henry Ford, beginning in 1913 with the world's first moving assembly line for cars at the Highland Park Ford Plant.\\\")]\"\n       ]\n      },\n      \"execution_count\": 9,\n@@ -315,7 +403,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 10,\n    \"id\": \"aaf37c82-625b-4fa1-8e88-73303f08ac16\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:36.703897Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:36.703718Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:38.451523Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:38.450925Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_community.vectorstores import FAISS\\n\",\n@@ -344,7 +439,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 11,\n    \"id\": \"47aad00b-7013-4f7f-a1b0-02ef269093bf\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:38.455094Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:38.454851Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:38.458315Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:38.457940Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"rag_extractor = {\\n\",\n@@ -356,7 +458,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 12,\n    \"id\": \"68f2de01-0cd8-456e-a959-db236189d41b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:38.460115Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:38.459949Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:43.195532Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:43.194254Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"results = rag_extractor.invoke(\\\"Key developments associated with cars\\\")\"\n@@ -366,15 +475,21 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 13,\n    \"id\": \"1788e2d6-77bb-417f-827c-eb96c035164e\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:43.200497Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:43.200037Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:43.206773Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:43.205426Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"year=1869 description='Mary Ward became one of the first documented car fatalities in Parsonstown, Ireland.' evidence='Mary Ward became one of the first documented car fatalities in 1869 in Parsonstown, Ireland,'\\n\",\n-      \"year=1899 description=\\\"Henry Bliss one of the US's first pedestrian car casualties in New York City.\\\" evidence=\\\"Henry Bliss one of the US's first pedestrian car casualties in 1899 in New York City.\\\"\\n\",\n-      \"year=2030 description='All fossil fuel vehicles will be banned in Amsterdam.' evidence='all fossil fuel vehicles will be banned in Amsterdam from 2030.'\\n\"\n+      \"year=2006 description='Car-sharing services in the US experienced double-digit growth in revenue and membership.' evidence='in the US, some car-sharing services have experienced double-digit growth in revenue and membership growth between 2006 and 2007.'\\n\",\n+      \"year=2020 description='56 million cars were manufactured worldwide, with China producing the most.' evidence='In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year. The automotive industry in China produces by far the most (20 million in 2020).'\\n\"\n      ]\n     }\n    ],\n@@ -416,7 +531,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.4\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/extraction_parse.ipynb",
          "status": "modified",
          "additions": 88,
          "deletions": 24,
          "patch": "@@ -27,9 +27,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 2,\n+   \"execution_count\": 1,\n    \"id\": \"25487939-8713-4ec7-b774-e4a761ac8298\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:44.442501Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:44.442044Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:44.872217Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:44.871897Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# | output: false\\n\",\n@@ -62,16 +69,23 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 2,\n    \"id\": \"497eb023-c043-443d-ac62-2d4ea85fe1b0\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:44.873979Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:44.873840Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:44.878966Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:44.878718Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List, Optional\\n\",\n     \"\\n\",\n     \"from langchain_core.output_parsers import PydanticOutputParser\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field, validator\\n\",\n+    \"from pydantic import BaseModel, Field, validator\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Person(BaseModel):\\n\",\n@@ -114,19 +128,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 3,\n    \"id\": \"20b99ffb-a114-49a9-a7be-154c525f8ada\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:44.880355Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:44.880277Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:44.881834Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:44.881601Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"query = \\\"Anna is 23 years old and she is 6 feet tall\\\"\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 4,\n    \"id\": \"4f3a66ce-de19-4571-9e54-67504ae3fba7\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:44.883138Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:44.883049Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:44.885139Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:44.884801Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -140,7 +168,7 @@\n       \"\\n\",\n       \"Here is the output schema:\\n\",\n       \"```\\n\",\n-      \"{\\\"description\\\": \\\"Identifying information about all people in a text.\\\", \\\"properties\\\": {\\\"people\\\": {\\\"title\\\": \\\"People\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"$ref\\\": \\\"#/definitions/Person\\\"}}}, \\\"required\\\": [\\\"people\\\"], \\\"definitions\\\": {\\\"Person\\\": {\\\"title\\\": \\\"Person\\\", \\\"description\\\": \\\"Information about a person.\\\", \\\"type\\\": \\\"object\\\", \\\"properties\\\": {\\\"name\\\": {\\\"title\\\": \\\"Name\\\", \\\"description\\\": \\\"The name of the person\\\", \\\"type\\\": \\\"string\\\"}, \\\"height_in_meters\\\": {\\\"title\\\": \\\"Height In Meters\\\", \\\"description\\\": \\\"The height of the person expressed in meters.\\\", \\\"type\\\": \\\"number\\\"}}, \\\"required\\\": [\\\"name\\\", \\\"height_in_meters\\\"]}}}\\n\",\n+      \"{\\\"$defs\\\": {\\\"Person\\\": {\\\"description\\\": \\\"Information about a person.\\\", \\\"properties\\\": {\\\"name\\\": {\\\"description\\\": \\\"The name of the person\\\", \\\"title\\\": \\\"Name\\\", \\\"type\\\": \\\"string\\\"}, \\\"height_in_meters\\\": {\\\"description\\\": \\\"The height of the person expressed in meters.\\\", \\\"title\\\": \\\"Height In Meters\\\", \\\"type\\\": \\\"number\\\"}}, \\\"required\\\": [\\\"name\\\", \\\"height_in_meters\\\"], \\\"title\\\": \\\"Person\\\", \\\"type\\\": \\\"object\\\"}}, \\\"description\\\": \\\"Identifying information about all people in a text.\\\", \\\"properties\\\": {\\\"people\\\": {\\\"items\\\": {\\\"$ref\\\": \\\"#/$defs/Person\\\"}, \\\"title\\\": \\\"People\\\", \\\"type\\\": \\\"array\\\"}}, \\\"required\\\": [\\\"people\\\"]}\\n\",\n       \"```\\n\",\n       \"Human: Anna is 23 years old and she is 6 feet tall\\n\"\n      ]\n@@ -160,17 +188,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 5,\n    \"id\": \"7e0041eb-37dc-4384-9fe3-6dd8c356371e\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:44.886765Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:44.886675Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:46.835960Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:46.835282Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"People(people=[Person(name='Anna', height_in_meters=1.83)])\"\n       ]\n      },\n-     \"execution_count\": 6,\n+     \"execution_count\": 5,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -202,16 +237,23 @@\n     \"\\n\",\n     \"If desired, it's easy to create a custom prompt and parser with `LangChain` and `LCEL`.\\n\",\n     \"\\n\",\n-    \"To create a custom parser, define a function to parse the output from the model (typically an [AIMessage](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html)) into an object of your choice.\\n\",\n+    \"To create a custom parser, define a function to parse the output from the model (typically an [AIMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html)) into an object of your choice.\\n\",\n     \"\\n\",\n     \"See below for a simple implementation of a JSON parser.\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 7,\n+   \"execution_count\": 6,\n    \"id\": \"b1f11912-c1bb-4a2a-a482-79bf3996961f\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:46.839577Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:46.839233Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:46.849663Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:46.849177Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import json\\n\",\n@@ -221,7 +263,7 @@\n     \"from langchain_anthropic.chat_models import ChatAnthropic\\n\",\n     \"from langchain_core.messages import AIMessage\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field, validator\\n\",\n+    \"from pydantic import BaseModel, Field, validator\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Person(BaseModel):\\n\",\n@@ -279,16 +321,23 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 8,\n+   \"execution_count\": 7,\n    \"id\": \"9260d5e8-3b6c-4639-9f3b-fb2f90239e4b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:46.851870Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:46.851698Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:46.854786Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:46.854424Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n       \"System: Answer the user query. Output your answer as JSON that  matches the given schema: ```json\\n\",\n-      \"{'title': 'People', 'description': 'Identifying information about all people in a text.', 'type': 'object', 'properties': {'people': {'title': 'People', 'type': 'array', 'items': {'$ref': '#/definitions/Person'}}}, 'required': ['people'], 'definitions': {'Person': {'title': 'Person', 'description': 'Information about a person.', 'type': 'object', 'properties': {'name': {'title': 'Name', 'description': 'The name of the person', 'type': 'string'}, 'height_in_meters': {'title': 'Height In Meters', 'description': 'The height of the person expressed in meters.', 'type': 'number'}}, 'required': ['name', 'height_in_meters']}}}\\n\",\n+      \"{'$defs': {'Person': {'description': 'Information about a person.', 'properties': {'name': {'description': 'The name of the person', 'title': 'Name', 'type': 'string'}, 'height_in_meters': {'description': 'The height of the person expressed in meters.', 'title': 'Height In Meters', 'type': 'number'}}, 'required': ['name', 'height_in_meters'], 'title': 'Person', 'type': 'object'}}, 'description': 'Identifying information about all people in a text.', 'properties': {'people': {'items': {'$ref': '#/$defs/Person'}, 'title': 'People', 'type': 'array'}}, 'required': ['people'], 'title': 'People', 'type': 'object'}\\n\",\n       \"```. Make sure to wrap the answer in ```json and ``` tags\\n\",\n       \"Human: Anna is 23 years old and she is 6 feet tall\\n\"\n      ]\n@@ -301,17 +350,32 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 9,\n+   \"execution_count\": 8,\n    \"id\": \"c523301d-ae0e-45e3-b195-7fd28c67a5c4\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-10T20:35:46.856945Z\",\n+     \"iopub.status.busy\": \"2024-09-10T20:35:46.856769Z\",\n+     \"iopub.status.idle\": \"2024-09-10T20:35:48.373728Z\",\n+     \"shell.execute_reply\": \"2024-09-10T20:35:48.373079Z\"\n+    }\n+   },\n    \"outputs\": [\n+    {\n+     \"name\": \"stderr\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"/Users/bagatur/langchain/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:201: UserWarning: Field name \\\"schema\\\" in \\\"PromptInput\\\" shadows an attribute in parent \\\"BaseModel\\\"\\n\",\n+      \"  warnings.warn(\\n\"\n+     ]\n+    },\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[{'people': [{'name': 'Anna', 'height_in_meters': 1.83}]}]\"\n       ]\n      },\n-     \"execution_count\": 9,\n+     \"execution_count\": 8,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -349,7 +413,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.4\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/fallbacks.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -90,7 +90,7 @@\n    \"outputs\": [],\n    \"source\": [\n     \"# Note that we set max_retries = 0 to avoid retrying on RateLimits, etc\\n\",\n-    \"openai_llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", max_retries=0)\\n\",\n+    \"openai_llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", max_retries=0)\\n\",\n     \"anthropic_llm = ChatAnthropic(model=\\\"claude-3-haiku-20240307\\\")\\n\",\n     \"llm = openai_llm.with_fallbacks([anthropic_llm])\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/few_shot_examples.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -29,7 +29,7 @@\n     \"\\n\",\n     \"In this guide, we'll learn how to create a simple prompt template that provides the model with example inputs and outputs when generating. Providing the LLM with a few such examples is called few-shotting, and is a simple yet powerful way to guide generation and in some cases drastically improve model performance.\\n\",\n     \"\\n\",\n-    \"A few-shot prompt template can be constructed from either a set of examples, or from an [Example Selector](https://python.langchain.com/v0.2/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html) class responsible for choosing a subset of examples from the defined set.\\n\",\n+    \"A few-shot prompt template can be constructed from either a set of examples, or from an [Example Selector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html) class responsible for choosing a subset of examples from the defined set.\\n\",\n     \"\\n\",\n     \"This guide will cover few-shotting with string prompt templates. For a guide on few-shotting with chat messages for chat models, see [here](/docs/how_to/few_shot_examples_chat/).\\n\",\n     \"\\n\",\n@@ -160,7 +160,7 @@\n    \"source\": [\n     \"### Pass the examples and formatter to `FewShotPromptTemplate`\\n\",\n     \"\\n\",\n-    \"Finally, create a [`FewShotPromptTemplate`](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html) object. This object takes in the few-shot examples and the formatter for the few-shot examples. When this `FewShotPromptTemplate` is formatted, it formats the passed examples using the `example_prompt`, then and adds them to the final prompt before `suffix`:\"\n+    \"Finally, create a [`FewShotPromptTemplate`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html) object. This object takes in the few-shot examples and the formatter for the few-shot examples. When this `FewShotPromptTemplate` is formatted, it formats the passed examples using the `example_prompt`, then and adds them to the final prompt before `suffix`:\"\n    ]\n   },\n   {\n@@ -251,7 +251,7 @@\n    \"source\": [\n     \"## Using an example selector\\n\",\n     \"\\n\",\n-    \"We will reuse the example set and the formatter from the previous section. However, instead of feeding the examples directly into the `FewShotPromptTemplate` object, we will feed them into an implementation of `ExampleSelector` called [`SemanticSimilarityExampleSelector`](https://python.langchain.com/v0.2/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html) instance. This class selects few-shot examples from the initial set based on their similarity to the input. It uses an embedding model to compute the similarity between the input and the few-shot examples, as well as a vector store to perform the nearest neighbor search.\\n\",\n+    \"We will reuse the example set and the formatter from the previous section. However, instead of feeding the examples directly into the `FewShotPromptTemplate` object, we will feed them into an implementation of `ExampleSelector` called [`SemanticSimilarityExampleSelector`](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html) instance. This class selects few-shot examples from the initial set based on their similarity to the input. It uses an embedding model to compute the similarity between the input and the few-shot examples, as well as a vector store to perform the nearest neighbor search.\\n\",\n     \"\\n\",\n     \"To show what it looks like, let's initialize an instance and call it in isolation:\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/few_shot_examples_chat.ipynb",
          "status": "modified",
          "additions": 11,
          "deletions": 10,
          "patch": "@@ -29,7 +29,7 @@\n     \"\\n\",\n     \"This guide covers how to prompt a chat model with example inputs and outputs. Providing the model with a few such examples is called few-shotting, and is a simple yet powerful way to guide generation and in some cases drastically improve model performance.\\n\",\n     \"\\n\",\n-    \"There does not appear to be solid consensus on how best to do few-shot prompting, and the optimal prompt compilation will likely vary by model. Because of this, we provide few-shot prompt templates like the [FewShotChatMessagePromptTemplate](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html?highlight=fewshot#langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate) as a flexible starting point, and you can modify or replace them as you see fit.\\n\",\n+    \"There does not appear to be solid consensus on how best to do few-shot prompting, and the optimal prompt compilation will likely vary by model. Because of this, we provide few-shot prompt templates like the [FewShotChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html?highlight=fewshot#langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate) as a flexible starting point, and you can modify or replace them as you see fit.\\n\",\n     \"\\n\",\n     \"The goal of few-shot prompt templates are to dynamically select examples based on an input, and then format the examples in a final prompt to provide for the model.\\n\",\n     \"\\n\",\n@@ -49,7 +49,7 @@\n     \"\\n\",\n     \"The basic components of the template are:\\n\",\n     \"- `examples`: A list of dictionary examples to include in the final prompt.\\n\",\n-    \"- `example_prompt`: converts each example into 1 or more messages through its [`format_messages`](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=format_messages#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) method. A common example would be to convert each example into one human message and one AI message response, or a human message followed by a function call message.\\n\",\n+    \"- `example_prompt`: converts each example into 1 or more messages through its [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=format_messages#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) method. A common example would be to convert each example into one human message and one AI message response, or a human message followed by a function call message.\\n\",\n     \"\\n\",\n     \"Below is a simple demonstration. First, define the examples you'd like to include. Let's give the LLM an unfamiliar mathematical operator, denoted by the \\\"\ud83e\udd9c\\\" emoji:\"\n    ]\n@@ -66,7 +66,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {\n@@ -86,7 +87,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='The expression \\\"2 \ud83e\udd9c 9\\\" is not a standard mathematical operation or equation. It appears to be a combination of the number 2 and the parrot emoji \ud83e\udd9c followed by the number 9. It does not have a specific mathematical meaning.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 17, 'total_tokens': 71}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aad12dda-5c47-4a1e-9949-6fe94e03242a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 54, 'total_tokens': 71})\"\n+       \"AIMessage(content='The expression \\\"2 \ud83e\udd9c 9\\\" is not a standard mathematical operation or equation. It appears to be a combination of the number 2 and the parrot emoji \ud83e\udd9c followed by the number 9. It does not have a specific mathematical meaning.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 17, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aad12dda-5c47-4a1e-9949-6fe94e03242a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 54, 'total_tokens': 71})\"\n       ]\n      },\n      \"execution_count\": 4,\n@@ -97,7 +98,7 @@\n    \"source\": [\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"model = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0.0)\\n\",\n+    \"model = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0.0)\\n\",\n     \"\\n\",\n     \"model.invoke(\\\"What is 2 \ud83e\udd9c 9?\\\")\"\n    ]\n@@ -212,7 +213,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='11', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5ec4e051-262f-408e-ad00-3f2ebeb561c3-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})\"\n+       \"AIMessage(content='11', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5ec4e051-262f-408e-ad00-3f2ebeb561c3-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})\"\n       ]\n      },\n      \"execution_count\": 8,\n@@ -239,8 +240,8 @@\n     \"\\n\",\n     \"Sometimes you may want to select only a few examples from your overall set to show based on the input. For this, you can replace the `examples` passed into `FewShotChatMessagePromptTemplate` with an `example_selector`. The other components remain the same as above! Our dynamic few-shot prompt template would look like:\\n\",\n     \"\\n\",\n-    \"- `example_selector`: responsible for selecting few-shot examples (and the order in which they are returned) for a given input. These implement the [BaseExampleSelector](https://python.langchain.com/v0.2/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html?highlight=baseexampleselector#langchain_core.example_selectors.base.BaseExampleSelector) interface. A common example is the vectorstore-backed [SemanticSimilarityExampleSelector](https://python.langchain.com/v0.2/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html?highlight=semanticsimilarityexampleselector#langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector)\\n\",\n-    \"- `example_prompt`: convert each example into 1 or more messages through its [`format_messages`](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=chatprompttemplate#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) method. A common example would be to convert each example into one human message and one AI message response, or a human message followed by a function call message.\\n\",\n+    \"- `example_selector`: responsible for selecting few-shot examples (and the order in which they are returned) for a given input. These implement the [BaseExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html?highlight=baseexampleselector#langchain_core.example_selectors.base.BaseExampleSelector) interface. A common example is the vectorstore-backed [SemanticSimilarityExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html?highlight=semanticsimilarityexampleselector#langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector)\\n\",\n+    \"- `example_prompt`: convert each example into 1 or more messages through its [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=chatprompttemplate#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) method. A common example would be to convert each example into one human message and one AI message response, or a human message followed by a function call message.\\n\",\n     \"\\n\",\n     \"These once again can be composed with other messages and chat templates to assemble your final prompt.\\n\",\n     \"\\n\",\n@@ -418,7 +419,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='6', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d1863e5e-17cd-4e9d-bf7a-b9f118747a65-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})\"\n+       \"AIMessage(content='6', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d1863e5e-17cd-4e9d-bf7a-b9f118747a65-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})\"\n       ]\n      },\n      \"execution_count\": 13,\n@@ -427,7 +428,7 @@\n     }\n    ],\n    \"source\": [\n-    \"chain = final_prompt | ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0.0)\\n\",\n+    \"chain = final_prompt | ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0.0)\\n\",\n     \"\\n\",\n     \"chain.invoke({\\\"input\\\": \\\"What's 3 \ud83e\udd9c 3?\\\"})\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/filter_messages.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -175,7 +175,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For a complete description of all arguments head to the API reference: https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.utils.filter_messages.html\"\n+    \"For a complete description of all arguments head to the API reference: https://python.langchain.com/api_reference/core/messages/langchain_core.messages.utils.filter_messages.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/how_to/function_calling.ipynb",
          "status": "modified",
          "additions": 11,
          "deletions": 11,
          "patch": "@@ -88,7 +88,7 @@\n     \"## Passing tools to LLMs\\n\",\n     \"\\n\",\n     \"Chat models supporting tool calling features implement a `.bind_tools` method, which \\n\",\n-    \"receives a list of LangChain [tool objects](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool) \\n\",\n+    \"receives a list of LangChain [tool objects](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool) \\n\",\n     \"and binds them to the chat model in its expected format. Subsequent invocations of the \\n\",\n     \"chat model will include tool schemas in its calls to the LLM.\\n\",\n     \"\\n\",\n@@ -136,7 +136,7 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"# Note that the docstrings here are crucial, as they will be passed along\\n\",\n@@ -191,7 +191,7 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -212,9 +212,9 @@\n     \"## Tool calls\\n\",\n     \"\\n\",\n     \"If tool calls are included in a LLM response, they are attached to the corresponding \\n\",\n-    \"[message](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage) \\n\",\n-    \"or [message chunk](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n-    \"as a list of [tool call](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.ToolCall.html#langchain_core.messages.tool.ToolCall) \\n\",\n+    \"[message](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage) \\n\",\n+    \"or [message chunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n+    \"as a list of [tool call](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolCall.html#langchain_core.messages.tool.ToolCall) \\n\",\n     \"objects in the `.tool_calls` attribute. A `ToolCall` is a typed dict that includes a \\n\",\n     \"tool name, dict of argument values, and (optionally) an identifier. Messages with no \\n\",\n     \"tool calls default to an empty list for this attribute.\\n\",\n@@ -258,7 +258,7 @@\n     \"The `.tool_calls` attribute should contain valid tool calls. Note that on occasion, \\n\",\n     \"model providers may output malformed tool calls (e.g., arguments that are not \\n\",\n     \"valid JSON). When parsing fails in these cases, instances \\n\",\n-    \"of [InvalidToolCall](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.InvalidToolCall.html#langchain_core.messages.tool.InvalidToolCall) \\n\",\n+    \"of [InvalidToolCall](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.InvalidToolCall.html#langchain_core.messages.tool.InvalidToolCall) \\n\",\n     \"are populated in the `.invalid_tool_calls` attribute. An `InvalidToolCall` can have \\n\",\n     \"a name, string arguments, identifier, and error message.\\n\",\n     \"\\n\",\n@@ -298,16 +298,16 @@\n     \"### Streaming\\n\",\n     \"\\n\",\n     \"When tools are called in a streaming context, \\n\",\n-    \"[message chunks](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n-    \"will be populated with [tool call chunk](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.ToolCallChunk.html#langchain_core.messages.tool.ToolCallChunk) \\n\",\n+    \"[message chunks](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n+    \"will be populated with [tool call chunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolCallChunk.html#langchain_core.messages.tool.ToolCallChunk) \\n\",\n     \"objects in a list via the `.tool_call_chunks` attribute. A `ToolCallChunk` includes \\n\",\n     \"optional string fields for the tool `name`, `args`, and `id`, and includes an optional \\n\",\n     \"integer field `index` that can be used to join chunks together. Fields are optional \\n\",\n     \"because portions of a tool call may be streamed across different chunks (e.g., a chunk \\n\",\n     \"that includes a substring of the arguments may have null values for the tool name and id).\\n\",\n     \"\\n\",\n     \"Because message chunks inherit from their parent message class, an \\n\",\n-    \"[AIMessageChunk](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n+    \"[AIMessageChunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n     \"with tool call chunks will also include `.tool_calls` and `.invalid_tool_calls` fields. \\n\",\n     \"These fields are parsed best-effort from the message's tool call chunks.\\n\",\n     \"\\n\",\n@@ -696,7 +696,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/functions.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 4,
          "patch": "@@ -26,7 +26,7 @@\n     \"\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"You can use arbitrary functions as [Runnables](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable). This is useful for formatting or when you need functionality not provided by other LangChain components, and custom functions used as Runnables are called [`RunnableLambdas`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html).\\n\",\n+    \"You can use arbitrary functions as [Runnables](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable). This is useful for formatting or when you need functionality not provided by other LangChain components, and custom functions used as Runnables are called [`RunnableLambdas`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html).\\n\",\n     \"\\n\",\n     \"Note that all inputs to these functions need to be a SINGLE argument. If you have a function that accepts multiple arguments, you should write a wrapper that accepts a single dict input and unpacks it into multiple arguments.\\n\",\n     \"\\n\",\n@@ -54,7 +54,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {\n@@ -210,7 +211,7 @@\n     \"\\n\",\n     \"## Passing run metadata\\n\",\n     \"\\n\",\n-    \"Runnable lambdas can optionally accept a [RunnableConfig](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig) parameter, which they can use to pass callbacks, tags, and other configuration information to nested runs.\"\n+    \"Runnable lambdas can optionally accept a [RunnableConfig](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html#langchain_core.runnables.config.RunnableConfig) parameter, which they can use to pass callbacks, tags, and other configuration information to nested runs.\"\n    ]\n   },\n   {\n@@ -303,7 +304,7 @@\n     \"## Streaming\\n\",\n     \"\\n\",\n     \":::{.callout-note}\\n\",\n-    \"[RunnableLambda](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html) is best suited for code that does not need to support streaming. If you need to support streaming (i.e., be able to operate on chunks of inputs and yield chunks of outputs), use [RunnableGenerator](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableGenerator.html) instead as in the example below.\\n\",\n+    \"[RunnableLambda](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html) is best suited for code that does not need to support streaming. If you need to support streaming (i.e., be able to operate on chunks of inputs and yield chunks of outputs), use [RunnableGenerator](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableGenerator.html) instead as in the example below.\\n\",\n     \":::\\n\",\n     \"\\n\",\n     \"You can use generator functions (ie. functions that use the `yield` keyword, and behave like iterators) in a chain.\\n\","
        },
        {
          "filename": "docs/docs/how_to/graph_mapping.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -163,8 +163,8 @@\n     \"from typing import List, Optional\\n\",\n     \"\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo\\\", temperature=0)\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/graph_prompting.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -347,7 +347,7 @@\n     \"\\n\",\n     \"If we have enough examples, we may want to only include the most relevant ones in the prompt, either because they don't fit in the model's context window or because the long tail of examples distracts the model. And specifically, given any input we want to include the examples most relevant to that input.\\n\",\n     \"\\n\",\n-    \"We can do just this using an ExampleSelector. In this case we'll use a [SemanticSimilarityExampleSelector](https://python.langchain.com/v0.2/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html), which will store the examples in the vector database of our choosing. At runtime it will perform a similarity search between the input and our examples, and return the most semantically similar ones: \"\n+    \"We can do just this using an ExampleSelector. In this case we'll use a [SemanticSimilarityExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html), which will store the examples in the vector database of our choosing. At runtime it will perform a similarity search between the input and our examples, and return the most semantically similar ones: \"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/graph_semantic.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 4,
          "patch": "@@ -177,14 +177,15 @@\n    \"source\": [\n     \"from typing import Optional, Type\\n\",\n     \"\\n\",\n-    \"# Import things that are needed generically\\n\",\n-    \"from langchain.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_core.callbacks import (\\n\",\n     \"    AsyncCallbackManagerForToolRun,\\n\",\n     \"    CallbackManagerForToolRun,\\n\",\n     \")\\n\",\n     \"from langchain_core.tools import BaseTool\\n\",\n     \"\\n\",\n+    \"# Import things that are needed generically\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n+    \"\\n\",\n     \"description_query = \\\"\\\"\\\"\\n\",\n     \"MATCH (m:Movie|Person)\\n\",\n     \"WHERE m.title CONTAINS $candidate OR m.name CONTAINS $candidate\\n\",\n@@ -226,14 +227,15 @@\n    \"source\": [\n     \"from typing import Optional, Type\\n\",\n     \"\\n\",\n-    \"# Import things that are needed generically\\n\",\n-    \"from langchain.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_core.callbacks import (\\n\",\n     \"    AsyncCallbackManagerForToolRun,\\n\",\n     \"    CallbackManagerForToolRun,\\n\",\n     \")\\n\",\n     \"from langchain_core.tools import BaseTool\\n\",\n     \"\\n\",\n+    \"# Import things that are needed generically\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n+    \"\\n\",\n     \"\\n\",\n     \"class InformationInput(BaseModel):\\n\",\n     \"    entity: str = Field(description=\\\"movie or a person mentioned in the question\\\")\\n\","
        },
        {
          "filename": "docs/docs/how_to/index.mdx",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -9,7 +9,7 @@ Here you\u2019ll find answers to \u201cHow do I\u2026.?\u201d types of questions.\n These guides are *goal-oriented* and *concrete*; they're meant to help you complete a specific task.\n For conceptual explanations see the [Conceptual guide](/docs/concepts/).\n For end-to-end walkthroughs see [Tutorials](/docs/tutorials).\n-For comprehensive descriptions of every class and function see the [API Reference](https://python.langchain.com/v0.2/api_reference/).\n+For comprehensive descriptions of every class and function see the [API Reference](https://python.langchain.com/api_reference/).\n \n ## Installation\n \n@@ -27,7 +27,7 @@ This highlights functionality that is core to using LangChain.\n \n ## LangChain Expression Language (LCEL)\n \n-[LangChain Expression Language](/docs/concepts/#langchain-expression-language-lcel) is a way to create arbitrary custom chains. It is built on the [Runnable](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) protocol.\n+[LangChain Expression Language](/docs/concepts/#langchain-expression-language-lcel) is a way to create arbitrary custom chains. It is built on the [Runnable](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) protocol.\n \n [**LCEL cheatsheet**](/docs/how_to/lcel_cheatsheet/): For a quick overview of how to use the main LCEL primitives.\n "
        },
        {
          "filename": "docs/docs/how_to/lcel_cheatsheet.ipynb",
          "status": "modified",
          "additions": 22,
          "deletions": 22,
          "patch": "@@ -7,10 +7,10 @@\n    \"source\": [\n     \"# LangChain Expression Language Cheatsheet\\n\",\n     \"\\n\",\n-    \"This is a quick reference for all the most important LCEL primitives. For more advanced usage see the [LCEL how-to guides](/docs/how_to/#langchain-expression-language-lcel) and the [full API reference](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html).\\n\",\n+    \"This is a quick reference for all the most important LCEL primitives. For more advanced usage see the [LCEL how-to guides](/docs/how_to/#langchain-expression-language-lcel) and the [full API reference](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html).\\n\",\n     \"\\n\",\n     \"### Invoke a runnable\\n\",\n-    \"#### [Runnable.invoke()](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.invoke) / [Runnable.ainvoke()](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.ainvoke)\"\n+    \"#### [Runnable.invoke()](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.invoke) / [Runnable.ainvoke()](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.ainvoke)\"\n    ]\n   },\n   {\n@@ -46,7 +46,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Batch a runnable\\n\",\n-    \"#### [Runnable.batch()](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.batch) / [Runnable.abatch()](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.abatch)\"\n+    \"#### [Runnable.batch()](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.batch) / [Runnable.abatch()](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.abatch)\"\n    ]\n   },\n   {\n@@ -82,7 +82,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Stream a runnable\\n\",\n-    \"#### [Runnable.stream()](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) / [Runnable.astream()](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream)\"\n+    \"#### [Runnable.stream()](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) / [Runnable.astream()](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream)\"\n    ]\n   },\n   {\n@@ -165,7 +165,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Invoke runnables in parallel\\n\",\n-    \"#### [RunnableParallel](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableParallel.html)\"\n+    \"#### [RunnableParallel](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableParallel.html)\"\n    ]\n   },\n   {\n@@ -202,7 +202,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Turn any function into a runnable\\n\",\n-    \"#### [RunnableLambda](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html)\"\n+    \"#### [RunnableLambda](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableLambda.html)\"\n    ]\n   },\n   {\n@@ -240,7 +240,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Merge input and output dicts\\n\",\n-    \"#### [RunnablePassthrough.assign](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)\"\n+    \"#### [RunnablePassthrough.assign](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)\"\n    ]\n   },\n   {\n@@ -276,7 +276,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Include input dict in output dict\\n\",\n-    \"#### [RunnablePassthrough](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)\"\n+    \"#### [RunnablePassthrough](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)\"\n    ]\n   },\n   {\n@@ -316,7 +316,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Add default invocation args\\n\",\n-    \"#### [Runnable.bind](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.bind)\"\n+    \"#### [Runnable.bind](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.bind)\"\n    ]\n   },\n   {\n@@ -360,7 +360,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Add fallbacks\\n\",\n-    \"#### [Runnable.with_fallbacks](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_fallbacks)\"\n+    \"#### [Runnable.with_fallbacks](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_fallbacks)\"\n    ]\n   },\n   {\n@@ -397,7 +397,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Add retries\\n\",\n-    \"#### [Runnable.with_retry](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_retry)\"\n+    \"#### [Runnable.with_retry](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_retry)\"\n    ]\n   },\n   {\n@@ -449,7 +449,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Configure runnable execution\\n\",\n-    \"#### [RunnableConfig](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html)\"\n+    \"#### [RunnableConfig](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html)\"\n    ]\n   },\n   {\n@@ -487,7 +487,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Add default config to runnable\\n\",\n-    \"#### [Runnable.with_config](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config)\"\n+    \"#### [Runnable.with_config](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config)\"\n    ]\n   },\n   {\n@@ -526,7 +526,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Make runnable attributes configurable\\n\",\n-    \"#### [Runnable.with_configurable_fields](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable.configurable_fields)\"\n+    \"#### [Runnable.with_configurable_fields](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable.configurable_fields)\"\n    ]\n   },\n   {\n@@ -605,7 +605,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Make chain components configurable\\n\",\n-    \"#### [Runnable.with_configurable_alternatives](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable.configurable_alternatives)\"\n+    \"#### [Runnable.with_configurable_alternatives](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableSerializable.html#langchain_core.runnables.base.RunnableSerializable.configurable_alternatives)\"\n    ]\n   },\n   {\n@@ -745,7 +745,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Generate a stream of events\\n\",\n-    \"#### [Runnable.astream_events](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events)\"\n+    \"#### [Runnable.astream_events](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events)\"\n    ]\n   },\n   {\n@@ -817,7 +817,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Yield batched outputs as they complete\\n\",\n-    \"#### [Runnable.batch_as_completed](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.batch_as_completed) / [Runnable.abatch_as_completed](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.abatch_as_completed)\"\n+    \"#### [Runnable.batch_as_completed](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.batch_as_completed) / [Runnable.abatch_as_completed](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.abatch_as_completed)\"\n    ]\n   },\n   {\n@@ -858,7 +858,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Return subset of output dict\\n\",\n-    \"#### [Runnable.pick](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.pick)\"\n+    \"#### [Runnable.pick](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.pick)\"\n    ]\n   },\n   {\n@@ -893,7 +893,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Declaratively make a batched version of a runnable\\n\",\n-    \"#### [Runnable.map](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.map)\"\n+    \"#### [Runnable.map](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.map)\"\n    ]\n   },\n   {\n@@ -930,7 +930,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Get a graph representation of a runnable\\n\",\n-    \"#### [Runnable.get_graph](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.get_graph)\"\n+    \"#### [Runnable.get_graph](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.get_graph)\"\n    ]\n   },\n   {\n@@ -991,7 +991,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Get all prompts in a chain\\n\",\n-    \"#### [Runnable.get_prompts](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.get_prompts)\"\n+    \"#### [Runnable.get_prompts](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.get_prompts)\"\n    ]\n   },\n   {\n@@ -1071,7 +1071,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"### Add lifecycle listeners\\n\",\n-    \"#### [Runnable.with_listeners](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_listeners)\"\n+    \"#### [Runnable.with_listeners](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_listeners)\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/llm_caching.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -25,7 +25,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"# Please manually enter OpenAI Key\"\n    ]\n   },"
        },
        {
          "filename": "docs/docs/how_to/llm_token_usage_tracking.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -24,7 +24,7 @@\n     \"\\n\",\n     \"There are some API-specific callback context managers that allow you to track token usage across multiple calls. You'll need to check whether such an integration is available for your particular model.\\n\",\n     \"\\n\",\n-    \"If such an integration is not available for your model, you can create a custom callback manager by adapting the implementation of the [OpenAI callback manager](https://python.langchain.com/v0.2/api_reference/community/callbacks/langchain_community.callbacks.openai_info.OpenAICallbackHandler.html).\\n\",\n+    \"If such an integration is not available for your model, you can create a custom callback manager by adapting the implementation of the [OpenAI callback manager](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.openai_info.OpenAICallbackHandler.html).\\n\",\n     \"\\n\",\n     \"### OpenAI\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/local_llms.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -244,7 +244,7 @@\n     \"\\n\",\n     \"* E.g., for Llama 2 7b: `ollama pull llama2` will download the most basic version of the model (e.g., smallest # parameters and 4 bit quantization)\\n\",\n     \"* We can also specify a particular version from the [model list](https://github.com/jmorganca/ollama?tab=readme-ov-file#model-library), e.g., `ollama pull llama2:13b`\\n\",\n-    \"* See the full set of parameters on the [API reference page](https://python.langchain.com/v0.2/api_reference/community/llms/langchain_community.llms.ollama.Ollama.html)\"\n+    \"* See the full set of parameters on the [API reference page](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.ollama.Ollama.html)\"\n    ]\n   },\n   {\n@@ -280,9 +280,9 @@\n     \"\\n\",\n     \"For example, below we run inference on `llama2-13b` with 4 bit quantization downloaded from [HuggingFace](https://huggingface.co/TheBloke/Llama-2-13B-GGML/tree/main).\\n\",\n     \"\\n\",\n-    \"As noted above, see the [API reference](https://python.langchain.com/v0.2/api_reference/langchain/llms/langchain.llms.llamacpp.LlamaCpp.html?highlight=llamacpp#langchain.llms.llamacpp.LlamaCpp) for the full set of parameters. \\n\",\n+    \"As noted above, see the [API reference](https://python.langchain.com/api_reference/langchain/llms/langchain.llms.llamacpp.LlamaCpp.html?highlight=llamacpp#langchain.llms.llamacpp.LlamaCpp) for the full set of parameters. \\n\",\n     \"\\n\",\n-    \"From the [llama.cpp API reference docs](https://python.langchain.com/v0.2/api_reference/community/llms/langchain_community.llms.llamacpp.LlamaCpp.html), a few are worth commenting on:\\n\",\n+    \"From the [llama.cpp API reference docs](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.llamacpp.LlamaCpp.html), a few are worth commenting on:\\n\",\n     \"\\n\",\n     \"`n_gpu_layers`: number of layers to be loaded into GPU memory\\n\",\n     \"\\n\",\n@@ -416,7 +416,7 @@\n     \"\\n\",\n     \"We can use model weights downloaded from [GPT4All](/docs/integrations/llms/gpt4all) model explorer.\\n\",\n     \"\\n\",\n-    \"Similar to what is shown above, we can run inference and use [the API reference](https://python.langchain.com/v0.2/api_reference/community/llms/langchain_community.llms.gpt4all.GPT4All.html) to set parameters of interest.\"\n+    \"Similar to what is shown above, we can run inference and use [the API reference](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.gpt4all.GPT4All.html) to set parameters of interest.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/logprobs.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -55,7 +55,7 @@\n    \"id\": \"f88ffa0d-f4a7-482c-88de-cbec501a79b1\",\n    \"metadata\": {},\n    \"source\": [\n-    \"For the OpenAI API to return log probabilities we need to configure the `logprobs=True` param. Then, the logprobs are included on each output [`AIMessage`](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html) as part of the `response_metadata`:\"\n+    \"For the OpenAI API to return log probabilities we need to configure the `logprobs=True` param. Then, the logprobs are included on each output [`AIMessage`](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html) as part of the `response_metadata`:\"\n    ]\n   },\n   {\n@@ -94,7 +94,7 @@\n    \"source\": [\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\").bind(logprobs=True)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\").bind(logprobs=True)\\n\",\n     \"\\n\",\n     \"msg = llm.invoke((\\\"human\\\", \\\"how are you today\\\"))\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/long_context_reorder.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -13,7 +13,7 @@\n     \"\\n\",\n     \"To mitigate the [\\\"lost in the middle\\\"](https://arxiv.org/abs/2307.03172) effect, you can re-order documents after retrieval such that the most relevant documents are positioned at extrema (e.g., the first and last pieces of context), and the least relevant documents are positioned in the middle. In some cases this can help surface the most relevant information to LLMs.\\n\",\n     \"\\n\",\n-    \"The [LongContextReorder](https://python.langchain.com/v0.2/api_reference/community/document_transformers/langchain_community.document_transformers.long_context_reorder.LongContextReorder.html) document transformer implements this re-ordering procedure. Below we demonstrate an example.\"\n+    \"The [LongContextReorder](https://python.langchain.com/api_reference/community/document_transformers/langchain_community.document_transformers.long_context_reorder.LongContextReorder.html) document transformer implements this re-ordering procedure. Below we demonstrate an example.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/markdown_header_metadata_splitter.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -17,7 +17,7 @@\n     \"When a full paragraph or document is embedded, the embedding process considers both the overall context and the relationships between the sentences and phrases within the text. This can result in a more comprehensive vector representation that captures the broader meaning and themes of the text.\\n\",\n     \"```\\n\",\n     \" \\n\",\n-    \"As mentioned, chunking often aims to keep text with common context together. With this in mind, we might want to specifically honor the structure of the document itself. For example, a markdown file is organized by headers. Creating chunks within specific header groups is an intuitive idea. To address this challenge, we can use [MarkdownHeaderTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/markdown/langchain_text_splitters.markdown.MarkdownHeaderTextSplitter.html). This will split a markdown file by a specified set of headers. \\n\",\n+    \"As mentioned, chunking often aims to keep text with common context together. With this in mind, we might want to specifically honor the structure of the document itself. For example, a markdown file is organized by headers. Creating chunks within specific header groups is an intuitive idea. To address this challenge, we can use [MarkdownHeaderTextSplitter](https://python.langchain.com/api_reference/text_splitters/markdown/langchain_text_splitters.markdown.MarkdownHeaderTextSplitter.html). This will split a markdown file by a specified set of headers. \\n\",\n     \"\\n\",\n     \"For example, if we want to split this markdown:\\n\",\n     \"```\\n\","
        },
        {
          "filename": "docs/docs/how_to/merge_message_runs.ipynb",
          "status": "modified",
          "additions": 87,
          "deletions": 47,
          "patch": "@@ -11,24 +11,42 @@\n     \"\\n\",\n     \"The `merge_message_runs` utility makes it easy to merge consecutive messages of the same type.\\n\",\n     \"\\n\",\n+    \"### Setup\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"198ce37f-4466-45a2-8878-d75cd01a5d23\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"%pip install -qU langchain-core langchain-anthropic\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"b5c3ca6e-e5b3-4151-8307-9101713a20ae\",\n+   \"metadata\": {},\n+   \"source\": [\n     \"## Basic usage\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": 8,\n    \"id\": \"1a215bbb-c05c-40b0-a6fd-d94884d517df\",\n    \"metadata\": {},\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"SystemMessage(content=\\\"you're a good assistant.\\\\nyou always respond with a joke.\\\")\\n\",\n+      \"SystemMessage(content=\\\"you're a good assistant.\\\\nyou always respond with a joke.\\\", additional_kwargs={}, response_metadata={})\\n\",\n       \"\\n\",\n-      \"HumanMessage(content=[{'type': 'text', 'text': \\\"i wonder why it's called langchain\\\"}, 'and who is harrison chasing anyways'])\\n\",\n+      \"HumanMessage(content=[{'type': 'text', 'text': \\\"i wonder why it's called langchain\\\"}, 'and who is harrison chasing anyways'], additional_kwargs={}, response_metadata={})\\n\",\n       \"\\n\",\n-      \"AIMessage(content='Well, I guess they thought \\\"WordRope\\\" and \\\"SentenceString\\\" just didn\\\\'t have the same ring to it!\\\\nWhy, he\\\\'s probably chasing after the last cup of coffee in the office!')\\n\"\n+      \"AIMessage(content='Well, I guess they thought \\\"WordRope\\\" and \\\"SentenceString\\\" just didn\\\\'t have the same ring to it!\\\\nWhy, he\\\\'s probably chasing after the last cup of coffee in the office!', additional_kwargs={}, response_metadata={})\\n\"\n      ]\n     }\n    ],\n@@ -63,38 +81,6 @@\n     \"Notice that if the contents of one of the messages to merge is a list of content blocks then the merged message will have a list of content blocks. And if both messages to merge have string contents then those are concatenated with a newline character.\"\n    ]\n   },\n-  {\n-   \"cell_type\": \"markdown\",\n-   \"id\": \"11f7e8d3\",\n-   \"metadata\": {},\n-   \"source\": [\n-    \"The `merge_message_runs` utility also works with messages composed together using the overloaded `+` operation:\"\n-   ]\n-  },\n-  {\n-   \"cell_type\": \"code\",\n-   \"execution_count\": null,\n-   \"id\": \"b51855c5\",\n-   \"metadata\": {},\n-   \"outputs\": [],\n-   \"source\": [\n-    \"messages = (\\n\",\n-    \"    SystemMessage(\\\"you're a good assistant.\\\")\\n\",\n-    \"    + SystemMessage(\\\"you always respond with a joke.\\\")\\n\",\n-    \"    + HumanMessage([{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"i wonder why it's called langchain\\\"}])\\n\",\n-    \"    + HumanMessage(\\\"and who is harrison chasing anyways\\\")\\n\",\n-    \"    + AIMessage(\\n\",\n-    \"        'Well, I guess they thought \\\"WordRope\\\" and \\\"SentenceString\\\" just didn\\\\'t have the same ring to it!'\\n\",\n-    \"    )\\n\",\n-    \"    + AIMessage(\\n\",\n-    \"        \\\"Why, he's probably chasing after the last cup of coffee in the office!\\\"\\n\",\n-    \"    )\\n\",\n-    \")\\n\",\n-    \"\\n\",\n-    \"merged = merge_message_runs(messages)\\n\",\n-    \"print(\\\"\\\\n\\\\n\\\".join([repr(x) for x in merged]))\"\n-   ]\n-  },\n   {\n    \"cell_type\": \"markdown\",\n    \"id\": \"1b2eee74-71c8-4168-b968-bca580c25d18\",\n@@ -107,23 +93,30 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 9,\n    \"id\": \"6d5a0283-11f8-435b-b27b-7b18f7693592\",\n    \"metadata\": {},\n    \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n+     ]\n+    },\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content=[], response_metadata={'id': 'msg_01D6R8Naum57q8qBau9vLBUX', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 84, 'output_tokens': 3}}, id='run-ac0c465b-b54f-4b8b-9295-e5951250d653-0', usage_metadata={'input_tokens': 84, 'output_tokens': 3, 'total_tokens': 87})\"\n+       \"AIMessage(content=[], additional_kwargs={}, response_metadata={'id': 'msg_01KNGUMTuzBVfwNouLDpUMwf', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 84, 'output_tokens': 3}}, id='run-b908b198-9c24-450b-9749-9d4a8182937b-0', usage_metadata={'input_tokens': 84, 'output_tokens': 3, 'total_tokens': 87})\"\n       ]\n      },\n-     \"execution_count\": 3,\n+     \"execution_count\": 9,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n    ],\n    \"source\": [\n-    \"# pip install -U langchain-anthropic\\n\",\n+    \"%pip install -qU langchain-anthropic\\n\",\n     \"from langchain_anthropic import ChatAnthropic\\n\",\n     \"\\n\",\n     \"llm = ChatAnthropic(model=\\\"claude-3-sonnet-20240229\\\", temperature=0)\\n\",\n@@ -146,19 +139,19 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 10,\n    \"id\": \"460817a6-c327-429d-958e-181a8c46059c\",\n    \"metadata\": {},\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"[SystemMessage(content=\\\"you're a good assistant.\\\\nyou always respond with a joke.\\\"),\\n\",\n-       \" HumanMessage(content=[{'type': 'text', 'text': \\\"i wonder why it's called langchain\\\"}, 'and who is harrison chasing anyways']),\\n\",\n-       \" AIMessage(content='Well, I guess they thought \\\"WordRope\\\" and \\\"SentenceString\\\" just didn\\\\'t have the same ring to it!\\\\nWhy, he\\\\'s probably chasing after the last cup of coffee in the office!')]\"\n+       \"[SystemMessage(content=\\\"you're a good assistant.\\\\nyou always respond with a joke.\\\", additional_kwargs={}, response_metadata={}),\\n\",\n+       \" HumanMessage(content=[{'type': 'text', 'text': \\\"i wonder why it's called langchain\\\"}, 'and who is harrison chasing anyways'], additional_kwargs={}, response_metadata={}),\\n\",\n+       \" AIMessage(content='Well, I guess they thought \\\"WordRope\\\" and \\\"SentenceString\\\" just didn\\\\'t have the same ring to it!\\\\nWhy, he\\\\'s probably chasing after the last cup of coffee in the office!', additional_kwargs={}, response_metadata={})]\"\n       ]\n      },\n-     \"execution_count\": 4,\n+     \"execution_count\": 10,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -167,14 +160,61 @@\n     \"merger.invoke(messages)\"\n    ]\n   },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"4178837d-b155-492d-9404-d567accc1fa0\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"`merge_message_runs` can also be placed after a prompt:\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": 14,\n+   \"id\": \"620530ab-ed05-4899-b984-bfa4cd738465\",\n+   \"metadata\": {},\n+   \"outputs\": [\n+    {\n+     \"data\": {\n+      \"text/plain\": [\n+       \"AIMessage(content='A convergent series is an infinite series whose partial sums approach a finite value as more terms are added. In other words, the sequence of partial sums has a limit.\\\\n\\\\nMore formally, an infinite series \u03a3 an (where an are the terms of the series) is said to be convergent if the sequence of partial sums:\\\\n\\\\nS1 = a1\\\\nS2 = a1 + a2  \\\\nS3 = a1 + a2 + a3\\\\n...\\\\nSn = a1 + a2 + a3 + ... + an\\\\n...\\\\n\\\\nconverges to some finite number S as n goes to infinity. We write:\\\\n\\\\nlim n\u2192\u221e Sn = S\\\\n\\\\nThe finite number S is called the sum of the convergent infinite series.\\\\n\\\\nIf the sequence of partial sums does not approach any finite limit, the infinite series is said to be divergent.\\\\n\\\\nSome key properties:\\\\n- A series converges if and only if the sequence of its partial sums is a Cauchy sequence.\\\\n- Absolute/conditional convergence criteria help determine if a given series converges.\\\\n- Convergent series have many important applications in mathematics, physics, engineering etc.', additional_kwargs={}, response_metadata={'id': 'msg_01MfV6y2hep7ZNvDz24A36U4', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 29, 'output_tokens': 267}}, id='run-9d925f58-021e-4bd0-94fc-f8f5e91010a4-0', usage_metadata={'input_tokens': 29, 'output_tokens': 267, 'total_tokens': 296})\"\n+      ]\n+     },\n+     \"execution_count\": 14,\n+     \"metadata\": {},\n+     \"output_type\": \"execute_result\"\n+    }\n+   ],\n+   \"source\": [\n+    \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n+    \"\\n\",\n+    \"prompt = ChatPromptTemplate(\\n\",\n+    \"    [\\n\",\n+    \"        (\\\"system\\\", \\\"You're great a {skill}\\\"),\\n\",\n+    \"        (\\\"system\\\", \\\"You're also great at explaining things\\\"),\\n\",\n+    \"        (\\\"human\\\", \\\"{query}\\\"),\\n\",\n+    \"    ]\\n\",\n+    \")\\n\",\n+    \"chain = prompt | merger | llm\\n\",\n+    \"chain.invoke({\\\"skill\\\": \\\"math\\\", \\\"query\\\": \\\"what's the definition of a convergent series\\\"})\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"id\": \"51ba533a-43c7-4e5f-bd91-a4ec23ceeb34\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"LangSmith Trace: https://smith.langchain.com/public/432150b6-9909-40a7-8ae7-944b7e657438/r/f4ad5fb2-4d38-42a6-b780-25f62617d53f\"\n+   ]\n+  },\n   {\n    \"cell_type\": \"markdown\",\n    \"id\": \"4548d916-ce21-4dc6-8f19-eedb8003ace6\",\n    \"metadata\": {},\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For a complete description of all arguments head to the API reference: https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.utils.merge_message_runs.html\"\n+    \"For a complete description of all arguments head to the API reference: https://python.langchain.com/api_reference/core/messages/langchain_core.messages.utils.merge_message_runs.html\"\n    ]\n   }\n  ],\n@@ -194,7 +234,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.9.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/message_history.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -32,7 +32,7 @@\n     \"\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"Passing conversation state into and out a chain is vital when building a chatbot. The [`RunnableWithMessageHistory`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html#langchain_core.runnables.history.RunnableWithMessageHistory) class lets us add message history to certain types of chains. It wraps another Runnable and manages the chat message history for it. Specifically, it loads previous messages in the conversation BEFORE passing it to the Runnable, and it saves the generated response as a message AFTER calling the runnable. This class also enables multiple conversations by saving each conversation with a `session_id` - it then expects a `session_id` to be passed in the config when calling the runnable, and uses that to look up the relevant conversation history.\\n\",\n+    \"Passing conversation state into and out a chain is vital when building a chatbot. The [`RunnableWithMessageHistory`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html#langchain_core.runnables.history.RunnableWithMessageHistory) class lets us add message history to certain types of chains. It wraps another Runnable and manages the chat message history for it. Specifically, it loads previous messages in the conversation BEFORE passing it to the Runnable, and it saves the generated response as a message AFTER calling the runnable. This class also enables multiple conversations by saving each conversation with a `session_id` - it then expects a `session_id` to be passed in the config when calling the runnable, and uses that to look up the relevant conversation history.\\n\",\n     \"\\n\",\n     \"![index_diagram](../../static/img/message_history.png)\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/migrate_agent.ipynb",
          "status": "modified",
          "additions": 10,
          "deletions": 8,
          "patch": "@@ -31,7 +31,7 @@\n     \":::\\n\",\n     \"\\n\",\n     \"Here we focus on how to move from legacy LangChain agents to more flexible [LangGraph](https://langchain-ai.github.io/langgraph/) agents.\\n\",\n-    \"LangChain agents (the [AgentExecutor](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor) in particular) have multiple configuration parameters.\\n\",\n+    \"LangChain agents (the [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor) in particular) have multiple configuration parameters.\\n\",\n     \"In this notebook we will show how those parameters map to the LangGraph react agent executor using the [create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent) prebuilt helper method.\\n\",\n     \"\\n\",\n     \"#### Prerequisites\\n\",\n@@ -65,9 +65,11 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n+    \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = \\\"sk-...\\\"\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API key:\\\\n\\\")\"\n    ]\n   },\n   {\n@@ -110,7 +112,7 @@\n    \"id\": \"af002033-fe51-4d14-b47c-3e9b483c8395\",\n    \"metadata\": {},\n    \"source\": [\n-    \"For the LangChain [AgentExecutor](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor), we define a prompt with a placeholder for the agent's scratchpad. The agent can be invoked as follows:\"\n+    \"For the LangChain [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor), we define a prompt with a placeholder for the agent's scratchpad. The agent can be invoked as follows:\"\n    ]\n   },\n   {\n@@ -381,7 +383,7 @@\n    \"source\": [\n     \"### In LangChain\\n\",\n     \"\\n\",\n-    \"With LangChain's [AgentExecutor](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter), you could add chat [Memory](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory) so it can engage in a multi-turn conversation.\"\n+    \"With LangChain's [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter), you could add chat [Memory](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory) so it can engage in a multi-turn conversation.\"\n    ]\n   },\n   {\n@@ -539,7 +541,7 @@\n     \"\\n\",\n     \"### In LangChain\\n\",\n     \"\\n\",\n-    \"With LangChain's [AgentExecutor](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter), you could iterate over the steps using the [stream](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) (or async `astream`) methods or the [iter](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter) method. LangGraph supports stepwise iteration using [stream](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) \"\n+    \"With LangChain's [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter), you could iterate over the steps using the [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) (or async `astream`) methods or the [iter](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter) method. LangGraph supports stepwise iteration using [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) \"\n    ]\n   },\n   {\n@@ -1017,7 +1019,7 @@\n     \"\\n\",\n     \"### In LangChain\\n\",\n     \"\\n\",\n-    \"With LangChain's [AgentExecutor](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter), you could configure an [early_stopping_method](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.early_stopping_method) to either return a string saying \\\"Agent stopped due to iteration limit or time limit.\\\" (`\\\"force\\\"`) or prompt the LLM a final time to respond (`\\\"generate\\\"`).\"\n+    \"With LangChain's [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter), you could configure an [early_stopping_method](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.early_stopping_method) to either return a string saying \\\"Agent stopped due to iteration limit or time limit.\\\" (`\\\"force\\\"`) or prompt the LLM a final time to respond (`\\\"generate\\\"`).\"\n    ]\n   },\n   {\n@@ -1128,7 +1130,7 @@\n     \"\\n\",\n     \"### In LangChain\\n\",\n     \"\\n\",\n-    \"With LangChain's [AgentExecutor](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor), you could trim the intermediate steps of long-running agents using [trim_intermediate_steps](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.trim_intermediate_steps), which is either an integer (indicating the agent should keep the last N steps) or a custom function.\\n\",\n+    \"With LangChain's [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor), you could trim the intermediate steps of long-running agents using [trim_intermediate_steps](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.trim_intermediate_steps), which is either an integer (indicating the agent should keep the last N steps) or a custom function.\\n\",\n     \"\\n\",\n     \"For instance, we could trim the value so the agent only sees the most recent intermediate step.\"\n    ]\n@@ -1325,7 +1327,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.11.2\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/multi_vector.ipynb",
          "status": "modified",
          "additions": 9,
          "deletions": 9,
          "patch": "@@ -9,17 +9,17 @@\n     \"\\n\",\n     \"It can often be useful to store multiple vectors per document. There are multiple use cases where this is beneficial. For example, we can embed multiple chunks of a document and associate those embeddings with the parent document, allowing retriever hits on the chunks to return the larger document.\\n\",\n     \"\\n\",\n-    \"LangChain implements a base [MultiVectorRetriever](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.multi_vector.MultiVectorRetriever.html), which simplifies this process. Much of the complexity lies in how to create the multiple vectors per document. This notebook covers some of the common ways to create those vectors and use the `MultiVectorRetriever`.\\n\",\n+    \"LangChain implements a base [MultiVectorRetriever](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.multi_vector.MultiVectorRetriever.html), which simplifies this process. Much of the complexity lies in how to create the multiple vectors per document. This notebook covers some of the common ways to create those vectors and use the `MultiVectorRetriever`.\\n\",\n     \"\\n\",\n     \"The methods to create multiple vectors per document include:\\n\",\n     \"\\n\",\n-    \"- Smaller chunks: split a document into smaller chunks, and embed those (this is [ParentDocumentRetriever](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html)).\\n\",\n+    \"- Smaller chunks: split a document into smaller chunks, and embed those (this is [ParentDocumentRetriever](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html)).\\n\",\n     \"- Summary: create a summary for each document, embed that along with (or instead of) the document.\\n\",\n     \"- Hypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.\\n\",\n     \"\\n\",\n     \"Note that this also enables another method of adding embeddings - manually. This is useful because you can explicitly add questions or queries that should lead to a document being recovered, giving you more control.\\n\",\n     \"\\n\",\n-    \"Below we walk through an example. First we instantiate some documents. We will index them in an (in-memory) [Chroma](/docs/integrations/providers/chroma/) vector store using [OpenAI](https://python.langchain.com/v0.2/docs/integrations/text_embedding/openai/) embeddings, but any LangChain vector store or embeddings model will suffice.\"\n+    \"Below we walk through an example. First we instantiate some documents. We will index them in an (in-memory) [Chroma](/docs/integrations/providers/chroma/) vector store using [OpenAI](https://python.langchain.com/docs/integrations/text_embedding/openai/) embeddings, but any LangChain vector store or embeddings model will suffice.\"\n    ]\n   },\n   {\n@@ -68,7 +68,7 @@\n    \"source\": [\n     \"## Smaller chunks\\n\",\n     \"\\n\",\n-    \"Often times it can be useful to retrieve larger chunks of information, but embed smaller chunks. This allows for embeddings to capture the semantic meaning as closely as possible, but for as much context as possible to be passed downstream. Note that this is what the [ParentDocumentRetriever](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html) does. Here we show what is going on under the hood.\\n\",\n+    \"Often times it can be useful to retrieve larger chunks of information, but embed smaller chunks. This allows for embeddings to capture the semantic meaning as closely as possible, but for as much context as possible to be passed downstream. Note that this is what the [ParentDocumentRetriever](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.parent_document_retriever.ParentDocumentRetriever.html) does. Here we show what is going on under the hood.\\n\",\n     \"\\n\",\n     \"We will make a distinction between the vector store, which indexes embeddings of the (sub) documents, and the document store, which houses the \\\"parent\\\" documents and associates them with an identifier.\"\n    ]\n@@ -103,7 +103,7 @@\n    \"id\": \"d4feded4-856a-4282-91c3-53aabc62e6ff\",\n    \"metadata\": {},\n    \"source\": [\n-    \"We next generate the \\\"sub\\\" documents by splitting the original documents. Note that we store the document identifier in the `metadata` of the corresponding [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) object.\"\n+    \"We next generate the \\\"sub\\\" documents by splitting the original documents. Note that we store the document identifier in the `metadata` of the corresponding [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) object.\"\n    ]\n   },\n   {\n@@ -207,7 +207,7 @@\n    \"id\": \"cdef8339-f9fa-4b3b-955f-ad9dbdf2734f\",\n    \"metadata\": {},\n    \"source\": [\n-    \"The default search type the retriever performs on the vector database is a similarity search. LangChain vector stores also support searching via [Max Marginal Relevance](https://python.langchain.com/v0.2/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search). This can be controlled via the `search_type` parameter of the retriever:\"\n+    \"The default search type the retriever performs on the vector database is a similarity search. LangChain vector stores also support searching via [Max Marginal Relevance](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search). This can be controlled via the `search_type` parameter of the retriever:\"\n    ]\n   },\n   {\n@@ -244,7 +244,7 @@\n     \"\\n\",\n     \"A summary may be able to distill more accurately what a chunk is about, leading to better retrieval. Here we show how to create summaries, and then embed those.\\n\",\n     \"\\n\",\n-    \"We construct a simple [chain](/docs/how_to/sequence) that will receive an input [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) object and generate a summary using a LLM.\\n\",\n+    \"We construct a simple [chain](/docs/how_to/sequence) that will receive an input [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) object and generate a summary using a LLM.\\n\",\n     \"\\n\",\n     \"```{=mdx}\\n\",\n     \"import ChatModelTabs from \\\"@theme/ChatModelTabs\\\";\\n\",\n@@ -294,7 +294,7 @@\n    \"id\": \"3faa9fde-1b09-4849-a815-8b2e89c30a02\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Note that we can [batch](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) the chain accross documents:\"\n+    \"Note that we can [batch](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable) the chain accross documents:\"\n    ]\n   },\n   {\n@@ -440,7 +440,7 @@\n    \"source\": [\n     \"from typing import List\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class HypotheticalQuestions(BaseModel):\\n\","
        },
        {
          "filename": "docs/docs/how_to/output_parser_fixing.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -24,8 +24,8 @@\n     \"from typing import List\\n\",\n     \"\\n\",\n     \"from langchain_core.output_parsers import PydanticOutputParser\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n-    \"from langchain_openai import ChatOpenAI\"\n+    \"from langchain_openai import ChatOpenAI\\n\",\n+    \"from pydantic import BaseModel, Field\"\n    ]\n   },\n   {\n@@ -131,7 +131,7 @@\n    \"id\": \"84498e02\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Find out api documentation for [OutputFixingParser](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html#langchain.output_parsers.fix.OutputFixingParser).\"\n+    \"Find out api documentation for [OutputFixingParser](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.fix.OutputFixingParser.html#langchain.output_parsers.fix.OutputFixingParser).\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/output_parser_json.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 3,
          "patch": "@@ -30,7 +30,7 @@\n    \"id\": \"ae909b7a\",\n    \"metadata\": {},\n    \"source\": [\n-    \"The [`JsonOutputParser`](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html) is one built-in option for prompting for and then parsing JSON output. While it is similar in functionality to the [`PydanticOutputParser`](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html), it also supports streaming back partial JSON objects.\\n\",\n+    \"The [`JsonOutputParser`](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.json.JsonOutputParser.html) is one built-in option for prompting for and then parsing JSON output. While it is similar in functionality to the [`PydanticOutputParser`](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html), it also supports streaming back partial JSON objects.\\n\",\n     \"\\n\",\n     \"Here's an example of how it can be used alongside [Pydantic](https://docs.pydantic.dev/) to conveniently declare the expected schema:\"\n    ]\n@@ -47,7 +47,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {\n@@ -71,8 +72,8 @@\n    \"source\": [\n     \"from langchain_core.output_parsers import JsonOutputParser\\n\",\n     \"from langchain_core.prompts import PromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"model = ChatOpenAI(temperature=0)\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/output_parser_retry.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -20,8 +20,8 @@\n     \"from langchain.output_parsers import OutputFixingParser\\n\",\n     \"from langchain_core.output_parsers import PydanticOutputParser\\n\",\n     \"from langchain_core.prompts import PromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n-    \"from langchain_openai import ChatOpenAI, OpenAI\"\n+    \"from langchain_openai import ChatOpenAI, OpenAI\\n\",\n+    \"from pydantic import BaseModel, Field\"\n    ]\n   },\n   {\n@@ -244,7 +244,7 @@\n    \"id\": \"e3a2513a\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Find out api documentation for [RetryOutputParser](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.retry.RetryOutputParser.html#langchain.output_parsers.retry.RetryOutputParser).\"\n+    \"Find out api documentation for [RetryOutputParser](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.retry.RetryOutputParser.html#langchain.output_parsers.retry.RetryOutputParser).\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/output_parser_structured.ipynb",
          "status": "modified",
          "additions": 13,
          "deletions": 11,
          "patch": "@@ -35,26 +35,26 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 1,\n    \"id\": \"1594b2bf-2a6f-47bb-9a81-38930f8e606b\",\n    \"metadata\": {},\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!')\"\n+       \"Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')\"\n       ]\n      },\n-     \"execution_count\": 6,\n+     \"execution_count\": 1,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n    ],\n    \"source\": [\n     \"from langchain_core.output_parsers import PydanticOutputParser\\n\",\n     \"from langchain_core.prompts import PromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field, validator\\n\",\n     \"from langchain_openai import OpenAI\\n\",\n+    \"from pydantic import BaseModel, Field, model_validator\\n\",\n     \"\\n\",\n     \"model = OpenAI(model_name=\\\"gpt-3.5-turbo-instruct\\\", temperature=0.0)\\n\",\n     \"\\n\",\n@@ -65,11 +65,13 @@\n     \"    punchline: str = Field(description=\\\"answer to resolve the joke\\\")\\n\",\n     \"\\n\",\n     \"    # You can add custom validation logic easily with Pydantic.\\n\",\n-    \"    @validator(\\\"setup\\\")\\n\",\n-    \"    def question_ends_with_question_mark(cls, field):\\n\",\n-    \"        if field[-1] != \\\"?\\\":\\n\",\n+    \"    @model_validator(mode=\\\"before\\\")\\n\",\n+    \"    @classmethod\\n\",\n+    \"    def question_ends_with_question_mark(cls, values: dict) -> dict:\\n\",\n+    \"        setup = values[\\\"setup\\\"]\\n\",\n+    \"        if setup[-1] != \\\"?\\\":\\n\",\n     \"            raise ValueError(\\\"Badly formed question!\\\")\\n\",\n-    \"        return field\\n\",\n+    \"        return values\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"# Set up a parser + inject instructions into the prompt template.\\n\",\n@@ -239,9 +241,9 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"poetry-venv-311\",\n    \"language\": \"python\",\n-   \"name\": \"python3\"\n+   \"name\": \"poetry-venv-311\"\n   },\n   \"language_info\": {\n    \"codemirror_mode\": {\n@@ -253,7 +255,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/output_parser_xml.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -20,7 +20,7 @@\n     \"\\n\",\n     \"LLMs from different providers often have different strengths depending on the specific data they are trianed on. This also means that some may be \\\"better\\\" and more reliable at generating output in formats other than JSON.\\n\",\n     \"\\n\",\n-    \"This guide shows you how to use the [`XMLOutputParser`](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.xml.XMLOutputParser.html) to prompt models for XML output, then and parse that output into a usable format.\\n\",\n+    \"This guide shows you how to use the [`XMLOutputParser`](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.xml.XMLOutputParser.html) to prompt models for XML output, then and parse that output into a usable format.\\n\",\n     \"\\n\",\n     \":::{.callout-note}\\n\",\n     \"Keep in mind that large language models are leaky abstractions! You'll have to use an LLM with sufficient capacity to generate well-formed XML.\\n\",\n@@ -41,7 +41,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\"\n+    \"if \\\"ANTHROPIC_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/output_parser_yaml.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 3,
          "patch": "@@ -39,15 +39,16 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n    \"id\": \"cc479f3a\",\n    \"metadata\": {},\n    \"source\": [\n-    \"We use [Pydantic](https://docs.pydantic.dev) with the [`YamlOutputParser`](https://python.langchain.com/v0.2/api_reference/langchain/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html#langchain.output_parsers.yaml.YamlOutputParser) to declare our data model and give the model more context as to what type of YAML it should generate:\"\n+    \"We use [Pydantic](https://docs.pydantic.dev) with the [`YamlOutputParser`](https://python.langchain.com/api_reference/langchain/output_parsers/langchain.output_parsers.yaml.YamlOutputParser.html#langchain.output_parsers.yaml.YamlOutputParser) to declare our data model and give the model more context as to what type of YAML it should generate:\"\n    ]\n   },\n   {\n@@ -70,8 +71,8 @@\n    \"source\": [\n     \"from langchain.output_parsers import YamlOutputParser\\n\",\n     \"from langchain_core.prompts import PromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"# Define your desired data structure.\\n\","
        },
        {
          "filename": "docs/docs/how_to/parallel.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -26,7 +26,7 @@\n     \"\\n\",\n     \":::\\n\",\n     \"\\n\",\n-    \"The [`RunnableParallel`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableParallel.html) primitive is essentially a dict whose values are runnables (or things that can be coerced to runnables, like functions). It runs all of its values in parallel, and each value is called with the overall input of the `RunnableParallel`. The final return value is a dict with the results of each value under its appropriate key.\\n\",\n+    \"The [`RunnableParallel`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableParallel.html) primitive is essentially a dict whose values are runnables (or things that can be coerced to runnables, like functions). It runs all of its values in parallel, and each value is called with the overall input of the `RunnableParallel`. The final return value is a dict with the results of each value under its appropriate key.\\n\",\n     \"\\n\",\n     \"## Formatting with `RunnableParallels`\\n\",\n     \"\\n\",\n@@ -60,7 +60,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/passthrough.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -29,7 +29,7 @@\n     \":::\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"When composing chains with several steps, sometimes you will want to pass data from previous steps unchanged for use as input to a later step. The [`RunnablePassthrough`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html) class allows you to do just this, and is typically is used in conjuction with a [RunnableParallel](/docs/how_to/parallel/) to pass data through to a later step in your constructed chains.\\n\",\n+    \"When composing chains with several steps, sometimes you will want to pass data from previous steps unchanged for use as input to a later step. The [`RunnablePassthrough`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html) class allows you to do just this, and is typically is used in conjuction with a [RunnableParallel](/docs/how_to/parallel/) to pass data through to a later step in your constructed chains.\\n\",\n     \"\\n\",\n     \"See the example below:\"\n    ]\n@@ -46,7 +46,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/prompts_composition.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -102,7 +102,7 @@\n    \"source\": [\n     \"A chat prompt is made up a of a list of messages. Similarly to the above example, we can concatenate chat prompt templates. Each new element is a new message in the final prompt.\\n\",\n     \"\\n\",\n-    \"First, let's initialize the a [`ChatPromptTemplate`](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) with a [`SystemMessage`](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html).\"\n+    \"First, let's initialize the a [`ChatPromptTemplate`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) with a [`SystemMessage`](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.system.SystemMessage.html).\"\n    ]\n   },\n   {\n@@ -123,7 +123,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"You can then easily create a pipeline combining it with other messages *or* message templates.\\n\",\n-    \"Use a `Message` when there is no variables to be formatted, use a `MessageTemplate` when there are variables to be formatted. You can also use just a string (note: this will automatically get inferred as a [`HumanMessagePromptTemplate`](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.HumanMessagePromptTemplate.html).)\"\n+    \"Use a `Message` when there is no variables to be formatted, use a `MessageTemplate` when there are variables to be formatted. You can also use just a string (note: this will automatically get inferred as a [`HumanMessagePromptTemplate`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.HumanMessagePromptTemplate.html).)\"\n    ]\n   },\n   {\n@@ -183,7 +183,7 @@\n    \"id\": \"0a5892f9-e4d8-4b7c-b6a5-4651539b9734\",\n    \"metadata\": {},\n    \"source\": [\n-    \"LangChain includes a class called [`PipelinePromptTemplate`](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html), which can be useful when you want to reuse parts of prompts. A PipelinePrompt consists of two main parts:\\n\",\n+    \"LangChain includes a class called [`PipelinePromptTemplate`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html), which can be useful when you want to reuse parts of prompts. A PipelinePrompt consists of two main parts:\\n\",\n     \"\\n\",\n     \"- Final prompt: The final prompt that is returned\\n\",\n     \"- Pipeline prompts: A list of tuples, consisting of a string name and a prompt template. Each prompt template will be formatted and then passed to future prompt templates as a variable with the same name.\""
        },
        {
          "filename": "docs/docs/how_to/pydantic_compatibility.md",
          "status": "modified",
          "additions": 5,
          "deletions": 174,
          "patch": "@@ -1,178 +1,9 @@\n # How to use LangChain with different Pydantic versions\n \n-- Pydantic v2 was released in June, 2023 (https://docs.pydantic.dev/2.0/blog/pydantic-v2-final/).\n-- v2 contains has a number of breaking changes (https://docs.pydantic.dev/2.0/migration/).\n-- Pydantic 1 End of Life was in June 2024. LangChain will be dropping support for Pydantic 1 in the near future,\n-and likely migrating internally to Pydantic 2. The timeline is tentatively September. This change will be accompanied by a minor version bump in the main langchain packages to version 0.3.x.\n+As of the `0.3` release, LangChain uses Pydantic 2 internally. \n \n-As of `langchain>=0.0.267`, LangChain allows users to install either Pydantic V1 or V2.\n+Users should install Pydantic 2 and are advised to **avoid** using the `pydantic.v1` namespace of Pydantic 2 with\n+LangChain APIs.\n \n-Internally, LangChain continues to use the [Pydantic V1](https://docs.pydantic.dev/latest/migration/#continue-using-pydantic-v1-features) via\n-the v1 namespace of Pydantic 2.\n-\n-Because Pydantic does not support mixing .v1 and .v2 objects, users should be aware of a number of issues\n-when using LangChain with Pydantic.\n-\n-:::caution\n-While LangChain supports Pydantic V2 objects in some APIs (listed below), it's suggested that users keep using Pydantic V1 objects until LangChain 0.3 is released.\n-:::\n-\n-\n-## 1. Passing Pydantic objects to LangChain APIs\n-\n-Most LangChain APIs for *tool usage* (see list below) have been updated to accept either Pydantic v1 or v2 objects.\n-\n-* Pydantic v1 objects correspond to subclasses of `pydantic.BaseModel` if `pydantic 1` is installed or subclasses of `pydantic.v1.BaseModel` if `pydantic 2` is installed.\n-* Pydantic v2 objects correspond to subclasses of `pydantic.BaseModel` if `pydantic 2` is installed.\n-\n-\n-| API                                    | Pydantic 1 | Pydantic 2                                                     |\n-|----------------------------------------|------------|----------------------------------------------------------------|\n-| `BaseChatModel.bind_tools`             | Yes        | langchain-core>=0.2.23, appropriate version of partner package |\n-| `BaseChatModel.with_structured_output` | Yes        | langchain-core>=0.2.23, appropriate version of partner package |\n-| `Tool.from_function`                   | Yes        | langchain-core>=0.2.23                                         |\n-| `StructuredTool.from_function`         | Yes        | langchain-core>=0.2.23                                         |\n-\n-\n-Partner packages that accept pydantic v2 objects via `bind_tools` or `with_structured_output` APIs:\n-\n-| Package Name        | pydantic v1 | pydantic v2 |\n-|---------------------|-------------|-------------|\n-| langchain-mistralai | Yes         | >=0.1.11    |\n-| langchain-anthropic | Yes         | >=0.1.21    |\n-| langchain-robocorp  | Yes         | >=0.0.10    |\n-| langchain-openai    | Yes         | >=0.1.19    |\n-| langchain-fireworks | Yes         | >=0.1.5     |\n-| langchain-aws       | Yes         | >=0.1.15    |\n-\n-Additional partner packages will be updated to accept Pydantic v2 objects in the future.\n-\n-If you are still seeing issues with these APIs or other APIs that accept Pydantic objects, please open an issue, and we'll\n-address it.\n-\n-Example:\n-\n-Prior to `langchain-core<0.2.23`, use Pydantic v1 objects when passing to LangChain APIs.\n-\n-\n-```python\n-from langchain_openai import ChatOpenAI\n-from pydantic.v1 import BaseModel # <-- Note v1 namespace\n-\n-class Person(BaseModel):\n-    \"\"\"Personal information\"\"\"\n-    name: str\n-    \n-model = ChatOpenAI()\n-model = model.with_structured_output(Person)\n-\n-model.invoke('Bob is a person.')\n-```\n-\n-After `langchain-core>=0.2.23`, use either Pydantic v1 or v2 objects when passing to LangChain APIs.\n-\n-```python\n-from langchain_openai import ChatOpenAI\n-from pydantic import BaseModel\n-\n-class Person(BaseModel):\n-    \"\"\"Personal information\"\"\"\n-    name: str\n-    \n-    \n-model = ChatOpenAI()\n-model = model.with_structured_output(Person)\n-\n-model.invoke('Bob is a person.')\n-```\n-\n-## 2. Sub-classing LangChain models\n-\n-Because LangChain internally uses Pydantic v1, if you are sub-classing LangChain models, you should use Pydantic v1\n-primitives.\n-\n-\n-**Example 1: Extending via inheritance**\n-\n-**YES** \n-\n-```python\n-from pydantic.v1 import validator\n-from langchain_core.tools import BaseTool\n-\n-class CustomTool(BaseTool): # BaseTool is v1 code\n-    x: int = Field(default=1)\n-\n-    def _run(*args, **kwargs):\n-        return \"hello\"\n-\n-    @validator('x') # v1 code\n-    @classmethod\n-    def validate_x(cls, x: int) -> int:\n-        return 1\n-    \n-\n-CustomTool(\n-    name='custom_tool',\n-    description=\"hello\",\n-    x=1,\n-)\n-```\n-\n-Mixing Pydantic v2 primitives with Pydantic v1 primitives can raise cryptic errors\n-\n-**NO** \n-\n-```python\n-from pydantic import Field, field_validator # pydantic v2\n-from langchain_core.tools import BaseTool\n-\n-class CustomTool(BaseTool): # BaseTool is v1 code\n-    x: int = Field(default=1)\n-\n-    def _run(*args, **kwargs):\n-        return \"hello\"\n-\n-    @field_validator('x') # v2 code\n-    @classmethod\n-    def validate_x(cls, x: int) -> int:\n-        return 1\n-    \n-\n-CustomTool( \n-    name='custom_tool',\n-    description=\"hello\",\n-    x=1,\n-)\n-```\n-\n-\n-## 3. Disable run-time validation for LangChain objects used inside Pydantic v2 models\n-\n-e.g.,\n-\n-```python\n-from typing import Annotated\n-\n-from langchain_openai import ChatOpenAI # <-- ChatOpenAI uses pydantic v1\n-from pydantic import BaseModel, SkipValidation\n-\n-\n-class Foo(BaseModel): # <-- BaseModel is from Pydantic v2\n-    model: Annotated[ChatOpenAI, SkipValidation()]\n-\n-Foo(model=ChatOpenAI(api_key=\"hello\"))\n-```\n-\n-## 4: LangServe cannot generate OpenAPI docs if running Pydantic 2\n-\n-If you are using Pydantic 2, you will not be able to generate OpenAPI docs using LangServe.\n-\n-If you need OpenAPI docs, your options are to either install Pydantic 1:\n-\n-`pip install pydantic==1.10.17`\n-\n-or else to use the `APIHandler` object in LangChain to manually create the\n-routes for your API.\n-\n-See: https://python.langchain.com/v0.2/docs/langserve/#pydantic\n+If you're working with prior versions of LangChain, please see the following guide\n+on [Pydantic compatibility](https://python.langchain.com/v0.2/docs/how_to/pydantic_compatibility).\n\\ No newline at end of file"
        },
        {
          "filename": "docs/docs/how_to/qa_chat_history_how_to.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -102,7 +102,7 @@\n    \"source\": [\n     \"## Chains {#chains}\\n\",\n     \"\\n\",\n-    \"In a conversational RAG application, queries issued to the retriever should be informed by the context of the conversation. LangChain provides a [create_history_aware_retriever](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html) constructor to simplify this. It constructs a chain that accepts keys `input` and `chat_history` as input, and has the same output schema as a retriever. `create_history_aware_retriever` requires as inputs:  \\n\",\n+    \"In a conversational RAG application, queries issued to the retriever should be informed by the context of the conversation. LangChain provides a [create_history_aware_retriever](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html) constructor to simplify this. It constructs a chain that accepts keys `input` and `chat_history` as input, and has the same output schema as a retriever. `create_history_aware_retriever` requires as inputs:  \\n\",\n     \"\\n\",\n     \"1. LLM;\\n\",\n     \"2. Retriever;\\n\",\n@@ -155,7 +155,7 @@\n    \"id\": \"15f8ad59-19de-42e3-85a8-3ba95ee0bd43\",\n    \"metadata\": {},\n    \"source\": [\n-    \"For the retriever, we will use [WebBaseLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) to load the content of a web page. Here we instantiate a `Chroma` vectorstore and then use its [.as_retriever](https://python.langchain.com/v0.2/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.as_retriever) method to build a retriever that can be incorporated into [LCEL](/docs/concepts/#langchain-expression-language) chains.\"\n+    \"For the retriever, we will use [WebBaseLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) to load the content of a web page. Here we instantiate a `Chroma` vectorstore and then use its [.as_retriever](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.as_retriever) method to build a retriever that can be incorporated into [LCEL](/docs/concepts/#langchain-expression-language) chains.\"\n    ]\n   },\n   {\n@@ -260,9 +260,9 @@\n     \"\\n\",\n     \"Now we can build our full QA chain.\\n\",\n     \"\\n\",\n-    \"As in the [RAG tutorial](/docs/tutorials/rag), we will use [create_stuff_documents_chain](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) to generate a `question_answer_chain`, with input keys `context`, `chat_history`, and `input`-- it accepts the retrieved context alongside the conversation history and query to generate an answer.\\n\",\n+    \"As in the [RAG tutorial](/docs/tutorials/rag), we will use [create_stuff_documents_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) to generate a `question_answer_chain`, with input keys `context`, `chat_history`, and `input`-- it accepts the retrieved context alongside the conversation history and query to generate an answer.\\n\",\n     \"\\n\",\n-    \"We build our final `rag_chain` with [create_retrieval_chain](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.retrieval.create_retrieval_chain.html). This chain applies the `history_aware_retriever` and `question_answer_chain` in sequence, retaining intermediate outputs such as the retrieved context for convenience. It has input keys `input` and `chat_history`, and includes `input`, `chat_history`, `context`, and `answer` in its output.\"\n+    \"We build our final `rag_chain` with [create_retrieval_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.retrieval.create_retrieval_chain.html). This chain applies the `history_aware_retriever` and `question_answer_chain` in sequence, retaining intermediate outputs such as the retrieved context for convenience. It has input keys `input` and `chat_history`, and includes `input`, `chat_history`, `context`, and `answer` in its output.\"\n    ]\n   },\n   {\n@@ -305,7 +305,7 @@\n     \"1. An object for storing the chat history;\\n\",\n     \"2. An object that wraps our chain and manages updates to the chat history.\\n\",\n     \"\\n\",\n-    \"For these we will use [BaseChatMessageHistory](https://python.langchain.com/v0.2/api_reference/core/chat_history/langchain_core.chat_history.BaseChatMessageHistory.html) and [RunnableWithMessageHistory](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html). The latter is a wrapper for an LCEL chain and a `BaseChatMessageHistory` that handles injecting chat history into inputs and updating it after each invocation.\\n\",\n+    \"For these we will use [BaseChatMessageHistory](https://python.langchain.com/api_reference/core/chat_history/langchain_core.chat_history.BaseChatMessageHistory.html) and [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html). The latter is a wrapper for an LCEL chain and a `BaseChatMessageHistory` that handles injecting chat history into inputs and updating it after each invocation.\\n\",\n     \"\\n\",\n     \"For a detailed walkthrough of how to use these classes together to create a stateful conversational chain, head to the [How to add message history (memory)](/docs/how_to/message_history/) LCEL how-to guide.\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/qa_citations.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -19,7 +19,7 @@\n     \"\\n\",\n     \"We generally suggest using the first item of the list that works for your use-case. That is, if your model supports tool-calling, try methods 1 or 2; otherwise, or if those fail, advance down the list.\\n\",\n     \"\\n\",\n-    \"Let's first create a simple RAG chain. To start we'll just retrieve from Wikipedia using the [WikipediaRetriever](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.wikipedia.WikipediaRetriever.html).\"\n+    \"Let's first create a simple RAG chain. To start we'll just retrieve from Wikipedia using the [WikipediaRetriever](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.wikipedia.WikipediaRetriever.html).\"\n    ]\n   },\n   {\n@@ -253,7 +253,7 @@\n    \"source\": [\n     \"## Function-calling\\n\",\n     \"\\n\",\n-    \"If your LLM of choice implements a [tool-calling](/docs/concepts#functiontool-calling) feature, you can use it to make the model specify which of the provided documents it's referencing when generating its answer. LangChain tool-calling models implement a `.with_structured_output` method which will force generation adhering to a desired schema (see for example [here](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI.with_structured_output)).\\n\",\n+    \"If your LLM of choice implements a [tool-calling](/docs/concepts#functiontool-calling) feature, you can use it to make the model specify which of the provided documents it's referencing when generating its answer. LangChain tool-calling models implement a `.with_structured_output` method which will force generation adhering to a desired schema (see for example [here](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI.with_structured_output)).\\n\",\n     \"\\n\",\n     \"### Cite documents\\n\",\n     \"\\n\",\n@@ -269,7 +269,7 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class CitedAnswer(BaseModel):\\n\",\n@@ -616,7 +616,7 @@\n     \"\\n\",\n     \"1. We update the formatting function to wrap the retrieved context in XML tags;\\n\",\n     \"2. We do not use `.with_structured_output` (e.g., because it does not exist for a model);\\n\",\n-    \"3. We use [XMLOutputParser](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.xml.XMLOutputParser.html) in place of `StrOutputParser` to parse the answer into a dict.\"\n+    \"3. We use [XMLOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.xml.XMLOutputParser.html) in place of `StrOutputParser` to parse the answer into a dict.\"\n    ]\n   },\n   {\n@@ -711,7 +711,7 @@\n    \"source\": [\n     \"## Retrieval post-processing\\n\",\n     \"\\n\",\n-    \"Another approach is to post-process our retrieved documents to compress the content, so that the source content is already minimal enough that we don't need the model to cite specific sources or spans. For example, we could break up each document into a sentence or two, embed those and keep only the most relevant ones. LangChain has some built-in components for this. Here we'll use a [RecursiveCharacterTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/text_splitter/langchain_text_splitters.RecursiveCharacterTextSplitter.html#langchain_text_splitters.RecursiveCharacterTextSplitter), which creates chunks of a sepacified size by splitting on separator substrings, and an [EmbeddingsFilter](https://python.langchain.com/v0.2/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html#langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter), which keeps only the texts with the most relevant embeddings.\\n\",\n+    \"Another approach is to post-process our retrieved documents to compress the content, so that the source content is already minimal enough that we don't need the model to cite specific sources or spans. For example, we could break up each document into a sentence or two, embed those and keep only the most relevant ones. LangChain has some built-in components for this. Here we'll use a [RecursiveCharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/text_splitter/langchain_text_splitters.RecursiveCharacterTextSplitter.html#langchain_text_splitters.RecursiveCharacterTextSplitter), which creates chunks of a sepacified size by splitting on separator substrings, and an [EmbeddingsFilter](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter.html#langchain.retrievers.document_compressors.embeddings_filter.EmbeddingsFilter), which keeps only the texts with the most relevant embeddings.\\n\",\n     \"\\n\",\n     \"This approach effectively swaps our original retriever with an updated one that compresses the documents. To start, we build the retriever:\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/qa_sources.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -13,7 +13,7 @@\n     \"\\n\",\n     \"We will cover two approaches:\\n\",\n     \"\\n\",\n-    \"1. Using the built-in [create_retrieval_chain](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.retrieval.create_retrieval_chain.html), which returns sources by default;\\n\",\n+    \"1. Using the built-in [create_retrieval_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.retrieval.create_retrieval_chain.html), which returns sources by default;\\n\",\n     \"2. Using a simple [LCEL](/docs/concepts#langchain-expression-language-lcel) implementation, to show the operating principle.\\n\",\n     \"\\n\",\n     \"We will also show how to structure sources into the model response, such that a model can report what specific sources it used in generating its answer.\""
        },
        {
          "filename": "docs/docs/how_to/qa_streaming.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -328,7 +328,7 @@\n    \"id\": \"8b2d224d-2a82-418b-b562-01ea210b86ef\",\n    \"metadata\": {},\n    \"source\": [\n-    \"More simply, we can use the [.pick](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.pick) method to select only the desired key:\"\n+    \"More simply, we can use the [.pick](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.pick) method to select only the desired key:\"\n    ]\n   },\n   {\n@@ -432,7 +432,7 @@\n     \"\\n\",\n     \"To stream intermediate output, we recommend use of the async `.astream_events` method. This method will stream output from all \\\"events\\\" in the chain, and can be quite verbose. We can filter using tags, event types, and other criteria, as we do here.\\n\",\n     \"\\n\",\n-    \"Below we show a typical `.astream_events` loop, where we pass in the chain input and emit desired results. See the [API reference](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) and [streaming guide](/docs/how_to/streaming) for more detail.\"\n+    \"Below we show a typical `.astream_events` loop, where we pass in the chain input and emit desired results. See the [API reference](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) and [streaming guide](/docs/how_to/streaming) for more detail.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/query_constructing_filters.ipynb",
          "status": "modified",
          "additions": 76,
          "deletions": 20,
          "patch": "@@ -24,9 +24,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 13,\n+   \"execution_count\": 1,\n    \"id\": \"8ca446a0\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:35.834087Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:35.833763Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.588973Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.588677Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import Optional\\n\",\n@@ -40,7 +47,7 @@\n     \")\\n\",\n     \"from langchain_community.query_constructors.chroma import ChromaTranslator\\n\",\n     \"from langchain_community.query_constructors.elasticsearch import ElasticsearchTranslator\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel\"\n+    \"from pydantic import BaseModel\"\n    ]\n   },\n   {\n@@ -53,9 +60,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 11,\n+   \"execution_count\": 2,\n    \"id\": \"64055006\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:36.590665Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:36.590527Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.592985Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.592763Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"class Search(BaseModel):\\n\",\n@@ -66,19 +80,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 12,\n+   \"execution_count\": 3,\n    \"id\": \"44eb6d98\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:36.594147Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:36.594072Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.595777Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.595563Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"search_query = Search(query=\\\"RAG\\\", start_year=2022, author=\\\"LangChain\\\")\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 15,\n+   \"execution_count\": 4,\n    \"id\": \"e8ba6705\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:36.596902Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:36.596824Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.598805Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.598629Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"def construct_comparisons(query: Search):\\n\",\n@@ -104,29 +132,50 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 16,\n+   \"execution_count\": 5,\n    \"id\": \"6a79c9da\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:36.599989Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:36.599909Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.601521Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.601306Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"comparisons = construct_comparisons(search_query)\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 17,\n+   \"execution_count\": 6,\n    \"id\": \"2d0e9689\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:36.602688Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:36.602603Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.604171Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.603981Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"_filter = Operation(operator=Operator.AND, arguments=comparisons)\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 18,\n+   \"execution_count\": 7,\n    \"id\": \"e4c0b2ce\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:36.605267Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:36.605190Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.607993Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.607796Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n@@ -135,7 +184,7 @@\n        \"   {'term': {'metadata.author.keyword': 'LangChain'}}]}}\"\n       ]\n      },\n-     \"execution_count\": 18,\n+     \"execution_count\": 7,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -146,17 +195,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 19,\n+   \"execution_count\": 8,\n    \"id\": \"d75455ae\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:32:36.609091Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:32:36.609012Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:32:36.611075Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:32:36.610869Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"{'$and': [{'start_year': {'$gt': 2022}}, {'author': {'$eq': 'LangChain'}}]}\"\n       ]\n      },\n-     \"execution_count\": 19,\n+     \"execution_count\": 8,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -182,7 +238,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/query_few_shot.ipynb",
          "status": "modified",
          "additions": 116,
          "deletions": 31,
          "patch": "@@ -35,7 +35,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n    \"id\": \"e168ef5c-e54e-49a6-8552-5502854a6f01\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:48.329739Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:48.329033Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:48.334555Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:48.334086Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# %pip install -qU langchain-core langchain-openai\"\n@@ -53,15 +60,23 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": 2,\n    \"id\": \"40e2979e-a818-4b96-ac25-039336f94319\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:48.337140Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:48.336958Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:48.342671Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:48.342281Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n     \"\\n\",\n     \"# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\\n\",\n     \"# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n@@ -80,14 +95,21 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 37,\n+   \"execution_count\": 3,\n    \"id\": \"0b51dd76-820d-41a4-98c8-893f6fe0d1ea\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:48.345004Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:48.344838Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:48.413166Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:48.412908Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List, Optional\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"sub_queries_description = \\\"\\\"\\\"\\\\\\n\",\n     \"If the original question contains multiple distinct sub-questions, \\\\\\n\",\n@@ -121,9 +143,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 64,\n+   \"execution_count\": 4,\n    \"id\": \"783c03c3-8c72-4f88-9cf4-5829ce6745d6\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:48.414805Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:48.414700Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:49.023858Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:49.023547Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\\n\",\n@@ -143,7 +172,7 @@\n     \"        (\\\"human\\\", \\\"{question}\\\"),\\n\",\n     \"    ]\\n\",\n     \")\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"structured_llm = llm.with_structured_output(Search)\\n\",\n     \"query_analyzer = {\\\"question\\\": RunnablePassthrough()} | prompt | structured_llm\"\n    ]\n@@ -158,17 +187,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 65,\n+   \"execution_count\": 5,\n    \"id\": \"0bcfce06-6f0c-4f9d-a1fc-dc29342d2aae\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:49.025536Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:49.025437Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:50.170550Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:50.169835Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='web voyager vs reflection agents', sub_queries=['difference between web voyager and reflection agents', 'do web voyager and reflection agents use langgraph'], publish_year=None)\"\n+       \"Search(query='difference between web voyager and reflection agents', sub_queries=['what is web voyager', 'what are reflection agents', 'do both web voyager and reflection agents use langgraph?'], publish_year=None)\"\n       ]\n      },\n-     \"execution_count\": 65,\n+     \"execution_count\": 5,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -193,19 +229,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 53,\n+   \"execution_count\": 6,\n    \"id\": \"15b4923d-a08e-452d-8889-9a09a57d1095\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:50.180367Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:50.173961Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:50.186703Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:50.186090Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"examples = []\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 54,\n+   \"execution_count\": 7,\n    \"id\": \"da5330e6-827a-40e5-982b-b23b6286b758\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:50.189822Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:50.189617Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:50.195116Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:50.194617Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"question = \\\"What's chat langchain, is it a langchain template?\\\"\\n\",\n@@ -218,9 +268,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 55,\n+   \"execution_count\": 8,\n    \"id\": \"580e857a-27df-4ecf-a19c-458dc9244ec8\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:50.198178Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:50.198002Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:50.204115Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:50.202534Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"question = \\\"How to build multi-agent system and stream intermediate steps from it\\\"\\n\",\n@@ -238,9 +295,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 56,\n+   \"execution_count\": 9,\n    \"id\": \"fa63310d-69e3-4701-825c-fbb01f8a5a16\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:50.207416Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:50.207196Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:50.212484Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:50.211974Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"question = \\\"LangChain agents vs LangGraph?\\\"\\n\",\n@@ -266,9 +330,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 57,\n+   \"execution_count\": 10,\n    \"id\": \"68b03709-9a60-4acf-b96c-cafe1056c6f3\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:50.215540Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:50.215250Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:50.224108Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:50.223490Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import uuid\\n\",\n@@ -313,9 +384,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 58,\n+   \"execution_count\": 11,\n    \"id\": \"d9bf9f87-3e6b-4fc2-957b-949b077fab54\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:50.227215Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:50.226993Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:50.231333Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:50.230742Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.prompts import MessagesPlaceholder\\n\",\n@@ -329,17 +407,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 62,\n+   \"execution_count\": 12,\n    \"id\": \"e565ccb0-3530-4782-b56b-d1f6d0a8e559\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:33:50.233833Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:33:50.233646Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:33:51.318133Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:33:51.317640Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='Difference between web voyager and reflection agents, do they both use LangGraph?', sub_queries=['What is Web Voyager', 'What are Reflection agents', 'Do Web Voyager and Reflection agents use LangGraph'], publish_year=None)\"\n+       \"Search(query=\\\"What's the difference between web voyager and reflection agents? Do both use langgraph?\\\", sub_queries=['What is web voyager', 'What are reflection agents', 'Do web voyager and reflection agents use langgraph?'], publish_year=None)\"\n       ]\n      },\n-     \"execution_count\": 62,\n+     \"execution_count\": 12,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -377,7 +462,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/query_high_cardinality.ipynb",
          "status": "modified",
          "additions": 259,
          "deletions": 96,
          "patch": "@@ -33,12 +33,20 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": null,\n    \"id\": \"e168ef5c-e54e-49a6-8552-5502854a6f01\",\n    \"metadata\": {},\n-   \"outputs\": [],\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n+     ]\n+    }\n+   ],\n    \"source\": [\n-    \"# %pip install -qU langchain langchain-community langchain-openai faker langchain-chroma\"\n+    \"%pip install -qU langchain langchain-community langchain-openai faker langchain-chroma\"\n    ]\n   },\n   {\n@@ -53,15 +61,23 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": 2,\n    \"id\": \"40e2979e-a818-4b96-ac25-039336f94319\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:54.036110Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:54.035829Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:54.038746Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:54.038430Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n     \"\\n\",\n     \"# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\\n\",\n     \"# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n@@ -80,9 +96,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": 3,\n    \"id\": \"e5ba65c2\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:54.040738Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:54.040515Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:54.622643Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:54.622382Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from faker import Faker\\n\",\n@@ -102,17 +125,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 2,\n+   \"execution_count\": 4,\n    \"id\": \"c901ea97\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:54.624195Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:54.624106Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:54.627231Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:54.626971Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"'Hayley Gonzalez'\"\n+       \"'Jacob Adams'\"\n       ]\n      },\n-     \"execution_count\": 2,\n+     \"execution_count\": 4,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -123,17 +153,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 5,\n    \"id\": \"b0d42ae2\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:54.628545Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:54.628460Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:54.630474Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:54.630282Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"'Jesse Knight'\"\n+       \"'Eric Acevedo'\"\n       ]\n      },\n-     \"execution_count\": 3,\n+     \"execution_count\": 5,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -154,19 +191,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 6,\n    \"id\": \"0ae69afc\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:54.631758Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:54.631678Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:54.666448Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:54.666216Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\"\n+    \"from pydantic import BaseModel, Field, model_validator\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 7,\n    \"id\": \"6c9485ce\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:54.667852Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:54.667733Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:54.700224Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:54.700004Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"class Search(BaseModel):\\n\",\n@@ -176,19 +227,17 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 8,\n    \"id\": \"aebd704a\",\n-   \"metadata\": {},\n-   \"outputs\": [\n-    {\n-     \"name\": \"stderr\",\n-     \"output_type\": \"stream\",\n-     \"text\": [\n-      \"/Users/harrisonchase/workplace/langchain/libs/core/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\\n\",\n-      \"  warn_beta(\\n\"\n-     ]\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:54.701556Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:54.701465Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:55.179986Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:55.179640Z\"\n     }\n-   ],\n+   },\n+   \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n     \"from langchain_core.runnables import RunnablePassthrough\\n\",\n@@ -201,7 +250,7 @@\n     \"        (\\\"human\\\", \\\"{question}\\\"),\\n\",\n     \"    ]\\n\",\n     \")\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"structured_llm = llm.with_structured_output(Search)\\n\",\n     \"query_analyzer = {\\\"question\\\": RunnablePassthrough()} | prompt | structured_llm\"\n    ]\n@@ -216,17 +265,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 33,\n+   \"execution_count\": 9,\n    \"id\": \"cc0d344b\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:55.181603Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:55.181500Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:55.778884Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:55.778324Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='books about aliens', author='Jesse Knight')\"\n+       \"Search(query='aliens', author='Jesse Knight')\"\n       ]\n      },\n-     \"execution_count\": 33,\n+     \"execution_count\": 9,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -245,17 +301,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 34,\n+   \"execution_count\": 10,\n    \"id\": \"82b6b2ad\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:55.784266Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:55.782603Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:56.206779Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:56.206068Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='books about aliens', author='Jess Knight')\"\n+       \"Search(query='aliens', author='Jess Knight')\"\n       ]\n      },\n-     \"execution_count\": 34,\n+     \"execution_count\": 10,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -276,9 +339,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 35,\n+   \"execution_count\": 11,\n    \"id\": \"98788a94\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:56.210043Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:56.209657Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:56.213962Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:56.213413Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"system = \\\"\\\"\\\"Generate a relevant search query for a library system.\\n\",\n@@ -299,9 +369,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 36,\n+   \"execution_count\": 12,\n    \"id\": \"e65412f5\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:56.216144Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:56.216005Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:56.218754Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:56.218416Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"query_analyzer_all = {\\\"question\\\": RunnablePassthrough()} | prompt | structured_llm\"\n@@ -317,18 +394,17 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 37,\n+   \"execution_count\": 13,\n    \"id\": \"696b000f\",\n-   \"metadata\": {},\n-   \"outputs\": [\n-    {\n-     \"name\": \"stdout\",\n-     \"output_type\": \"stream\",\n-     \"text\": [\n-      \"Error code: 400 - {'error': {'message': \\\"This model's maximum context length is 16385 tokens. However, your messages resulted in 33885 tokens (33855 in the messages, 30 in the functions). Please reduce the length of the messages or functions.\\\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\\n\"\n-     ]\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:56.220827Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:56.220680Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:58.846872Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:58.846273Z\"\n     }\n-   ],\n+   },\n+   \"outputs\": [],\n    \"source\": [\n     \"try:\\n\",\n     \"    res = query_analyzer_all.invoke(\\\"what are books about aliens by jess knight\\\")\\n\",\n@@ -346,9 +422,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 38,\n+   \"execution_count\": 14,\n    \"id\": \"0f0d0757\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:58.850318Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:58.850100Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:34:58.873883Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:34:58.873525Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"llm_long = ChatOpenAI(model=\\\"gpt-4-turbo-preview\\\", temperature=0)\\n\",\n@@ -358,17 +441,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 39,\n+   \"execution_count\": 15,\n    \"id\": \"03e5b7b2\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:34:58.875940Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:34:58.875811Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:02.947273Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:02.946220Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='aliens', author='Kevin Knight')\"\n+       \"Search(query='aliens', author='jess knight')\"\n       ]\n      },\n-     \"execution_count\": 39,\n+     \"execution_count\": 15,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -389,9 +479,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 25,\n+   \"execution_count\": 16,\n    \"id\": \"32b19e07\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:02.951939Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:02.951583Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:41.777839Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:41.777392Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_chroma import Chroma\\n\",\n@@ -403,9 +500,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 51,\n+   \"execution_count\": 17,\n    \"id\": \"774cb7b0\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:41.780883Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:41.780774Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:41.782739Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:41.782498Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"def select_names(question):\\n\",\n@@ -416,9 +520,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 52,\n+   \"execution_count\": 18,\n    \"id\": \"1173159c\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:41.783992Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:41.783913Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:41.785911Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:41.785632Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"create_prompt = {\\n\",\n@@ -429,27 +540,41 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 53,\n+   \"execution_count\": 19,\n    \"id\": \"0a892607\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:41.787082Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:41.787008Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:41.788543Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:41.788362Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"query_analyzer_select = create_prompt | structured_llm\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 54,\n+   \"execution_count\": 20,\n    \"id\": \"8195d7cd\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:41.789624Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:41.789551Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:42.099839Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:42.099042Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"ChatPromptValue(messages=[SystemMessage(content='Generate a relevant search query for a library system.\\\\n\\\\n`author` attribute MUST be one of:\\\\n\\\\nJesse Knight, Kelly Knight, Scott Knight, Richard Knight, Andrew Knight, Katherine Knight, Erica Knight, Ashley Knight, Becky Knight, Kevin Knight\\\\n\\\\nDo NOT hallucinate author name!'), HumanMessage(content='what are books by jess knight')])\"\n+       \"ChatPromptValue(messages=[SystemMessage(content='Generate a relevant search query for a library system.\\\\n\\\\n`author` attribute MUST be one of:\\\\n\\\\nJennifer Knight, Jill Knight, John Knight, Dr. Jeffrey Knight, Christopher Knight, Andrea Knight, Brandy Knight, Jennifer Keller, Becky Chambers, Sarah Knapp\\\\n\\\\nDo NOT hallucinate author name!'), HumanMessage(content='what are books by jess knight')])\"\n       ]\n      },\n-     \"execution_count\": 54,\n+     \"execution_count\": 20,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -460,17 +585,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 55,\n+   \"execution_count\": 21,\n    \"id\": \"d3228b4e\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:42.106571Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:42.105861Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:42.909738Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:42.908875Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='books about aliens', author='Jesse Knight')\"\n+       \"Search(query='books about aliens', author='Jennifer Knight')\"\n       ]\n      },\n-     \"execution_count\": 55,\n+     \"execution_count\": 21,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -492,28 +624,45 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 47,\n+   \"execution_count\": 22,\n    \"id\": \"a2e8b434\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:42.915376Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:42.914923Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:42.923958Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:42.922391Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import validator\\n\",\n-    \"\\n\",\n-    \"\\n\",\n     \"class Search(BaseModel):\\n\",\n     \"    query: str\\n\",\n     \"    author: str\\n\",\n     \"\\n\",\n-    \"    @validator(\\\"author\\\")\\n\",\n-    \"    def double(cls, v: str) -> str:\\n\",\n-    \"        return vectorstore.similarity_search(v, k=1)[0].page_content\"\n+    \"    @model_validator(mode=\\\"before\\\")\\n\",\n+    \"    @classmethod\\n\",\n+    \"    def double(cls, values: dict) -> dict:\\n\",\n+    \"        author = values[\\\"author\\\"]\\n\",\n+    \"        closest_valid_author = vectorstore.similarity_search(author, k=1)[\\n\",\n+    \"            0\\n\",\n+    \"        ].page_content\\n\",\n+    \"        values[\\\"author\\\"] = closest_valid_author\\n\",\n+    \"        return values\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 48,\n+   \"execution_count\": 23,\n    \"id\": \"919c0601\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:42.927718Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:42.927428Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:42.933784Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:42.933344Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"system = \\\"\\\"\\\"Generate a relevant search query for a library system\\\"\\\"\\\"\\n\",\n@@ -531,17 +680,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 50,\n+   \"execution_count\": 24,\n    \"id\": \"6c4f3e9a\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:42.936506Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:42.936186Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:43.711754Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:43.710695Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='books about aliens', author='Jesse Knight')\"\n+       \"Search(query='aliens', author='John Knight')\"\n       ]\n      },\n-     \"execution_count\": 50,\n+     \"execution_count\": 24,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -552,9 +708,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 25,\n    \"id\": \"a309cb11\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:35:43.717567Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:35:43.717189Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:35:43.722339Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:35:43.720537Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# TODO: show trigram similarity\"\n@@ -563,9 +726,9 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"poetry-venv-311\",\n    \"language\": \"python\",\n-   \"name\": \"python3\"\n+   \"name\": \"poetry-venv-311\"\n   },\n   \"language_info\": {\n    \"codemirror_mode\": {\n@@ -577,7 +740,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/query_multiple_queries.ipynb",
          "status": "modified",
          "additions": 121,
          "deletions": 43,
          "patch": "@@ -33,10 +33,25 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n    \"id\": \"e168ef5c-e54e-49a6-8552-5502854a6f01\",\n-   \"metadata\": {},\n-   \"outputs\": [],\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:41:53.160868Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:41:53.160512Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:41:57.605370Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:41:57.604888Z\"\n+    }\n+   },\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n+     ]\n+    }\n+   ],\n    \"source\": [\n-    \"# %pip install -qU langchain langchain-community langchain-openai langchain-chroma\"\n+    \"%pip install -qU langchain langchain-community langchain-openai langchain-chroma\"\n    ]\n   },\n   {\n@@ -51,15 +66,23 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 2,\n    \"id\": \"40e2979e-a818-4b96-ac25-039336f94319\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:41:57.607874Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:41:57.607697Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:41:57.610422Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:41:57.610012Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n     \"\\n\",\n     \"# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\\n\",\n     \"# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n@@ -78,9 +101,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": 3,\n    \"id\": \"1f621694\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:41:57.612276Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:41:57.612146Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:41:59.074590Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:41:59.074052Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_chroma import Chroma\\n\",\n@@ -108,14 +138,21 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 2,\n+   \"execution_count\": 4,\n    \"id\": \"0b51dd76-820d-41a4-98c8-893f6fe0d1ea\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:41:59.077712Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:41:59.077514Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:41:59.081509Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:41:59.081112Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List, Optional\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Search(BaseModel):\\n\",\n@@ -129,19 +166,17 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 5,\n    \"id\": \"783c03c3-8c72-4f88-9cf4-5829ce6745d6\",\n-   \"metadata\": {},\n-   \"outputs\": [\n-    {\n-     \"name\": \"stderr\",\n-     \"output_type\": \"stream\",\n-     \"text\": [\n-      \"/Users/harrisonchase/workplace/langchain/libs/core/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `with_structured_output` is in beta. It is actively being worked on, so the API may change.\\n\",\n-      \"  warn_beta(\\n\"\n-     ]\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:41:59.083613Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:41:59.083492Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:41:59.204636Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:41:59.204377Z\"\n     }\n-   ],\n+   },\n+   \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.output_parsers.openai_tools import PydanticToolsParser\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n@@ -159,7 +194,7 @@\n     \"        (\\\"human\\\", \\\"{question}\\\"),\\n\",\n     \"    ]\\n\",\n     \")\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"structured_llm = llm.with_structured_output(Search)\\n\",\n     \"query_analyzer = {\\\"question\\\": RunnablePassthrough()} | prompt | structured_llm\"\n    ]\n@@ -174,17 +209,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 6,\n    \"id\": \"bc1d3863\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:41:59.206178Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:41:59.206101Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:41:59.817758Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:41:59.817310Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(queries=['Harrison work location'])\"\n+       \"Search(queries=['Harrison Work', 'Harrison employment history'])\"\n       ]\n      },\n-     \"execution_count\": 4,\n+     \"execution_count\": 6,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -195,17 +237,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 7,\n    \"id\": \"af62af17-4f90-4dbd-a8b4-dfff51f1db95\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:41:59.820168Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:41:59.819990Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:00.309034Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:00.308578Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(queries=['Harrison work place', 'Ankush work place'])\"\n+       \"Search(queries=['Harrison work history', 'Ankush work history'])\"\n       ]\n      },\n-     \"execution_count\": 5,\n+     \"execution_count\": 7,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -226,19 +275,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 8,\n    \"id\": \"1e047d87\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:00.311131Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:00.310972Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:00.313365Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:00.313025Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.runnables import chain\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 31,\n+   \"execution_count\": 9,\n    \"id\": \"8dac7866\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:00.315138Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:00.315016Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:00.317427Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:00.317088Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"@chain\\n\",\n@@ -255,17 +318,25 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 33,\n+   \"execution_count\": 10,\n    \"id\": \"232ad8a7-7990-4066-9228-d35a555f7293\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:00.318951Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:00.318829Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:01.512855Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:01.512321Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"[Document(page_content='Harrison worked at Kensho')]\"\n+       \"[Document(page_content='Harrison worked at Kensho'),\\n\",\n+       \" Document(page_content='Harrison worked at Kensho')]\"\n       ]\n      },\n-     \"execution_count\": 33,\n+     \"execution_count\": 10,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -276,9 +347,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 34,\n+   \"execution_count\": 11,\n    \"id\": \"28e14ba5\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:01.515743Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:01.515400Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:02.349930Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:02.349382Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n@@ -287,7 +365,7 @@\n        \" Document(page_content='Ankush worked at Facebook')]\"\n       ]\n      },\n-     \"execution_count\": 34,\n+     \"execution_count\": 11,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -321,7 +399,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/query_multiple_retrievers.ipynb",
          "status": "modified",
          "additions": 128,
          "deletions": 35,
          "patch": "@@ -33,10 +33,25 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n    \"id\": \"e168ef5c-e54e-49a6-8552-5502854a6f01\",\n-   \"metadata\": {},\n-   \"outputs\": [],\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:13.105266Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:13.104556Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:17.936922Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:17.936478Z\"\n+    }\n+   },\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n+     ]\n+    }\n+   ],\n    \"source\": [\n-    \"# %pip install -qU langchain langchain-community langchain-openai langchain-chroma\"\n+    \"%pip install -qU langchain langchain-community langchain-openai langchain-chroma\"\n    ]\n   },\n   {\n@@ -51,15 +66,23 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 2,\n    \"id\": \"40e2979e-a818-4b96-ac25-039336f94319\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:17.939072Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:17.938929Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:17.941266Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:17.940968Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n     \"\\n\",\n     \"# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\\n\",\n     \"# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n@@ -78,9 +101,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 16,\n+   \"execution_count\": 3,\n    \"id\": \"1f621694\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:17.942794Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:17.942674Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:19.939459Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:19.938842Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_chroma import Chroma\\n\",\n@@ -110,14 +140,21 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 17,\n+   \"execution_count\": 4,\n    \"id\": \"0b51dd76-820d-41a4-98c8-893f6fe0d1ea\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:19.942780Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:19.942567Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:19.947709Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:19.947252Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List, Optional\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Search(BaseModel):\\n\",\n@@ -135,9 +172,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 18,\n+   \"execution_count\": 5,\n    \"id\": \"783c03c3-8c72-4f88-9cf4-5829ce6745d6\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:19.949936Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:19.949778Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:20.073883Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:20.073556Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.output_parsers.openai_tools import PydanticToolsParser\\n\",\n@@ -154,7 +198,7 @@\n     \"        (\\\"human\\\", \\\"{question}\\\"),\\n\",\n     \"    ]\\n\",\n     \")\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"structured_llm = llm.with_structured_output(Search)\\n\",\n     \"query_analyzer = {\\\"question\\\": RunnablePassthrough()} | prompt | structured_llm\"\n    ]\n@@ -169,17 +213,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 19,\n+   \"execution_count\": 6,\n    \"id\": \"bc1d3863\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:20.075511Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:20.075428Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:20.902011Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:20.901558Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='workplace', person='HARRISON')\"\n+       \"Search(query='work history', person='HARRISON')\"\n       ]\n      },\n-     \"execution_count\": 19,\n+     \"execution_count\": 6,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -190,17 +241,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 20,\n+   \"execution_count\": 7,\n    \"id\": \"af62af17-4f90-4dbd-a8b4-dfff51f1db95\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:20.904384Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:20.904195Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:21.468172Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:21.467639Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Search(query='workplace', person='ANKUSH')\"\n+       \"Search(query='work history', person='ANKUSH')\"\n       ]\n      },\n-     \"execution_count\": 20,\n+     \"execution_count\": 7,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -221,19 +279,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 21,\n+   \"execution_count\": 8,\n    \"id\": \"1e047d87\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:21.470953Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:21.470736Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:21.473544Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:21.473064Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.runnables import chain\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 22,\n+   \"execution_count\": 9,\n    \"id\": \"4ec0c7fe\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:21.476024Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:21.475835Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:21.478359Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:21.477932Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"retrievers = {\\n\",\n@@ -244,9 +316,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 23,\n+   \"execution_count\": 10,\n    \"id\": \"8dac7866\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:21.480247Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:21.480084Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:21.482732Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:21.482382Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"@chain\\n\",\n@@ -258,17 +337,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 24,\n+   \"execution_count\": 11,\n    \"id\": \"232ad8a7-7990-4066-9228-d35a555f7293\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:21.484480Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:21.484361Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:22.136704Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:22.136244Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[Document(page_content='Harrison worked at Kensho')]\"\n       ]\n      },\n-     \"execution_count\": 24,\n+     \"execution_count\": 11,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -279,17 +365,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 25,\n+   \"execution_count\": 12,\n    \"id\": \"28e14ba5\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:22.139305Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:22.139106Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:23.479739Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:23.479170Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[Document(page_content='Ankush worked at Facebook')]\"\n       ]\n      },\n-     \"execution_count\": 25,\n+     \"execution_count\": 12,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -323,7 +416,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/query_no_queries.ipynb",
          "status": "modified",
          "additions": 120,
          "deletions": 34,
          "patch": "@@ -35,10 +35,25 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n    \"id\": \"e168ef5c-e54e-49a6-8552-5502854a6f01\",\n-   \"metadata\": {},\n-   \"outputs\": [],\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:33.121714Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:33.121392Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:36.998607Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:36.998126Z\"\n+    }\n+   },\n+   \"outputs\": [\n+    {\n+     \"name\": \"stdout\",\n+     \"output_type\": \"stream\",\n+     \"text\": [\n+      \"Note: you may need to restart the kernel to use updated packages.\\n\"\n+     ]\n+    }\n+   ],\n    \"source\": [\n-    \"# %pip install -qU langchain langchain-community langchain-openai langchain-chroma\"\n+    \"%pip install -qU langchain langchain-community langchain-openai langchain-chroma\"\n    ]\n   },\n   {\n@@ -53,15 +68,23 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 2,\n    \"id\": \"40e2979e-a818-4b96-ac25-039336f94319\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:37.001017Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:37.000859Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:37.003704Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:37.003335Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n     \"\\n\",\n     \"# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\\n\",\n     \"# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n@@ -80,9 +103,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 1,\n+   \"execution_count\": 3,\n    \"id\": \"1f621694\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:37.005644Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:37.005493Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:38.288481Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:38.287904Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_chroma import Chroma\\n\",\n@@ -110,14 +140,21 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 2,\n+   \"execution_count\": 4,\n    \"id\": \"0b51dd76-820d-41a4-98c8-893f6fe0d1ea\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:38.291700Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:38.291468Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:38.295796Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:38.295205Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import Optional\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Search(BaseModel):\\n\",\n@@ -131,9 +168,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 3,\n+   \"execution_count\": 5,\n    \"id\": \"783c03c3-8c72-4f88-9cf4-5829ce6745d6\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:38.297840Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:38.297712Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:38.420456Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:38.420140Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n@@ -149,7 +193,7 @@\n     \"        (\\\"human\\\", \\\"{question}\\\"),\\n\",\n     \"    ]\\n\",\n     \")\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"structured_llm = llm.bind_tools([Search])\\n\",\n     \"query_analyzer = {\\\"question\\\": RunnablePassthrough()} | prompt | structured_llm\"\n    ]\n@@ -164,17 +208,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 6,\n    \"id\": \"bc1d3863\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:38.421934Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:38.421831Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:39.048915Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:39.048519Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ZnoVX4j9Mn8wgChaORyd1cvq', 'function': {'arguments': '{\\\"query\\\":\\\"Harrison\\\"}', 'name': 'Search'}, 'type': 'function'}]})\"\n+       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\\\"query\\\":\\\"Harrison\\\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\"\n       ]\n      },\n-     \"execution_count\": 4,\n+     \"execution_count\": 6,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -185,17 +236,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 7,\n    \"id\": \"af62af17-4f90-4dbd-a8b4-dfff51f1db95\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:39.050923Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:39.050785Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:40.090421Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:40.089454Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='Hello! How can I assist you today?')\"\n+       \"AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\"\n       ]\n      },\n-     \"execution_count\": 5,\n+     \"execution_count\": 7,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -216,9 +274,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 8,\n    \"id\": \"1e047d87\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:40.093716Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:40.093472Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:40.097732Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:40.097274Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.output_parsers.openai_tools import PydanticToolsParser\\n\",\n@@ -229,9 +294,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 7,\n+   \"execution_count\": 9,\n    \"id\": \"8dac7866\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:40.100028Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:40.099882Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:40.103105Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:40.102734Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"@chain\\n\",\n@@ -248,9 +320,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 8,\n+   \"execution_count\": 10,\n    \"id\": \"232ad8a7-7990-4066-9228-d35a555f7293\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:40.105092Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:40.104917Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:41.341967Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:41.341455Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stderr\",\n@@ -265,7 +344,7 @@\n        \"[Document(page_content='Harrison worked at Kensho')]\"\n       ]\n      },\n-     \"execution_count\": 8,\n+     \"execution_count\": 10,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -276,17 +355,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 9,\n+   \"execution_count\": 11,\n    \"id\": \"28e14ba5\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:42:41.344639Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:42:41.344411Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:42:41.798332Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:42:41.798054Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='Hello! How can I assist you today?')\"\n+       \"AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\"\n       ]\n      },\n-     \"execution_count\": 9,\n+     \"execution_count\": 11,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -320,7 +406,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.1\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/recursive_json_splitter.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -107,7 +107,7 @@\n    \"id\": \"3f05bc21-227e-4d2c-af51-16d69ad3cd7b\",\n    \"metadata\": {},\n    \"source\": [\n-    \"To obtain LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) objects, use the `.create_documents` method:\"\n+    \"To obtain LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects, use the `.create_documents` method:\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/recursive_text_splitter.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -30,7 +30,7 @@\n     \"\\n\",\n     \"To obtain the string content directly, use `.split_text`.\\n\",\n     \"\\n\",\n-    \"To create LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) objects (e.g., for use in downstream tasks), use `.create_documents`.\"\n+    \"To create LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects (e.g., for use in downstream tasks), use `.create_documents`.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/semantic-chunker.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -69,7 +69,7 @@\n    \"id\": \"774a5199-c2ff-43bc-bf07-87573e0b8db4\",\n    \"metadata\": {},\n    \"source\": [\n-    \"To instantiate a [SemanticChunker](https://python.langchain.com/v0.2/api_reference/experimental/text_splitter/langchain_experimental.text_splitter.SemanticChunker.html), we must specify an embedding model. Below we will use [OpenAIEmbeddings](https://python.langchain.com/v0.2/api_reference/community/embeddings/langchain_community.embeddings.openai.OpenAIEmbeddings.html). \"\n+    \"To instantiate a [SemanticChunker](https://python.langchain.com/api_reference/experimental/text_splitter/langchain_experimental.text_splitter.SemanticChunker.html), we must specify an embedding model. Below we will use [OpenAIEmbeddings](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.openai.OpenAIEmbeddings.html). \"\n    ]\n   },\n   {\n@@ -92,7 +92,7 @@\n    \"source\": [\n     \"## Split Text\\n\",\n     \"\\n\",\n-    \"We split text in the usual way, e.g., by invoking `.create_documents` to create LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) objects:\"\n+    \"We split text in the usual way, e.g., by invoking `.create_documents` to create LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects:\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/sequence.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -31,7 +31,7 @@\n     \"\\n\",\n     \"One point about [LangChain Expression Language](/docs/concepts/#langchain-expression-language) is that any two runnables can be \\\"chained\\\" together into sequences. The output of the previous runnable's `.invoke()` call is passed as input to the next runnable. This can be done using the pipe operator (`|`), or the more explicit `.pipe()` method, which does the same thing.\\n\",\n     \"\\n\",\n-    \"The resulting [`RunnableSequence`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.RunnableSequence.html) is itself a runnable, which means it can be invoked, streamed, or further chained just like any other runnable. Advantages of chaining runnables in this way are efficient streaming (the sequence will stream output as soon as it is available), and debugging and tracing with tools like [LangSmith](/docs/how_to/debugging).\\n\",\n+    \"The resulting [`RunnableSequence`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.RunnableSequence.html) is itself a runnable, which means it can be invoked, streamed, or further chained just like any other runnable. Advantages of chaining runnables in this way are efficient streaming (the sequence will stream output as soon as it is available), and debugging and tracing with tools like [LangSmith](/docs/how_to/debugging).\\n\",\n     \"\\n\",\n     \"## The pipe operator: `|`\\n\",\n     \"\\n\",\n@@ -62,7 +62,8 @@\n     \"\\n\",\n     \"from langchain_anthropic import ChatAnthropic\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"ANTHROPIC_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n     \"model = ChatAnthropic(model=\\\"claude-3-sonnet-20240229\\\", temperature=0)\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/serialization.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -12,9 +12,9 @@\n     \"- Secrets, such as API keys, are separated from other parameters and can be loaded back to the object on de-serialization;\\n\",\n     \"- De-serialization is kept compatible across package versions, so objects that were serialized with one version of LangChain can be properly de-serialized with another.\\n\",\n     \"\\n\",\n-    \"To save and load LangChain objects using this system, use the `dumpd`, `dumps`, `load`, and `loads` functions in the [load module](https://python.langchain.com/v0.2/api_reference/core/load.html) of `langchain-core`. These functions support JSON and JSON-serializable objects.\\n\",\n+    \"To save and load LangChain objects using this system, use the `dumpd`, `dumps`, `load`, and `loads` functions in the [load module](https://python.langchain.com/api_reference/core/load.html) of `langchain-core`. These functions support JSON and JSON-serializable objects.\\n\",\n     \"\\n\",\n-    \"All LangChain objects that inherit from [Serializable](https://python.langchain.com/v0.2/api_reference/core/load/langchain_core.load.serializable.Serializable.html) are JSON-serializable. Examples include [messages](https://python.langchain.com/v0.2/api_reference//python/core_api_reference.html#module-langchain_core.messages), [document objects](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) (e.g., as returned from [retrievers](/docs/concepts/#retrievers)), and most [Runnables](/docs/concepts/#langchain-expression-language-lcel), such as chat models, retrievers, and [chains](/docs/how_to/sequence) implemented with the LangChain Expression Language.\\n\",\n+    \"All LangChain objects that inherit from [Serializable](https://python.langchain.com/api_reference/core/load/langchain_core.load.serializable.Serializable.html) are JSON-serializable. Examples include [messages](https://python.langchain.com/api_reference//python/core_api_reference.html#module-langchain_core.messages), [document objects](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) (e.g., as returned from [retrievers](/docs/concepts/#retrievers)), and most [Runnables](/docs/concepts/#langchain-expression-language-lcel), such as chat models, retrievers, and [chains](/docs/how_to/sequence) implemented with the LangChain Expression Language.\\n\",\n     \"\\n\",\n     \"Below we walk through an example with a simple [LLM chain](/docs/tutorials/llm_chain).\\n\",\n     \"\\n\",\n@@ -44,7 +44,7 @@\n     \"    ],\\n\",\n     \")\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", api_key=\\\"llm-api-key\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", api_key=\\\"llm-api-key\\\")\\n\",\n     \"\\n\",\n     \"chain = prompt | llm\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/split_by_token.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -27,7 +27,7 @@\n     \"1. How the text is split: by character passed in.\\n\",\n     \"2. How the chunk size is measured: by `tiktoken` tokenizer.\\n\",\n     \"\\n\",\n-    \"[CharacterTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html), [RecursiveCharacterTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html), and [TokenTextSplitter](https://python.langchain.com/v0.2/api_reference/langchain_text_splitters/base/langchain_text_splitters.base.TokenTextSplitter.html) can be used with `tiktoken` directly.\"\n+    \"[CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html), [RecursiveCharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html), and [TokenTextSplitter](https://python.langchain.com/api_reference/langchain_text_splitters/base/langchain_text_splitters.base.TokenTextSplitter.html) can be used with `tiktoken` directly.\"\n    ]\n   },\n   {\n@@ -59,7 +59,7 @@\n    \"id\": \"a3ba1d8a\",\n    \"metadata\": {},\n    \"source\": [\n-    \"To split with a [CharacterTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html) and then merge chunks with `tiktoken`, use its `.from_tiktoken_encoder()` method. Note that splits from this method can be larger than the chunk size measured by the `tiktoken` tokenizer.\\n\",\n+    \"To split with a [CharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.CharacterTextSplitter.html) and then merge chunks with `tiktoken`, use its `.from_tiktoken_encoder()` method. Note that splits from this method can be larger than the chunk size measured by the `tiktoken` tokenizer.\\n\",\n     \"\\n\",\n     \"The `.from_tiktoken_encoder()` method takes either `encoding_name` as an argument (e.g. `cl100k_base`), or the `model_name` (e.g. `gpt-4`). All additional arguments like `chunk_size`, `chunk_overlap`, and `separators` are used to instantiate `CharacterTextSplitter`:\"\n    ]\n@@ -279,7 +279,7 @@\n    \"source\": [\n     \"## SentenceTransformers\\n\",\n     \"\\n\",\n-    \"The [SentenceTransformersTokenTextSplitter](https://python.langchain.com/v0.2/api_reference/text_splitters/sentence_transformers/langchain_text_splitters.sentence_transformers.SentenceTransformersTokenTextSplitter.html) is a specialized text splitter for use with the sentence-transformer models. The default behaviour is to split the text into chunks that fit the token window of the sentence transformer model that you would like to use.\\n\",\n+    \"The [SentenceTransformersTokenTextSplitter](https://python.langchain.com/api_reference/text_splitters/sentence_transformers/langchain_text_splitters.sentence_transformers.SentenceTransformersTokenTextSplitter.html) is a specialized text splitter for use with the sentence-transformer models. The default behaviour is to split the text into chunks that fit the token window of the sentence transformer model that you would like to use.\\n\",\n     \"\\n\",\n     \"To split text and constrain token counts according to the sentence-transformers tokenizer, instantiate a `SentenceTransformersTokenTextSplitter`. You can optionally specify:\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/sql_csv.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -609,7 +609,7 @@\n    \"source\": [\n     \"### Agent\\n\",\n     \"\\n\",\n-    \"For complex questions it can be helpful for an LLM to be able to iteratively execute code while maintaining the inputs and outputs of its previous executions. This is where Agents come into play. They allow an LLM to decide how many times a tool needs to be invoked and keep track of the executions it's made so far. The [create_pandas_dataframe_agent](https://python.langchain.com/v0.2/api_reference/experimental/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html) is a built-in agent that makes it easy to work with dataframes:\"\n+    \"For complex questions it can be helpful for an LLM to be able to iteratively execute code while maintaining the inputs and outputs of its previous executions. This is where Agents come into play. They allow an LLM to decide how many times a tool needs to be invoked and keep track of the executions it's made so far. The [create_pandas_dataframe_agent](https://python.langchain.com/api_reference/experimental/agents/langchain_experimental.agents.agent_toolkits.pandas.base.create_pandas_dataframe_agent.html) is a built-in agent that makes it easy to work with dataframes:\"\n    ]\n   },\n   {\n@@ -761,7 +761,7 @@\n     \"* [SQL tutorial](/docs/tutorials/sql_qa): Many of the challenges of working with SQL db's and CSV's are generic to any structured data type, so it's useful to read the SQL techniques even if you're using Pandas for CSV data analysis.\\n\",\n     \"* [Tool use](/docs/how_to/tool_calling): Guides on general best practices when working with chains and agents that invoke tools\\n\",\n     \"* [Agents](/docs/tutorials/agents): Understand the fundamentals of building LLM agents.\\n\",\n-    \"* Integrations: Sandboxed envs like [E2B](/docs/integrations/tools/e2b_data_analysis) and [Bearly](/docs/integrations/tools/bearly), utilities like [SQLDatabase](https://python.langchain.com/v0.2/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), related agents like [Spark DataFrame agent](/docs/integrations/tools/spark_sql).\"\n+    \"* Integrations: Sandboxed envs like [E2B](/docs/integrations/tools/e2b_data_analysis) and [Bearly](/docs/integrations/tools/bearly), utilities like [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), related agents like [Spark DataFrame agent](/docs/integrations/tools/spark_sql).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/how_to/sql_large_db.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -55,7 +55,7 @@\n     \"* Run `.read Chinook_Sqlite.sql`\\n\",\n     \"* Test `SELECT * FROM Artist LIMIT 10;`\\n\",\n     \"\\n\",\n-    \"Now, `Chinhook.db` is in our directory and we can interface with it using the SQLAlchemy-driven [SQLDatabase](https://python.langchain.com/v0.2/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) class:\"\n+    \"Now, `Chinhook.db` is in our directory and we can interface with it using the SQLAlchemy-driven [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) class:\"\n    ]\n   },\n   {\n@@ -136,7 +136,7 @@\n    \"source\": [\n     \"from langchain_core.output_parsers.openai_tools import PydanticToolsParser\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Table(BaseModel):\\n\",\n@@ -271,7 +271,7 @@\n    \"id\": \"04d52d01-1ccf-4753-b34a-0dcbc4921f78\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Now that we've got a chain that can output the relevant tables for any query we can combine this with our [create_sql_query_chain](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html), which can accept a list of `table_names_to_use` to determine which table schemas are included in the prompt:\"\n+    \"Now that we've got a chain that can output the relevant tables for any query we can combine this with our [create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html), which can accept a list of `table_names_to_use` to determine which table schemas are included in the prompt:\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/sql_prompting.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -6,11 +6,11 @@\n    \"source\": [\n     \"# How to better prompt when doing SQL question-answering\\n\",\n     \"\\n\",\n-    \"In this guide we'll go over prompting strategies to improve SQL query generation using [create_sql_query_chain](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html). We'll largely focus on methods for getting relevant database-specific information in your prompt.\\n\",\n+    \"In this guide we'll go over prompting strategies to improve SQL query generation using [create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html). We'll largely focus on methods for getting relevant database-specific information in your prompt.\\n\",\n     \"\\n\",\n     \"We will cover: \\n\",\n     \"\\n\",\n-    \"- How the dialect of the LangChain [SQLDatabase](https://python.langchain.com/v0.2/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) impacts the prompt of the chain;\\n\",\n+    \"- How the dialect of the LangChain [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) impacts the prompt of the chain;\\n\",\n     \"- How to format schema information into the prompt using `SQLDatabase.get_context`;\\n\",\n     \"- How to build and select few-shot examples to assist the model.\\n\",\n     \"\\n\",\n@@ -84,7 +84,7 @@\n    \"source\": [\n     \"## Dialect-specific prompting\\n\",\n     \"\\n\",\n-    \"One of the simplest things we can do is make our prompt specific to the SQL dialect we're using. When using the built-in [create_sql_query_chain](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html) and [SQLDatabase](https://python.langchain.com/v0.2/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html), this is handled for you for any of the following dialects:\"\n+    \"One of the simplest things we can do is make our prompt specific to the SQL dialect we're using. When using the built-in [create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html) and [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html), this is handled for you for any of the following dialects:\"\n    ]\n   },\n   {\n@@ -629,7 +629,7 @@\n     \"\\n\",\n     \"If we have enough examples, we may want to only include the most relevant ones in the prompt, either because they don't fit in the model's context window or because the long tail of examples distracts the model. And specifically, given any input we want to include the examples most relevant to that input.\\n\",\n     \"\\n\",\n-    \"We can do just this using an ExampleSelector. In this case we'll use a [SemanticSimilarityExampleSelector](https://python.langchain.com/v0.2/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html), which will store the examples in the vector database of our choosing. At runtime it will perform a similarity search between the input and our examples, and return the most semantically similar ones.\\n\",\n+    \"We can do just this using an ExampleSelector. In this case we'll use a [SemanticSimilarityExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html), which will store the examples in the vector database of our choosing. At runtime it will perform a similarity search between the input and our examples, and return the most semantically similar ones.\\n\",\n     \"\\n\",\n     \"We default to OpenAI embeddings here, but you can swap them out for the model provider of your choice.\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/streaming.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -246,7 +246,7 @@\n     \"\\n\",\n     \"Let's build a simple chain using `LangChain Expression Language` (`LCEL`) that combines a prompt, model and a parser and verify that streaming works.\\n\",\n     \"\\n\",\n-    \"We will use [`StrOutputParser`](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) to parse the output from the model. This is a simple parser that extracts the `content` field from an `AIMessageChunk`, giving us the `token` returned by the model.\\n\",\n+    \"We will use [`StrOutputParser`](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) to parse the output from the model. This is a simple parser that extracts the `content` field from an `AIMessageChunk`, giving us the `token` returned by the model.\\n\",\n     \"\\n\",\n     \":::{.callout-tip}\\n\",\n     \"LCEL is a *declarative* way to specify a \\\"program\\\" by chainining together different LangChain primitives. Chains created using LCEL benefit from an automatic implementation of `stream` and `astream` allowing streaming of the final output. In fact, chains created with LCEL implement the entire standard Runnable interface.\\n\","
        },
        {
          "filename": "docs/docs/how_to/streaming_llm.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -7,7 +7,7 @@\n    \"source\": [\n     \"# How to stream responses from an LLM\\n\",\n     \"\\n\",\n-    \"All `LLM`s implement the [Runnable interface](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable), which comes with **default** implementations of standard runnable methods (i.e. `ainvoke`, `batch`, `abatch`, `stream`, `astream`, `astream_events`).\\n\",\n+    \"All `LLM`s implement the [Runnable interface](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable), which comes with **default** implementations of standard runnable methods (i.e. `ainvoke`, `batch`, `abatch`, `stream`, `astream`, `astream_events`).\\n\",\n     \"\\n\",\n     \"The **default** streaming implementations provide an`Iterator` (or `AsyncIterator` for asynchronous streaming) that yields a single value: the final output from the underlying chat model provider.\\n\",\n     \"\\n\",\n@@ -112,7 +112,7 @@\n     \"## Async event streaming\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"LLMs also support the standard [astream events](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) method.\\n\",\n+    \"LLMs also support the standard [astream events](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) method.\\n\",\n     \"\\n\",\n     \":::{.callout-tip}\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/structured_output.ipynb",
          "status": "modified",
          "additions": 16,
          "deletions": 16,
          "patch": "@@ -101,7 +101,7 @@\n    \"source\": [\n     \"from typing import Optional\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"# Pydantic\\n\",\n@@ -257,17 +257,17 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 19,\n    \"id\": \"9194bcf2\",\n    \"metadata\": {},\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Response(output=Joke(setup='Why was the cat sitting on the computer?', punchline='To keep an eye on the mouse!', rating=8))\"\n+       \"FinalResponse(final_output=Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=7))\"\n       ]\n      },\n-     \"execution_count\": 4,\n+     \"execution_count\": 19,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -293,28 +293,28 @@\n     \"    response: str = Field(description=\\\"A conversational response to the user's query\\\")\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"class Response(BaseModel):\\n\",\n-    \"    output: Union[Joke, ConversationalResponse]\\n\",\n+    \"class FinalResponse(BaseModel):\\n\",\n+    \"    final_output: Union[Joke, ConversationalResponse]\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"structured_llm = llm.with_structured_output(Response)\\n\",\n+    \"structured_llm = llm.with_structured_output(FinalResponse)\\n\",\n     \"\\n\",\n     \"structured_llm.invoke(\\\"Tell me a joke about cats\\\")\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 20,\n    \"id\": \"84d86132\",\n    \"metadata\": {},\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Response(output=ConversationalResponse(response=\\\"I'm just a digital assistant, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\\\"))\"\n+       \"FinalResponse(final_output=ConversationalResponse(response=\\\"I'm just a bunch of code, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\\\"))\"\n       ]\n      },\n-     \"execution_count\": 5,\n+     \"execution_count\": 20,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -574,7 +574,7 @@\n     \"\\n\",\n     \"If using JSON mode you'll have to still specify the desired schema in the model prompt. The schema you pass to `with_structured_output` will only be used for parsing the model outputs, it will not be passed to the model the way it is with tool calling.\\n\",\n     \"\\n\",\n-    \"To see if the model you're using supports JSON mode, check its entry in the [API reference](https://python.langchain.com/v0.2/api_reference/langchain/index.html).\\n\",\n+    \"To see if the model you're using supports JSON mode, check its entry in the [API reference](https://python.langchain.com/api_reference/langchain/index.html).\\n\",\n     \"\\n\",\n     \":::\"\n    ]\n@@ -653,7 +653,7 @@\n     \"\\n\",\n     \"### Using `PydanticOutputParser`\\n\",\n     \"\\n\",\n-    \"The following example uses the built-in [`PydanticOutputParser`](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html) to parse the output of a chat model prompted to match the given Pydantic schema. Note that we are adding `format_instructions` directly to the prompt from a method on the parser:\"\n+    \"The following example uses the built-in [`PydanticOutputParser`](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html) to parse the output of a chat model prompted to match the given Pydantic schema. Note that we are adding `format_instructions` directly to the prompt from a method on the parser:\"\n    ]\n   },\n   {\n@@ -667,7 +667,7 @@\n     \"\\n\",\n     \"from langchain_core.output_parsers import PydanticOutputParser\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Person(BaseModel):\\n\",\n@@ -794,7 +794,7 @@\n     \"\\n\",\n     \"from langchain_core.messages import AIMessage\\n\",\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Person(BaseModel):\\n\",\n@@ -915,9 +915,9 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"poetry-venv-2\",\n    \"language\": \"python\",\n-   \"name\": \"python3\"\n+   \"name\": \"poetry-venv-2\"\n   },\n   \"language_info\": {\n    \"codemirror_mode\": {"
        },
        {
          "filename": "docs/docs/how_to/summarize_map_reduce.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -72,7 +72,7 @@\n    \"source\": [\n     \"## Load documents\\n\",\n     \"\\n\",\n-    \"First we load in our documents. We will use [WebBaseLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) to load a blog post, and split the documents into smaller sub-documents.\"\n+    \"First we load in our documents. We will use [WebBaseLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) to load a blog post, and split the documents into smaller sub-documents.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/summarize_stuff.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -20,7 +20,7 @@\n     \"\\n\",\n     \"LLMs can summarize and otherwise distill desired information from text, including large volumes of text. In many cases, especially for models with larger context windows, this can be adequately achieved via a single LLM call.\\n\",\n     \"\\n\",\n-    \"LangChain implements a simple [pre-built chain](https://python.langchain.com/v0.2/api_reference/langchain/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) that \\\"stuffs\\\" a prompt with the desired context for summarization and other purposes. In this guide we demonstrate how to use the chain.\"\n+    \"LangChain implements a simple [pre-built chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html) that \\\"stuffs\\\" a prompt with the desired context for summarization and other purposes. In this guide we demonstrate how to use the chain.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/tool_artifacts.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -18,7 +18,7 @@\n     \"\\n\",\n     \"Tools are utilities that can be called by a model, and whose outputs are designed to be fed back to a model. Sometimes, however, there are artifacts of a tool's execution that we want to make accessible to downstream components in our chain or agent, but that we don't want to expose to the model itself. For example if a tool returns a custom object, a dataframe or an image, we may want to pass some metadata about this output to the model without passing the actual output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.\\n\",\n     \"\\n\",\n-    \"The Tool and [ToolMessage](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) interfaces make it possible to distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact).\\n\",\n+    \"The Tool and [ToolMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolMessage.html) interfaces make it possible to distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact).\\n\",\n     \"\\n\",\n     \":::info Requires ``langchain-core >= 0.2.19``\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/tool_calling.ipynb",
          "status": "modified",
          "additions": 62,
          "deletions": 19,
          "patch": "@@ -55,7 +55,7 @@\n    \"source\": [\n     \"## Defining tool schemas\\n\",\n     \"\\n\",\n-    \"For a model to be able to call tools, we need to pass in tool schemas that describe what the tool does and what it's arguments are. Chat models that support tool calling features implement a `.bind_tools()` method for passing tool schemas to the model. Tool schemas can be passed in as Python functions (with typehints and docstrings), Pydantic models, TypedDict classes, or LangChain [Tool objects](https://python.langchain.com/v0.2/api_reference/core/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool). Subsequent invocations of the model will pass in these tool schemas along with the prompt.\\n\",\n+    \"For a model to be able to call tools, we need to pass in tool schemas that describe what the tool does and what it's arguments are. Chat models that support tool calling features implement a `.bind_tools()` method for passing tool schemas to the model. Tool schemas can be passed in as Python functions (with typehints and docstrings), Pydantic models, TypedDict classes, or LangChain [Tool objects](https://python.langchain.com/api_reference/core/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool). Subsequent invocations of the model will pass in these tool schemas along with the prompt.\\n\",\n     \"\\n\",\n     \"### Python functions\\n\",\n     \"Our tool schemas can be Python functions:\"\n@@ -64,7 +64,14 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:43:40.609832Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:43:40.609565Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:43:40.617860Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:43:40.617391Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# The function name, type hints, and docstring are all part of the tool\\n\",\n@@ -109,10 +116,17 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 2,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:43:40.620257Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:43:40.620084Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:43:40.689214Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:43:40.688938Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class add(BaseModel):\\n\",\n@@ -144,7 +158,14 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 3,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:43:40.690850Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:43:40.690739Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:43:40.693436Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:43:40.693199Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing_extensions import Annotated, TypedDict\\n\",\n@@ -201,20 +222,28 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n     \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 5,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:43:42.447839Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:43:42.447760Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:43:43.181171Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:43:43.180680Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BwYJ4UgU5pRVCBOUmiu7NhF9', 'function': {'arguments': '{\\\"a\\\":3,\\\"b\\\":12}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_ba606877f9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7f05e19e-4561-40e2-a2d0-8f4e28e9a00f-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BwYJ4UgU5pRVCBOUmiu7NhF9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97})\"\n+       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_iXj4DiW1p7WLjTAQMRO0jxMs', 'function': {'arguments': '{\\\"a\\\":3,\\\"b\\\":12}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 80, 'total_tokens': 97}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0b620986-3f62-4df7-9ba3-4595089f9ad4-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_iXj4DiW1p7WLjTAQMRO0jxMs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 80, 'output_tokens': 17, 'total_tokens': 97})\"\n       ]\n      },\n      \"execution_count\": 5,\n@@ -234,7 +263,7 @@\n    \"cell_type\": \"markdown\",\n    \"metadata\": {},\n    \"source\": [\n-    \"As we can see our LLM generated arguments to a tool! You can look at the docs for [bind_tools()](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.BaseChatOpenAI.html#langchain_openai.chat_models.base.BaseChatOpenAI.bind_tools) to learn about all the ways to customize how your LLM selects tools, as well as [this guide on how to force the LLM to call a tool](/docs/how_to/tool_choice/) rather than letting it decide.\"\n+    \"As we can see our LLM generated arguments to a tool! You can look at the docs for [bind_tools()](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.BaseChatOpenAI.html#langchain_openai.chat_models.base.BaseChatOpenAI.bind_tools) to learn about all the ways to customize how your LLM selects tools, as well as [this guide on how to force the LLM to call a tool](/docs/how_to/tool_choice/) rather than letting it decide.\"\n    ]\n   },\n   {\n@@ -244,9 +273,9 @@\n     \"## Tool calls\\n\",\n     \"\\n\",\n     \"If tool calls are included in a LLM response, they are attached to the corresponding \\n\",\n-    \"[message](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage) \\n\",\n-    \"or [message chunk](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n-    \"as a list of [tool call](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.ToolCall.html#langchain_core.messages.tool.ToolCall) \\n\",\n+    \"[message](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage) \\n\",\n+    \"or [message chunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n+    \"as a list of [tool call](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolCall.html#langchain_core.messages.tool.ToolCall) \\n\",\n     \"objects in the `.tool_calls` attribute.\\n\",\n     \"\\n\",\n     \"Note that chat models can call multiple tools at once.\\n\",\n@@ -259,18 +288,25 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 6,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:43:43.184004Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:43:43.183777Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:43:43.743024Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:43:43.742171Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[{'name': 'multiply',\\n\",\n        \"  'args': {'a': 3, 'b': 12},\\n\",\n-       \"  'id': 'call_rcdMie7E89Xx06lEKKxJyB5N',\\n\",\n+       \"  'id': 'call_1fyhJAbJHuKQe6n0PacubGsL',\\n\",\n        \"  'type': 'tool_call'},\\n\",\n        \" {'name': 'add',\\n\",\n        \"  'args': {'a': 11, 'b': 49},\\n\",\n-       \"  'id': 'call_nheGN8yfvSJsnIuGZaXihou3',\\n\",\n+       \"  'id': 'call_fc2jVkKzwuPWyU7kS9qn1hyG',\\n\",\n        \"  'type': 'tool_call'}]\"\n       ]\n      },\n@@ -292,21 +328,28 @@\n     \"The `.tool_calls` attribute should contain valid tool calls. Note that on occasion, \\n\",\n     \"model providers may output malformed tool calls (e.g., arguments that are not \\n\",\n     \"valid JSON). When parsing fails in these cases, instances \\n\",\n-    \"of [InvalidToolCall](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.InvalidToolCall.html#langchain_core.messages.tool.InvalidToolCall) \\n\",\n+    \"of [InvalidToolCall](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.InvalidToolCall.html#langchain_core.messages.tool.InvalidToolCall) \\n\",\n     \"are populated in the `.invalid_tool_calls` attribute. An `InvalidToolCall` can have \\n\",\n     \"a name, string arguments, identifier, and error message.\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Parsing\\n\",\n     \"\\n\",\n     \"If desired, [output parsers](/docs/how_to#output-parsers) can further process the output. For example, we can convert existing values populated on the `.tool_calls` to Pydantic objects using the\\n\",\n-    \"[PydanticToolsParser](https://python.langchain.com/v0.2/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html):\"\n+    \"[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html):\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 7,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:43:43.746273Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:43:43.746020Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:43:44.586236Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:43:44.585619Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n@@ -321,7 +364,7 @@\n    ],\n    \"source\": [\n     \"from langchain_core.output_parsers import PydanticToolsParser\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class add(BaseModel):\\n\","
        },
        {
          "filename": "docs/docs/how_to/tool_calling_parallel.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -57,9 +57,10 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/how_to/tool_choice.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 4,
          "patch": "@@ -57,9 +57,10 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -77,7 +78,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9cViskmLvPnHjXk9tbVla5HA', 'function': {'arguments': '{\\\"a\\\":2,\\\"b\\\":4}', 'name': 'Multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 103, 'total_tokens': 112}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-095b827e-2bdd-43bb-8897-c843f4504883-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 2, 'b': 4}, 'id': 'call_9cViskmLvPnHjXk9tbVla5HA'}], usage_metadata={'input_tokens': 103, 'output_tokens': 9, 'total_tokens': 112})\"\n+       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9cViskmLvPnHjXk9tbVla5HA', 'function': {'arguments': '{\\\"a\\\":2,\\\"b\\\":4}', 'name': 'Multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 103, 'total_tokens': 112}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-095b827e-2bdd-43bb-8897-c843f4504883-0', tool_calls=[{'name': 'Multiply', 'args': {'a': 2, 'b': 4}, 'id': 'call_9cViskmLvPnHjXk9tbVla5HA'}], usage_metadata={'input_tokens': 103, 'output_tokens': 9, 'total_tokens': 112})\"\n       ]\n      },\n      \"metadata\": {},\n@@ -111,7 +112,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mCSiJntCwHJUBfaHZVUB2D8W', 'function': {'arguments': '{\\\"a\\\":1,\\\"b\\\":2}', 'name': 'Add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 94, 'total_tokens': 109}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-28f75260-9900-4bed-8cd3-f1579abb65e5-0', tool_calls=[{'name': 'Add', 'args': {'a': 1, 'b': 2}, 'id': 'call_mCSiJntCwHJUBfaHZVUB2D8W'}], usage_metadata={'input_tokens': 94, 'output_tokens': 15, 'total_tokens': 109})\"\n+       \"AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mCSiJntCwHJUBfaHZVUB2D8W', 'function': {'arguments': '{\\\"a\\\":1,\\\"b\\\":2}', 'name': 'Add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 94, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-28f75260-9900-4bed-8cd3-f1579abb65e5-0', tool_calls=[{'name': 'Add', 'args': {'a': 1, 'b': 2}, 'id': 'call_mCSiJntCwHJUBfaHZVUB2D8W'}], usage_metadata={'input_tokens': 94, 'output_tokens': 15, 'total_tokens': 109})\"\n       ]\n      },\n      \"metadata\": {},"
        },
        {
          "filename": "docs/docs/how_to/tool_configure.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -19,7 +19,7 @@\n     \"\\n\",\n     \"If you have a tool  that call chat models, retrievers, or other runnables, you may want to access internal events from those runnables or configure them with additional properties. This guide shows you how to manually pass parameters properly so that you can do this using the `astream_events()` method.\\n\",\n     \"\\n\",\n-    \"Tools are runnables, and you can treat them the same way as any other runnable at the interface level - you can call `invoke()`, `batch()`, and `stream()` on them as normal. However, when writing custom tools, you may want to invoke other runnables like chat models or retrievers. In order to properly trace and configure those sub-invocations, you'll need to manually access and pass in the tool's current [`RunnableConfig`](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html) object. This guide show you some examples of how to do that.\\n\",\n+    \"Tools are runnables, and you can treat them the same way as any other runnable at the interface level - you can call `invoke()`, `batch()`, and `stream()` on them as normal. However, when writing custom tools, you may want to invoke other runnables like chat models or retrievers. In order to properly trace and configure those sub-invocations, you'll need to manually access and pass in the tool's current [`RunnableConfig`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.config.RunnableConfig.html) object. This guide show you some examples of how to do that.\\n\",\n     \"\\n\",\n     \":::caution Compatibility\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/tool_results_pass_to_model.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -53,7 +53,8 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n     \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/tool_runtime.ipynb",
          "status": "modified",
          "additions": 204,
          "deletions": 99,
          "patch": "@@ -55,13 +55,20 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 1,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:51.802901Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:51.802682Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:52.398167Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:52.397911Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# | output: false\\n\",\n     \"# | echo: false\\n\",\n     \"\\n\",\n-    \"# %pip install -qU langchain langchain_openai\\n\",\n+    \"%pip install -qU langchain langchain_openai\\n\",\n     \"\\n\",\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n@@ -71,7 +78,7 @@\n     \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n     \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -86,7 +93,14 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 2,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:52.399922Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:52.399796Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:52.406349Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:52.406077Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from typing import List\\n\",\n@@ -141,22 +155,29 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 3,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:52.407763Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:52.407691Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:52.411761Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:52.411512Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'update_favorite_petsSchema',\\n\",\n-       \" 'description': 'Add the list of favorite pets.',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'description': 'List of favorite pets to set.',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}},\\n\",\n-       \"  'user_id': {'title': 'User Id',\\n\",\n-       \"   'description': \\\"User's ID.\\\",\\n\",\n+       \"{'description': 'Add the list of favorite pets.',\\n\",\n+       \" 'properties': {'pets': {'description': 'List of favorite pets to set.',\\n\",\n+       \"   'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'},\\n\",\n+       \"  'user_id': {'description': \\\"User's ID.\\\",\\n\",\n+       \"   'title': 'User Id',\\n\",\n        \"   'type': 'string'}},\\n\",\n-       \" 'required': ['pets', 'user_id']}\"\n+       \" 'required': ['pets', 'user_id'],\\n\",\n+       \" 'title': 'update_favorite_petsSchema',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n      \"execution_count\": 3,\n@@ -178,19 +199,26 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 4,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:52.427826Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:52.427691Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:52.431791Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:52.431574Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'update_favorite_pets',\\n\",\n-       \" 'description': 'Add the list of favorite pets.',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'description': 'List of favorite pets to set.',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}}},\\n\",\n-       \" 'required': ['pets']}\"\n+       \"{'description': 'Add the list of favorite pets.',\\n\",\n+       \" 'properties': {'pets': {'description': 'List of favorite pets to set.',\\n\",\n+       \"   'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'}},\\n\",\n+       \" 'required': ['pets'],\\n\",\n+       \" 'title': 'update_favorite_pets',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n      \"execution_count\": 4,\n@@ -212,7 +240,14 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 5,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:52.433096Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:52.433014Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:52.437499Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:52.437239Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -240,14 +275,21 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 6,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:52.439148Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:52.438742Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:53.394524Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:53.394005Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[{'name': 'update_favorite_pets',\\n\",\n        \"  'args': {'pets': ['cats', 'parrots']},\\n\",\n-       \"  'id': 'call_W3cn4lZmJlyk8PCrKN4PRwqB',\\n\",\n+       \"  'id': 'call_pZ6XVREGh1L0BBSsiGIf1xVm',\\n\",\n        \"  'type': 'tool_call'}]\"\n       ]\n      },\n@@ -284,14 +326,21 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 7,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:53.397134Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:53.396972Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:53.403332Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:53.402787Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"[{'name': 'update_favorite_pets',\\n\",\n        \"  'args': {'pets': ['cats', 'parrots'], 'user_id': '123'},\\n\",\n-       \"  'id': 'call_W3cn4lZmJlyk8PCrKN4PRwqB',\\n\",\n+       \"  'id': 'call_pZ6XVREGh1L0BBSsiGIf1xVm',\\n\",\n        \"  'type': 'tool_call'}]\"\n       ]\n      },\n@@ -329,12 +378,19 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 8,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:53.405183Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:53.405048Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.248576Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.248107Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"[ToolMessage(content='null', name='update_favorite_pets', tool_call_id='call_HUyF6AihqANzEYxQnTUKxkXj')]\"\n+       \"[ToolMessage(content='null', name='update_favorite_pets', tool_call_id='call_oYCD0THSedHTbwNAY3NW6uUj')]\"\n       ]\n      },\n      \"execution_count\": 8,\n@@ -365,7 +421,14 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 9,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:54.251169Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:54.250948Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.254279Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.253889Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n@@ -394,22 +457,29 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 10,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:54.256425Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:54.256279Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.262533Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.262228Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'UpdateFavoritePetsSchema',\\n\",\n-       \" 'description': 'Update list of favorite pets',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'description': 'List of favorite pets to set.',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}},\\n\",\n-       \"  'user_id': {'title': 'User Id',\\n\",\n-       \"   'description': \\\"User's ID.\\\",\\n\",\n+       \"{'description': 'Update list of favorite pets',\\n\",\n+       \" 'properties': {'pets': {'description': 'List of favorite pets to set.',\\n\",\n+       \"   'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'},\\n\",\n+       \"  'user_id': {'description': \\\"User's ID.\\\",\\n\",\n+       \"   'title': 'User Id',\\n\",\n        \"   'type': 'string'}},\\n\",\n-       \" 'required': ['pets', 'user_id']}\"\n+       \" 'required': ['pets', 'user_id'],\\n\",\n+       \" 'title': 'UpdateFavoritePetsSchema',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n      \"execution_count\": 10,\n@@ -418,8 +488,8 @@\n     }\n    ],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_core.tools import BaseTool\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class UpdateFavoritePetsSchema(BaseModel):\\n\",\n@@ -440,19 +510,26 @@\n   {\n    \"cell_type\": \"code\",\n    \"execution_count\": 11,\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:54.264192Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:54.264074Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.267400Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.267113Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'update_favorite_pets',\\n\",\n-       \" 'description': 'Update list of favorite pets',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'description': 'List of favorite pets to set.',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}}},\\n\",\n-       \" 'required': ['pets']}\"\n+       \"{'description': 'Update list of favorite pets',\\n\",\n+       \" 'properties': {'pets': {'description': 'List of favorite pets to set.',\\n\",\n+       \"   'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'}},\\n\",\n+       \" 'required': ['pets'],\\n\",\n+       \" 'title': 'update_favorite_pets',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n      \"execution_count\": 11,\n@@ -466,26 +543,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 22,\n-   \"metadata\": {},\n+   \"execution_count\": 12,\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:54.269027Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:54.268905Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.276123Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.275876Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'UpdateFavoritePetsSchema',\\n\",\n-       \" 'description': 'Update list of favorite pets',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'description': 'List of favorite pets to set.',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}},\\n\",\n-       \"  'user_id': {'title': 'User Id',\\n\",\n-       \"   'description': \\\"User's ID.\\\",\\n\",\n+       \"{'description': 'Update list of favorite pets',\\n\",\n+       \" 'properties': {'pets': {'description': 'List of favorite pets to set.',\\n\",\n+       \"   'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'},\\n\",\n+       \"  'user_id': {'description': \\\"User's ID.\\\",\\n\",\n+       \"   'title': 'User Id',\\n\",\n        \"   'type': 'string'}},\\n\",\n-       \" 'required': ['pets', 'user_id']}\"\n+       \" 'required': ['pets', 'user_id'],\\n\",\n+       \" 'title': 'UpdateFavoritePetsSchema',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n-     \"execution_count\": 22,\n+     \"execution_count\": 12,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -508,23 +592,30 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 23,\n-   \"metadata\": {},\n+   \"execution_count\": 13,\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:54.277497Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:54.277400Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.280323Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.280072Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'update_favorite_pets',\\n\",\n-       \" 'description': 'Update list of favorite pets',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'description': 'List of favorite pets to set.',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}}},\\n\",\n-       \" 'required': ['pets']}\"\n+       \"{'description': 'Update list of favorite pets',\\n\",\n+       \" 'properties': {'pets': {'description': 'List of favorite pets to set.',\\n\",\n+       \"   'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'}},\\n\",\n+       \" 'required': ['pets'],\\n\",\n+       \" 'title': 'update_favorite_pets',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n-     \"execution_count\": 23,\n+     \"execution_count\": 13,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -535,23 +626,30 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 24,\n-   \"metadata\": {},\n+   \"execution_count\": 14,\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:54.281741Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:54.281642Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.288857Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.288632Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'update_favorite_petsSchema',\\n\",\n-       \" 'description': 'Use the tool.\\\\n\\\\nAdd run_manager: Optional[CallbackManagerForToolRun] = None\\\\nto child implementations to enable tracing.',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}},\\n\",\n+       \"{'description': 'Use the tool.\\\\n\\\\nAdd run_manager: Optional[CallbackManagerForToolRun] = None\\\\nto child implementations to enable tracing.',\\n\",\n+       \" 'properties': {'pets': {'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'},\\n\",\n        \"  'user_id': {'title': 'User Id', 'type': 'string'}},\\n\",\n-       \" 'required': ['pets', 'user_id']}\"\n+       \" 'required': ['pets', 'user_id'],\\n\",\n+       \" 'title': 'update_favorite_petsSchema',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n-     \"execution_count\": 24,\n+     \"execution_count\": 14,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -570,22 +668,29 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 26,\n-   \"metadata\": {},\n+   \"execution_count\": 15,\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T02:52:54.290237Z\",\n+     \"iopub.status.busy\": \"2024-09-11T02:52:54.290145Z\",\n+     \"iopub.status.idle\": \"2024-09-11T02:52:54.294273Z\",\n+     \"shell.execute_reply\": \"2024-09-11T02:52:54.294053Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"{'title': 'update_favorite_pets',\\n\",\n-       \" 'description': 'Update list of favorite pets',\\n\",\n-       \" 'type': 'object',\\n\",\n-       \" 'properties': {'pets': {'title': 'Pets',\\n\",\n-       \"   'type': 'array',\\n\",\n-       \"   'items': {'type': 'string'}}},\\n\",\n-       \" 'required': ['pets']}\"\n+       \"{'description': 'Update list of favorite pets',\\n\",\n+       \" 'properties': {'pets': {'items': {'type': 'string'},\\n\",\n+       \"   'title': 'Pets',\\n\",\n+       \"   'type': 'array'}},\\n\",\n+       \" 'required': ['pets'],\\n\",\n+       \" 'title': 'update_favorite_pets',\\n\",\n+       \" 'type': 'object'}\"\n       ]\n      },\n-     \"execution_count\": 26,\n+     \"execution_count\": 15,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -597,7 +702,7 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3\",\n+   \"display_name\": \"Python 3 (ipykernel)\",\n    \"language\": \"python\",\n    \"name\": \"python3\"\n   },\n@@ -611,7 +716,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.5\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/tool_streaming.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 5,
          "patch": "@@ -7,16 +7,16 @@\n     \"# How to stream tool calls\\n\",\n     \"\\n\",\n     \"When tools are called in a streaming context, \\n\",\n-    \"[message chunks](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n-    \"will be populated with [tool call chunk](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.tool.ToolCallChunk.html#langchain_core.messages.tool.ToolCallChunk) \\n\",\n+    \"[message chunks](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n+    \"will be populated with [tool call chunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.tool.ToolCallChunk.html#langchain_core.messages.tool.ToolCallChunk) \\n\",\n     \"objects in a list via the `.tool_call_chunks` attribute. A `ToolCallChunk` includes \\n\",\n     \"optional string fields for the tool `name`, `args`, and `id`, and includes an optional \\n\",\n     \"integer field `index` that can be used to join chunks together. Fields are optional \\n\",\n     \"because portions of a tool call may be streamed across different chunks (e.g., a chunk \\n\",\n     \"that includes a substring of the arguments may have null values for the tool name and id).\\n\",\n     \"\\n\",\n     \"Because message chunks inherit from their parent message class, an \\n\",\n-    \"[AIMessageChunk](https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n+    \"[AIMessageChunk](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html#langchain_core.messages.ai.AIMessageChunk) \\n\",\n     \"with tool call chunks will also include `.tool_calls` and `.invalid_tool_calls` fields. \\n\",\n     \"These fields are parsed best-effort from the message's tool call chunks.\\n\",\n     \"\\n\",\n@@ -58,9 +58,10 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"llm_with_tools = llm.bind_tools(tools)\"\n    ]\n   },"
        },
        {
          "filename": "docs/docs/how_to/tools_builtin.ipynb",
          "status": "modified",
          "additions": 55,
          "deletions": 20,
          "patch": "@@ -36,7 +36,7 @@\n     \"\\n\",\n     \"When using 3rd party tools, make sure that you understand how the tool works, what permissions\\n\",\n     \"it has. Read over its documentation and check if anything is required from you\\n\",\n-    \"from a security point of view. Please see our [security](https://python.langchain.com/v0.2/docs/security/) \\n\",\n+    \"from a security point of view. Please see our [security](https://python.langchain.com/docs/security/) \\n\",\n     \"guidelines for more information.\\n\",\n     \"\\n\",\n     \":::\\n\",\n@@ -46,19 +46,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": null,\n+   \"execution_count\": 1,\n    \"id\": \"84f70856-b865-4658-9930-7577fb4712ce\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:01:11.847104Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:01:11.846727Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:01:13.200038Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:01:13.199355Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n-    \"!pip install -qU wikipedia\"\n+    \"!pip install -qU langchain-community wikipedia\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 51,\n+   \"execution_count\": 2,\n    \"id\": \"b4eaed85-c5a6-4ba9-b401-40258b0131c2\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:01:13.203356Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:01:13.202996Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:01:14.740686Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:01:14.739748Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -89,18 +103,25 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 55,\n+   \"execution_count\": 3,\n    \"id\": \"7f094f01-2e98-4947-acc4-0846963a96e0\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:01:14.745018Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:01:14.744347Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:01:14.752527Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:01:14.752112Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n-      \"Name: wiki-tool\\n\",\n-      \"Description: look up things in wikipedia\\n\",\n-      \"args schema: {'query': {'title': 'Query', 'description': 'query to look up in Wikipedia, should be 3 or less words', 'type': 'string'}}\\n\",\n-      \"returns directly?: True\\n\"\n+      \"Name: wikipedia\\n\",\n+      \"Description: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\",\n+      \"args schema: {'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\\n\",\n+      \"returns directly?: False\\n\"\n      ]\n     }\n    ],\n@@ -124,9 +145,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 56,\n+   \"execution_count\": 4,\n    \"id\": \"1365784c-e666-41c8-a1bb-e50f822b5936\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:01:14.755274Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:01:14.755068Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:01:15.375704Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:01:15.374841Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -140,7 +168,7 @@\n    \"source\": [\n     \"from langchain_community.tools import WikipediaQueryRun\\n\",\n     \"from langchain_community.utilities import WikipediaAPIWrapper\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class WikiInputs(BaseModel):\\n\",\n@@ -164,17 +192,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 57,\n+   \"execution_count\": 5,\n    \"id\": \"6e8850d6-6840-443e-a2be-adf64b30975c\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:01:15.378598Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:01:15.378414Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:01:15.382248Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:01:15.381801Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n      \"output_type\": \"stream\",\n      \"text\": [\n       \"Name: wiki-tool\\n\",\n       \"Description: look up things in wikipedia\\n\",\n-      \"args schema: {'query': {'title': 'Query', 'description': 'query to look up in Wikipedia, should be 3 or less words', 'type': 'string'}}\\n\",\n+      \"args schema: {'query': {'description': 'query to look up in Wikipedia, should be 3 or less words', 'title': 'Query', 'type': 'string'}}\\n\",\n       \"returns directly?: True\\n\"\n      ]\n     }\n@@ -212,9 +247,9 @@\n  ],\n  \"metadata\": {\n   \"kernelspec\": {\n-   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"display_name\": \"poetry-venv-311\",\n    \"language\": \"python\",\n-   \"name\": \"python3\"\n+   \"name\": \"poetry-venv-311\"\n   },\n   \"language_info\": {\n    \"codemirror_mode\": {"
        },
        {
          "filename": "docs/docs/how_to/tools_chain.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -166,7 +166,7 @@\n     \"\\n\",\n     \"from langchain_openai.chat_models import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -280,7 +280,7 @@\n     \"\\n\",\n     \"LangChain comes with a number of built-in agents that are optimized for different use cases. Read about all the [agent types here](/docs/concepts#agents).\\n\",\n     \"\\n\",\n-    \"We'll use the [tool calling agent](https://python.langchain.com/v0.2/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html), which is generally the most reliable kind and the recommended one for most use cases.\\n\",\n+    \"We'll use the [tool calling agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html), which is generally the most reliable kind and the recommended one for most use cases.\\n\",\n     \"\\n\",\n     \"![agent](../../static/img/tool_agent.svg)\"\n    ]"
        },
        {
          "filename": "docs/docs/how_to/tools_error.ipynb",
          "status": "modified",
          "additions": 90,
          "deletions": 32,
          "patch": "@@ -53,7 +53,14 @@\n    \"cell_type\": \"code\",\n    \"execution_count\": 2,\n    \"id\": \"08785b6d-722d-4620-b6ec-36deb3842c69\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:25.005243Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:25.005074Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:25.007679Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:25.007361Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"import getpass\\n\",\n@@ -81,26 +88,41 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 4,\n+   \"execution_count\": 3,\n    \"id\": \"86258950-5e61-4340-81b9-84a5d26e8773\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:25.009496Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:25.009371Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:25.552917Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:25.552592Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# | echo: false\\n\",\n     \"# | output: false\\n\",\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass()\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 5,\n+   \"execution_count\": 4,\n    \"id\": \"1d20604e-c4d1-4d21-841b-23e4f61aec36\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:25.554543Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:25.554439Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:25.631610Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:25.631346Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"# Define tool\\n\",\n@@ -131,26 +153,33 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 6,\n+   \"execution_count\": 5,\n    \"id\": \"d354664c-ac44-4967-a35f-8912b3ad9477\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:25.633050Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:25.632978Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:26.556508Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:26.556233Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"ename\": \"ValidationError\",\n-     \"evalue\": \"1 validation error for complex_toolSchema\\ndict_arg\\n  field required (type=value_error.missing)\",\n+     \"evalue\": \"1 validation error for complex_toolSchema\\ndict_arg\\n  Field required [type=missing, input_value={'int_arg': 5, 'float_arg': 2.1}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\",\n      \"output_type\": \"error\",\n      \"traceback\": [\n       \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n       \"\\u001b[0;31mValidationError\\u001b[0m                           Traceback (most recent call last)\",\n-      \"Cell \\u001b[0;32mIn[6], line 1\\u001b[0m\\n\\u001b[0;32m----> 1\\u001b[0m \\u001b[43mchain\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43minvoke\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m      2\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43muse complex tool. the args are 5, 2.1, empty dictionary. don\\u001b[39;49m\\u001b[38;5;124;43m'\\u001b[39;49m\\u001b[38;5;124;43mt forget dict_arg\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\n\\u001b[1;32m      3\\u001b[0m \\u001b[43m)\\u001b[49m\\n\",\n-      \"File \\u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/langchain_core/runnables/base.py:2572\\u001b[0m, in \\u001b[0;36mRunnableSequence.invoke\\u001b[0;34m(self, input, config, **kwargs)\\u001b[0m\\n\\u001b[1;32m   2570\\u001b[0m             \\u001b[38;5;28minput\\u001b[39m \\u001b[38;5;241m=\\u001b[39m step\\u001b[38;5;241m.\\u001b[39minvoke(\\u001b[38;5;28minput\\u001b[39m, config, \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mkwargs)\\n\\u001b[1;32m   2571\\u001b[0m         \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[0;32m-> 2572\\u001b[0m             \\u001b[38;5;28minput\\u001b[39m \\u001b[38;5;241m=\\u001b[39m \\u001b[43mstep\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43minvoke\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;28;43minput\\u001b[39;49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mconfig\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m   2573\\u001b[0m \\u001b[38;5;66;03m# finish the root run\\u001b[39;00m\\n\\u001b[1;32m   2574\\u001b[0m \\u001b[38;5;28;01mexcept\\u001b[39;00m \\u001b[38;5;167;01mBaseException\\u001b[39;00m \\u001b[38;5;28;01mas\\u001b[39;00m e:\\n\",\n-      \"File \\u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/langchain_core/tools.py:380\\u001b[0m, in \\u001b[0;36mBaseTool.invoke\\u001b[0;34m(self, input, config, **kwargs)\\u001b[0m\\n\\u001b[1;32m    373\\u001b[0m \\u001b[38;5;28;01mdef\\u001b[39;00m \\u001b[38;5;21minvoke\\u001b[39m(\\n\\u001b[1;32m    374\\u001b[0m     \\u001b[38;5;28mself\\u001b[39m,\\n\\u001b[1;32m    375\\u001b[0m     \\u001b[38;5;28minput\\u001b[39m: Union[\\u001b[38;5;28mstr\\u001b[39m, Dict],\\n\\u001b[1;32m    376\\u001b[0m     config: Optional[RunnableConfig] \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mNone\\u001b[39;00m,\\n\\u001b[1;32m    377\\u001b[0m     \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mkwargs: Any,\\n\\u001b[1;32m    378\\u001b[0m ) \\u001b[38;5;241m-\\u001b[39m\\u001b[38;5;241m>\\u001b[39m Any:\\n\\u001b[1;32m    379\\u001b[0m     config \\u001b[38;5;241m=\\u001b[39m ensure_config(config)\\n\\u001b[0;32m--> 380\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mrun\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m    381\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[38;5;28;43minput\\u001b[39;49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    382\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mcallbacks\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconfig\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mget\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mcallbacks\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m)\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    383\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mtags\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconfig\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mget\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mtags\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m)\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    384\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mmetadata\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconfig\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mget\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mmetadata\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m)\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    385\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mrun_name\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconfig\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mget\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mrun_name\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m)\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    386\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mrun_id\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconfig\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpop\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43mrun_id\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;28;43;01mNone\\u001b[39;49;00m\\u001b[43m)\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    387\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[43mconfig\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mconfig\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    388\\u001b[0m \\u001b[43m        \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m,\\u001b[49m\\n\\u001b[1;32m    389\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43m)\\u001b[49m\\n\",\n-      \"File \\u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/langchain_core/tools.py:537\\u001b[0m, in \\u001b[0;36mBaseTool.run\\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\\u001b[0m\\n\\u001b[1;32m    535\\u001b[0m \\u001b[38;5;28;01mexcept\\u001b[39;00m ValidationError \\u001b[38;5;28;01mas\\u001b[39;00m e:\\n\\u001b[1;32m    536\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mhandle_validation_error:\\n\\u001b[0;32m--> 537\\u001b[0m         \\u001b[38;5;28;01mraise\\u001b[39;00m e\\n\\u001b[1;32m    538\\u001b[0m     \\u001b[38;5;28;01melif\\u001b[39;00m \\u001b[38;5;28misinstance\\u001b[39m(\\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mhandle_validation_error, \\u001b[38;5;28mbool\\u001b[39m):\\n\\u001b[1;32m    539\\u001b[0m         observation \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mTool input validation error\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\n\",\n-      \"File \\u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/langchain_core/tools.py:526\\u001b[0m, in \\u001b[0;36mBaseTool.run\\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\\u001b[0m\\n\\u001b[1;32m    524\\u001b[0m context \\u001b[38;5;241m=\\u001b[39m copy_context()\\n\\u001b[1;32m    525\\u001b[0m context\\u001b[38;5;241m.\\u001b[39mrun(_set_config_context, child_config)\\n\\u001b[0;32m--> 526\\u001b[0m parsed_input \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m_parse_input\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mtool_input\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    527\\u001b[0m tool_args, tool_kwargs \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39m_to_args_and_kwargs(parsed_input)\\n\\u001b[1;32m    528\\u001b[0m observation \\u001b[38;5;241m=\\u001b[39m (\\n\\u001b[1;32m    529\\u001b[0m     context\\u001b[38;5;241m.\\u001b[39mrun(\\n\\u001b[1;32m    530\\u001b[0m         \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39m_run, \\u001b[38;5;241m*\\u001b[39mtool_args, run_manager\\u001b[38;5;241m=\\u001b[39mrun_manager, \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mtool_kwargs\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    533\\u001b[0m     \\u001b[38;5;28;01melse\\u001b[39;00m context\\u001b[38;5;241m.\\u001b[39mrun(\\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39m_run, \\u001b[38;5;241m*\\u001b[39mtool_args, \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mtool_kwargs)\\n\\u001b[1;32m    534\\u001b[0m )\\n\",\n-      \"File \\u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/langchain_core/tools.py:424\\u001b[0m, in \\u001b[0;36mBaseTool._parse_input\\u001b[0;34m(self, tool_input)\\u001b[0m\\n\\u001b[1;32m    422\\u001b[0m \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[1;32m    423\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m input_args \\u001b[38;5;129;01mis\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m \\u001b[38;5;28;01mNone\\u001b[39;00m:\\n\\u001b[0;32m--> 424\\u001b[0m         result \\u001b[38;5;241m=\\u001b[39m \\u001b[43minput_args\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mparse_obj\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mtool_input\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    425\\u001b[0m         \\u001b[38;5;28;01mreturn\\u001b[39;00m {\\n\\u001b[1;32m    426\\u001b[0m             k: \\u001b[38;5;28mgetattr\\u001b[39m(result, k)\\n\\u001b[1;32m    427\\u001b[0m             \\u001b[38;5;28;01mfor\\u001b[39;00m k, v \\u001b[38;5;129;01min\\u001b[39;00m result\\u001b[38;5;241m.\\u001b[39mdict()\\u001b[38;5;241m.\\u001b[39mitems()\\n\\u001b[1;32m    428\\u001b[0m             \\u001b[38;5;28;01mif\\u001b[39;00m k \\u001b[38;5;129;01min\\u001b[39;00m tool_input\\n\\u001b[1;32m    429\\u001b[0m         }\\n\\u001b[1;32m    430\\u001b[0m \\u001b[38;5;28;01mreturn\\u001b[39;00m tool_input\\n\",\n-      \"File \\u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/pydantic/main.py:526\\u001b[0m, in \\u001b[0;36mpydantic.main.BaseModel.parse_obj\\u001b[0;34m()\\u001b[0m\\n\",\n-      \"File \\u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/pydantic/main.py:341\\u001b[0m, in \\u001b[0;36mpydantic.main.BaseModel.__init__\\u001b[0;34m()\\u001b[0m\\n\",\n-      \"\\u001b[0;31mValidationError\\u001b[0m: 1 validation error for complex_toolSchema\\ndict_arg\\n  field required (type=value_error.missing)\"\n+      \"Cell \\u001b[0;32mIn[5], line 1\\u001b[0m\\n\\u001b[0;32m----> 1\\u001b[0m \\u001b[43mchain\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43minvoke\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m      2\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\u001b[38;5;124;43muse complex tool. the args are 5, 2.1, empty dictionary. don\\u001b[39;49m\\u001b[38;5;124;43m'\\u001b[39;49m\\u001b[38;5;124;43mt forget dict_arg\\u001b[39;49m\\u001b[38;5;124;43m\\\"\\u001b[39;49m\\n\\u001b[1;32m      3\\u001b[0m \\u001b[43m)\\u001b[49m\\n\",\n+      \"File \\u001b[0;32m~/langchain/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:2998\\u001b[0m, in \\u001b[0;36mRunnableSequence.invoke\\u001b[0;34m(self, input, config, **kwargs)\\u001b[0m\\n\\u001b[1;32m   2996\\u001b[0m             \\u001b[38;5;28minput\\u001b[39m \\u001b[38;5;241m=\\u001b[39m context\\u001b[38;5;241m.\\u001b[39mrun(step\\u001b[38;5;241m.\\u001b[39minvoke, \\u001b[38;5;28minput\\u001b[39m, config, \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mkwargs)\\n\\u001b[1;32m   2997\\u001b[0m         \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[0;32m-> 2998\\u001b[0m             \\u001b[38;5;28minput\\u001b[39m \\u001b[38;5;241m=\\u001b[39m \\u001b[43mcontext\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mrun\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mstep\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43minvoke\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;28;43minput\\u001b[39;49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mconfig\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m   2999\\u001b[0m \\u001b[38;5;66;03m# finish the root run\\u001b[39;00m\\n\\u001b[1;32m   3000\\u001b[0m \\u001b[38;5;28;01mexcept\\u001b[39;00m \\u001b[38;5;167;01mBaseException\\u001b[39;00m \\u001b[38;5;28;01mas\\u001b[39;00m e:\\n\",\n+      \"File \\u001b[0;32m~/langchain/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:456\\u001b[0m, in \\u001b[0;36mBaseTool.invoke\\u001b[0;34m(self, input, config, **kwargs)\\u001b[0m\\n\\u001b[1;32m    449\\u001b[0m \\u001b[38;5;28;01mdef\\u001b[39;00m \\u001b[38;5;21minvoke\\u001b[39m(\\n\\u001b[1;32m    450\\u001b[0m     \\u001b[38;5;28mself\\u001b[39m,\\n\\u001b[1;32m    451\\u001b[0m     \\u001b[38;5;28minput\\u001b[39m: Union[\\u001b[38;5;28mstr\\u001b[39m, Dict, ToolCall],\\n\\u001b[1;32m    452\\u001b[0m     config: Optional[RunnableConfig] \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mNone\\u001b[39;00m,\\n\\u001b[1;32m    453\\u001b[0m     \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mkwargs: Any,\\n\\u001b[1;32m    454\\u001b[0m ) \\u001b[38;5;241m-\\u001b[39m\\u001b[38;5;241m>\\u001b[39m Any:\\n\\u001b[1;32m    455\\u001b[0m     tool_input, kwargs \\u001b[38;5;241m=\\u001b[39m _prep_run_args(\\u001b[38;5;28minput\\u001b[39m, config, \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mkwargs)\\n\\u001b[0;32m--> 456\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mrun\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mtool_input\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[38;5;241;43m*\\u001b[39;49m\\u001b[43mkwargs\\u001b[49m\\u001b[43m)\\u001b[49m\\n\",\n+      \"File \\u001b[0;32m~/langchain/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:659\\u001b[0m, in \\u001b[0;36mBaseTool.run\\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\\u001b[0m\\n\\u001b[1;32m    657\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m error_to_raise:\\n\\u001b[1;32m    658\\u001b[0m     run_manager\\u001b[38;5;241m.\\u001b[39mon_tool_error(error_to_raise)\\n\\u001b[0;32m--> 659\\u001b[0m     \\u001b[38;5;28;01mraise\\u001b[39;00m error_to_raise\\n\\u001b[1;32m    660\\u001b[0m output \\u001b[38;5;241m=\\u001b[39m _format_output(content, artifact, tool_call_id, \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mname, status)\\n\\u001b[1;32m    661\\u001b[0m run_manager\\u001b[38;5;241m.\\u001b[39mon_tool_end(output, color\\u001b[38;5;241m=\\u001b[39mcolor, name\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mname, \\u001b[38;5;241m*\\u001b[39m\\u001b[38;5;241m*\\u001b[39mkwargs)\\n\",\n+      \"File \\u001b[0;32m~/langchain/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:622\\u001b[0m, in \\u001b[0;36mBaseTool.run\\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\\u001b[0m\\n\\u001b[1;32m    620\\u001b[0m context \\u001b[38;5;241m=\\u001b[39m copy_context()\\n\\u001b[1;32m    621\\u001b[0m context\\u001b[38;5;241m.\\u001b[39mrun(_set_config_context, child_config)\\n\\u001b[0;32m--> 622\\u001b[0m tool_args, tool_kwargs \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m_to_args_and_kwargs\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mtool_input\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    623\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m signature(\\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39m_run)\\u001b[38;5;241m.\\u001b[39mparameters\\u001b[38;5;241m.\\u001b[39mget(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mrun_manager\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m):\\n\\u001b[1;32m    624\\u001b[0m     tool_kwargs[\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mrun_manager\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m] \\u001b[38;5;241m=\\u001b[39m run_manager\\n\",\n+      \"File \\u001b[0;32m~/langchain/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:545\\u001b[0m, in \\u001b[0;36mBaseTool._to_args_and_kwargs\\u001b[0;34m(self, tool_input)\\u001b[0m\\n\\u001b[1;32m    544\\u001b[0m \\u001b[38;5;28;01mdef\\u001b[39;00m \\u001b[38;5;21m_to_args_and_kwargs\\u001b[39m(\\u001b[38;5;28mself\\u001b[39m, tool_input: Union[\\u001b[38;5;28mstr\\u001b[39m, Dict]) \\u001b[38;5;241m-\\u001b[39m\\u001b[38;5;241m>\\u001b[39m Tuple[Tuple, Dict]:\\n\\u001b[0;32m--> 545\\u001b[0m     tool_input \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m_parse_input\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mtool_input\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    546\\u001b[0m     \\u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\\u001b[39;00m\\n\\u001b[1;32m    547\\u001b[0m     \\u001b[38;5;66;03m# pass as a positional argument.\\u001b[39;00m\\n\\u001b[1;32m    548\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;28misinstance\\u001b[39m(tool_input, \\u001b[38;5;28mstr\\u001b[39m):\\n\",\n+      \"File \\u001b[0;32m~/langchain/.venv/lib/python3.11/site-packages/langchain_core/tools/base.py:487\\u001b[0m, in \\u001b[0;36mBaseTool._parse_input\\u001b[0;34m(self, tool_input)\\u001b[0m\\n\\u001b[1;32m    485\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m input_args \\u001b[38;5;129;01mis\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m \\u001b[38;5;28;01mNone\\u001b[39;00m:\\n\\u001b[1;32m    486\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;28missubclass\\u001b[39m(input_args, BaseModel):\\n\\u001b[0;32m--> 487\\u001b[0m         result \\u001b[38;5;241m=\\u001b[39m \\u001b[43minput_args\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mmodel_validate\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mtool_input\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    488\\u001b[0m         result_dict \\u001b[38;5;241m=\\u001b[39m result\\u001b[38;5;241m.\\u001b[39mmodel_dump()\\n\\u001b[1;32m    489\\u001b[0m     \\u001b[38;5;28;01melif\\u001b[39;00m \\u001b[38;5;28missubclass\\u001b[39m(input_args, BaseModelV1):\\n\",\n+      \"File \\u001b[0;32m~/langchain/.venv/lib/python3.11/site-packages/pydantic/main.py:568\\u001b[0m, in \\u001b[0;36mBaseModel.model_validate\\u001b[0;34m(cls, obj, strict, from_attributes, context)\\u001b[0m\\n\\u001b[1;32m    566\\u001b[0m \\u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\\u001b[39;00m\\n\\u001b[1;32m    567\\u001b[0m __tracebackhide__ \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mTrue\\u001b[39;00m\\n\\u001b[0;32m--> 568\\u001b[0m \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28;43mcls\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m__pydantic_validator__\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mvalidate_python\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m    569\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mobj\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mstrict\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mstrict\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mfrom_attributes\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mfrom_attributes\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mcontext\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mcontext\\u001b[49m\\n\\u001b[1;32m    570\\u001b[0m \\u001b[43m\\u001b[49m\\u001b[43m)\\u001b[49m\\n\",\n+      \"\\u001b[0;31mValidationError\\u001b[0m: 1 validation error for complex_toolSchema\\ndict_arg\\n  Field required [type=missing, input_value={'int_arg': 5, 'float_arg': 2.1}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\"\n      ]\n     }\n    ],\n@@ -172,9 +201,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 8,\n+   \"execution_count\": 6,\n    \"id\": \"8fedb550-683d-45ae-8876-ae7acb332019\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:26.558131Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:26.558031Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:27.399844Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:27.399201Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"name\": \"stdout\",\n@@ -186,9 +222,10 @@\n       \"\\n\",\n       \"raised the following error:\\n\",\n       \"\\n\",\n-      \"<class 'pydantic.error_wrappers.ValidationError'>: 1 validation error for complex_toolSchema\\n\",\n+      \"<class 'pydantic_core._pydantic_core.ValidationError'>: 1 validation error for complex_toolSchema\\n\",\n       \"dict_arg\\n\",\n-      \"  field required (type=value_error.missing)\\n\"\n+      \"  Field required [type=missing, input_value={'int_arg': 5, 'float_arg': 2.1}, input_type=dict]\\n\",\n+      \"    For further information visit https://errors.pydantic.dev/2.8/v/missing\\n\"\n      ]\n     }\n    ],\n@@ -226,17 +263,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 10,\n+   \"execution_count\": 7,\n    \"id\": \"02cc4223-35fa-4240-976a-012299ca703c\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:27.404122Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:27.403539Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:38.080547Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:38.079955Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"10.5\"\n       ]\n      },\n-     \"execution_count\": 10,\n+     \"execution_count\": 7,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -277,9 +321,16 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 11,\n+   \"execution_count\": 8,\n    \"id\": \"b5659956-9454-468a-9753-a3ff9052b8f5\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:38.083810Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:38.083623Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:38.090089Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:38.089682Z\"\n+    }\n+   },\n    \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.messages import AIMessage, HumanMessage, ToolCall, ToolMessage\\n\",\n@@ -335,17 +386,24 @@\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"execution_count\": 12,\n+   \"execution_count\": 9,\n    \"id\": \"4c45f5bd-cbb4-47d5-b4b6-aec50673c750\",\n-   \"metadata\": {},\n+   \"metadata\": {\n+    \"execution\": {\n+     \"iopub.execute_input\": \"2024-09-11T03:10:38.092152Z\",\n+     \"iopub.status.busy\": \"2024-09-11T03:10:38.092021Z\",\n+     \"iopub.status.idle\": \"2024-09-11T03:10:39.592443Z\",\n+     \"shell.execute_reply\": \"2024-09-11T03:10:39.591990Z\"\n+    }\n+   },\n    \"outputs\": [\n     {\n      \"data\": {\n       \"text/plain\": [\n        \"10.5\"\n       ]\n      },\n-     \"execution_count\": 12,\n+     \"execution_count\": 9,\n      \"metadata\": {},\n      \"output_type\": \"execute_result\"\n     }\n@@ -401,7 +459,7 @@\n    \"name\": \"python\",\n    \"nbconvert_exporter\": \"python\",\n    \"pygments_lexer\": \"ipython3\",\n-   \"version\": \"3.10.5\"\n+   \"version\": \"3.11.9\"\n   }\n  },\n  \"nbformat\": 4,"
        },
        {
          "filename": "docs/docs/how_to/tools_few_shot.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -46,9 +46,10 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"llm_with_tools = llm.bind_tools(tools)\"\n    ]\n   },"
        },
        {
          "filename": "docs/docs/how_to/tools_prompting.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -28,7 +28,7 @@\n     \"This guide assumes familiarity with the following concepts:\\n\",\n     \"\\n\",\n     \"- [LangChain Tools](/docs/concepts/#tools)\\n\",\n-    \"- [Function/tool calling](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)\\n\",\n+    \"- [Function/tool calling](https://python.langchain.com/docs/concepts/#functiontool-calling)\\n\",\n     \"- [Chat models](/docs/concepts/#chat-models)\\n\",\n     \"- [LLMs](/docs/concepts/#llms)\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/how_to/trim_messages.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -451,7 +451,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For a complete description of all arguments head to the API reference: https://python.langchain.com/v0.2/api_reference/core/messages/langchain_core.messages.utils.trim_messages.html\"\n+    \"For a complete description of all arguments head to the API reference: https://python.langchain.com/api_reference/core/messages/langchain_core.messages.utils.trim_messages.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/how_to/vectorstore_retriever.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -28,9 +28,9 @@\n     \"\\n\",\n     \"## Creating a retriever from a vectorstore\\n\",\n     \"\\n\",\n-    \"You can build a retriever from a vectorstore using its [.as_retriever](https://python.langchain.com/v0.2/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.as_retriever) method. Let's walk through an example.\\n\",\n+    \"You can build a retriever from a vectorstore using its [.as_retriever](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.as_retriever) method. Let's walk through an example.\\n\",\n     \"\\n\",\n-    \"First we instantiate a vectorstore. We will use an in-memory [FAISS](https://python.langchain.com/v0.2/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) vectorstore:\"\n+    \"First we instantiate a vectorstore. We will use an in-memory [FAISS](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) vectorstore:\"\n    ]\n   },\n   {\n@@ -77,7 +77,7 @@\n    \"id\": \"08f8b820-5912-49c1-9d76-40be0571dffb\",\n    \"metadata\": {},\n    \"source\": [\n-    \"This creates a retriever (specifically a [VectorStoreRetriever](https://python.langchain.com/v0.2/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStoreRetriever.html)), which we can use in the usual way:\"\n+    \"This creates a retriever (specifically a [VectorStoreRetriever](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.VectorStoreRetriever.html)), which we can use in the usual way:\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/callbacks/streamlit.md",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -37,7 +37,7 @@ st_callback = StreamlitCallbackHandler(st.container())\n ```\n \n Additional keyword arguments to customize the display behavior are described in the\n-[API reference](https://python.langchain.com/v0.2/api_reference/langchain/callbacks/langchain.callbacks.streamlit.streamlit_callback_handler.StreamlitCallbackHandler.html).\n+[API reference](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streamlit.streamlit_callback_handler.StreamlitCallbackHandler.html).\n \n ### Scenario 1: Using an Agent with Tools\n "
        },
        {
          "filename": "docs/docs/integrations/chat/ai21.ipynb",
          "status": "modified",
          "additions": 33,
          "deletions": 31,
          "patch": "@@ -25,9 +25,9 @@\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/__package_name_short_snake__) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/__package_name_short_snake__) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatAI21](https://python.langchain.com/v0.2/api_reference/ai21/chat_models/langchain_ai21.chat_models.ChatAI21.html#langchain_ai21.chat_models.ChatAI21) | [langchain-ai21](https://python.langchain.com/v0.2/api_reference/ai21/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-ai21?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-ai21?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatAI21](https://python.langchain.com/api_reference/ai21/chat_models/langchain_ai21.chat_models.ChatAI21.html#langchain_ai21.chat_models.ChatAI21) | [langchain-ai21](https://python.langchain.com/api_reference/ai21/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-ai21?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-ai21?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -50,18 +50,19 @@\n   },\n   {\n    \"cell_type\": \"code\",\n+   \"execution_count\": null,\n    \"id\": \"62e0dbc3\",\n    \"metadata\": {\n     \"tags\": []\n    },\n+   \"outputs\": [],\n    \"source\": [\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"AI21_API_KEY\\\"] = getpass()\"\n-   ],\n-   \"outputs\": [],\n-   \"execution_count\": null\n+    \"if \\\"AI21_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"AI21_API_KEY\\\"] = getpass()\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -73,14 +74,14 @@\n   },\n   {\n    \"cell_type\": \"code\",\n+   \"execution_count\": null,\n    \"id\": \"7c2e19d3-7c58-4470-9e1a-718b27a32056\",\n    \"metadata\": {},\n+   \"outputs\": [],\n    \"source\": [\n     \"# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n\",\n     \"# os.environ[\\\"LANGCHAIN_API_KEY\\\"] = getpass.getpass(\\\"Enter your LangSmith API key: \\\")\"\n-   ],\n-   \"outputs\": [],\n-   \"execution_count\": null\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -115,15 +116,15 @@\n   },\n   {\n    \"cell_type\": \"code\",\n+   \"execution_count\": null,\n    \"id\": \"c40756fb-cbf8-4d44-a293-3989d707237e\",\n    \"metadata\": {},\n+   \"outputs\": [],\n    \"source\": [\n     \"from langchain_ai21 import ChatAI21\\n\",\n     \"\\n\",\n     \"llm = ChatAI21(model=\\\"jamba-instruct\\\", temperature=0)\"\n-   ],\n-   \"outputs\": [],\n-   \"execution_count\": null\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -135,8 +136,10 @@\n   },\n   {\n    \"cell_type\": \"code\",\n+   \"execution_count\": null,\n    \"id\": \"46b982dc-5d8a-46da-a711-81c03ccd6adc\",\n    \"metadata\": {},\n+   \"outputs\": [],\n    \"source\": [\n     \"messages = [\\n\",\n     \"    (\\n\",\n@@ -147,9 +150,7 @@\n     \"]\\n\",\n     \"ai_msg = llm.invoke(messages)\\n\",\n     \"ai_msg\"\n-   ],\n-   \"outputs\": [],\n-   \"execution_count\": null\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -163,13 +164,15 @@\n   },\n   {\n    \"cell_type\": \"code\",\n+   \"execution_count\": null,\n    \"id\": \"39353473fce5dd2e\",\n    \"metadata\": {\n     \"collapsed\": false,\n     \"jupyter\": {\n      \"outputs_hidden\": false\n     }\n    },\n+   \"outputs\": [],\n    \"source\": [\n     \"from langchain_core.prompts import ChatPromptTemplate\\n\",\n     \"\\n\",\n@@ -191,25 +194,26 @@\n     \"        \\\"input\\\": \\\"I love programming.\\\",\\n\",\n     \"    }\\n\",\n     \")\"\n-   ],\n-   \"outputs\": [],\n-   \"execution_count\": null\n+   ]\n   },\n   {\n-   \"metadata\": {},\n    \"cell_type\": \"markdown\",\n-   \"source\": \"# Tool Calls / Function Calling\",\n-   \"id\": \"39c0ccd229927eab\"\n+   \"id\": \"39c0ccd229927eab\",\n+   \"metadata\": {},\n+   \"source\": \"# Tool Calls / Function Calling\"\n   },\n   {\n-   \"metadata\": {},\n    \"cell_type\": \"markdown\",\n-   \"source\": \"This example shows how to use tool calling with AI21 models:\",\n-   \"id\": \"2bf6b40be07fe2d4\"\n+   \"id\": \"2bf6b40be07fe2d4\",\n+   \"metadata\": {},\n+   \"source\": \"This example shows how to use tool calling with AI21 models:\"\n   },\n   {\n-   \"metadata\": {},\n    \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"id\": \"a181a28df77120fb\",\n+   \"metadata\": {},\n+   \"outputs\": [],\n    \"source\": [\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n@@ -219,7 +223,8 @@\n     \"from langchain_core.tools import tool\\n\",\n     \"from langchain_core.utils.function_calling import convert_to_openai_tool\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"AI21_API_KEY\\\"] = getpass()\\n\",\n+    \"if \\\"AI21_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"AI21_API_KEY\\\"] = getpass()\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"@tool\\n\",\n@@ -276,10 +281,7 @@\n     \"            print(f\\\"Assistant: {llm_answer.content}\\\")\\n\",\n     \"    else:\\n\",\n     \"        print(f\\\"Assistant: {response.content}\\\")\"\n-   ],\n-   \"id\": \"a181a28df77120fb\",\n-   \"outputs\": [],\n-   \"execution_count\": null\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n@@ -288,7 +290,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatAI21 features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/ai21/chat_models/langchain_ai21.chat_models.ChatAI21.html\"\n+    \"For detailed documentation of all ChatAI21 features and configurations head to the API reference: https://python.langchain.com/api_reference/ai21/chat_models/langchain_ai21.chat_models.ChatAI21.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/anthropic.ipynb",
          "status": "modified",
          "additions": 7,
          "deletions": 6,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# ChatAnthropic\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with Anthropic [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatAnthropic features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with Anthropic [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatAnthropic features and configurations head to the [API reference](https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html).\\n\",\n     \"\\n\",\n     \"Anthropic has several chat models. You can find information about their latest models and their costs, context windows, and supported input types in the [Anthropic docs](https://docs.anthropic.com/en/docs/models-overview).\\n\",\n     \"\\n\",\n@@ -31,9 +31,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/anthropic) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/anthropic) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatAnthropic](https://python.langchain.com/v0.2/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html) | [langchain-anthropic](https://python.langchain.com/v0.2/api_reference/anthropic/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-anthropic?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-anthropic?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatAnthropic](https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html) | [langchain-anthropic](https://python.langchain.com/api_reference/anthropic/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-anthropic?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-anthropic?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -59,7 +59,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass.getpass(\\\"Enter your Anthropic API key: \\\")\"\n+    \"if \\\"ANTHROPIC_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass.getpass(\\\"Enter your Anthropic API key: \\\")\"\n    ]\n   },\n   {\n@@ -274,7 +275,7 @@\n     }\n    ],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class GetWeather(BaseModel):\\n\",\n@@ -321,7 +322,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatAnthropic features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html\"\n+    \"For detailed documentation of all ChatAnthropic features and configurations head to the API reference: https://python.langchain.com/api_reference/anthropic/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/anthropic_functions.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -69,7 +69,7 @@\n     }\n    ],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel\\n\",\n+    \"from pydantic import BaseModel\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Person(BaseModel):\\n\","
        },
        {
          "filename": "docs/docs/integrations/chat/anyscale.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -54,7 +54,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"ANYSCALE_API_KEY\\\"] = getpass()\"\n+    \"if \\\"ANYSCALE_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ANYSCALE_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/chat/azure_chat_openai.ipynb",
          "status": "modified",
          "additions": 8,
          "deletions": 5,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# AzureChatOpenAI\\n\",\n     \"\\n\",\n-    \"This guide will help you get started with AzureOpenAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all AzureChatOpenAI features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html).\\n\",\n+    \"This guide will help you get started with AzureOpenAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all AzureChatOpenAI features and configurations head to the [API reference](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html).\\n\",\n     \"\\n\",\n     \"Azure OpenAI has several chat models. You can find information about their latest models and their costs, context windows, and supported input types in the [Azure docs](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models).\\n\",\n     \"\\n\",\n@@ -30,9 +30,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/azure) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/azure) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [AzureChatOpenAI](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html) | [langchain-openai](https://python.langchain.com/v0.2/api_reference/openai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\\n\",\n+    \"| [AzureChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html) | [langchain-openai](https://python.langchain.com/api_reference/openai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -58,7 +58,10 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"AZURE_OPENAI_API_KEY\\\"] = getpass.getpass(\\\"Enter your AzureOpenAI API key: \\\")\\n\",\n+    \"if \\\"AZURE_OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"AZURE_OPENAI_API_KEY\\\"] = getpass.getpass(\\n\",\n+    \"        \\\"Enter your AzureOpenAI API key: \\\"\\n\",\n+    \"    )\\n\",\n     \"os.environ[\\\"AZURE_OPENAI_ENDPOINT\\\"] = \\\"https://YOUR-ENDPOINT.openai.azure.com/\\\"\"\n    ]\n   },\n@@ -318,7 +321,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all AzureChatOpenAI features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html\"\n+    \"For detailed documentation of all AzureChatOpenAI features and configurations head to the API reference: https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/bedrock.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 6,
          "patch": "@@ -21,14 +21,14 @@\n     \"\\n\",\n     \"For more information on which models are accessible via Bedrock, head to the [AWS docs](https://docs.aws.amazon.com/bedrock/latest/userguide/models-features.html).\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatBedrock features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html).\\n\",\n+    \"For detailed documentation of all ChatBedrock features and configurations head to the [API reference](https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/bedrock) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/bedrock) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatBedrock](https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html) | [langchain-aws](https://python.langchain.com/v0.2/api_reference/aws/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-aws?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-aws?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatBedrock](https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html) | [langchain-aws](https://python.langchain.com/api_reference/aws/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-aws?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-aws?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -225,7 +225,7 @@\n    \"source\": [\n     \"## Bedrock Converse API\\n\",\n     \"\\n\",\n-    \"AWS has recently released the Bedrock Converse API which provides a unified conversational interface for Bedrock models. This API does not yet support custom models. You can see a list of all [models that are supported here](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html). To improve reliability the ChatBedrock integration will switch to using the Bedrock Converse API as soon as it has feature parity with the existing Bedrock API. Until then a separate [ChatBedrockConverse](https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html) integration has been released.\\n\",\n+    \"AWS has recently released the Bedrock Converse API which provides a unified conversational interface for Bedrock models. This API does not yet support custom models. You can see a list of all [models that are supported here](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html). To improve reliability the ChatBedrock integration will switch to using the Bedrock Converse API as soon as it has feature parity with the existing Bedrock API. Until then a separate [ChatBedrockConverse](https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html) integration has been released.\\n\",\n     \"\\n\",\n     \"We recommend using `ChatBedrockConverse` for users who do not need to use custom models.\\n\",\n     \"\\n\",\n@@ -350,9 +350,9 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatBedrock features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html\\n\",\n+    \"For detailed documentation of all ChatBedrock features and configurations head to the API reference: https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatBedrockConverse features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html\"\n+    \"For detailed documentation of all ChatBedrockConverse features and configurations head to the API reference: https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/cerebras.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -35,7 +35,7 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/cerebras) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/cerebras) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n     \"| [ChatCerebras](https://api.python.langchain.com/en/latest/chat_models/langchain_cerebras.chat_models.ChatCerebras.html) | [langchain-cerebras](https://api.python.langchain.com/en/latest/cerebras_api_reference.html) | \u274c | beta | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-cerebras?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-cerebras?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n@@ -76,7 +76,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"CEREBRAS_API_KEY\\\"] = getpass.getpass(\\\"Enter your Cerebras API key: \\\")\"\n+    \"if \\\"CEREBRAS_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"CEREBRAS_API_KEY\\\"] = getpass.getpass(\\\"Enter your Cerebras API key: \\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/chat/cohere.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -19,7 +19,7 @@\n     \"\\n\",\n     \"This notebook covers how to get started with [Cohere chat models](https://cohere.com/chat).\\n\",\n     \"\\n\",\n-    \"Head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.cohere.ChatCohere.html) for detailed documentation of all attributes and methods.\"\n+    \"Head to the [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.cohere.ChatCohere.html) for detailed documentation of all attributes and methods.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/chat/databricks.ipynb",
          "status": "modified",
          "additions": 8,
          "deletions": 5,
          "patch": "@@ -21,7 +21,7 @@\n     \"\\n\",\n     \"> [Databricks](https://www.databricks.com/) Lakehouse Platform unifies data, analytics, and AI on one platform. \\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with Databricks [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatDatabricks features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.databricks.ChatDatabricks.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with Databricks [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatDatabricks features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.databricks.ChatDatabricks.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n@@ -31,7 +31,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [ChatDatabricks](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.databricks.ChatDatabricks.html) | [langchain-databricks](https://python.langchain.com/v0.2/api_reference/databricks/index.html) | \u274c | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-databricks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-databricks?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatDatabricks](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.databricks.ChatDatabricks.html) | [langchain-databricks](https://python.langchain.com/api_reference/databricks/index.html) | \u274c | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-databricks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-databricks?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling/) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -90,7 +90,10 @@\n     \"import os\\n\",\n     \"\\n\",\n     \"os.environ[\\\"DATABRICKS_HOST\\\"] = \\\"https://your-workspace.cloud.databricks.com\\\"\\n\",\n-    \"os.environ[\\\"DATABRICKS_TOKEN\\\"] = getpass.getpass(\\\"Enter your Databricks access token: \\\")\"\n+    \"if \\\"DATABRICKS_TOKEN\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"DATABRICKS_TOKEN\\\"] = getpass.getpass(\\n\",\n+    \"        \\\"Enter your Databricks access token: \\\"\\n\",\n+    \"    )\"\n    ]\n   },\n   {\n@@ -139,7 +142,7 @@\n     \"    endpoint=\\\"databricks-dbrx-instruct\\\",\\n\",\n     \"    temperature=0.1,\\n\",\n     \"    max_tokens=256,\\n\",\n-    \"    # See https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.databricks.ChatDatabricks.html for other supported parameters\\n\",\n+    \"    # See https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.databricks.ChatDatabricks.html for other supported parameters\\n\",\n     \")\"\n    ]\n   },\n@@ -457,7 +460,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatDatabricks features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/databricks/chat_models/langchain_databricks.chat_models.ChatDatabricks.html\"\n+    \"For detailed documentation of all ChatDatabricks features and configurations head to the API reference: https://python.langchain.com/api_reference/databricks/chat_models/langchain_databricks.chat_models.ChatDatabricks.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/deepinfra.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -123,8 +123,8 @@\n     \"from dotenv import find_dotenv, load_dotenv\\n\",\n     \"from langchain_community.chat_models import ChatDeepInfra\\n\",\n     \"from langchain_core.messages import HumanMessage\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel\\n\",\n     \"from langchain_core.tools import tool\\n\",\n+    \"from pydantic import BaseModel\\n\",\n     \"\\n\",\n     \"model_name = \\\"meta-llama/Meta-Llama-3-70B-Instruct\\\"\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/integrations/chat/edenai.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -264,7 +264,7 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"llm = ChatEdenAI(provider=\\\"openai\\\", temperature=0.2, max_tokens=500)\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/integrations/chat/everlyai.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -47,7 +47,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"EVERLYAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"EVERLYAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"EVERLYAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/chat/fireworks.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 5,
          "patch": "@@ -17,16 +17,16 @@\n    \"source\": [\n     \"# ChatFireworks\\n\",\n     \"\\n\",\n-    \"This doc help you get started with Fireworks AI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatFireworks features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/fireworks/chat_models/langchain_fireworks.chat_models.ChatFireworks.html).\\n\",\n+    \"This doc help you get started with Fireworks AI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatFireworks features and configurations head to the [API reference](https://python.langchain.com/api_reference/fireworks/chat_models/langchain_fireworks.chat_models.ChatFireworks.html).\\n\",\n     \"\\n\",\n     \"Fireworks AI is an AI inference platform to run and customize models. For a list of all models served by Fireworks see the [Fireworks docs](https://fireworks.ai/models).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/fireworks) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/fireworks) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatFireworks](https://python.langchain.com/v0.2/api_reference/fireworks/chat_models/langchain_fireworks.chat_models.ChatFireworks.html) | [langchain-fireworks](https://python.langchain.com/v0.2/api_reference/fireworks/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-fireworks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-fireworks?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatFireworks](https://python.langchain.com/api_reference/fireworks/chat_models/langchain_fireworks.chat_models.ChatFireworks.html) | [langchain-fireworks](https://python.langchain.com/api_reference/fireworks/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-fireworks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-fireworks?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -52,7 +52,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"FIREWORKS_API_KEY\\\"] = getpass.getpass(\\\"Enter your Fireworks API key: \\\")\"\n+    \"if \\\"FIREWORKS_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"FIREWORKS_API_KEY\\\"] = getpass.getpass(\\\"Enter your Fireworks API key: \\\")\"\n    ]\n   },\n   {\n@@ -239,7 +240,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatFireworks features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/fireworks/chat_models/langchain_fireworks.chat_models.ChatFireworks.html\"\n+    \"For detailed documentation of all ChatFireworks features and configurations head to the API reference: https://python.langchain.com/api_reference/fireworks/chat_models/langchain_fireworks.chat_models.ChatFireworks.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/friendli.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -44,7 +44,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"FRIENDLI_TOKEN\\\"] = getpass.getpass(\\\"Friendi Personal Access Token: \\\")\"\n+    \"if \\\"FRIENDLI_TOKEN\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"FRIENDLI_TOKEN\\\"] = getpass.getpass(\\\"Friendi Personal Access Token: \\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/chat/gigachat.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -47,7 +47,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"GIGACHAT_CREDENTIALS\\\"] = getpass()\"\n+    \"if \\\"GIGACHAT_CREDENTIALS\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"GIGACHAT_CREDENTIALS\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/chat/google_generative_ai.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 5,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# ChatGoogleGenerativeAI\\n\",\n     \"\\n\",\n-    \"This docs will help you get started with Google AI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatGoogleGenerativeAI features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/google_genai/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html).\\n\",\n+    \"This docs will help you get started with Google AI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatGoogleGenerativeAI features and configurations head to the [API reference](https://python.langchain.com/api_reference/google_genai/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html).\\n\",\n     \"\\n\",\n     \"Google AI offers a number of different chat models. For information on the latest models, their features, context windows, etc. head to the [Google AI docs](https://ai.google.dev/gemini-api/docs/models/gemini).\\n\",\n     \"\\n\",\n@@ -32,9 +32,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/google_generativeai) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/google_generativeai) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatGoogleGenerativeAI](https://python.langchain.com/v0.2/api_reference/google_genai/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html) | [langchain-google-genai](https://python.langchain.com/v0.2/api_reference/google_genai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-google-genai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-google-genai?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatGoogleGenerativeAI](https://python.langchain.com/api_reference/google_genai/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html) | [langchain-google-genai](https://python.langchain.com/api_reference/google_genai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-google-genai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-google-genai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -60,7 +60,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"GOOGLE_API_KEY\\\"] = getpass.getpass(\\\"Enter your Google AI API key: \\\")\"\n+    \"if \\\"GOOGLE_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"GOOGLE_API_KEY\\\"] = getpass.getpass(\\\"Enter your Google AI API key: \\\")\"\n    ]\n   },\n   {\n@@ -285,7 +286,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatGoogleGenerativeAI features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/google_genai/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html\"\n+    \"For detailed documentation of all ChatGoogleGenerativeAI features and configurations head to the API reference: https://python.langchain.com/api_reference/google_genai/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/google_vertex_ai_palm.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# ChatVertexAI\\n\",\n     \"\\n\",\n-    \"This page provides a quick overview for getting started with VertexAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatVertexAI features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/google_vertexai/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html).\\n\",\n+    \"This page provides a quick overview for getting started with VertexAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatVertexAI features and configurations head to the [API reference](https://python.langchain.com/api_reference/google_vertexai/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html).\\n\",\n     \"\\n\",\n     \"ChatVertexAI exposes all foundational models available in Google Cloud, like `gemini-1.5-pro`, `gemini-1.5-flash`, etc. For a full and updated list of available models visit [VertexAI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/overview).\\n\",\n     \"\\n\",\n@@ -30,9 +30,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/google_vertex_ai) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/google_vertex_ai) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatVertexAI](https://python.langchain.com/v0.2/api_reference/google_vertexai/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html) | [langchain-google-vertexai](https://python.langchain.com/v0.2/api_reference/google_vertexai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-google-vertexai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-google-vertexai?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatVertexAI](https://python.langchain.com/api_reference/google_vertexai/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html) | [langchain-google-vertexai](https://python.langchain.com/api_reference/google_vertexai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-google-vertexai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-google-vertexai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -241,7 +241,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatVertexAI features and configurations, like how to send multimodal inputs and configure safety settings, head to the API reference: https://python.langchain.com/v0.2/api_reference/google_vertexai/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html\"\n+    \"For detailed documentation of all ChatVertexAI features and configurations, like how to send multimodal inputs and configure safety settings, head to the API reference: https://python.langchain.com/api_reference/google_vertexai/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/groq.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 5,
          "patch": "@@ -17,14 +17,14 @@\n    \"source\": [\n     \"# ChatGroq\\n\",\n     \"\\n\",\n-    \"This will help you getting started with Groq [chat models](../../concepts.mdx#chat-models). For detailed documentation of all ChatGroq features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html). For a list of all Groq models, visit this [link](https://console.groq.com/docs/models).\\n\",\n+    \"This will help you getting started with Groq [chat models](../../concepts.mdx#chat-models). For detailed documentation of all ChatGroq features and configurations head to the [API reference](https://python.langchain.com/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html). For a list of all Groq models, visit this [link](https://console.groq.com/docs/models).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/groq) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/groq) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatGroq](https://python.langchain.com/v0.2/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html) | [langchain-groq](https://python.langchain.com/v0.2/api_reference/groq/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-groq?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-groq?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatGroq](https://python.langchain.com/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html) | [langchain-groq](https://python.langchain.com/api_reference/groq/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-groq?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-groq?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](../../how_to/tool_calling.ipynb) | [Structured output](../../how_to/structured_output.ipynb) | JSON mode | [Image input](../../how_to/multimodal_inputs.ipynb) | Audio input | Video input | [Token-level streaming](../../how_to/chat_streaming.ipynb) | Native async | [Token usage](../../how_to/chat_token_usage_tracking.ipynb) | [Logprobs](../../how_to/logprobs.ipynb) |\\n\",\n@@ -50,7 +50,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"GROQ_API_KEY\\\"] = getpass.getpass(\\\"Enter your Groq API key: \\\")\"\n+    \"if \\\"GROQ_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"GROQ_API_KEY\\\"] = getpass.getpass(\\\"Enter your Groq API key: \\\")\"\n    ]\n   },\n   {\n@@ -248,7 +249,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatGroq features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html\"\n+    \"For detailed documentation of all ChatGroq features and configurations head to the API reference: https://python.langchain.com/api_reference/groq/chat_models/langchain_groq.chat_models.ChatGroq.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/huggingface.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -6,7 +6,7 @@\n    \"source\": [\n     \"# ChatHuggingFace\\n\",\n     \"\\n\",\n-    \"This will help you getting started with `langchain_huggingface` [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatHuggingFace` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html). For a list of models supported by Hugging Face check out [this page](https://huggingface.co/models).\\n\",\n+    \"This will help you getting started with `langchain_huggingface` [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatHuggingFace` features and configurations head to the [API reference](https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html). For a list of models supported by Hugging Face check out [this page](https://huggingface.co/models).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -15,7 +15,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatHuggingFace](https://python.langchain.com/v0.2/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html) | [langchain-huggingface](https://python.langchain.com/v0.2/api_reference/huggingface/index.html) | \u2705 | beta | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_huggingface?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_huggingface?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatHuggingFace](https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html) | [langchain-huggingface](https://python.langchain.com/api_reference/huggingface/index.html) | \u2705 | beta | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_huggingface?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_huggingface?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -52,7 +52,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatHuggingFace](https://python.langchain.com/v0.2/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html) | [langchain_huggingface](https://python.langchain.com/v0.2/api_reference/huggingface/index.html) | \u2705 | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_huggingface?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_huggingface?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatHuggingFace](https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html) | [langchain_huggingface](https://python.langchain.com/api_reference/huggingface/index.html) | \u2705 | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_huggingface?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_huggingface?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -465,7 +465,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `ChatHuggingFace` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html\"\n+    \"For detailed documentation of all `ChatHuggingFace` features and configurations head to the API reference: https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html\"\n    ]\n   },\n   {\n@@ -474,7 +474,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatHuggingFace features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html\"\n+    \"For detailed documentation of all ChatHuggingFace features and configurations head to the API reference: https://python.langchain.com/api_reference/huggingface/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/ibm_watsonx.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -34,7 +34,7 @@\n     \"## Overview\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/openai) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/openai) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n     \"| ChatWatsonx | \u274c | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-ibm?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-ibm?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n@@ -483,7 +483,7 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class GetWeather(BaseModel):\\n\","
        },
        {
          "filename": "docs/docs/integrations/chat/llamacpp.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -32,7 +32,7 @@\n     \"### Integration details\\n\",\n     \"| Class | Package | Local | Serializable | JS support |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [ChatLlamaCpp](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.llamacpp.ChatLlamaCpp.html) | [langchain-community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c |\\n\",\n+    \"| [ChatLlamaCpp](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.llamacpp.ChatLlamaCpp.html) | [langchain-community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | Image input | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -226,8 +226,8 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_core.tools import tool\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class WeatherInput(BaseModel):\\n\",\n@@ -343,8 +343,8 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel\\n\",\n     \"from langchain_core.utils.function_calling import convert_to_openai_tool\\n\",\n+    \"from pydantic import BaseModel\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Joke(BaseModel):\\n\",\n@@ -404,7 +404,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatLlamaCpp features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.llamacpp.ChatLlamaCpp.html\"\n+    \"For detailed documentation of all ChatLlamaCpp features and configurations head to the API reference: https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.llamacpp.ChatLlamaCpp.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/mistralai.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 5,
          "patch": "@@ -17,14 +17,14 @@\n    \"source\": [\n     \"# ChatMistralAI\\n\",\n     \"\\n\",\n-    \"This will help you getting started with Mistral [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatMistralAI` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html). The `ChatMistralAI` class is built on top of the [Mistral API](https://docs.mistral.ai/api/). For a list of all the models supported by Mistral, check out [this page](https://docs.mistral.ai/getting-started/models/).\\n\",\n+    \"This will help you getting started with Mistral [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatMistralAI` features and configurations head to the [API reference](https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html). The `ChatMistralAI` class is built on top of the [Mistral API](https://docs.mistral.ai/api/). For a list of all the models supported by Mistral, check out [this page](https://docs.mistral.ai/getting-started/models/).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/mistral) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/mistral) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatMistralAI](https://python.langchain.com/v0.2/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html) | [langchain_mistralai](https://python.langchain.com/v0.2/api_reference/mistralai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_mistralai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_mistralai?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatMistralAI](https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html) | [langchain_mistralai](https://python.langchain.com/api_reference/mistralai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_mistralai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_mistralai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -52,7 +52,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"MISTRAL_API_KEY\\\"] = getpass.getpass(\\\"Enter your Mistral API key: \\\")\"\n+    \"if \\\"MISTRAL_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"MISTRAL_API_KEY\\\"] = getpass.getpass(\\\"Enter your Mistral API key: \\\")\"\n    ]\n   },\n   {\n@@ -233,7 +234,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"Head to the [API reference](https://python.langchain.com/v0.2/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html) for detailed documentation of all attributes and methods.\"\n+    \"Head to the [API reference](https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html) for detailed documentation of all attributes and methods.\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/nvidia_ai_endpoints.ipynb",
          "status": "modified",
          "additions": 7,
          "deletions": 7,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# ChatNVIDIA\\n\",\n     \"\\n\",\n-    \"This will help you getting started with NVIDIA [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatNVIDIA` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/nvidia_ai_endpoints/chat_models/langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA.html).\\n\",\n+    \"This will help you getting started with NVIDIA [chat models](/docs/concepts/#chat-models). For detailed documentation of all `ChatNVIDIA` features and configurations head to the [API reference](https://python.langchain.com/api_reference/nvidia_ai_endpoints/chat_models/langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"The `langchain-nvidia-ai-endpoints` package contains LangChain integrations building applications with models on \\n\",\n@@ -41,7 +41,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatNVIDIA](https://python.langchain.com/v0.2/api_reference/nvidia_ai_endpoints/chat_models/langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA.html) | [langchain_nvidia_ai_endpoints](https://python.langchain.com/v0.2/api_reference/nvidia_ai_endpoints/index.html) | \u2705 | beta | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_nvidia_ai_endpoints?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_nvidia_ai_endpoints?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatNVIDIA](https://python.langchain.com/api_reference/nvidia_ai_endpoints/chat_models/langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA.html) | [langchain_nvidia_ai_endpoints](https://python.langchain.com/api_reference/nvidia_ai_endpoints/index.html) | \u2705 | beta | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_nvidia_ai_endpoints?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_nvidia_ai_endpoints?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -513,7 +513,7 @@\n     \"id\": \"79efa62d\"\n    },\n    \"source\": [\n-    \"Like any other integration, ChatNVIDIA is fine to support chat utilities like RunnableWithMessageHistory which is analogous to using `ConversationChain`. Below, we show the [LangChain RunnableWithMessageHistory](https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) example applied to the `mistralai/mixtral-8x22b-instruct-v0.1` model.\"\n+    \"Like any other integration, ChatNVIDIA is fine to support chat utilities like RunnableWithMessageHistory which is analogous to using `ConversationChain`. Below, we show the [LangChain RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) example applied to the `mistralai/mixtral-8x22b-instruct-v0.1` model.\"\n    ]\n   },\n   {\n@@ -617,7 +617,7 @@\n    \"source\": [\n     \"## Tool calling\\n\",\n     \"\\n\",\n-    \"Starting in v0.2, `ChatNVIDIA` supports [bind_tools](https://python.langchain.com/v0.2/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel.bind_tools).\\n\",\n+    \"Starting in v0.2, `ChatNVIDIA` supports [bind_tools](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel.bind_tools).\\n\",\n     \"\\n\",\n     \"`ChatNVIDIA` provides integration with the variety of models on [build.nvidia.com](https://build.nvidia.com) as well as local NIMs. Not all these models are trained for tool calling. Be sure to select a model that does have tool calling for your experimention and applications.\"\n    ]\n@@ -658,8 +658,8 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import Field\\n\",\n     \"from langchain_core.tools import tool\\n\",\n+    \"from pydantic import Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"@tool\\n\",\n@@ -680,7 +680,7 @@\n    \"id\": \"e08df68c\",\n    \"metadata\": {},\n    \"source\": [\n-    \"See [How to use chat models to call tools](https://python.langchain.com/v0.2/docs/how_to/tool_calling/) for additional examples.\"\n+    \"See [How to use chat models to call tools](https://python.langchain.com/docs/how_to/tool_calling/) for additional examples.\"\n    ]\n   },\n   {\n@@ -729,7 +729,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `ChatNVIDIA` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/nvidia_ai_endpoints/chat_models/langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA.html\"\n+    \"For detailed documentation of all `ChatNVIDIA` features and configurations head to the API reference: https://python.langchain.com/api_reference/nvidia_ai_endpoints/chat_models/langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/oci_generative_ai.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# ChatOCIGenAI\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with OCIGenAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatOCIGenAI features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with OCIGenAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatOCIGenAI features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html).\\n\",\n     \"\\n\",\n     \"Oracle Cloud Infrastructure (OCI) Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, and which is available through a single API.\\n\",\n     \"Using the OCI Generative AI service you can access ready-to-use pretrained models, or create and host your own fine-tuned custom models based on your own data on dedicated AI clusters. Detailed documentation of the service and API is available __[here](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm)__ and __[here](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/)__.\\n\",\n@@ -26,9 +26,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/oci_generative_ai) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/oci_generative_ai) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatOCIGenAI](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html) | [langchain-community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u274c | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-oci-generative-ai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-oci-generative-ai?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatOCIGenAI](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html) | [langchain-community](https://python.langchain.com/api_reference/community/index.html) | \u274c | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-oci-generative-ai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-oci-generative-ai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling/) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -162,7 +162,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatOCIGenAI features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html\"\n+    \"For detailed documentation of all ChatOCIGenAI features and configurations head to the API reference: https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/ollama.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -435,7 +435,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatOllama features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html\"\n+    \"For detailed documentation of all ChatOllama features and configurations head to the API reference: https://python.langchain.com/api_reference/ollama/chat_models/langchain_ollama.chat_models.ChatOllama.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/openai.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# ChatOpenAI\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with OpenAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatOpenAI features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with OpenAI [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatOpenAI features and configurations head to the [API reference](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html).\\n\",\n     \"\\n\",\n     \"OpenAI has several chat models. You can find information about their latest models and their costs, context windows, and supported input types in the [OpenAI docs](https://platform.openai.com/docs/models).\\n\",\n     \"\\n\",\n@@ -36,9 +36,9 @@\n     \"## Overview\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/openai) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/openai) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatOpenAI](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain-openai](https://python.langchain.com/v0.2/api_reference/openai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain-openai](https://python.langchain.com/api_reference/openai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | Image input | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -441,7 +441,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatOpenAI features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html\"\n+    \"For detailed documentation of all ChatOpenAI features and configurations head to the API reference: https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/premai.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -426,8 +426,8 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_core.tools import tool\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"# Define the schema for function arguments\\n\","
        },
        {
          "filename": "docs/docs/integrations/chat/symblai_nebula.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -269,7 +269,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"Check out the [API reference](https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.symblai_nebula.ChatNebula.html) for more detail.\"\n+    \"Check out the [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.symblai_nebula.ChatNebula.html) for more detail.\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/together.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -18,16 +18,16 @@\n     \"# ChatTogether\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"This page will help you get started with Together AI [chat models](../../concepts.mdx#chat-models). For detailed documentation of all ChatTogether features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/together/chat_models/langchain_together.chat_models.ChatTogether.html).\\n\",\n+    \"This page will help you get started with Together AI [chat models](../../concepts.mdx#chat-models). For detailed documentation of all ChatTogether features and configurations head to the [API reference](https://python.langchain.com/api_reference/together/chat_models/langchain_together.chat_models.ChatTogether.html).\\n\",\n     \"\\n\",\n     \"[Together AI](https://www.together.ai/) offers an API to query [50+ leading open-source models](https://docs.together.ai/docs/chat-models)\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/togetherai) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/togetherai) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatTogether](https://python.langchain.com/v0.2/api_reference/together/chat_models/langchain_together.chat_models.ChatTogether.html) | [langchain-together](https://python.langchain.com/v0.2/api_reference/together/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-together?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-together?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatTogether](https://python.langchain.com/api_reference/together/chat_models/langchain_together.chat_models.ChatTogether.html) | [langchain-together](https://python.langchain.com/api_reference/together/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-together?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-together?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](../../how_to/tool_calling.ipynb) | [Structured output](../../how_to/structured_output.ipynb) | JSON mode | [Image input](../../how_to/multimodal_inputs.ipynb) | Audio input | Video input | [Token-level streaming](../../how_to/chat_streaming.ipynb) | Native async | [Token usage](../../how_to/chat_token_usage_tracking.ipynb) | [Logprobs](../../how_to/logprobs.ipynb) |\\n\",\n@@ -239,7 +239,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatTogether features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/together/chat_models/langchain_together.chat_models.ChatTogether.html\"\n+    \"For detailed documentation of all ChatTogether features and configurations head to the API reference: https://python.langchain.com/api_reference/together/chat_models/langchain_together.chat_models.ChatTogether.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat/vllm.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -20,13 +20,13 @@\n     \"vLLM can be deployed as a server that mimics the OpenAI API protocol. This allows vLLM to be used as a drop-in replacement for applications using OpenAI API. This server can be queried in the same format as OpenAI API.\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n-    \"This will help you getting started with vLLM [chat models](/docs/concepts/#chat-models), which leverage the `langchain-openai` package. For detailed documentation of all `ChatOpenAI` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html).\\n\",\n+    \"This will help you getting started with vLLM [chat models](/docs/concepts/#chat-models), which leverage the `langchain-openai` package. For detailed documentation of all `ChatOpenAI` features and configurations head to the [API reference](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html).\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatOpenAI](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain_openai](https://python.langchain.com/v0.2/api_reference/openai/) | \u2705 | beta | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_openai?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain_openai](https://python.langchain.com/api_reference/openai/) | \u2705 | beta | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_openai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"Specific model features-- such as tool calling, support for multi-modal inputs, support for token-level streaming, etc.-- will depend on the hosted model.\\n\",\n@@ -214,7 +214,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all features and configurations exposed via `langchain-openai`, head to the API reference: https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html\\n\",\n+    \"For detailed documentation of all features and configurations exposed via `langchain-openai`, head to the API reference: https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html\\n\",\n     \"\\n\",\n     \"Refer to the vLLM [documentation](https://docs.vllm.ai/en/latest/) as well.\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/chat/yi.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 4,
          "patch": "@@ -6,7 +6,7 @@\n    \"source\": [\n     \"# ChatYI\\n\",\n     \"\\n\",\n-    \"This will help you getting started with Yi [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatYi features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/lanchain_community/chat_models/lanchain_community.chat_models.yi.ChatYi.html).\\n\",\n+    \"This will help you getting started with Yi [chat models](/docs/concepts/#chat-models). For detailed documentation of all ChatYi features and configurations head to the [API reference](https://python.langchain.com/api_reference/lanchain_community/chat_models/lanchain_community.chat_models.yi.ChatYi.html).\\n\",\n     \"\\n\",\n     \"[01.AI](https://www.lingyiwanwu.com/en), founded by Dr. Kai-Fu Lee, is a global company at the forefront of AI 2.0. They offer cutting-edge large language models, including the Yi series, which range from 6B to hundreds of billions of parameters. 01.AI also provides multimodal models, an open API platform, and open-source options like Yi-34B/9B/6B and Yi-VL.\\n\",\n     \"\\n\",\n@@ -16,7 +16,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatYi](https://python.langchain.com/v0.2/api_reference/lanchain_community/chat_models/lanchain_community.chat_models.yi.ChatYi.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatYi](https://python.langchain.com/api_reference/lanchain_community/chat_models/lanchain_community.chat_models.yi.ChatYi.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Model features\\n\",\n     \"| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\\n\",\n@@ -41,7 +41,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"YI_API_KEY\\\"] = getpass.getpass(\\\"Enter your Yi API key: \\\")\"\n+    \"if \\\"YI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"YI_API_KEY\\\"] = getpass.getpass(\\\"Enter your Yi API key: \\\")\"\n    ]\n   },\n   {\n@@ -198,7 +199,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ChatYi features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/chat_models/langchain_community.chat_models.yi.ChatYi.html\"\n+    \"For detailed documentation of all ChatYi features and configurations head to the API reference: https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.yi.ChatYi.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/chat_loaders/langsmith_llm_runs.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -72,7 +72,7 @@\n    \"source\": [\n     \"from enum import Enum\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"class Operation(Enum):\\n\",\n@@ -135,8 +135,8 @@\n    \"source\": [\n     \"from pprint import pprint\\n\",\n     \"\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel\\n\",\n     \"from langchain_core.utils.function_calling import convert_pydantic_to_openai_function\\n\",\n+    \"from pydantic import BaseModel\\n\",\n     \"\\n\",\n     \"openai_function_def = convert_pydantic_to_openai_function(Calculator)\\n\",\n     \"pprint(openai_function_def)\""
        },
        {
          "filename": "docs/docs/integrations/document_loaders/arxiv.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -188,7 +188,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all ArxivLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html#langchain_community.document_loaders.arxiv.ArxivLoader\"\n+    \"For detailed documentation of all ArxivLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.arxiv.ArxivLoader.html#langchain_community.document_loaders.arxiv.ArxivLoader\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/box.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -15,7 +15,7 @@\n    \"source\": [\n     \"# BoxLoader\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with Box [document loader](/docs/integrations/document_loaders/). For detailed documentation of all BoxLoader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/box/document_loaders/langchain_box.document_loaders.box.BoxLoader.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with Box [document loader](/docs/integrations/document_loaders/). For detailed documentation of all BoxLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/box/document_loaders/langchain_box.document_loaders.box.BoxLoader.html).\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n@@ -34,7 +34,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [BoxLoader](https://python.langchain.com/v0.2/api_reference/box/document_loaders/langchain_box.document_loaders.box.BoxLoader.html) | [langchain_box](https://python.langchain.com/v0.2/api_reference/box/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [BoxLoader](https://python.langchain.com/api_reference/box/document_loaders/langchain_box.document_loaders.box.BoxLoader.html) | [langchain_box](https://python.langchain.com/api_reference/box/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -244,7 +244,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all BoxLoader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/box/document_loaders/langchain_box.document_loaders.box.BoxLoader.html)\\n\",\n+    \"For detailed documentation of all BoxLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/box/document_loaders/langchain_box.document_loaders.box.BoxLoader.html)\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Help\\n\","
        },
        {
          "filename": "docs/docs/integrations/document_loaders/bshtml.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -7,7 +7,7 @@\n     \"# BSHTMLLoader\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with BeautifulSoup4 [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with BeautifulSoup4 [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html).\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n@@ -16,7 +16,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [BSHTMLLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [BSHTMLLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -215,7 +215,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all BSHTMLLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html\"\n+    \"For detailed documentation of all BSHTMLLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/dedoc.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 6,
          "patch": "@@ -23,9 +23,9 @@\n     \"\\n\",\n     \"| Class                                                                                                                                                | Package                                                                                        | Local | Serializable | JS support |\\n\",\n     \"|:-----------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------|:-----:|:------------:|:----------:|\\n\",\n-    \"| [DedocFileLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocFileLoader.html)       | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) |   \u274c   |     beta     |     \u274c      |\\n\",\n-    \"| [DedocPDFLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.DedocPDFLoader.html)           | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) |   \u274c   |     beta     |     \u274c      | \\n\",\n-    \"| [DedocAPIFileLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocAPIFileLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) |   \u274c   |     beta     |     \u274c      | \\n\",\n+    \"| [DedocFileLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocFileLoader.html)       | [langchain_community](https://python.langchain.com/api_reference/community/index.html) |   \u274c   |     beta     |     \u274c      |\\n\",\n+    \"| [DedocPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.DedocPDFLoader.html)           | [langchain_community](https://python.langchain.com/api_reference/community/index.html) |   \u274c   |     beta     |     \u274c      | \\n\",\n+    \"| [DedocAPIFileLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocAPIFileLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) |   \u274c   |     beta     |     \u274c      | \\n\",\n     \"\\n\",\n     \"\\n\",\n     \"### Loader features\\n\",\n@@ -161,9 +161,9 @@\n     \"\\n\",\n     \"For detailed information on configuring and calling `Dedoc` loaders, please see the API references: \\n\",\n     \"\\n\",\n-    \"* https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocFileLoader.html\\n\",\n-    \"* https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.DedocPDFLoader.html\\n\",\n-    \"* https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocAPIFileLoader.html\"\n+    \"* https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocFileLoader.html\\n\",\n+    \"* https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.DedocPDFLoader.html\\n\",\n+    \"* https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.dedoc.DedocAPIFileLoader.html\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/firecrawl.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -13,9 +13,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/web_loaders/firecrawl/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/firecrawl/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [FireCrawlLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.firecrawl.FireCrawlLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n+    \"| [FireCrawlLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.firecrawl.FireCrawlLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -102,7 +102,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"Document(metadata={'ogUrl': 'https://www.firecrawl.dev/', 'title': 'Home - Firecrawl', 'robots': 'follow, index', 'ogImage': 'https://www.firecrawl.dev/og.png?123', 'ogTitle': 'Firecrawl', 'sitemap': {'lastmod': '2024-08-12T00:28:16.681Z', 'changefreq': 'weekly'}, 'keywords': 'Firecrawl,Markdown,Data,Mendable,Langchain', 'sourceURL': 'https://www.firecrawl.dev/', 'ogSiteName': 'Firecrawl', 'description': 'Firecrawl crawls and converts any website into clean markdown.', 'ogDescription': 'Turn any website into LLM-ready data.', 'pageStatusCode': 200, 'ogLocaleAlternate': []}, page_content='Introducing [Smart Crawl!](https://www.firecrawl.dev/smart-crawl)\\\\n Join the waitlist to turn any website into an API with AI\\\\n\\\\n\\\\n\\\\n[\ud83d\udd25 Firecrawl](/)\\\\n\\\\n*   [Playground](/playground)\\\\n    \\\\n*   [Docs](https://docs.firecrawl.dev)\\\\n    \\\\n*   [Pricing](/pricing)\\\\n    \\\\n*   [Blog](/blog)\\\\n    \\\\n*   Beta Features\\\\n\\\\n[Log In](/signin)\\\\n[Log In](/signin)\\\\n[Sign Up](/signin/signup)\\\\n 8.9k\\\\n\\\\n[\ud83d\udca5 Get 2 months free with yearly plan](/pricing)\\\\n\\\\nTurn websites into  \\\\n_LLM-ready_ data\\\\n=====================================\\\\n\\\\nPower your AI apps with clean data crawled from any website. It\\\\'s also open-source.\\\\n\\\\nStart for free (500 credits)Start for free[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\\\n\\\\nA product by\\\\n\\\\n[![Mendable Logo](https://www.firecrawl.dev/images/mendable_logo_transparent.png)Mendable](https://mendable.ai)\\\\n\\\\n![Example Webpage](https://www.firecrawl.dev/multiple-websites.png)\\\\n\\\\nCrawl, Scrape, Clean\\\\n--------------------\\\\n\\\\nWe crawl all accessible subpages and give you clean markdown for each. No sitemap required.\\\\n\\\\n    \\\\n      [\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## Welcome to Firecrawl\\\\\\\\\\\\n            Firecrawl is a web scraper that allows you to extract the content of a webpage.\\\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/features\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## Features\\\\\\\\\\\\n            Discover how Firecrawl\\\\'s cutting-edge features can \\\\\\\\\\\\n            transform your data operations.\\\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/pricing\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## Pricing Plans\\\\\\\\\\\\n            Choose the perfect plan that fits your needs.\\\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/about\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## About Us\\\\\\\\\\\\n            Learn more about Firecrawl\\\\'s mission and the \\\\\\\\\\\\n            team behind our innovative platform.\\\"\\\\\\\\\\\\n        }\\\\\\\\\\\\n      ]\\\\n      \\\\n\\\\nNote: The markdown has been edited for display purposes.\\\\n\\\\nTrusted by Top Companies\\\\n------------------------\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/zapier.png)](https://www.zapier.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/gamma.svg)](https://gamma.app)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/nvidia-com.png)](https://www.nvidia.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/teller-io.svg)](https://www.teller.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/stackai.svg)](https://www.stack-ai.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/palladiumdigital-co-uk.svg)](https://www.palladiumdigital.co.uk)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/worldwide-casting-com.svg)](https://www.worldwide-casting.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/open-gov-sg.png)](https://www.open.gov.sg)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/bain-com.svg)](https://www.bain.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/demand-io.svg)](https://www.demand.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/nocodegarden-io.png)](https://www.nocodegarden.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/cyberagent-co-jp.svg)](https://www.cyberagent.co.jp)\\\\n\\\\nIntegrate today\\\\n---------------\\\\n\\\\nEnhance your applications with top-tier web scraping and crawling capabilities.\\\\n\\\\n#### Scrape\\\\n\\\\nExtract markdown or structured data from websites quickly and efficiently.\\\\n\\\\n#### Crawling\\\\n\\\\nNavigate and retrieve data from all accessible subpages, even without a sitemap.\\\\n\\\\nNode.js\\\\n\\\\nPython\\\\n\\\\ncURL\\\\n\\\\n1\\\\n\\\\n2\\\\n\\\\n3\\\\n\\\\n4\\\\n\\\\n5\\\\n\\\\n6\\\\n\\\\n7\\\\n\\\\n8\\\\n\\\\n9\\\\n\\\\n10\\\\n\\\\n// npm install @mendable/firecrawl-js  \\\\n  \\\\nimport FirecrawlApp from \\\\'@mendable/firecrawl-js\\\\';  \\\\n  \\\\nconst app \\\\\\\\= new FirecrawlApp({ apiKey: \\\"fc-YOUR\\\\\\\\_API\\\\\\\\_KEY\\\" });  \\\\n  \\\\n// Scrape a website:  \\\\nconst scrapeResult \\\\\\\\= await app.scrapeUrl(\\\\'firecrawl.dev\\\\');  \\\\n  \\\\nconsole.log(scrapeResult.data.markdown)\\\\n\\\\n#### Use well-known tools\\\\n\\\\nAlready fully integrated with the greatest existing tools and workflows.\\\\n\\\\n[![LlamaIndex](https://www.firecrawl.dev/logos/llamaindex.svg)](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/#using-firecrawl-reader/)\\\\n[![Langchain](https://www.firecrawl.dev/integrations/langchain.png)](https://python.langchain.com/v0.2/docs/integrations/document_loaders/firecrawl/)\\\\n[![Dify](https://www.firecrawl.dev/logos/dify.png)](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl/)\\\\n[![Dify](https://www.firecrawl.dev/integrations/langflow_2.png)](https://www.langflow.org/)\\\\n[![Flowise](https://www.firecrawl.dev/integrations/flowise.png)](https://flowiseai.com/)\\\\n[![CrewAI](https://www.firecrawl.dev/integrations/crewai.png)](https://crewai.com/)\\\\n\\\\n#### Start for free, scale easily\\\\n\\\\nKick off your journey for free and scale seamlessly as your project expands.\\\\n\\\\n[Try it out](/signin/signup)\\\\n\\\\n#### Open-source\\\\n\\\\nDeveloped transparently and collaboratively. Join our community of contributors.\\\\n\\\\n[Check out our repo](https://github.com/mendableai/firecrawl)\\\\n\\\\nWe handle the hard stuff\\\\n------------------------\\\\n\\\\nRotating proxies, caching, rate limits, js-blocked content and more\\\\n\\\\n#### Crawling\\\\n\\\\nFirecrawl crawls all accessible subpages, even without a sitemap.\\\\n\\\\n#### Dynamic content\\\\n\\\\nFirecrawl gathers data even if a website uses javascript to render content.\\\\n\\\\n#### To Markdown\\\\n\\\\nFirecrawl returns clean, well formatted markdown - ready for use in LLM applications\\\\n\\\\n#### Crawling Orchestration\\\\n\\\\nFirecrawl orchestrates the crawling process in parallel for the fastest results.\\\\n\\\\n#### Caching\\\\n\\\\nFirecrawl caches content, so you don\\\\'t have to wait for a full scrape unless new content exists.\\\\n\\\\n#### Built for AI\\\\n\\\\nBuilt by LLM engineers, for LLM engineers. Giving you clean data the way you want it.\\\\n\\\\nOur wall of love\\\\n\\\\nDon\\\\'t take our word for it\\\\n--------------------------\\\\n\\\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\\\n\\\\nGreg Kamradt\\\\n\\\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\\\n\\\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\\\n\\\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\\\n\\\\nAmit Naik\\\\n\\\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\\\n\\\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. \ud83d\udc4f\\\\n\\\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\\\n\\\\nJerry Liu\\\\n\\\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\\\n\\\\nFirecrawl is awesome \ud83d\udd25 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\\\n\\\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\\\n\\\\nBardia Pourvakil\\\\n\\\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\\\n\\\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\\\'t recommend them enough.\\\\n\\\\n![latentsauce \ud83e\uddd8\ud83c\udffd](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\\\n\\\\nlatentsauce \ud83e\uddd8\ud83c\udffd\\\\n\\\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\\\n\\\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f\\\\n\\\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\\\n\\\\nGreg Kamradt\\\\n\\\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\\\n\\\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\\\n\\\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\\\n\\\\nAmit Naik\\\\n\\\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\\\n\\\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. \ud83d\udc4f\\\\n\\\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\\\n\\\\nJerry Liu\\\\n\\\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\\\n\\\\nFirecrawl is awesome \ud83d\udd25 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\\\n\\\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\\\n\\\\nBardia Pourvakil\\\\n\\\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\\\n\\\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\\\'t recommend them enough.\\\\n\\\\n![latentsauce \ud83e\uddd8\ud83c\udffd](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\\\n\\\\nlatentsauce \ud83e\uddd8\ud83c\udffd\\\\n\\\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\\\n\\\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f\\\\n\\\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\\\n\\\\nMichael Ning\\\\n\\\\n[](#)\\\\n\\\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\\\n\\\\n![Alex Reibman \ud83d\udd87\ufe0f](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\\\n\\\\nAlex Reibman \ud83d\udd87\ufe0f\\\\n\\\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\\\n\\\\nMoved our internal agent\\\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\\\n\\\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\\\n\\\\nMichael\\\\n\\\\n[@michael\\\\\\\\_chomsky](#)\\\\n\\\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\\\n\\\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\\\n\\\\nPaul Scott\\\\n\\\\n[@palebluepaul](https://twitter.com/palebluepaul)\\\\n\\\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\\\n\\\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\\\n\\\\nMichael Ning\\\\n\\\\n[](#)\\\\n\\\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\\\n\\\\n![Alex Reibman \ud83d\udd87\ufe0f](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\\\n\\\\nAlex Reibman \ud83d\udd87\ufe0f\\\\n\\\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\\\n\\\\nMoved our internal agent\\\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\\\n\\\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\\\n\\\\nMichael\\\\n\\\\n[@michael\\\\\\\\_chomsky](#)\\\\n\\\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\\\n\\\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\\\n\\\\nPaul Scott\\\\n\\\\n[@palebluepaul](https://twitter.com/palebluepaul)\\\\n\\\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\\\n\\\\nFlexible Pricing\\\\n----------------\\\\n\\\\nStart for free, then scale as you grow\\\\n\\\\nYearly (17% off)Yearly (2 months free)Monthly\\\\n\\\\nFree Plan\\\\n---------\\\\n\\\\n500 credits\\\\n\\\\n$0/month\\\\n\\\\n*   Scrape 500 pages\\\\n*   5 /scrape per min\\\\n*   1 /crawl per min\\\\n\\\\nGet Started\\\\n\\\\nHobby\\\\n-----\\\\n\\\\n3,000 credits\\\\n\\\\n$16/month\\\\n\\\\n*   Scrape 3,000 pages\\\\n*   10 /scrape per min\\\\n*   3 /crawl per min\\\\n\\\\nSubscribe\\\\n\\\\nStandardMost Popular\\\\n--------------------\\\\n\\\\n100,000 credits\\\\n\\\\n$83/month\\\\n\\\\n*   Scrape 100,000 pages\\\\n*   50 /scrape per min\\\\n*   10 /crawl per min\\\\n\\\\nSubscribe\\\\n\\\\nGrowth\\\\n------\\\\n\\\\n500,000 credits\\\\n\\\\n$333/month\\\\n\\\\n*   Scrape 500,000 pages\\\\n*   500 /scrape per min\\\\n*   50 /crawl per min\\\\n*   Priority Support\\\\n\\\\nSubscribe\\\\n\\\\nEnterprise Plan\\\\n---------------\\\\n\\\\nUnlimited credits. Custom RPMs.\\\\n\\\\nTalk to us\\\\n\\\\n*   Top priority support\\\\n*   Feature Acceleration\\\\n*   SLAs\\\\n*   Account Manager\\\\n*   Custom rate limits volume\\\\n*   Custom concurrency limits\\\\n*   Beta features access\\\\n*   CEO\\\\'s number\\\\n\\\\n\\\\\\\\* a /scrape refers to the [scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)\\\\n API endpoint.\\\\n\\\\n\\\\\\\\* a /crawl refers to the [crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl)\\\\n API endpoint.\\\\n\\\\nScrape Credits\\\\n--------------\\\\n\\\\nScrape credits are consumed for each API request, varying by endpoint and feature.\\\\n\\\\n| Features | Credits per page |\\\\n| --- | --- |\\\\n| Scrape(/scrape) | 1   |\\\\n| Crawl(/crawl) | 1   |\\\\n| Search(/search) | 1   |\\\\n| Scrape + LLM extraction (/scrape) | 50  |\\\\n\\\\n[\ud83d\udd25](/)\\\\n\\\\nReady to _Build?_\\\\n-----------------\\\\n\\\\nStart scraping web data for your AI apps today.  \\\\nNo credit card needed.\\\\n\\\\n[Get Started](/signin)\\\\n\\\\n[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\\\n\\\\nFAQ\\\\n---\\\\n\\\\nFrequently asked questions about Firecrawl\\\\n\\\\n#### General\\\\n\\\\nWhat is Firecrawl?\\\\n\\\\nFirecrawl turns entire websites into clean, LLM-ready markdown or structured data. Scrape, crawl and extract the web with a single API. Ideal for AI companies looking to empower their LLM applications with web data.\\\\n\\\\nWhat sites work?\\\\n\\\\nFirecrawl is best suited for business websites, docs and help centers. We currently don\\\\'t support social media platforms.\\\\n\\\\nWho can benefit from using Firecrawl?\\\\n\\\\nFirecrawl is tailored for LLM engineers, data scientists, AI researchers, and developers looking to harness web data for training machine learning models, market research, content aggregation, and more. It simplifies the data preparation process, allowing professionals to focus on insights and model development.\\\\n\\\\nIs Firecrawl open-source?\\\\n\\\\nYes, it is. You can check out the repository on GitHub. Keep in mind that this repository is currently in its early stages of development. We are in the process of merging custom modules into this mono repository.\\\\n\\\\n#### Scraping & Crawling\\\\n\\\\nHow does Firecrawl handle dynamic content on websites?\\\\n\\\\nUnlike traditional web scrapers, Firecrawl is equipped to handle dynamic content rendered with JavaScript. It ensures comprehensive data collection from all accessible subpages, making it a reliable tool for scraping websites that rely heavily on JS for content delivery.\\\\n\\\\nWhy is it not crawling all the pages?\\\\n\\\\nThere are a few reasons why Firecrawl may not be able to crawl all the pages of a website. Some common reasons include rate limiting, and anti-scraping mechanisms, disallowing the crawler from accessing certain pages. If you\\\\'re experiencing issues with the crawler, please reach out to our support team at hello@firecrawl.com.\\\\n\\\\nCan Firecrawl crawl websites without a sitemap?\\\\n\\\\nYes, Firecrawl can access and crawl all accessible subpages of a website, even in the absence of a sitemap. This feature enables users to gather data from a wide array of web sources with minimal setup.\\\\n\\\\nWhat formats can Firecrawl convert web data into?\\\\n\\\\nFirecrawl specializes in converting web data into clean, well-formatted markdown. This format is particularly suited for LLM applications, offering a structured yet flexible way to represent web content.\\\\n\\\\nHow does Firecrawl ensure the cleanliness of the data?\\\\n\\\\nFirecrawl employs advanced algorithms to clean and structure the scraped data, removing unnecessary elements and formatting the content into readable markdown. This process ensures that the data is ready for use in LLM applications without further preprocessing.\\\\n\\\\nIs Firecrawl suitable for large-scale data scraping projects?\\\\n\\\\nAbsolutely. Firecrawl offers various pricing plans, including a Scale plan that supports scraping of millions of pages. With features like caching and scheduled syncs, it\\\\'s designed to efficiently handle large-scale data scraping and continuous updates, making it ideal for enterprises and large projects.\\\\n\\\\nDoes it respect robots.txt?\\\\n\\\\nYes, Firecrawl crawler respects the rules set in a website\\\\'s robots.txt file. If you notice any issues with the way Firecrawl interacts with your website, you can adjust the robots.txt file to control the crawler\\\\'s behavior. Firecrawl user agent name is \\\\'FirecrawlAgent\\\\'. If you notice any behavior that is not expected, please let us know at hello@firecrawl.com.\\\\n\\\\nWhat measures does Firecrawl take to handle web scraping challenges like rate limits and caching?\\\\n\\\\nFirecrawl is built to navigate common web scraping challenges, including reverse proxies, rate limits, and caching. It smartly manages requests and employs caching techniques to minimize bandwidth usage and avoid triggering anti-scraping mechanisms, ensuring reliable data collection.\\\\n\\\\nDoes Firecrawl handle captcha or authentication?\\\\n\\\\nFirecrawl avoids captcha by using stealth proxyies. When it encounters captcha, it attempts to solve it automatically, but this is not always possible. We are working to add support for more captcha solving methods. Firecrawl can handle authentication by providing auth headers to the API.\\\\n\\\\n#### API Related\\\\n\\\\nWhere can I find my API key?\\\\n\\\\nClick on the dashboard button on the top navigation menu when logged in and you will find your API key in the main screen and under API Keys.\\\\n\\\\n#### Billing\\\\n\\\\nIs Firecrawl free?\\\\n\\\\nFirecrawl is free for the first 500 scraped pages (500 free credits). After that, you can upgrade to our Standard or Scale plans for more credits.\\\\n\\\\nIs there a pay per use plan instead of monthly?\\\\n\\\\nNo we do not currently offer a pay per use plan, instead you can upgrade to our Standard or Growth plans for more credits and higher rate limits.\\\\n\\\\nHow many credit does scraping, crawling, and extraction cost?\\\\n\\\\nScraping costs 1 credit per page. Crawling costs 1 credit per page.\\\\n\\\\nDo you charge for failed requests (scrape, crawl, extract)?\\\\n\\\\nWe do not charge for any failed requests (scrape, crawl, extract). Please contact support at help@firecrawl.dev if you have any questions.\\\\n\\\\nWhat payment methods do you accept?\\\\n\\\\nWe accept payments through Stripe which accepts most major credit cards, debit cards, and PayPal.\\\\n\\\\n[\ud83d\udd25](/)\\\\n\\\\n\u00a9 A product by Mendable.ai - All rights reserved.\\\\n\\\\n[StatusStatus](https://firecrawl.betteruptime.com)\\\\n[Terms of ServiceTerms of Service](/terms-of-service)\\\\n[Privacy PolicyPrivacy Policy](/privacy-policy)\\\\n\\\\n[Twitter](https://twitter.com/mendableai)\\\\n[GitHub](https://github.com/mendableai)\\\\n[Discord](https://discord.gg/gSmWdAkdwd)\\\\n\\\\n###### Helpful Links\\\\n\\\\n*   [Status](https://firecrawl.betteruptime.com/)\\\\n    \\\\n*   [Pricing](/pricing)\\\\n    \\\\n*   [Blog](https://www.firecrawl.dev/blog)\\\\n    \\\\n*   [Docs](https://docs.firecrawl.dev)\\\\n    \\\\n\\\\nBacked by![Y Combinator Logo](https://www.firecrawl.dev/images/yc.svg)\\\\n\\\\n![SOC 2 Type II](https://www.firecrawl.dev/soc2type2badge.png)\\\\n\\\\n###### Resources\\\\n\\\\n*   [Community](#0)\\\\n    \\\\n*   [Terms of service](#0)\\\\n    \\\\n*   [Collaboration features](#0)\\\\n    \\\\n\\\\n###### Legals\\\\n\\\\n*   [Refund policy](#0)\\\\n    \\\\n*   [Terms & Conditions](#0)\\\\n    \\\\n*   [Privacy policy](#0)\\\\n    \\\\n*   [Brand Kit](#0)')\"\n+       \"Document(metadata={'ogUrl': 'https://www.firecrawl.dev/', 'title': 'Home - Firecrawl', 'robots': 'follow, index', 'ogImage': 'https://www.firecrawl.dev/og.png?123', 'ogTitle': 'Firecrawl', 'sitemap': {'lastmod': '2024-08-12T00:28:16.681Z', 'changefreq': 'weekly'}, 'keywords': 'Firecrawl,Markdown,Data,Mendable,Langchain', 'sourceURL': 'https://www.firecrawl.dev/', 'ogSiteName': 'Firecrawl', 'description': 'Firecrawl crawls and converts any website into clean markdown.', 'ogDescription': 'Turn any website into LLM-ready data.', 'pageStatusCode': 200, 'ogLocaleAlternate': []}, page_content='Introducing [Smart Crawl!](https://www.firecrawl.dev/smart-crawl)\\\\n Join the waitlist to turn any website into an API with AI\\\\n\\\\n\\\\n\\\\n[\ud83d\udd25 Firecrawl](/)\\\\n\\\\n*   [Playground](/playground)\\\\n    \\\\n*   [Docs](https://docs.firecrawl.dev)\\\\n    \\\\n*   [Pricing](/pricing)\\\\n    \\\\n*   [Blog](/blog)\\\\n    \\\\n*   Beta Features\\\\n\\\\n[Log In](/signin)\\\\n[Log In](/signin)\\\\n[Sign Up](/signin/signup)\\\\n 8.9k\\\\n\\\\n[\ud83d\udca5 Get 2 months free with yearly plan](/pricing)\\\\n\\\\nTurn websites into  \\\\n_LLM-ready_ data\\\\n=====================================\\\\n\\\\nPower your AI apps with clean data crawled from any website. It\\\\'s also open-source.\\\\n\\\\nStart for free (500 credits)Start for free[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\\\n\\\\nA product by\\\\n\\\\n[![Mendable Logo](https://www.firecrawl.dev/images/mendable_logo_transparent.png)Mendable](https://mendable.ai)\\\\n\\\\n![Example Webpage](https://www.firecrawl.dev/multiple-websites.png)\\\\n\\\\nCrawl, Scrape, Clean\\\\n--------------------\\\\n\\\\nWe crawl all accessible subpages and give you clean markdown for each. No sitemap required.\\\\n\\\\n    \\\\n      [\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## Welcome to Firecrawl\\\\\\\\\\\\n            Firecrawl is a web scraper that allows you to extract the content of a webpage.\\\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/features\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## Features\\\\\\\\\\\\n            Discover how Firecrawl\\\\'s cutting-edge features can \\\\\\\\\\\\n            transform your data operations.\\\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/pricing\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## Pricing Plans\\\\\\\\\\\\n            Choose the perfect plan that fits your needs.\\\"\\\\\\\\\\\\n        },\\\\\\\\\\\\n        {\\\\\\\\\\\\n          \\\"url\\\": \\\"https://www.firecrawl.dev/about\\\",\\\\\\\\\\\\n          \\\"markdown\\\": \\\"## About Us\\\\\\\\\\\\n            Learn more about Firecrawl\\\\'s mission and the \\\\\\\\\\\\n            team behind our innovative platform.\\\"\\\\\\\\\\\\n        }\\\\\\\\\\\\n      ]\\\\n      \\\\n\\\\nNote: The markdown has been edited for display purposes.\\\\n\\\\nTrusted by Top Companies\\\\n------------------------\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/zapier.png)](https://www.zapier.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/gamma.svg)](https://gamma.app)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/nvidia-com.png)](https://www.nvidia.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/teller-io.svg)](https://www.teller.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/stackai.svg)](https://www.stack-ai.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/palladiumdigital-co-uk.svg)](https://www.palladiumdigital.co.uk)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/worldwide-casting-com.svg)](https://www.worldwide-casting.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/open-gov-sg.png)](https://www.open.gov.sg)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/bain-com.svg)](https://www.bain.com)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/demand-io.svg)](https://www.demand.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/nocodegarden-io.png)](https://www.nocodegarden.io)\\\\n\\\\n[![Customer Logo](https://www.firecrawl.dev/logos/cyberagent-co-jp.svg)](https://www.cyberagent.co.jp)\\\\n\\\\nIntegrate today\\\\n---------------\\\\n\\\\nEnhance your applications with top-tier web scraping and crawling capabilities.\\\\n\\\\n#### Scrape\\\\n\\\\nExtract markdown or structured data from websites quickly and efficiently.\\\\n\\\\n#### Crawling\\\\n\\\\nNavigate and retrieve data from all accessible subpages, even without a sitemap.\\\\n\\\\nNode.js\\\\n\\\\nPython\\\\n\\\\ncURL\\\\n\\\\n1\\\\n\\\\n2\\\\n\\\\n3\\\\n\\\\n4\\\\n\\\\n5\\\\n\\\\n6\\\\n\\\\n7\\\\n\\\\n8\\\\n\\\\n9\\\\n\\\\n10\\\\n\\\\n// npm install @mendable/firecrawl-js  \\\\n  \\\\nimport FirecrawlApp from \\\\'@mendable/firecrawl-js\\\\';  \\\\n  \\\\nconst app \\\\\\\\= new FirecrawlApp({ apiKey: \\\"fc-YOUR\\\\\\\\_API\\\\\\\\_KEY\\\" });  \\\\n  \\\\n// Scrape a website:  \\\\nconst scrapeResult \\\\\\\\= await app.scrapeUrl(\\\\'firecrawl.dev\\\\');  \\\\n  \\\\nconsole.log(scrapeResult.data.markdown)\\\\n\\\\n#### Use well-known tools\\\\n\\\\nAlready fully integrated with the greatest existing tools and workflows.\\\\n\\\\n[![LlamaIndex](https://www.firecrawl.dev/logos/llamaindex.svg)](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/#using-firecrawl-reader/)\\\\n[![Langchain](https://www.firecrawl.dev/integrations/langchain.png)](https://python.langchain.com/docs/integrations/document_loaders/firecrawl/)\\\\n[![Dify](https://www.firecrawl.dev/logos/dify.png)](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl/)\\\\n[![Dify](https://www.firecrawl.dev/integrations/langflow_2.png)](https://www.langflow.org/)\\\\n[![Flowise](https://www.firecrawl.dev/integrations/flowise.png)](https://flowiseai.com/)\\\\n[![CrewAI](https://www.firecrawl.dev/integrations/crewai.png)](https://crewai.com/)\\\\n\\\\n#### Start for free, scale easily\\\\n\\\\nKick off your journey for free and scale seamlessly as your project expands.\\\\n\\\\n[Try it out](/signin/signup)\\\\n\\\\n#### Open-source\\\\n\\\\nDeveloped transparently and collaboratively. Join our community of contributors.\\\\n\\\\n[Check out our repo](https://github.com/mendableai/firecrawl)\\\\n\\\\nWe handle the hard stuff\\\\n------------------------\\\\n\\\\nRotating proxies, caching, rate limits, js-blocked content and more\\\\n\\\\n#### Crawling\\\\n\\\\nFirecrawl crawls all accessible subpages, even without a sitemap.\\\\n\\\\n#### Dynamic content\\\\n\\\\nFirecrawl gathers data even if a website uses javascript to render content.\\\\n\\\\n#### To Markdown\\\\n\\\\nFirecrawl returns clean, well formatted markdown - ready for use in LLM applications\\\\n\\\\n#### Crawling Orchestration\\\\n\\\\nFirecrawl orchestrates the crawling process in parallel for the fastest results.\\\\n\\\\n#### Caching\\\\n\\\\nFirecrawl caches content, so you don\\\\'t have to wait for a full scrape unless new content exists.\\\\n\\\\n#### Built for AI\\\\n\\\\nBuilt by LLM engineers, for LLM engineers. Giving you clean data the way you want it.\\\\n\\\\nOur wall of love\\\\n\\\\nDon\\\\'t take our word for it\\\\n--------------------------\\\\n\\\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\\\n\\\\nGreg Kamradt\\\\n\\\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\\\n\\\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\\\n\\\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\\\n\\\\nAmit Naik\\\\n\\\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\\\n\\\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. \ud83d\udc4f\\\\n\\\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\\\n\\\\nJerry Liu\\\\n\\\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\\\n\\\\nFirecrawl is awesome \ud83d\udd25 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\\\n\\\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\\\n\\\\nBardia Pourvakil\\\\n\\\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\\\n\\\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\\\'t recommend them enough.\\\\n\\\\n![latentsauce \ud83e\uddd8\ud83c\udffd](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\\\n\\\\nlatentsauce \ud83e\uddd8\ud83c\udffd\\\\n\\\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\\\n\\\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f\\\\n\\\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\\\n\\\\nGreg Kamradt\\\\n\\\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\\\n\\\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\\\n\\\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\\\n\\\\nAmit Naik\\\\n\\\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\\\n\\\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. \ud83d\udc4f\\\\n\\\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\\\n\\\\nJerry Liu\\\\n\\\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\\\n\\\\nFirecrawl is awesome \ud83d\udd25 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\\\n\\\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\\\n\\\\nBardia Pourvakil\\\\n\\\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\\\n\\\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\\\'t recommend them enough.\\\\n\\\\n![latentsauce \ud83e\uddd8\ud83c\udffd](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\\\n\\\\nlatentsauce \ud83e\uddd8\ud83c\udffd\\\\n\\\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\\\n\\\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl \u2764\ufe0f\u2764\ufe0f\u2764\ufe0f\\\\n\\\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\\\n\\\\nMichael Ning\\\\n\\\\n[](#)\\\\n\\\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\\\n\\\\n![Alex Reibman \ud83d\udd87\ufe0f](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\\\n\\\\nAlex Reibman \ud83d\udd87\ufe0f\\\\n\\\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\\\n\\\\nMoved our internal agent\\\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\\\n\\\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\\\n\\\\nMichael\\\\n\\\\n[@michael\\\\\\\\_chomsky](#)\\\\n\\\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\\\n\\\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\\\n\\\\nPaul Scott\\\\n\\\\n[@palebluepaul](https://twitter.com/palebluepaul)\\\\n\\\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\\\n\\\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\\\n\\\\nMichael Ning\\\\n\\\\n[](#)\\\\n\\\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\\\n\\\\n![Alex Reibman \ud83d\udd87\ufe0f](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\\\n\\\\nAlex Reibman \ud83d\udd87\ufe0f\\\\n\\\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\\\n\\\\nMoved our internal agent\\\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\\\n\\\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\\\n\\\\nMichael\\\\n\\\\n[@michael\\\\\\\\_chomsky](#)\\\\n\\\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\\\n\\\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\\\n\\\\nPaul Scott\\\\n\\\\n[@palebluepaul](https://twitter.com/palebluepaul)\\\\n\\\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\\\n\\\\nFlexible Pricing\\\\n----------------\\\\n\\\\nStart for free, then scale as you grow\\\\n\\\\nYearly (17% off)Yearly (2 months free)Monthly\\\\n\\\\nFree Plan\\\\n---------\\\\n\\\\n500 credits\\\\n\\\\n$0/month\\\\n\\\\n*   Scrape 500 pages\\\\n*   5 /scrape per min\\\\n*   1 /crawl per min\\\\n\\\\nGet Started\\\\n\\\\nHobby\\\\n-----\\\\n\\\\n3,000 credits\\\\n\\\\n$16/month\\\\n\\\\n*   Scrape 3,000 pages\\\\n*   10 /scrape per min\\\\n*   3 /crawl per min\\\\n\\\\nSubscribe\\\\n\\\\nStandardMost Popular\\\\n--------------------\\\\n\\\\n100,000 credits\\\\n\\\\n$83/month\\\\n\\\\n*   Scrape 100,000 pages\\\\n*   50 /scrape per min\\\\n*   10 /crawl per min\\\\n\\\\nSubscribe\\\\n\\\\nGrowth\\\\n------\\\\n\\\\n500,000 credits\\\\n\\\\n$333/month\\\\n\\\\n*   Scrape 500,000 pages\\\\n*   500 /scrape per min\\\\n*   50 /crawl per min\\\\n*   Priority Support\\\\n\\\\nSubscribe\\\\n\\\\nEnterprise Plan\\\\n---------------\\\\n\\\\nUnlimited credits. Custom RPMs.\\\\n\\\\nTalk to us\\\\n\\\\n*   Top priority support\\\\n*   Feature Acceleration\\\\n*   SLAs\\\\n*   Account Manager\\\\n*   Custom rate limits volume\\\\n*   Custom concurrency limits\\\\n*   Beta features access\\\\n*   CEO\\\\'s number\\\\n\\\\n\\\\\\\\* a /scrape refers to the [scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)\\\\n API endpoint.\\\\n\\\\n\\\\\\\\* a /crawl refers to the [crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl)\\\\n API endpoint.\\\\n\\\\nScrape Credits\\\\n--------------\\\\n\\\\nScrape credits are consumed for each API request, varying by endpoint and feature.\\\\n\\\\n| Features | Credits per page |\\\\n| --- | --- |\\\\n| Scrape(/scrape) | 1   |\\\\n| Crawl(/crawl) | 1   |\\\\n| Search(/search) | 1   |\\\\n| Scrape + LLM extraction (/scrape) | 50  |\\\\n\\\\n[\ud83d\udd25](/)\\\\n\\\\nReady to _Build?_\\\\n-----------------\\\\n\\\\nStart scraping web data for your AI apps today.  \\\\nNo credit card needed.\\\\n\\\\n[Get Started](/signin)\\\\n\\\\n[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\\\n\\\\nFAQ\\\\n---\\\\n\\\\nFrequently asked questions about Firecrawl\\\\n\\\\n#### General\\\\n\\\\nWhat is Firecrawl?\\\\n\\\\nFirecrawl turns entire websites into clean, LLM-ready markdown or structured data. Scrape, crawl and extract the web with a single API. Ideal for AI companies looking to empower their LLM applications with web data.\\\\n\\\\nWhat sites work?\\\\n\\\\nFirecrawl is best suited for business websites, docs and help centers. We currently don\\\\'t support social media platforms.\\\\n\\\\nWho can benefit from using Firecrawl?\\\\n\\\\nFirecrawl is tailored for LLM engineers, data scientists, AI researchers, and developers looking to harness web data for training machine learning models, market research, content aggregation, and more. It simplifies the data preparation process, allowing professionals to focus on insights and model development.\\\\n\\\\nIs Firecrawl open-source?\\\\n\\\\nYes, it is. You can check out the repository on GitHub. Keep in mind that this repository is currently in its early stages of development. We are in the process of merging custom modules into this mono repository.\\\\n\\\\n#### Scraping & Crawling\\\\n\\\\nHow does Firecrawl handle dynamic content on websites?\\\\n\\\\nUnlike traditional web scrapers, Firecrawl is equipped to handle dynamic content rendered with JavaScript. It ensures comprehensive data collection from all accessible subpages, making it a reliable tool for scraping websites that rely heavily on JS for content delivery.\\\\n\\\\nWhy is it not crawling all the pages?\\\\n\\\\nThere are a few reasons why Firecrawl may not be able to crawl all the pages of a website. Some common reasons include rate limiting, and anti-scraping mechanisms, disallowing the crawler from accessing certain pages. If you\\\\'re experiencing issues with the crawler, please reach out to our support team at hello@firecrawl.com.\\\\n\\\\nCan Firecrawl crawl websites without a sitemap?\\\\n\\\\nYes, Firecrawl can access and crawl all accessible subpages of a website, even in the absence of a sitemap. This feature enables users to gather data from a wide array of web sources with minimal setup.\\\\n\\\\nWhat formats can Firecrawl convert web data into?\\\\n\\\\nFirecrawl specializes in converting web data into clean, well-formatted markdown. This format is particularly suited for LLM applications, offering a structured yet flexible way to represent web content.\\\\n\\\\nHow does Firecrawl ensure the cleanliness of the data?\\\\n\\\\nFirecrawl employs advanced algorithms to clean and structure the scraped data, removing unnecessary elements and formatting the content into readable markdown. This process ensures that the data is ready for use in LLM applications without further preprocessing.\\\\n\\\\nIs Firecrawl suitable for large-scale data scraping projects?\\\\n\\\\nAbsolutely. Firecrawl offers various pricing plans, including a Scale plan that supports scraping of millions of pages. With features like caching and scheduled syncs, it\\\\'s designed to efficiently handle large-scale data scraping and continuous updates, making it ideal for enterprises and large projects.\\\\n\\\\nDoes it respect robots.txt?\\\\n\\\\nYes, Firecrawl crawler respects the rules set in a website\\\\'s robots.txt file. If you notice any issues with the way Firecrawl interacts with your website, you can adjust the robots.txt file to control the crawler\\\\'s behavior. Firecrawl user agent name is \\\\'FirecrawlAgent\\\\'. If you notice any behavior that is not expected, please let us know at hello@firecrawl.com.\\\\n\\\\nWhat measures does Firecrawl take to handle web scraping challenges like rate limits and caching?\\\\n\\\\nFirecrawl is built to navigate common web scraping challenges, including reverse proxies, rate limits, and caching. It smartly manages requests and employs caching techniques to minimize bandwidth usage and avoid triggering anti-scraping mechanisms, ensuring reliable data collection.\\\\n\\\\nDoes Firecrawl handle captcha or authentication?\\\\n\\\\nFirecrawl avoids captcha by using stealth proxyies. When it encounters captcha, it attempts to solve it automatically, but this is not always possible. We are working to add support for more captcha solving methods. Firecrawl can handle authentication by providing auth headers to the API.\\\\n\\\\n#### API Related\\\\n\\\\nWhere can I find my API key?\\\\n\\\\nClick on the dashboard button on the top navigation menu when logged in and you will find your API key in the main screen and under API Keys.\\\\n\\\\n#### Billing\\\\n\\\\nIs Firecrawl free?\\\\n\\\\nFirecrawl is free for the first 500 scraped pages (500 free credits). After that, you can upgrade to our Standard or Scale plans for more credits.\\\\n\\\\nIs there a pay per use plan instead of monthly?\\\\n\\\\nNo we do not currently offer a pay per use plan, instead you can upgrade to our Standard or Growth plans for more credits and higher rate limits.\\\\n\\\\nHow many credit does scraping, crawling, and extraction cost?\\\\n\\\\nScraping costs 1 credit per page. Crawling costs 1 credit per page.\\\\n\\\\nDo you charge for failed requests (scrape, crawl, extract)?\\\\n\\\\nWe do not charge for any failed requests (scrape, crawl, extract). Please contact support at help@firecrawl.dev if you have any questions.\\\\n\\\\nWhat payment methods do you accept?\\\\n\\\\nWe accept payments through Stripe which accepts most major credit cards, debit cards, and PayPal.\\\\n\\\\n[\ud83d\udd25](/)\\\\n\\\\n\u00a9 A product by Mendable.ai - All rights reserved.\\\\n\\\\n[StatusStatus](https://firecrawl.betteruptime.com)\\\\n[Terms of ServiceTerms of Service](/terms-of-service)\\\\n[Privacy PolicyPrivacy Policy](/privacy-policy)\\\\n\\\\n[Twitter](https://twitter.com/mendableai)\\\\n[GitHub](https://github.com/mendableai)\\\\n[Discord](https://discord.gg/gSmWdAkdwd)\\\\n\\\\n###### Helpful Links\\\\n\\\\n*   [Status](https://firecrawl.betteruptime.com/)\\\\n    \\\\n*   [Pricing](/pricing)\\\\n    \\\\n*   [Blog](https://www.firecrawl.dev/blog)\\\\n    \\\\n*   [Docs](https://docs.firecrawl.dev)\\\\n    \\\\n\\\\nBacked by![Y Combinator Logo](https://www.firecrawl.dev/images/yc.svg)\\\\n\\\\n![SOC 2 Type II](https://www.firecrawl.dev/soc2type2badge.png)\\\\n\\\\n###### Resources\\\\n\\\\n*   [Community](#0)\\\\n    \\\\n*   [Terms of service](#0)\\\\n    \\\\n*   [Collaboration features](#0)\\\\n    \\\\n\\\\n###### Legals\\\\n\\\\n*   [Refund policy](#0)\\\\n    \\\\n*   [Terms & Conditions](#0)\\\\n    \\\\n*   [Privacy policy](#0)\\\\n    \\\\n*   [Brand Kit](#0)')\"\n       ]\n      },\n      \"execution_count\": 4,\n@@ -214,7 +214,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `FireCrawlLoader` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.firecrawl.FireCrawlLoader.html\"\n+    \"For detailed documentation of all `FireCrawlLoader` features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.firecrawl.FireCrawlLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/json.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -6,16 +6,16 @@\n    \"source\": [\n     \"# JSONLoader\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\\n\",\n     \"\\n\",\n     \"- TODO: Add any other relevant links, like information about underlying API, etc.\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/json/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/file_loaders/json/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [JSONLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n+    \"| [JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -320,7 +320,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all JSONLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html\"\n+    \"For detailed documentation of all JSONLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/langsmith.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -15,14 +15,14 @@\n    \"source\": [\n     \"# LangSmithLoader\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with the LangSmith [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all LangSmithLoader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/core/document_loaders/langchain_core.document_loaders.langsmith.LangSmithLoader.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with the LangSmith [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all LangSmithLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/core/document_loaders/langchain_core.document_loaders.langsmith.LangSmithLoader.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [LangSmithLoader](https://python.langchain.com/v0.2/api_reference/core/document_loaders/langchain_core.document_loaders.langsmith.LangSmithLoader.html) | [langchain-core](https://python.langchain.com/v0.2/api_reference/core/index.html) | \u274c | \u274c | \u274c | \\n\",\n+    \"| [LangSmithLoader](https://python.langchain.com/api_reference/core/document_loaders/langchain_core.document_loaders.langsmith.LangSmithLoader.html) | [langchain-core](https://python.langchain.com/api_reference/core/index.html) | \u274c | \u274c | \u274c | \\n\",\n     \"\\n\",\n     \"### Loader features\\n\",\n     \"| Source | Lazy loading | Native async\\n\",\n@@ -266,7 +266,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all LangSmithLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/core/document_loaders/langchain_core.document_loaders.langsmith.LangSmithLoader.html\"\n+    \"For detailed documentation of all LangSmithLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/core/document_loaders/langchain_core.document_loaders.langsmith.LangSmithLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/mathpix.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -13,7 +13,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [MathPixPDFLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.MathpixPDFLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [MathPixPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.MathpixPDFLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -150,7 +150,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all MathpixPDFLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.MathpixPDFLoader.html\"\n+    \"For detailed documentation of all MathpixPDFLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.MathpixPDFLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/pdfminer.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -12,7 +12,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [PDFMinerLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [PDFMinerLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -289,7 +289,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all PDFMinerLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html\"\n+    \"For detailed documentation of all PDFMinerLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFMinerLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/pdfplumber.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -13,7 +13,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [PDFPlumberLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [PDFPlumberLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -155,7 +155,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all PDFPlumberLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html\"\n+    \"For detailed documentation of all PDFPlumberLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/pymupdf.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -13,7 +13,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [PyMuPDFLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [PyMuPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -157,7 +157,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all PyMuPDFLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html\"\n+    \"For detailed documentation of all PyMuPDFLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/pypdfdirectory.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -14,7 +14,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [PyPDFDirectoryLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFDirectoryLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [PyPDFDirectoryLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFDirectoryLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -159,7 +159,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all PyPDFDirectoryLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFDirectoryLoader.html\"\n+    \"For detailed documentation of all PyPDFDirectoryLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFDirectoryLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/pypdfium2.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -7,14 +7,14 @@\n     \"# PyPDFium2Loader\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with PyPDFium2 [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with PyPDFium2 [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [PyPDFium2Loader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [PyPDFium2Loader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -160,7 +160,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all PyPDFium2Loader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html\"\n+    \"For detailed documentation of all PyPDFium2Loader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/pypdfloader.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -6,7 +6,7 @@\n    \"source\": [\n     \"# PyPDFLoader\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with `PyPDF` [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all DocumentLoader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with `PyPDF` [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all DocumentLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html).\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n@@ -15,7 +15,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [PyPDFLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [PyPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -174,7 +174,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `PyPDFLoader` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html\"\n+    \"For detailed documentation of all `PyPDFLoader` features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/recursive_url.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -12,9 +12,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/web_loaders/recursive_url_loader/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/recursive_url_loader/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [RecursiveUrlLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n+    \"| [RecursiveUrlLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -314,7 +314,7 @@\n    \"source\": [\n     \"This looks much nicer!\\n\",\n     \"\\n\",\n-    \"You can similarly pass in a `metadata_extractor` to customize how Document metadata is extracted from the HTTP response. See the [API reference](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html) for more on this.\"\n+    \"You can similarly pass in a `metadata_extractor` to customize how Document metadata is extracted from the HTTP response. See the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html) for more on this.\"\n    ]\n   },\n   {\n@@ -326,7 +326,7 @@\n     \"\\n\",\n     \"These examples show just a few of the ways in which you can modify the default `RecursiveUrlLoader`, but there are many more modifications that can be made to best fit your use case. Using the parameters `link_regex` and `exclude_dirs` can help you filter out unwanted URLs, `aload()` and `alazy_load()` can be used for aynchronous loading, and more.\\n\",\n     \"\\n\",\n-    \"For detailed information on configuring and calling the ``RecursiveUrlLoader``, please see the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html.\"\n+    \"For detailed information on configuring and calling the ``RecursiveUrlLoader``, please see the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.recursive_url_loader.RecursiveUrlLoader.html.\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/scrapingant.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -18,7 +18,7 @@\n     \"\\n\",\n     \"| Class                                                                                                                                                    | Package                                                                                        | Local | Serializable | JS support |\\n\",\n     \"|:---------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------|:-----:|:------------:|:----------:|\\n\",\n-    \"| [ScrapingAntLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.scrapingant.ScrapingAntLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) |   \u274c   |      \u274c       |     \u274c      | \\n\",\n+    \"| [ScrapingAntLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.scrapingant.ScrapingAntLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) |   \u274c   |      \u274c       |     \u274c      | \\n\",\n     \"\\n\",\n     \"### Loader features\\n\",\n     \"|      Source       | Document Lazy Loading | Async Support |\\n\","
        },
        {
          "filename": "docs/docs/integrations/document_loaders/sitemap.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -13,9 +13,9 @@\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/web_loaders/sitemap/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/sitemap/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [SiteMapLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.sitemap.SitemapLoader.html#langchain_community.document_loaders.sitemap.SitemapLoader) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n+    \"| [SiteMapLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.sitemap.SitemapLoader.html#langchain_community.document_loaders.sitemap.SitemapLoader) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -352,7 +352,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all SiteMapLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.sitemap.SitemapLoader.html#langchain_community.document_loaders.sitemap.SitemapLoader\"\n+    \"For detailed documentation of all SiteMapLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.sitemap.SitemapLoader.html#langchain_community.document_loaders.sitemap.SitemapLoader\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/unstructured_file.ipynb",
          "status": "modified",
          "additions": 8,
          "deletions": 7,
          "patch": "@@ -7,16 +7,16 @@\n    \"source\": [\n     \"# Unstructured\\n\",\n     \"\\n\",\n-    \"This notebook covers how to use `Unstructured` [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders) to load files of many types. `Unstructured` currently supports loading of text files, powerpoints, html, pdfs, images, and more.\\n\",\n+    \"This notebook covers how to use `Unstructured` [document loader](https://python.langchain.com/docs/concepts/#document-loaders) to load files of many types. `Unstructured` currently supports loading of text files, powerpoints, html, pdfs, images, and more.\\n\",\n     \"\\n\",\n     \"Please see [this guide](../../integrations/providers/unstructured.mdx) for more instructions on setting up Unstructured locally, including setting up required system dependencies.\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [UnstructuredLoader](https://python.langchain.com/v0.2/api_reference/unstructured/document_loaders/langchain_unstructured.document_loaders.UnstructuredLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/unstructured/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n+    \"| [UnstructuredLoader](https://python.langchain.com/api_reference/unstructured/document_loaders/langchain_unstructured.document_loaders.UnstructuredLoader.html) | [langchain_community](https://python.langchain.com/api_reference/unstructured/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -39,9 +39,10 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"UNSTRUCTURED_API_KEY\\\"] = getpass.getpass(\\n\",\n-    \"    \\\"Enter your Unstructured API key: \\\"\\n\",\n-    \")\"\n+    \"if \\\"UNSTRUCTURED_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"UNSTRUCTURED_API_KEY\\\"] = getpass.getpass(\\n\",\n+    \"        \\\"Enter your Unstructured API key: \\\"\\n\",\n+    \"    )\"\n    ]\n   },\n   {\n@@ -525,7 +526,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `UnstructuredLoader` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/unstructured/document_loaders/langchain_unstructured.document_loaders.UnstructuredLoader.html\"\n+    \"For detailed documentation of all `UnstructuredLoader` features and configurations head to the API reference: https://python.langchain.com/api_reference/unstructured/document_loaders/langchain_unstructured.document_loaders.UnstructuredLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/unstructured_markdown.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -6,15 +6,15 @@\n    \"source\": [\n     \"# UnstructuredMarkdownLoader\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with UnstructuredMarkdown [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with UnstructuredMarkdown [document loader](https://python.langchain.com/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [UnstructuredMarkdownLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u274c | \u274c | \u2705 | \\n\",\n+    \"| [UnstructuredMarkdownLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u274c | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -241,7 +241,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all UnstructuredMarkdownLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html\"\n+    \"For detailed documentation of all UnstructuredMarkdownLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/unstructured_pdfloader.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -8,17 +8,17 @@\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n-    \"[Unstructured](https://unstructured-io.github.io/unstructured/) supports a common interface for working with unstructured or semi-structured file formats, such as Markdown or PDF. LangChain's [UnstructuredPDFLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html) integrates with Unstructured to parse PDF documents into LangChain [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) objects.\\n\",\n+    \"[Unstructured](https://unstructured-io.github.io/unstructured/) supports a common interface for working with unstructured or semi-structured file formats, such as Markdown or PDF. LangChain's [UnstructuredPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html) integrates with Unstructured to parse PDF documents into LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects.\\n\",\n     \"\\n\",\n     \"Please see [this page](/docs/integrations/providers/unstructured/) for more information on installing system requirements.\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [UnstructuredPDFLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n+    \"| [UnstructuredPDFLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -256,7 +256,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all UnstructuredPDFLoader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html\"\n+    \"For detailed documentation of all UnstructuredPDFLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/web_base.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -20,7 +20,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | JS support|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [WebBaseLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n+    \"| [WebBaseLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u274c | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -370,7 +370,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `WebBaseLoader` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html\"\n+    \"For detailed documentation of all `WebBaseLoader` features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_loaders/xml.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -7,16 +7,16 @@\n    \"source\": [\n     \"# UnstructuredXMLLoader\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with UnstructuredXMLLoader [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). The `UnstructuredXMLLoader` is used to load `XML` files. The loader works with `.xml` files. The page content will be the text extracted from the XML tags.\\n\",\n+    \"This notebook provides a quick overview for getting started with UnstructuredXMLLoader [document loader](https://python.langchain.com/docs/concepts/#document-loaders). The `UnstructuredXMLLoader` is used to load `XML` files. The loader works with `.xml` files. The page content will be the text extracted from the XML tags.\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/document_loaders/file_loaders/unstructured/)|\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: |\\n\",\n-    \"| [UnstructuredXMLLoader](https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.xml.UnstructuredXMLLoader.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n+    \"| [UnstructuredXMLLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.xml.UnstructuredXMLLoader.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u274c | \u2705 | \\n\",\n     \"### Loader features\\n\",\n     \"| Source | Document Lazy Loading | Native Async Support\\n\",\n     \"| :---: | :---: | :---: | \\n\",\n@@ -174,7 +174,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all __ModuleName__Loader features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/document_loaders/langchain_community.document_loaders.xml.UnstructuredXMLLoader.html\"\n+    \"For detailed documentation of all __ModuleName__Loader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.xml.UnstructuredXMLLoader.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/document_transformers/ai21_semantic_text_splitter.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -58,7 +58,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"AI21_API_KEY\\\"] = getpass()\"\n+    \"if \\\"AI21_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"AI21_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/document_transformers/dashscope_rerank.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -44,7 +44,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"DASHSCOPE_API_KEY\\\"] = getpass.getpass(\\\"DashScope API Key:\\\")\"\n+    \"if \\\"DASHSCOPE_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"DASHSCOPE_API_KEY\\\"] = getpass.getpass(\\\"DashScope API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/document_transformers/google_cloud_vertexai_rerank.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -546,7 +546,7 @@\n     \"id\": \"ud_cnGszb1i9\"\n    },\n    \"source\": [\n-    \"Let's inspect a couple of reranked documents. We observe that the retriever still returns the relevant Langchain type [documents](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) but as part of the metadata field, we also recieve the `relevance_score` from the Ranking API.\"\n+    \"Let's inspect a couple of reranked documents. We observe that the retriever still returns the relevant Langchain type [documents](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) but as part of the metadata field, we also recieve the `relevance_score` from the Ranking API.\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/document_transformers/jina_rerank.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -214,7 +214,7 @@\n    \"source\": [\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\",\n     \"combine_docs_chain = create_stuff_documents_chain(llm, retrieval_qa_chat_prompt)\\n\",\n     \"chain = create_retrieval_chain(compression_retriever, combine_docs_chain)\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/document_transformers/rankllm-reranker.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -50,7 +50,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/document_transformers/volcengine_rerank.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 2,
          "patch": "@@ -44,8 +44,10 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"VOLC_API_AK\\\"] = getpass.getpass(\\\"Volcengine API AK:\\\")\\n\",\n-    \"os.environ[\\\"VOLC_API_SK\\\"] = getpass.getpass(\\\"Volcengine API SK:\\\")\"\n+    \"if \\\"VOLC_API_AK\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"VOLC_API_AK\\\"] = getpass.getpass(\\\"Volcengine API AK:\\\")\\n\",\n+    \"if \\\"VOLC_API_SK\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"VOLC_API_SK\\\"] = getpass.getpass(\\\"Volcengine API SK:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/document_transformers/voyageai-reranker.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -51,7 +51,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"VOYAGE_API_KEY\\\"] = getpass.getpass(\\\"Voyage AI API Key:\\\")\"\n+    \"if \\\"VOYAGE_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"VOYAGE_API_KEY\\\"] = getpass.getpass(\\\"Voyage AI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/llm_caching.ipynb",
          "status": "modified",
          "additions": 25,
          "deletions": 24,
          "patch": "@@ -24,7 +24,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {\n@@ -2753,35 +2754,35 @@\n     }\n    },\n    \"source\": [\n-    \"**Cache** classes are implemented by inheriting the [BaseCache](https://python.langchain.com/v0.2/api_reference/core/caches/langchain_core.caches.BaseCache.html) class.\\n\",\n+    \"**Cache** classes are implemented by inheriting the [BaseCache](https://python.langchain.com/api_reference/core/caches/langchain_core.caches.BaseCache.html) class.\\n\",\n     \"\\n\",\n     \"This table lists all 21 derived classes with links to the API Reference.\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"| Namespace \ud83d\udd3b | Class |\\n\",\n     \"|------------|---------|\\n\",\n-    \"| langchain_astradb.cache | [AstraDBCache](https://python.langchain.com/v0.2/api_reference/astradb/cache/langchain_astradb.cache.AstraDBCache.html) |\\n\",\n-    \"| langchain_astradb.cache | [AstraDBSemanticCache](https://python.langchain.com/v0.2/api_reference/astradb/cache/langchain_astradb.cache.AstraDBSemanticCache.html) |\\n\",\n-    \"| langchain_community.cache | [AstraDBCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.AstraDBCache.html) |\\n\",\n-    \"| langchain_community.cache | [AstraDBSemanticCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.AstraDBSemanticCache.html) |\\n\",\n-    \"| langchain_community.cache | [AzureCosmosDBSemanticCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.AzureCosmosDBSemanticCache.html) |\\n\",\n-    \"| langchain_community.cache | [CassandraCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.CassandraCache.html) |\\n\",\n-    \"| langchain_community.cache | [CassandraSemanticCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.CassandraSemanticCache.html) |\\n\",\n-    \"| langchain_community.cache | [GPTCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.GPTCache.html) |\\n\",\n-    \"| langchain_community.cache | [InMemoryCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.InMemoryCache.html) |\\n\",\n-    \"| langchain_community.cache | [MomentoCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.MomentoCache.html) |\\n\",\n-    \"| langchain_community.cache | [OpenSearchSemanticCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.OpenSearchSemanticCache.html) |\\n\",\n-    \"| langchain_community.cache | [RedisSemanticCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.RedisSemanticCache.html) |\\n\",\n-    \"| langchain_community.cache | [SingleStoreDBSemanticCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.SingleStoreDBSemanticCache.html) |\\n\",\n-    \"| langchain_community.cache | [SQLAlchemyCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.SQLAlchemyCache.html) |\\n\",\n-    \"| langchain_community.cache | [SQLAlchemyMd5Cache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.SQLAlchemyMd5Cache.html) |\\n\",\n-    \"| langchain_community.cache | [UpstashRedisCache](https://python.langchain.com/v0.2/api_reference/community/cache/langchain_community.cache.UpstashRedisCache.html) |\\n\",\n-    \"| langchain_core.caches | [InMemoryCache](https://python.langchain.com/v0.2/api_reference/core/caches/langchain_core.caches.InMemoryCache.html) |\\n\",\n-    \"| langchain_elasticsearch.cache | [ElasticsearchCache](https://python.langchain.com/v0.2/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchCache.html) |\\n\",\n-    \"| langchain_mongodb.cache | [MongoDBAtlasSemanticCache](https://python.langchain.com/v0.2/api_reference/mongodb/cache/langchain_mongodb.cache.MongoDBAtlasSemanticCache.html) |\\n\",\n-    \"| langchain_mongodb.cache | [MongoDBCache](https://python.langchain.com/v0.2/api_reference/mongodb/cache/langchain_mongodb.cache.MongoDBCache.html) |\\n\",\n-    \"| langchain_couchbase.cache | [CouchbaseCache](https://python.langchain.com/v0.2/api_reference/couchbase/cache/langchain_couchbase.cache.CouchbaseCache.html) |\\n\",\n-    \"| langchain_couchbase.cache | [CouchbaseSemanticCache](https://python.langchain.com/v0.2/api_reference/couchbase/cache/langchain_couchbase.cache.CouchbaseSemanticCache.html) |\\n\"\n+    \"| langchain_astradb.cache | [AstraDBCache](https://python.langchain.com/api_reference/astradb/cache/langchain_astradb.cache.AstraDBCache.html) |\\n\",\n+    \"| langchain_astradb.cache | [AstraDBSemanticCache](https://python.langchain.com/api_reference/astradb/cache/langchain_astradb.cache.AstraDBSemanticCache.html) |\\n\",\n+    \"| langchain_community.cache | [AstraDBCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.AstraDBCache.html) |\\n\",\n+    \"| langchain_community.cache | [AstraDBSemanticCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.AstraDBSemanticCache.html) |\\n\",\n+    \"| langchain_community.cache | [AzureCosmosDBSemanticCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.AzureCosmosDBSemanticCache.html) |\\n\",\n+    \"| langchain_community.cache | [CassandraCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.CassandraCache.html) |\\n\",\n+    \"| langchain_community.cache | [CassandraSemanticCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.CassandraSemanticCache.html) |\\n\",\n+    \"| langchain_community.cache | [GPTCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.GPTCache.html) |\\n\",\n+    \"| langchain_community.cache | [InMemoryCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.InMemoryCache.html) |\\n\",\n+    \"| langchain_community.cache | [MomentoCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.MomentoCache.html) |\\n\",\n+    \"| langchain_community.cache | [OpenSearchSemanticCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.OpenSearchSemanticCache.html) |\\n\",\n+    \"| langchain_community.cache | [RedisSemanticCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.RedisSemanticCache.html) |\\n\",\n+    \"| langchain_community.cache | [SingleStoreDBSemanticCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.SingleStoreDBSemanticCache.html) |\\n\",\n+    \"| langchain_community.cache | [SQLAlchemyCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.SQLAlchemyCache.html) |\\n\",\n+    \"| langchain_community.cache | [SQLAlchemyMd5Cache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.SQLAlchemyMd5Cache.html) |\\n\",\n+    \"| langchain_community.cache | [UpstashRedisCache](https://python.langchain.com/api_reference/community/cache/langchain_community.cache.UpstashRedisCache.html) |\\n\",\n+    \"| langchain_core.caches | [InMemoryCache](https://python.langchain.com/api_reference/core/caches/langchain_core.caches.InMemoryCache.html) |\\n\",\n+    \"| langchain_elasticsearch.cache | [ElasticsearchCache](https://python.langchain.com/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchCache.html) |\\n\",\n+    \"| langchain_mongodb.cache | [MongoDBAtlasSemanticCache](https://python.langchain.com/api_reference/mongodb/cache/langchain_mongodb.cache.MongoDBAtlasSemanticCache.html) |\\n\",\n+    \"| langchain_mongodb.cache | [MongoDBCache](https://python.langchain.com/api_reference/mongodb/cache/langchain_mongodb.cache.MongoDBCache.html) |\\n\",\n+    \"| langchain_couchbase.cache | [CouchbaseCache](https://python.langchain.com/api_reference/couchbase/cache/langchain_couchbase.cache.CouchbaseCache.html) |\\n\",\n+    \"| langchain_couchbase.cache | [CouchbaseSemanticCache](https://python.langchain.com/api_reference/couchbase/cache/langchain_couchbase.cache.CouchbaseSemanticCache.html) |\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/llms/ai21.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# AI21LLM\\n\",\n     \"\\n\",\n-    \"This example goes over how to use LangChain to interact with `AI21` Jurassic models. To use the Jamba model, use the [ChatAI21 object](https://python.langchain.com/v0.2/docs/integrations/chat/ai21/) instead.\\n\",\n+    \"This example goes over how to use LangChain to interact with `AI21` Jurassic models. To use the Jamba model, use the [ChatAI21 object](https://python.langchain.com/docs/integrations/chat/ai21/) instead.\\n\",\n     \"\\n\",\n     \"[See a full list of AI21 models and tools on LangChain.](https://pypi.org/project/langchain-ai21/)\\n\",\n     \"\\n\",\n@@ -67,7 +67,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"AI21_API_KEY\\\"] = getpass()\"\n+    \"if \\\"AI21_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"AI21_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/llms/anthropic.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -67,7 +67,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\"\n+    \"if \\\"ANTHROPIC_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ANTHROPIC_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/llms/cohere.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -15,14 +15,14 @@\n     \"\\n\",\n     \">[Cohere](https://cohere.ai/about) is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.\\n\",\n     \"\\n\",\n-    \"Head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html) for detailed documentation of all attributes and methods.\\n\",\n+    \"Head to the [API reference](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html) for detailed documentation of all attributes and methods.\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/llms/cohere/) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/llms/cohere/) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [Cohere](https://python.langchain.com/v0.2/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\"\n+    \"| [Cohere](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\"\n    ]\n   },\n   {\n@@ -261,7 +261,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `Cohere` llm features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html\"\n+    \"For detailed documentation of all `Cohere` llm features and configurations head to the API reference: https://python.langchain.com/api_reference/community/llms/langchain_community.llms.cohere.Cohere.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/llms/databricks.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -10,7 +10,7 @@\n     \"> [Databricks](https://www.databricks.com/) Lakehouse Platform unifies data, analytics, and AI on one platform.\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with Databricks [LLM models](https://python.langchain.com/v0.2/docs/concepts/#llms). For detailed documentation of all features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/llms/langchain_community.llms.databricks.Databricks.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with Databricks [LLM models](https://python.langchain.com/docs/concepts/#llms). For detailed documentation of all features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.databricks.Databricks.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n@@ -33,7 +33,7 @@\n     \"* Only supports synchronous invocation. Streaming or async APIs are not supported.\\n\",\n     \"* `batch` API is not supported.\\n\",\n     \"\\n\",\n-    \"To use those features, please use the new [ChatDatabricks](https://python.langchain.com/v0.2/docs/integrations/chat/databricks) class instead. `ChatDatabricks` supports all APIs of `ChatModel` including streaming, async, batch, etc.\\n\"\n+    \"To use those features, please use the new [ChatDatabricks](https://python.langchain.com/docs/integrations/chat/databricks) class instead. `ChatDatabricks` supports all APIs of `ChatModel` including streaming, async, batch, etc.\\n\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/llms/fireworks.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -22,7 +22,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.1/docs/integrations/llms/fireworks/) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [Fireworks](https://python.langchain.com/v0.2/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks) | [langchain_fireworks](https://python.langchain.com/v0.2/api_reference/fireworks/index.html) | \u274c | \u274c | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_fireworks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_fireworks?style=flat-square&label=%20) |\"\n+    \"| [Fireworks](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks) | [langchain_fireworks](https://python.langchain.com/api_reference/fireworks/index.html) | \u274c | \u274c | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_fireworks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_fireworks?style=flat-square&label=%20) |\"\n    ]\n   },\n   {\n@@ -282,7 +282,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `Fireworks` LLM features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks\"\n+    \"For detailed documentation of all `Fireworks` LLM features and configurations head to the API reference: https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/llms/gigachat.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -47,7 +47,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"GIGACHAT_CREDENTIALS\\\"] = getpass()\"\n+    \"if \\\"GIGACHAT_CREDENTIALS\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"GIGACHAT_CREDENTIALS\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/llms/gpt4all.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -84,7 +84,7 @@\n     \"\\n\",\n     \"---\\n\",\n     \"\\n\",\n-    \"This integration does not yet support streaming in chunks via the [`.stream()`](https://python.langchain.com/v0.2/docs/how_to/streaming/) method. The below example uses a callback handler with `streaming=True`:\"\n+    \"This integration does not yet support streaming in chunks via the [`.stream()`](https://python.langchain.com/docs/how_to/streaming/) method. The below example uses a callback handler with `streaming=True`:\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/llms/openai.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -26,9 +26,9 @@\n     \"## Overview\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n-    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/openai) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/openai) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\\n\",\n-    \"| [ChatOpenAI](https://python.langchain.com/v0.2/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain-openai](https://python.langchain.com/v0.2/api_reference/openai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\\n\",\n+    \"| [ChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain-openai](https://python.langchain.com/api_reference/openai/index.html) | \u274c | beta | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n@@ -230,7 +230,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `OpenAI` llm features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html\"\n+    \"For detailed documentation of all `OpenAI` llm features and configurations head to the API reference: https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/memory/couchbase_chat_message_history.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -187,7 +187,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"## Chaining\\n\",\n-    \"The chat message history class can be used with [LCEL Runnables](https://python.langchain.com/v0.2/docs/how_to/message_history/)\"\n+    \"The chat message history class can be used with [LCEL Runnables](https://python.langchain.com/docs/how_to/message_history/)\"\n    ]\n   },\n   {\n@@ -267,7 +267,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='Hello Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 22, 'total_tokens': 32}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a0f8a29e-ddf4-4e06-a1fe-cf8c325a2b72-0', usage_metadata={'input_tokens': 22, 'output_tokens': 10, 'total_tokens': 32})\"\n+       \"AIMessage(content='Hello Bob! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 22, 'total_tokens': 32}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a0f8a29e-ddf4-4e06-a1fe-cf8c325a2b72-0', usage_metadata={'input_tokens': 22, 'output_tokens': 10, 'total_tokens': 32})\"\n       ]\n      },\n      \"execution_count\": 11,\n@@ -288,7 +288,7 @@\n     {\n      \"data\": {\n       \"text/plain\": [\n-       \"AIMessage(content='Your name is Bob.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 43, 'total_tokens': 48}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f764a9eb-999e-4042-96b6-fe47b7ae4779-0', usage_metadata={'input_tokens': 43, 'output_tokens': 5, 'total_tokens': 48})\"\n+       \"AIMessage(content='Your name is Bob.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 43, 'total_tokens': 48}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f764a9eb-999e-4042-96b6-fe47b7ae4779-0', usage_metadata={'input_tokens': 43, 'output_tokens': 5, 'total_tokens': 48})\"\n       ]\n      },\n      \"execution_count\": 12,"
        },
        {
          "filename": "docs/docs/integrations/memory/tidb_chat_message_history.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -45,7 +45,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"Input your OpenAI API key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"Input your OpenAI API key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/memory/xata_chat_message_history.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -128,7 +128,8 @@\n    \"source\": [\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/platforms/aws.mdx",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -35,9 +35,9 @@ from langchain_aws import ChatBedrock\n ```\n \n ### Bedrock Converse\n-AWS has recently released the Bedrock Converse API which provides a unified conversational interface for Bedrock models. This API does not yet support custom models. You can see a list of all [models that are supported here](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html). To improve reliability the ChatBedrock integration will switch to using the Bedrock Converse API as soon as it has feature parity with the existing Bedrock API. Until then a separate [ChatBedrockConverse](https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html) integration has been released.\n+AWS has recently released the Bedrock Converse API which provides a unified conversational interface for Bedrock models. This API does not yet support custom models. You can see a list of all [models that are supported here](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html). To improve reliability the ChatBedrock integration will switch to using the Bedrock Converse API as soon as it has feature parity with the existing Bedrock API. Until then a separate [ChatBedrockConverse](https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html) integration has been released.\n \n-We recommend using `ChatBedrockConverse` for users who do not need to use custom models. See the [docs](/docs/integrations/chat/bedrock/#bedrock-converse-api) and [API reference](https://python.langchain.com/v0.2/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html) for more detail.\n+We recommend using `ChatBedrockConverse` for users who do not need to use custom models. See the [docs](/docs/integrations/chat/bedrock/#bedrock-converse-api) and [API reference](https://python.langchain.com/api_reference/aws/chat_models/langchain_aws.chat_models.bedrock_converse.ChatBedrockConverse.html) for more detail.\n \n ```python\n from langchain_aws import ChatBedrockConverse"
        },
        {
          "filename": "docs/docs/integrations/platforms/microsoft.mdx",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -440,11 +440,11 @@ from langchain_community.agent_toolkits import azure_ai_services\n \n The `azure_ai_services` toolkit includes the following tools:\n \n-- Image Analysis: [AzureAiServicesImageAnalysisTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.azure_ai_services.image_analysis.AzureAiServicesImageAnalysisTool.html)\n-- Document Intelligence: [AzureAiServicesDocumentIntelligenceTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.azure_ai_services.document_intelligence.AzureAiServicesDocumentIntelligenceTool.html)\n-- Speech to Text: [AzureAiServicesSpeechToTextTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.azure_ai_services.speech_to_text.AzureAiServicesSpeechToTextTool.html)\n-- Text to Speech: [AzureAiServicesTextToSpeechTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.azure_ai_services.text_to_speech.AzureAiServicesTextToSpeechTool.html)\n-- Text Analytics for Health: [AzureAiServicesTextAnalyticsForHealthTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.azure_ai_services.text_analytics_for_health.AzureAiServicesTextAnalyticsForHealthTool.html)\n+- Image Analysis: [AzureAiServicesImageAnalysisTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.azure_ai_services.image_analysis.AzureAiServicesImageAnalysisTool.html)\n+- Document Intelligence: [AzureAiServicesDocumentIntelligenceTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.azure_ai_services.document_intelligence.AzureAiServicesDocumentIntelligenceTool.html)\n+- Speech to Text: [AzureAiServicesSpeechToTextTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.azure_ai_services.speech_to_text.AzureAiServicesSpeechToTextTool.html)\n+- Text to Speech: [AzureAiServicesTextToSpeechTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.azure_ai_services.text_to_speech.AzureAiServicesTextToSpeechTool.html)\n+- Text Analytics for Health: [AzureAiServicesTextAnalyticsForHealthTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.azure_ai_services.text_analytics_for_health.AzureAiServicesTextAnalyticsForHealthTool.html)\n \n \n ### Microsoft Office 365 email and calendar"
        },
        {
          "filename": "docs/docs/integrations/providers/apify.mdx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -27,7 +27,7 @@ You can use the `ApifyWrapper` to run Actors on the Apify platform.\n from langchain_community.utilities import ApifyWrapper\n ```\n \n-For more information on this wrapper, see [the API reference](https://python.langchain.com/v0.2/api_reference/community/utilities/langchain_community.utilities.apify.ApifyWrapper.html).\n+For more information on this wrapper, see [the API reference](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.apify.ApifyWrapper.html).\n \n \n ## Document loader"
        },
        {
          "filename": "docs/docs/integrations/providers/mlflow_tracking.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -523,7 +523,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"#### Where to Pass the Callback\\n\",\n-    \" LangChain supports two ways of passing callback instances: (1) Request time callbacks - pass them to the `invoke` method or bind with `with_config()` (2) Constructor callbacks - set them in the chain constructor. When using the `MlflowLangchainTracer` as a callback, you **must use request time callbacks**. Setting it in the constructor instead will only apply the callback to the top-level object, preventing it from being propagated to child components, resulting in incomplete traces. For more information on this behavior, please refer to [Callbacks Documentation](https://python.langchain.com/v0.2/docs/concepts/#callbacks) for more details.\\n\",\n+    \" LangChain supports two ways of passing callback instances: (1) Request time callbacks - pass them to the `invoke` method or bind with `with_config()` (2) Constructor callbacks - set them in the chain constructor. When using the `MlflowLangchainTracer` as a callback, you **must use request time callbacks**. Setting it in the constructor instead will only apply the callback to the top-level object, preventing it from being propagated to child components, resulting in incomplete traces. For more information on this behavior, please refer to [Callbacks Documentation](https://python.langchain.com/docs/concepts/#callbacks) for more details.\\n\",\n     \"\\n\",\n     \"```python\\n\",\n     \"# OK\\n\","
        },
        {
          "filename": "docs/docs/integrations/providers/premai.md",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -286,7 +286,7 @@ In order to pass tools and let the LLM choose the tool it needs to call, we need\n \n ```python\n from langchain_core.tools import tool\n-from langchain_core.pydantic_v1 import BaseModel, Field \n+from pydantic import BaseModel, Field \n \n # Define the schema for function arguments\n class OperationInput(BaseModel):"
        },
        {
          "filename": "docs/docs/integrations/providers/redis.mdx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -132,7 +132,7 @@ Redis can be used to persist LLM conversations.\n \n ### Vector Store Retriever Memory\n \n-For a more detailed walkthrough of the `VectorStoreRetrieverMemory` wrapper, see [this notebook](https://python.langchain.com/v0.2/api_reference/langchain/memory/langchain.memory.vectorstore.VectorStoreRetrieverMemory.html).\n+For a more detailed walkthrough of the `VectorStoreRetrieverMemory` wrapper, see [this notebook](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.vectorstore.VectorStoreRetrieverMemory.html).\n \n ### Chat Message History Memory\n For a detailed example of Redis to cache conversation message history, see [this notebook](/docs/integrations/memory/redis_chat_message_history)."
        },
        {
          "filename": "docs/docs/integrations/retrievers/activeloop.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 4,
          "patch": "@@ -91,11 +91,13 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"Enter your OpenAI API token: \\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"Enter your OpenAI API token: \\\")\\n\",\n     \"# # activeloop token is needed if you are not signed in using CLI: `activeloop login -u <USERNAME> -p <PASSWORD>`\\n\",\n-    \"os.environ[\\\"ACTIVELOOP_TOKEN\\\"] = getpass.getpass(\\n\",\n-    \"    \\\"Enter your ActiveLoop API token: \\\"\\n\",\n-    \")  # Get your API token from https://app.activeloop.ai, click on your profile picture in the top right corner, and select \\\"API Tokens\\\"\\n\",\n+    \"if \\\"ACTIVELOOP_TOKEN\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ACTIVELOOP_TOKEN\\\"] = getpass.getpass(\\n\",\n+    \"        \\\"Enter your ActiveLoop API token: \\\"\\n\",\n+    \"    )  # Get your API token from https://app.activeloop.ai, click on your profile picture in the top right corner, and select \\\"API Tokens\\\"\\n\",\n     \"\\n\",\n     \"token = os.getenv(\\\"ACTIVELOOP_TOKEN\\\")\\n\",\n     \"openai_embeddings = OpenAIEmbeddings()\""
        },
        {
          "filename": "docs/docs/integrations/retrievers/arxiv.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -19,9 +19,9 @@\n     \"\\n\",\n     \">[arXiv](https://arxiv.org/) is an open-access archive for 2 million scholarly articles in the fields of physics, mathematics, computer science, quantitative biology, quantitative finance, statistics, electrical engineering and systems science, and economics.\\n\",\n     \"\\n\",\n-    \"This notebook shows how to retrieve scientific articles from Arxiv.org into the [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) format that is used downstream.\\n\",\n+    \"This notebook shows how to retrieve scientific articles from Arxiv.org into the [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that is used downstream.\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `ArxivRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html).\\n\",\n+    \"For detailed documentation of all `ArxivRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html).\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n@@ -79,7 +79,7 @@\n     \"- optional `load_all_available_meta`: default=False. By default only the most important fields downloaded: `Published` (date when document was published/last updated), `Title`, `Authors`, `Summary`. If True, other fields also downloaded.\\n\",\n     \"- `get_full_documents`: boolean, default False. Determines whether to fetch full text of documents.\\n\",\n     \"\\n\",\n-    \"See [API reference](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html) for more detail.\"\n+    \"See [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html) for more detail.\"\n    ]\n   },\n   {\n@@ -299,7 +299,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `ArxivRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html).\"\n+    \"For detailed documentation of all `ArxivRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.arxiv.ArxivRetriever.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/retrievers/azure_ai_search.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -21,7 +21,7 @@\n     \"\\n\",\n     \"`AzureAISearchRetriever` is an integration module that returns documents from an unstructured query. It's based on the BaseRetriever class and it targets the 2023-11-01 stable REST API version of Azure AI Search, which means it supports vector indexing and queries.\\n\",\n     \"\\n\",\n-    \"This guide will help you getting started with the Azure AI Search [retriever](/docs/concepts/#retrievers). For detailed documentation of all `AzureAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever.html).\\n\",\n+    \"This guide will help you getting started with the Azure AI Search [retriever](/docs/concepts/#retrievers). For detailed documentation of all `AzureAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever.html).\\n\",\n     \"\\n\",\n     \"`AzureAISearchRetriever` replaces `AzureCognitiveSearchRetriever`, which will soon be deprecated. We recommend switching to the newer version that's based on the most recent stable version of the search APIs.\\n\",\n     \"\\n\",\n@@ -304,7 +304,7 @@\n     \"Question: {question}\\\"\\\"\\\"\\n\",\n     \")\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"def format_docs(docs):\\n\",\n@@ -336,7 +336,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `AzureAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever.html).\"\n+    \"For detailed documentation of all `AzureAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.azure_ai_search.AzureAISearchRetriever.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/retrievers/bedrock.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -163,7 +163,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `AmazonKnowledgeBasesRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/aws/retrievers/langchain_aws.retrievers.bedrock.AmazonKnowledgeBasesRetriever.html).\"\n+    \"For detailed documentation of all `AmazonKnowledgeBasesRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/aws/retrievers/langchain_aws.retrievers.bedrock.AmazonKnowledgeBasesRetriever.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/retrievers/box.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# BoxRetriever\\n\",\n     \"\\n\",\n-    \"This will help you getting started with the Box [retriever](/docs/concepts/#retrievers). For detailed documentation of all BoxRetriever features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/box/retrievers/langchain_box.retrievers.box.BoxRetriever.html).\\n\",\n+    \"This will help you getting started with the Box [retriever](/docs/concepts/#retrievers). For detailed documentation of all BoxRetriever features and configurations head to the [API reference](https://python.langchain.com/api_reference/box/retrievers/langchain_box.retrievers.box.BoxRetriever.html).\\n\",\n     \"\\n\",\n     \"# Overview\\n\",\n     \"\\n\",\n@@ -35,7 +35,7 @@\n     \"\\n\",\n     \"| Retriever | Self-host | Cloud offering | Package |\\n\",\n     \"| :--- | :--- | :---: | :---: |\\n\",\n-    \"[BoxRetriever](https://python.langchain.com/v0.2/api_reference/box/retrievers/langchain_box.retrievers.box.BoxRetriever.html) | \u274c | \u2705 | langchain-box |\\n\",\n+    \"[BoxRetriever](https://python.langchain.com/api_reference/box/retrievers/langchain_box.retrievers.box.BoxRetriever.html) | \u274c | \u2705 | langchain-box |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -220,7 +220,7 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -290,7 +290,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all BoxRetriever features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/box/retrievers/langchain_box.retrievers.box.BoxRetriever.html).\\n\",\n+    \"For detailed documentation of all BoxRetriever features and configurations head to the [API reference](https://python.langchain.com/api_reference/box/retrievers/langchain_box.retrievers.box.BoxRetriever.html).\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Help\\n\","
        },
        {
          "filename": "docs/docs/integrations/retrievers/chatgpt-plugin.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -100,7 +100,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/cohere-reranker.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -50,7 +50,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"COHERE_API_KEY\\\"] = getpass.getpass(\\\"Cohere API Key:\\\")\"\n+    \"if \\\"COHERE_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"COHERE_API_KEY\\\"] = getpass.getpass(\\\"Cohere API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/docarray_retriever.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -562,7 +562,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/elasticsearch_retriever.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -21,7 +21,7 @@\n     \"\\n\",\n     \"The `ElasticsearchRetriever` is a generic wrapper to enable flexible access to all `Elasticsearch` features through the [Query DSL](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html).  For most use cases the other classes (`ElasticsearchStore`, `ElasticsearchEmbeddings`, etc.) should suffice, but if they don't you can use `ElasticsearchRetriever`.\\n\",\n     \"\\n\",\n-    \"This guide will help you getting started with the Elasticsearch [retriever](/docs/concepts/#retrievers). For detailed documentation of all `ElasticsearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/elasticsearch/retrievers/langchain_elasticsearch.retrievers.ElasticsearchRetriever.html).\\n\",\n+    \"This guide will help you getting started with the Elasticsearch [retriever](/docs/concepts/#retrievers). For detailed documentation of all `ElasticsearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/elasticsearch/retrievers/langchain_elasticsearch.retrievers.ElasticsearchRetriever.html).\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n@@ -645,7 +645,7 @@\n     \"Question: {question}\\\"\\\"\\\"\\n\",\n     \")\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"def format_docs(docs):\\n\",\n@@ -677,7 +677,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `ElasticsearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/elasticsearch/retrievers/langchain_elasticsearch.retrievers.ElasticsearchRetriever.html).\"\n+    \"For detailed documentation of all `ElasticsearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/elasticsearch/retrievers/langchain_elasticsearch.retrievers.ElasticsearchRetriever.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/retrievers/embedchain.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -68,7 +68,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/google_vertex_ai_search.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -23,7 +23,7 @@\n     \"\\n\",\n     \"This notebook demonstrates how to configure `Vertex AI Search` and use the Vertex AI Search [retriever](/docs/concepts/#retrievers). The Vertex AI Search retriever encapsulates the [Python client library](https://cloud.google.com/generative-ai-app-builder/docs/libraries#client-libraries-install-python) and uses it to access the [Search Service API](https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1beta.services.search_service).\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `VertexAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/google_community/vertex_ai_search/langchain_google_community.vertex_ai_search.VertexAISearchRetriever.html).\\n\",\n+    \"For detailed documentation of all `VertexAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/google_community/vertex_ai_search/langchain_google_community.vertex_ai_search.VertexAISearchRetriever.html).\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n@@ -444,7 +444,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `VertexAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/google_community/vertex_ai_search/langchain_google_community.vertex_ai_search.VertexAISearchRetriever.html).\"\n+    \"For detailed documentation of all `VertexAISearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/google_community/vertex_ai_search/langchain_google_community.vertex_ai_search.VertexAISearchRetriever.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/retrievers/index.mdx",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -12,7 +12,7 @@ It is more general than a vector store.\n A retriever does not need to be able to store documents, only to return (or retrieve) them.\n Retrievers can be created from vector stores, but are also broad enough to include [Wikipedia search](/docs/integrations/retrievers/wikipedia/) and [Amazon Kendra](/docs/integrations/retrievers/amazon_kendra_retriever/).\n \n-Retrievers accept a string query as input and return a list of [Documents](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) as output.\n+Retrievers accept a string query as input and return a list of [Documents](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) as output.\n \n For specifics on how to use retrievers, see the [relevant how-to guides here](/docs/how_to/#retrievers).\n "
        },
        {
          "filename": "docs/docs/integrations/retrievers/kinetica.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -41,7 +41,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/milvus_hybrid_search.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n     \"\\n\",\n     \"> [Milvus](https://milvus.io/docs) is an open-source vector database built to power embedding similarity search and AI applications. Milvus makes unstructured data search more accessible, and provides a consistent user experience regardless of the deployment environment.\\n\",\n     \"\\n\",\n-    \"This will help you getting started with the Milvus Hybrid Search [retriever](/docs/concepts/#retrievers), which combines the strengths of both dense and sparse vector search. For detailed documentation of all `MilvusCollectionHybridSearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/milvus/retrievers/langchain_milvus.retrievers.milvus_hybrid_search.MilvusCollectionHybridSearchRetriever.html).\\n\",\n+    \"This will help you getting started with the Milvus Hybrid Search [retriever](/docs/concepts/#retrievers), which combines the strengths of both dense and sparse vector search. For detailed documentation of all `MilvusCollectionHybridSearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/milvus/retrievers/langchain_milvus.retrievers.milvus_hybrid_search.MilvusCollectionHybridSearchRetriever.html).\\n\",\n     \"\\n\",\n     \"See also the Milvus Multi-Vector Search [docs](https://milvus.io/docs/multi-vector-search.md).\\n\",\n     \"\\n\",\n@@ -611,7 +611,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `MilvusCollectionHybridSearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/milvus/retrievers/langchain_milvus.retrievers.milvus_hybrid_search.MilvusCollectionHybridSearchRetriever.html).\"\n+    \"For detailed documentation of all `MilvusCollectionHybridSearchRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/milvus/retrievers/langchain_milvus.retrievers.milvus_hybrid_search.MilvusCollectionHybridSearchRetriever.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/retrievers/outline.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -128,7 +128,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/pinecone_hybrid_search.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -73,7 +73,8 @@\n    \"source\": [\n     \"import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/activeloop_deeplake_self_query.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 2,
          "patch": "@@ -70,8 +70,10 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n-    \"os.environ[\\\"ACTIVELOOP_TOKEN\\\"] = getpass.getpass(\\\"Activeloop token:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"ACTIVELOOP_TOKEN\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"ACTIVELOOP_TOKEN\\\"] = getpass.getpass(\\\"Activeloop token:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/astradb.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -48,7 +48,8 @@\n     \"\\n\",\n     \"from langchain_openai.embeddings import OpenAIEmbeddings\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"\\n\",\n     \"embeddings = OpenAIEmbeddings()\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/chroma_self_query.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -75,7 +75,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/databricks_vector_search.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -103,7 +103,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"databricks_host = getpass.getpass(\\\"Databricks host:\\\")\\n\",\n     \"databricks_token = getpass.getpass(\\\"Databricks token:\\\")\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/elasticsearch_self_query.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -64,7 +64,8 @@\n     \"from langchain_elasticsearch import ElasticsearchStore\\n\",\n     \"from langchain_openai import OpenAIEmbeddings\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"\\n\",\n     \"embeddings = OpenAIEmbeddings()\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/myscale_self_query.ipynb",
          "status": "modified",
          "additions": 10,
          "deletions": 5,
          "patch": "@@ -62,11 +62,16 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n-    \"os.environ[\\\"MYSCALE_HOST\\\"] = getpass.getpass(\\\"MyScale URL:\\\")\\n\",\n-    \"os.environ[\\\"MYSCALE_PORT\\\"] = getpass.getpass(\\\"MyScale Port:\\\")\\n\",\n-    \"os.environ[\\\"MYSCALE_USERNAME\\\"] = getpass.getpass(\\\"MyScale Username:\\\")\\n\",\n-    \"os.environ[\\\"MYSCALE_PASSWORD\\\"] = getpass.getpass(\\\"MyScale Password:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"MYSCALE_HOST\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"MYSCALE_HOST\\\"] = getpass.getpass(\\\"MyScale URL:\\\")\\n\",\n+    \"if \\\"MYSCALE_PORT\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"MYSCALE_PORT\\\"] = getpass.getpass(\\\"MyScale Port:\\\")\\n\",\n+    \"if \\\"MYSCALE_USERNAME\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"MYSCALE_USERNAME\\\"] = getpass.getpass(\\\"MyScale Username:\\\")\\n\",\n+    \"if \\\"MYSCALE_PASSWORD\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"MYSCALE_PASSWORD\\\"] = getpass.getpass(\\\"MyScale Password:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/neo4j_self_query.ipynb",
          "status": "modified",
          "additions": 8,
          "deletions": 4,
          "patch": "@@ -62,7 +62,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {\n@@ -84,9 +85,12 @@\n     \"# To run this notebook, you can set up a free neo4j account on neo4j.com and input the following information.\\n\",\n     \"# (If you are having trouble connecting to the database, try using neo4j+ssc: instead of neo4j+s)\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"NEO4J_URI\\\"] = getpass.getpass(\\\"Neo4j URL:\\\")\\n\",\n-    \"os.environ[\\\"NEO4J_USERNAME\\\"] = getpass.getpass(\\\"Neo4j User Name:\\\")\\n\",\n-    \"os.environ[\\\"NEO4J_PASSWORD\\\"] = getpass.getpass(\\\"Neo4j Password:\\\")\"\n+    \"if \\\"NEO4J_URI\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"NEO4J_URI\\\"] = getpass.getpass(\\\"Neo4j URL:\\\")\\n\",\n+    \"if \\\"NEO4J_USERNAME\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"NEO4J_USERNAME\\\"] = getpass.getpass(\\\"Neo4j User Name:\\\")\\n\",\n+    \"if \\\"NEO4J_PASSWORD\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"NEO4J_PASSWORD\\\"] = getpass.getpass(\\\"Neo4j Password:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/opensearch_self_query.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -63,7 +63,8 @@\n     \"from langchain_core.documents import Document\\n\",\n     \"from langchain_openai import OpenAIEmbeddings\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"\\n\",\n     \"embeddings = OpenAIEmbeddings()\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/pgvector_self_query.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -55,7 +55,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/pinecone.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -88,7 +88,8 @@\n    \"source\": [\n     \"import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/redis_self_query.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -55,7 +55,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/supabase_self_query.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 3,
          "patch": "@@ -163,9 +163,12 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"SUPABASE_URL\\\"] = getpass.getpass(\\\"Supabase URL:\\\")\\n\",\n-    \"os.environ[\\\"SUPABASE_SERVICE_KEY\\\"] = getpass.getpass(\\\"Supabase Service Key:\\\")\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"SUPABASE_URL\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"SUPABASE_URL\\\"] = getpass.getpass(\\\"Supabase URL:\\\")\\n\",\n+    \"if \\\"SUPABASE_SERVICE_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"SUPABASE_SERVICE_KEY\\\"] = getpass.getpass(\\\"Supabase Service Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/self_query/tencentvectordb.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -80,7 +80,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/singlestoredb.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -48,7 +48,8 @@\n     \"import os\\n\",\n     \"\\n\",\n     \"# We want to use OpenAIEmbeddings so we have to get the OpenAI API Key.\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"\\n\",\n     \"from langchain_community.document_loaders import TextLoader\\n\",\n     \"from langchain_community.vectorstores import SingleStoreDB\\n\","
        },
        {
          "filename": "docs/docs/integrations/retrievers/svm.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -68,7 +68,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/retrievers/tavily.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -161,7 +161,7 @@\n     \"Question: {question}\\\"\\\"\\\"\\n\",\n     \")\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"def format_docs(docs):\\n\",\n@@ -202,7 +202,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `TavilySearchAPIRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.tavily_search_api.TavilySearchAPIRetriever.html).\"\n+    \"For detailed documentation of all `TavilySearchAPIRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.tavily_search_api.TavilySearchAPIRetriever.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/retrievers/wikipedia.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -20,7 +20,7 @@\n     \"## Overview\\n\",\n     \">[Wikipedia](https://wikipedia.org/) is a multilingual free online encyclopedia written and maintained by a community of volunteers, known as Wikipedians, through open collaboration and using a wiki-based editing system called MediaWiki. `Wikipedia` is the largest and most-read reference work in history.\\n\",\n     \"\\n\",\n-    \"This notebook shows how to retrieve wiki pages from `wikipedia.org` into the [Document](https://python.langchain.com/v0.2/api_reference/core/documents/langchain_core.documents.base.Document.html) format that is used downstream.\\n\",\n+    \"This notebook shows how to retrieve wiki pages from `wikipedia.org` into the [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) format that is used downstream.\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n@@ -171,7 +171,7 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -236,7 +236,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `WikipediaRetriever` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/retrievers/langchain_community.retrievers.wikipedia.WikipediaRetriever.html#langchain-community-retrievers-wikipedia-wikipediaretriever).\"\n+    \"For detailed documentation of all `WikipediaRetriever` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/retrievers/langchain_community.retrievers.wikipedia.WikipediaRetriever.html#langchain-community-retrievers-wikipedia-wikipediaretriever).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/stores/astradb.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -19,7 +19,7 @@\n    \"source\": [\n     \"# AstraDBByteStore\\n\",\n     \"\\n\",\n-    \"This will help you get started with Astra DB [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `AstraDBByteStore` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/astradb/storage/langchain_astradb.storage.AstraDBByteStore.html).\\n\",\n+    \"This will help you get started with Astra DB [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `AstraDBByteStore` features and configurations head to the [API reference](https://python.langchain.com/api_reference/astradb/storage/langchain_astradb.storage.AstraDBByteStore.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n@@ -29,7 +29,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | JS support | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [AstraDBByteStore](https://python.langchain.com/v0.2/api_reference/astradb/storage/langchain_astradb.storage.AstraDBByteStore.html) | [langchain_astradb](https://python.langchain.com/v0.2/api_reference/astradb/index.html) | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_astradb?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_astradb?style=flat-square&label=%20) |\\n\",\n+    \"| [AstraDBByteStore](https://python.langchain.com/api_reference/astradb/storage/langchain_astradb.storage.AstraDBByteStore.html) | [langchain_astradb](https://python.langchain.com/api_reference/astradb/index.html) | \u274c | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_astradb?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_astradb?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -187,7 +187,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `AstraDBByteStore` features and configurations, head to the API reference: https://python.langchain.com/v0.2/api_reference/astradb/storage/langchain_astradb.storage.AstraDBByteStore.html\"\n+    \"For detailed documentation of all `AstraDBByteStore` features and configurations, head to the API reference: https://python.langchain.com/api_reference/astradb/storage/langchain_astradb.storage.AstraDBByteStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/stores/cassandra.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -19,17 +19,17 @@\n    \"source\": [\n     \"# CassandraByteStore\\n\",\n     \"\\n\",\n-    \"This will help you get started with Cassandra [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `CassandraByteStore` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.cassandra.CassandraByteStore.html).\\n\",\n+    \"This will help you get started with Cassandra [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `CassandraByteStore` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/storage/langchain_community.storage.cassandra.CassandraByteStore.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n     \"[Cassandra](https://cassandra.apache.org/) is a NoSQL, row-oriented, highly scalable and highly available database.\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | [JS support](https://js.langchain.com/v0.2/docs/integrations/stores/cassandra_storage) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | [JS support](https://js.langchain.com/docs/integrations/stores/cassandra_storage) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [CassandraByteStore](https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.cassandra.CassandraByteStore.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n+    \"| [CassandraByteStore](https://python.langchain.com/api_reference/community/storage/langchain_community.storage.cassandra.CassandraByteStore.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -199,7 +199,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `CassandraByteStore` features and configurations, head to the API reference: https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.cassandra.CassandraByteStore.html\"\n+    \"For detailed documentation of all `CassandraByteStore` features and configurations, head to the API reference: https://python.langchain.com/api_reference/community/storage/langchain_community.storage.cassandra.CassandraByteStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/stores/elasticsearch.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -19,7 +19,7 @@\n    \"source\": [\n     \"# ElasticsearchEmbeddingsCache\\n\",\n     \"\\n\",\n-    \"This will help you get started with Elasticsearch [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `ElasticsearchEmbeddingsCache` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchEmbeddingsCache.html).\\n\",\n+    \"This will help you get started with Elasticsearch [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `ElasticsearchEmbeddingsCache` features and configurations head to the [API reference](https://python.langchain.com/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchEmbeddingsCache.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n@@ -29,7 +29,7 @@\n     \"\\n\",\n     \"| Class | Package | Local | JS support | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [ElasticsearchEmbeddingsCache](https://python.langchain.com/v0.2/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchEmbeddingsCache.html) | [langchain_elasticsearch](https://python.langchain.com/v0.2/api_reference/elasticsearch/index.html) | \u2705 | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_elasticsearch?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_elasticsearch?style=flat-square&label=%20) |\\n\",\n+    \"| [ElasticsearchEmbeddingsCache](https://python.langchain.com/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchEmbeddingsCache.html) | [langchain_elasticsearch](https://python.langchain.com/api_reference/elasticsearch/index.html) | \u2705 | \u274c | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_elasticsearch?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_elasticsearch?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -218,7 +218,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `ElasticsearchEmbeddingsCache` features and configurations, head to the API reference: https://python.langchain.com/v0.2/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchEmbeddingsCache.html\"\n+    \"For detailed documentation of all `ElasticsearchEmbeddingsCache` features and configurations, head to the API reference: https://python.langchain.com/api_reference/elasticsearch/cache/langchain_elasticsearch.cache.ElasticsearchEmbeddingsCache.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/stores/file_system.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -19,17 +19,17 @@\n    \"source\": [\n     \"# LocalFileStore\\n\",\n     \"\\n\",\n-    \"This will help you get started with local filesystem [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all LocalFileStore features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/langchain/storage/langchain.storage.file_system.LocalFileStore.html).\\n\",\n+    \"This will help you get started with local filesystem [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all LocalFileStore features and configurations head to the [API reference](https://python.langchain.com/api_reference/langchain/storage/langchain.storage.file_system.LocalFileStore.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n     \"The `LocalFileStore` is a persistent implementation of `ByteStore` that stores everything in a folder of your choosing. It's useful if you're using a single machine and are tolerant of files being added or deleted.\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | [JS support](https://js.langchain.com/v0.2/docs/integrations/stores/file_system) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | [JS support](https://js.langchain.com/docs/integrations/stores/file_system) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [LocalFileStore](https://python.langchain.com/v0.2/api_reference/langchain/storage/langchain.storage.file_system.LocalFileStore.html) | [langchain](https://python.langchain.com/v0.2/api_reference/langchain/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain?style=flat-square&label=%20) |\"\n+    \"| [LocalFileStore](https://python.langchain.com/api_reference/langchain/storage/langchain.storage.file_system.LocalFileStore.html) | [langchain](https://python.langchain.com/api_reference/langchain/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain?style=flat-square&label=%20) |\"\n    ]\n   },\n   {\n@@ -184,7 +184,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `LocalFileStore` features and configurations, head to the API reference: https://python.langchain.com/v0.2/api_reference/langchain/storage/langchain.storage.file_system.LocalFileStore.html\"\n+    \"For detailed documentation of all `LocalFileStore` features and configurations, head to the API reference: https://python.langchain.com/api_reference/langchain/storage/langchain.storage.file_system.LocalFileStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/stores/in_memory.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -19,17 +19,17 @@\n    \"source\": [\n     \"# InMemoryByteStore\\n\",\n     \"\\n\",\n-    \"This guide will help you get started with in-memory [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `InMemoryByteStore` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/core/stores/langchain_core.stores.InMemoryByteStore.html).\\n\",\n+    \"This guide will help you get started with in-memory [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `InMemoryByteStore` features and configurations head to the [API reference](https://python.langchain.com/api_reference/core/stores/langchain_core.stores.InMemoryByteStore.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n     \"The `InMemoryByteStore` is a non-persistent implementation of a `ByteStore` that stores everything in a Python dictionary. It's intended for demos and cases where you don't need persistence past the lifetime of the Python process.\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | [JS support](https://js.langchain.com/v0.2/docs/integrations/stores/in_memory/) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | [JS support](https://js.langchain.com/docs/integrations/stores/in_memory/) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [InMemoryByteStore](https://python.langchain.com/v0.2/api_reference/core/stores/langchain_core.stores.InMemoryByteStore.html) | [langchain_core](https://python.langchain.com/v0.2/api_reference/core/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_core?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_core?style=flat-square&label=%20) |\"\n+    \"| [InMemoryByteStore](https://python.langchain.com/api_reference/core/stores/langchain_core.stores.InMemoryByteStore.html) | [langchain_core](https://python.langchain.com/api_reference/core/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_core?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_core?style=flat-square&label=%20) |\"\n    ]\n   },\n   {\n@@ -156,7 +156,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `InMemoryByteStore` features and configurations, head to the API reference: https://python.langchain.com/v0.2/api_reference/core/stores/langchain_core.stores.InMemoryByteStore.html\"\n+    \"For detailed documentation of all `InMemoryByteStore` features and configurations, head to the API reference: https://python.langchain.com/api_reference/core/stores/langchain_core.stores.InMemoryByteStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/stores/redis.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -19,17 +19,17 @@\n    \"source\": [\n     \"# RedisStore\\n\",\n     \"\\n\",\n-    \"This will help you get started with Redis [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `RedisStore` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.redis.RedisStore.html).\\n\",\n+    \"This will help you get started with Redis [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `RedisStore` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/storage/langchain_community.storage.redis.RedisStore.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n     \"The `RedisStore` is an implementation of `ByteStore` that stores everything in your Redis instance.\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | [JS support](https://js.langchain.com/v0.2/docs/integrations/stores/ioredis_storage) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | [JS support](https://js.langchain.com/docs/integrations/stores/ioredis_storage) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [RedisStore](https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.redis.RedisStore.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n+    \"| [RedisStore](https://python.langchain.com/api_reference/community/storage/langchain_community.storage.redis.RedisStore.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u2705 | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -160,7 +160,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `RedisStore` features and configurations, head to the API reference: https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.redis.RedisStore.html\"\n+    \"For detailed documentation of all `RedisStore` features and configurations, head to the API reference: https://python.langchain.com/api_reference/community/storage/langchain_community.storage.redis.RedisStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/stores/upstash_redis.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -19,7 +19,7 @@\n    \"source\": [\n     \"# UpstashRedisByteStore\\n\",\n     \"\\n\",\n-    \"This will help you get started with Upstash redis [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `UpstashRedisByteStore` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.upstash_redis.UpstashRedisByteStore.html).\\n\",\n+    \"This will help you get started with Upstash redis [key-value stores](/docs/concepts/#key-value-stores). For detailed documentation of all `UpstashRedisByteStore` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/storage/langchain_community.storage.upstash_redis.UpstashRedisByteStore.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n@@ -29,9 +29,9 @@\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n-    \"| Class | Package | Local | [JS support](https://js.langchain.com/v0.2/docs/integrations/stores/upstash_redis_storage) | Package downloads | Package latest |\\n\",\n+    \"| Class | Package | Local | [JS support](https://js.langchain.com/docs/integrations/stores/upstash_redis_storage) | Package downloads | Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: |  :---: | :---: |\\n\",\n-    \"| [UpstashRedisByteStore](https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.upstash_redis.UpstashRedisByteStore.html) | [langchain_community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u274c | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n+    \"| [UpstashRedisByteStore](https://python.langchain.com/api_reference/community/storage/langchain_community.storage.upstash_redis.UpstashRedisByteStore.html) | [langchain_community](https://python.langchain.com/api_reference/community/index.html) | \u274c | \u2705 | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -180,7 +180,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `UpstashRedisByteStore` features and configurations, head to the API reference: https://python.langchain.com/v0.2/api_reference/community/storage/langchain_community.storage.upstash_redis.UpstashRedisByteStore.html\"\n+    \"For detailed documentation of all `UpstashRedisByteStore` features and configurations, head to the API reference: https://python.langchain.com/api_reference/community/storage/langchain_community.storage.upstash_redis.UpstashRedisByteStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/ai21.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# AI21Embeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with AI21 embedding models using LangChain. For detailed documentation on `AI21Embeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/ai21/embeddings/langchain_ai21.embeddings.AI21Embeddings.html).\\n\",\n+    \"This will help you get started with AI21 embedding models using LangChain. For detailed documentation on `AI21Embeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/ai21/embeddings/langchain_ai21.embeddings.AI21Embeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -242,7 +242,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `AI21Embeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/ai21/embeddings/langchain_ai21.embeddings.AI21Embeddings.html).\\n\"\n+    \"For detailed documentation on `AI21Embeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/ai21/embeddings/langchain_ai21.embeddings.AI21Embeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/azureopenai.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# AzureOpenAIEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with AzureOpenAI embedding models using LangChain. For detailed documentation on `AzureOpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/openai/embeddings/langchain_openai.embeddings.azure.AzureOpenAIEmbeddings.html).\\n\",\n+    \"This will help you get started with AzureOpenAI embedding models using LangChain. For detailed documentation on `AzureOpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.azure.AzureOpenAIEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -250,7 +250,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `AzureOpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/openai/embeddings/langchain_openai.embeddings.azure.AzureOpenAIEmbeddings.html).\\n\"\n+    \"For detailed documentation on `AzureOpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.azure.AzureOpenAIEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/cohere.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# CohereEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with Cohere embedding models using LangChain. For detailed documentation on `CohereEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/cohere/embeddings/langchain_cohere.embeddings.CohereEmbeddings.html).\\n\",\n+    \"This will help you get started with Cohere embedding models using LangChain. For detailed documentation on `CohereEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/cohere/embeddings/langchain_cohere.embeddings.CohereEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -239,7 +239,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `CohereEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/cohere/embeddings/langchain_cohere.embeddings.CohereEmbeddings.html).\\n\"\n+    \"For detailed documentation on `CohereEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/cohere/embeddings/langchain_cohere.embeddings.CohereEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/databricks.ipynb",
          "status": "modified",
          "additions": 6,
          "deletions": 3,
          "patch": "@@ -19,7 +19,7 @@\n     \"\\n\",\n     \"> [Databricks](https://www.databricks.com/) Lakehouse Platform unifies data, analytics, and AI on one platform.\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with Databricks [embedding models](/docs/concepts/#embedding-models). For detailed documentation of all `DatabricksEmbeddings` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/embeddings/langchain_community.embeddings.databricks.DatabricksEmbeddings.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with Databricks [embedding models](/docs/concepts/#embedding-models). For detailed documentation of all `DatabricksEmbeddings` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.databricks.DatabricksEmbeddings.html).\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"\\n\",\n@@ -67,7 +67,10 @@\n     \"import os\\n\",\n     \"\\n\",\n     \"os.environ[\\\"DATABRICKS_HOST\\\"] = \\\"https://your-workspace.cloud.databricks.com\\\"\\n\",\n-    \"os.environ[\\\"DATABRICKS_TOKEN\\\"] = getpass.getpass(\\\"Enter your Databricks access token: \\\")\"\n+    \"if \\\"DATABRICKS_TOKEN\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"DATABRICKS_TOKEN\\\"] = getpass.getpass(\\n\",\n+    \"        \\\"Enter your Databricks access token: \\\"\\n\",\n+    \"    )\"\n    ]\n   },\n   {\n@@ -241,7 +244,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `DatabricksEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/community/embeddings/langchain_community.embeddings.databricks.DatabricksEmbeddings.html).\\n\"\n+    \"For detailed documentation on `DatabricksEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.databricks.DatabricksEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/fireworks.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# FireworksEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with Fireworks embedding models using LangChain. For detailed documentation on `FireworksEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/fireworks/embeddings/langchain_fireworks.embeddings.FireworksEmbeddings.html).\\n\",\n+    \"This will help you get started with Fireworks embedding models using LangChain. For detailed documentation on `FireworksEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/fireworks/embeddings/langchain_fireworks.embeddings.FireworksEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n@@ -239,7 +239,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `FireworksEmbeddings` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/fireworks/embeddings/langchain_fireworks.embeddings.FireworksEmbeddings.html).\"\n+    \"For detailed documentation of all `FireworksEmbeddings` features and configurations head to the [API reference](https://python.langchain.com/api_reference/fireworks/embeddings/langchain_fireworks.embeddings.FireworksEmbeddings.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/gigachat.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -44,7 +44,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"GIGACHAT_CREDENTIALS\\\"] = getpass()\"\n+    \"if \\\"GIGACHAT_CREDENTIALS\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"GIGACHAT_CREDENTIALS\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/google_vertex_ai_palm.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -18,14 +18,14 @@\n    \"source\": [\n     \"# Google Vertex AI Embeddings \\n\",\n     \"\\n\",\n-    \"This will help you get started with Google Vertex AI Embeddings models using LangChain. For detailed documentation on `Google Vertex AI Embeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/google_vertexai/embeddings/langchain_google_vertexai.embeddings.VertexAIEmbeddings.html).\\n\",\n+    \"This will help you get started with Google Vertex AI Embeddings models using LangChain. For detailed documentation on `Google Vertex AI Embeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/google_vertexai/embeddings/langchain_google_vertexai.embeddings.VertexAIEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"| Provider | Package |\\n\",\n     \"|:--------:|:-------:|\\n\",\n-    \"| [Google](https://python.langchain.com/v0.2/docs/integrations/platforms/google/) | [langchain-google-vertexai](https://python.langchain.com/v0.2/api_reference/google_vertexai/embeddings/langchain_google_vertexai.embeddings.VertexAIEmbeddings.html) |\\n\",\n+    \"| [Google](https://python.langchain.com/docs/integrations/platforms/google/) | [langchain-google-vertexai](https://python.langchain.com/api_reference/google_vertexai/embeddings/langchain_google_vertexai.embeddings.VertexAIEmbeddings.html) |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -289,7 +289,7 @@\n     \"## API Reference\\n\",\n     \"\\n\",\n     \"For detailed documentation on `Google Vertex AI Embeddings\\n\",\n-    \"` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/google_vertexai/embeddings/langchain_google_vertexai.embeddings.VertexAIEmbeddings.html).\\n\"\n+    \"` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/google_vertexai/embeddings/langchain_google_vertexai.embeddings.VertexAIEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/ipex_llm.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -70,7 +70,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"API Reference\\n\",\n-    \"- [IpexLLMBgeEmbeddings](https://python.langchain.com/v0.2/api_reference/community/embeddings/langchain_community.embeddings.ipex_llm.IpexLLMBgeEmbeddings.html)\"\n+    \"- [IpexLLMBgeEmbeddings](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.ipex_llm.IpexLLMBgeEmbeddings.html)\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/ipex_llm_gpu.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -133,7 +133,7 @@\n    \"metadata\": {},\n    \"source\": [\n     \"API Reference\\n\",\n-    \"- [IpexLLMBgeEmbeddings](https://python.langchain.com/v0.2/api_reference/community/embeddings/langchain_community.embeddings.ipex_llm.IpexLLMBgeEmbeddings.html)\"\n+    \"- [IpexLLMBgeEmbeddings](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.ipex_llm.IpexLLMBgeEmbeddings.html)\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/mistralai.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# MistralAIEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with MistralAI embedding models using LangChain. For detailed documentation on `MistralAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/mistralai/embeddings/langchain_mistralai.embeddings.MistralAIEmbeddings.html).\\n\",\n+    \"This will help you get started with MistralAI embedding models using LangChain. For detailed documentation on `MistralAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/mistralai/embeddings/langchain_mistralai.embeddings.MistralAIEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -238,7 +238,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `MistralAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/mistralai/embeddings/langchain_mistralai.embeddings.MistralAIEmbeddings.html).\\n\"\n+    \"For detailed documentation on `MistralAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/mistralai/embeddings/langchain_mistralai.embeddings.MistralAIEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/nomic.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# NomicEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with Nomic embedding models using LangChain. For detailed documentation on `NomicEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/nomic/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html).\\n\",\n+    \"This will help you get started with Nomic embedding models using LangChain. For detailed documentation on `NomicEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/nomic/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -259,7 +259,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `NomicEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/nomic/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html).\\n\"\n+    \"For detailed documentation on `NomicEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/nomic/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/ollama.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# OllamaEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with Ollama embedding models using LangChain. For detailed documentation on `OllamaEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html).\\n\",\n+    \"This will help you get started with Ollama embedding models using LangChain. For detailed documentation on `OllamaEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -248,7 +248,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `OllamaEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html).\\n\"\n+    \"For detailed documentation on `OllamaEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/ollama/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/openai.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -18,7 +18,7 @@\n    \"source\": [\n     \"# OpenAIEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with OpenAI embedding models using LangChain. For detailed documentation on `OpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html).\\n\",\n+    \"This will help you get started with OpenAI embedding models using LangChain. For detailed documentation on `OpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html).\\n\",\n     \"\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n@@ -244,7 +244,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `OpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html).\\n\"\n+    \"For detailed documentation on `OpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/openai/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/together.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -17,7 +17,7 @@\n    \"source\": [\n     \"# TogetherEmbeddings\\n\",\n     \"\\n\",\n-    \"This will help you get started with Together embedding models using LangChain. For detailed documentation on `TogetherEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/together/embeddings/langchain_together.embeddings.TogetherEmbeddings.html).\\n\",\n+    \"This will help you get started with Together embedding models using LangChain. For detailed documentation on `TogetherEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/together/embeddings/langchain_together.embeddings.TogetherEmbeddings.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"### Integration details\\n\",\n@@ -249,7 +249,7 @@\n    \"source\": [\n     \"## API Reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation on `TogetherEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/v0.2/api_reference/together/embeddings/langchain_together.embeddings.TogetherEmbeddings.html).\\n\"\n+    \"For detailed documentation on `TogetherEmbeddings` features and configuration options, please refer to the [API reference](https://python.langchain.com/api_reference/together/embeddings/langchain_together.embeddings.TogetherEmbeddings.html).\\n\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/text_embedding/zhipuai.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -25,7 +25,7 @@\n     \"\\n\",\n     \"| Provider | Package |\\n\",\n     \"|:--------:|:-------:|\\n\",\n-    \"| [ZhipuAI](/docs/integrations/providers/zhipuai/) | [langchain-community](https://python.langchain.com/v0.2/api_reference/community/embeddings/langchain_community.embeddings.zhipuai.ZhipuAIEmbeddings.html) |\\n\",\n+    \"| [ZhipuAI](/docs/integrations/providers/zhipuai/) | [langchain-community](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.zhipuai.ZhipuAIEmbeddings.html) |\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\","
        },
        {
          "filename": "docs/docs/integrations/tools/connery.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -257,8 +257,8 @@\n     \"\\n\",\n     \"For detailed documentation of all Connery features and configurations head to the API reference:\\n\",\n     \"\\n\",\n-    \"- Toolkit: https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.connery.toolkit.ConneryToolkit.html\\n\",\n-    \"- Tool: https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.connery.service.ConneryService.html\"\n+    \"- Toolkit: https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.connery.toolkit.ConneryToolkit.html\\n\",\n+    \"- Tool: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.connery.service.ConneryService.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/ddg.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -153,7 +153,7 @@\n    \"source\": [\n     \"## Related\\n\",\n     \"\\n\",\n-    \"- [How to use a chat model to call tools](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)\"\n+    \"- [How to use a chat model to call tools](https://python.langchain.com/docs/how_to/tool_calling/)\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/financial_datasets.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -281,7 +281,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `FinancialDatasetsToolkit` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.financial_datasets.toolkit.FinancialDatasetsToolkit.html).\"\n+    \"For detailed documentation of all `FinancialDatasetsToolkit` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.financial_datasets.toolkit.FinancialDatasetsToolkit.html).\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/tools/github.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -9,7 +9,7 @@\n     \"The `Github` toolkit contains tools that enable an LLM agent to interact with a github repository. \\n\",\n     \"The tool is a wrapper for the [PyGitHub](https://github.com/PyGithub/PyGithub) library. \\n\",\n     \"\\n\",\n-    \"For detailed documentation of all GithubToolkit features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.github.toolkit.GitHubToolkit.html).\\n\",\n+    \"For detailed documentation of all GithubToolkit features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.github.toolkit.GitHubToolkit.html).\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -226,7 +226,7 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -279,7 +279,7 @@\n       \"=================================\\u001b[1m Tool Message \\u001b[0m=================================\\n\",\n       \"Name: get_issue\\n\",\n       \"\\n\",\n-      \"{\\\"number\\\": 24888, \\\"title\\\": \\\"Standardize KV-Store Docs\\\", \\\"body\\\": \\\"To make our KV-store integrations as easy to use as possible we need to make sure the docs for them are thorough and standardized. There are two parts to this: updating the KV-store docstrings and updating the actual integration docs.\\\\r\\\\n\\\\r\\\\nThis needs to be done for each KV-store integration, ideally with one PR per KV-store.\\\\r\\\\n\\\\r\\\\nRelated to broader issues #21983 and #22005.\\\\r\\\\n\\\\r\\\\n## Docstrings\\\\r\\\\nEach KV-store class docstring should have the sections shown in the [Appendix](#appendix) below. The sections should have input and output code blocks when relevant.\\\\r\\\\n\\\\r\\\\nTo build a preview of the API docs for the package you're working on run (from root of repo):\\\\r\\\\n\\\\r\\\\n```shell\\\\r\\\\nmake api_docs_clean; make api_docs_quick_preview API_PKG=openai\\\\r\\\\n```\\\\r\\\\n\\\\r\\\\nwhere `API_PKG=` should be the parent directory that houses the edited package (e.g. community, openai, anthropic, huggingface, together, mistralai, groq, fireworks, etc.). This should be quite fast for all the partner packages.\\\\r\\\\n\\\\r\\\\n## Doc pages\\\\r\\\\nEach KV-store [docs page](https://python.langchain.com/v0.2/docs/integrations/stores/) should follow [this template](https://github.com/langchain-ai/langchain/blob/master/libs/cli/langchain_cli/integration_template/docs/kv_store.ipynb).\\\\r\\\\n\\\\r\\\\nHere is an example: https://python.langchain.com/v0.2/docs/integrations/stores/in_memory/\\\\r\\\\n\\\\r\\\\nYou can use the `langchain-cli` to quickly get started with a new chat model integration docs page (run from root of repo):\\\\r\\\\n\\\\r\\\\n```shell\\\\r\\\\npoetry run pip install -e libs/cli\\\\r\\\\npoetry run langchain-cli integration create-doc --name \\\\\\\"foo-bar\\\\\\\" --name-class FooBar --component-type kv_store --destination-dir ./docs/docs/integrations/stores/\\\\r\\\\n```\\\\r\\\\n\\\\r\\\\nwhere `--name` is the integration package name without the \\\\\\\"langchain-\\\\\\\" prefix and `--name-class` is the class name without the \\\\\\\"ByteStore\\\\\\\" suffix. This will create a template doc with some autopopulated fields at docs/docs/integrations/stores/foo_bar.ipynb.\\\\r\\\\n\\\\r\\\\nTo build a preview of the docs you can run (from root):\\\\r\\\\n\\\\r\\\\n```shell\\\\r\\\\nmake docs_clean\\\\r\\\\nmake docs_build\\\\r\\\\ncd docs/build/output-new\\\\r\\\\nyarn\\\\r\\\\nyarn start\\\\r\\\\n```\\\\r\\\\n\\\\r\\\\n## Appendix\\\\r\\\\nExpected sections for the KV-store class docstring.\\\\r\\\\n\\\\r\\\\n```python\\\\r\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"__ModuleName__ completion KV-store integration.\\\\r\\\\n\\\\r\\\\n    # TODO: Replace with relevant packages, env vars.\\\\r\\\\n    Setup:\\\\r\\\\n        Install ``__package_name__`` and set environment variable ``__MODULE_NAME___API_KEY``.\\\\r\\\\n\\\\r\\\\n        .. code-block:: bash\\\\r\\\\n\\\\r\\\\n            pip install -U __package_name__\\\\r\\\\n            export __MODULE_NAME___API_KEY=\\\\\\\"your-api-key\\\\\\\"\\\\r\\\\n\\\\r\\\\n    # TODO: Populate with relevant params.\\\\r\\\\n    Key init args \\\\u2014 client params:\\\\r\\\\n        api_key: Optional[str]\\\\r\\\\n            __ModuleName__ API key. If not passed in will be read from env var __MODULE_NAME___API_KEY.\\\\r\\\\n\\\\r\\\\n    See full list of supported init args and their descriptions in the params section.\\\\r\\\\n\\\\r\\\\n    # TODO: Replace with relevant init params.\\\\r\\\\n    Instantiate:\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            from __module_name__ import __ModuleName__ByteStore\\\\r\\\\n\\\\r\\\\n            kv_store = __ModuleName__ByteStore(\\\\r\\\\n                # api_key=\\\\\\\"...\\\\\\\",\\\\r\\\\n                # other params...\\\\r\\\\n            )\\\\r\\\\n\\\\r\\\\n    Set keys:\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            kv_pairs = [\\\\r\\\\n                [\\\\\\\"key1\\\\\\\", \\\\\\\"value1\\\\\\\"],\\\\r\\\\n                [\\\\\\\"key2\\\\\\\", \\\\\\\"value2\\\\\\\"],\\\\r\\\\n            ]\\\\r\\\\n\\\\r\\\\n            kv_store.mset(kv_pairs)\\\\r\\\\n\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n    Get keys:\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            kv_store.mget([\\\\\\\"key1\\\\\\\", \\\\\\\"key2\\\\\\\"])\\\\r\\\\n\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            # TODO: Example output.\\\\r\\\\n\\\\r\\\\n    Delete keys:\\\\r\\\\n        ..code-block:: python\\\\r\\\\n\\\\r\\\\n            kv_store.mdelete([\\\\\\\"key1\\\\\\\", \\\\\\\"key2\\\\\\\"])\\\\r\\\\n\\\\r\\\\n        ..code-block:: python\\\\r\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"  # noqa: E501\\\\r\\\\n```\\\", \\\"comments\\\": \\\"[]\\\", \\\"opened_by\\\": \\\"jacoblee93\\\"}\\n\",\n+      \"{\\\"number\\\": 24888, \\\"title\\\": \\\"Standardize KV-Store Docs\\\", \\\"body\\\": \\\"To make our KV-store integrations as easy to use as possible we need to make sure the docs for them are thorough and standardized. There are two parts to this: updating the KV-store docstrings and updating the actual integration docs.\\\\r\\\\n\\\\r\\\\nThis needs to be done for each KV-store integration, ideally with one PR per KV-store.\\\\r\\\\n\\\\r\\\\nRelated to broader issues #21983 and #22005.\\\\r\\\\n\\\\r\\\\n## Docstrings\\\\r\\\\nEach KV-store class docstring should have the sections shown in the [Appendix](#appendix) below. The sections should have input and output code blocks when relevant.\\\\r\\\\n\\\\r\\\\nTo build a preview of the API docs for the package you're working on run (from root of repo):\\\\r\\\\n\\\\r\\\\n```shell\\\\r\\\\nmake api_docs_clean; make api_docs_quick_preview API_PKG=openai\\\\r\\\\n```\\\\r\\\\n\\\\r\\\\nwhere `API_PKG=` should be the parent directory that houses the edited package (e.g. community, openai, anthropic, huggingface, together, mistralai, groq, fireworks, etc.). This should be quite fast for all the partner packages.\\\\r\\\\n\\\\r\\\\n## Doc pages\\\\r\\\\nEach KV-store [docs page](https://python.langchain.com/docs/integrations/stores/) should follow [this template](https://github.com/langchain-ai/langchain/blob/master/libs/cli/langchain_cli/integration_template/docs/kv_store.ipynb).\\\\r\\\\n\\\\r\\\\nHere is an example: https://python.langchain.com/docs/integrations/stores/in_memory/\\\\r\\\\n\\\\r\\\\nYou can use the `langchain-cli` to quickly get started with a new chat model integration docs page (run from root of repo):\\\\r\\\\n\\\\r\\\\n```shell\\\\r\\\\npoetry run pip install -e libs/cli\\\\r\\\\npoetry run langchain-cli integration create-doc --name \\\\\\\"foo-bar\\\\\\\" --name-class FooBar --component-type kv_store --destination-dir ./docs/docs/integrations/stores/\\\\r\\\\n```\\\\r\\\\n\\\\r\\\\nwhere `--name` is the integration package name without the \\\\\\\"langchain-\\\\\\\" prefix and `--name-class` is the class name without the \\\\\\\"ByteStore\\\\\\\" suffix. This will create a template doc with some autopopulated fields at docs/docs/integrations/stores/foo_bar.ipynb.\\\\r\\\\n\\\\r\\\\nTo build a preview of the docs you can run (from root):\\\\r\\\\n\\\\r\\\\n```shell\\\\r\\\\nmake docs_clean\\\\r\\\\nmake docs_build\\\\r\\\\ncd docs/build/output-new\\\\r\\\\nyarn\\\\r\\\\nyarn start\\\\r\\\\n```\\\\r\\\\n\\\\r\\\\n## Appendix\\\\r\\\\nExpected sections for the KV-store class docstring.\\\\r\\\\n\\\\r\\\\n```python\\\\r\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"__ModuleName__ completion KV-store integration.\\\\r\\\\n\\\\r\\\\n    # TODO: Replace with relevant packages, env vars.\\\\r\\\\n    Setup:\\\\r\\\\n        Install ``__package_name__`` and set environment variable ``__MODULE_NAME___API_KEY``.\\\\r\\\\n\\\\r\\\\n        .. code-block:: bash\\\\r\\\\n\\\\r\\\\n            pip install -U __package_name__\\\\r\\\\n            export __MODULE_NAME___API_KEY=\\\\\\\"your-api-key\\\\\\\"\\\\r\\\\n\\\\r\\\\n    # TODO: Populate with relevant params.\\\\r\\\\n    Key init args \\\\u2014 client params:\\\\r\\\\n        api_key: Optional[str]\\\\r\\\\n            __ModuleName__ API key. If not passed in will be read from env var __MODULE_NAME___API_KEY.\\\\r\\\\n\\\\r\\\\n    See full list of supported init args and their descriptions in the params section.\\\\r\\\\n\\\\r\\\\n    # TODO: Replace with relevant init params.\\\\r\\\\n    Instantiate:\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            from __module_name__ import __ModuleName__ByteStore\\\\r\\\\n\\\\r\\\\n            kv_store = __ModuleName__ByteStore(\\\\r\\\\n                # api_key=\\\\\\\"...\\\\\\\",\\\\r\\\\n                # other params...\\\\r\\\\n            )\\\\r\\\\n\\\\r\\\\n    Set keys:\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            kv_pairs = [\\\\r\\\\n                [\\\\\\\"key1\\\\\\\", \\\\\\\"value1\\\\\\\"],\\\\r\\\\n                [\\\\\\\"key2\\\\\\\", \\\\\\\"value2\\\\\\\"],\\\\r\\\\n            ]\\\\r\\\\n\\\\r\\\\n            kv_store.mset(kv_pairs)\\\\r\\\\n\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n    Get keys:\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            kv_store.mget([\\\\\\\"key1\\\\\\\", \\\\\\\"key2\\\\\\\"])\\\\r\\\\n\\\\r\\\\n        .. code-block:: python\\\\r\\\\n\\\\r\\\\n            # TODO: Example output.\\\\r\\\\n\\\\r\\\\n    Delete keys:\\\\r\\\\n        ..code-block:: python\\\\r\\\\n\\\\r\\\\n            kv_store.mdelete([\\\\\\\"key1\\\\\\\", \\\\\\\"key2\\\\\\\"])\\\\r\\\\n\\\\r\\\\n        ..code-block:: python\\\\r\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"  # noqa: E501\\\\r\\\\n```\\\", \\\"comments\\\": \\\"[]\\\", \\\"opened_by\\\": \\\"jacoblee93\\\"}\\n\",\n       \"==================================\\u001b[1m Ai Message \\u001b[0m==================================\\n\",\n       \"\\n\",\n       \"The title of issue 24888 is \\\"Standardize KV-Store Docs\\\".\\n\"\n@@ -303,7 +303,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `GithubToolkit` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.github.toolkit.GitHubToolkit.html).\"\n+    \"For detailed documentation of all `GithubToolkit` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.github.toolkit.GitHubToolkit.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/gmail.ipynb",
          "status": "modified",
          "additions": 8,
          "deletions": 8,
          "patch": "@@ -6,7 +6,7 @@\n    \"source\": [\n     \"# Gmail Toolkit\\n\",\n     \"\\n\",\n-    \"This will help you getting started with the GMail [toolkit](/docs/concepts/#toolkits). This toolkit interacts with the GMail API to read messages, draft and send messages, and more. For detailed documentation of all GmailToolkit features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/google_community/gmail/langchain_google_community.gmail.toolkit.GmailToolkit.html).\\n\",\n+    \"This will help you getting started with the GMail [toolkit](/docs/concepts/#toolkits). This toolkit interacts with the GMail API to read messages, draft and send messages, and more. For detailed documentation of all GmailToolkit features and configurations head to the [API reference](https://python.langchain.com/api_reference/google_community/gmail/langchain_google_community.gmail.toolkit.GmailToolkit.html).\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -142,11 +142,11 @@\n    \"cell_type\": \"markdown\",\n    \"metadata\": {},\n    \"source\": [\n-    \"- [GmailCreateDraft](https://python.langchain.com/v0.2/api_reference/google_community/gmail/langchain_google_community.gmail.create_draft.GmailCreateDraft.html)\\n\",\n-    \"- [GmailSendMessage](https://python.langchain.com/v0.2/api_reference/google_community/gmail/langchain_google_community.gmail.send_message.GmailSendMessage.html)\\n\",\n-    \"- [GmailSearch](https://python.langchain.com/v0.2/api_reference/google_community/gmail/langchain_google_community.gmail.search.GmailSearch.html)\\n\",\n-    \"- [GmailGetMessage](https://python.langchain.com/v0.2/api_reference/google_community/gmail/langchain_google_community.gmail.get_message.GmailGetMessage.html)\\n\",\n-    \"- [GmailGetThread](https://python.langchain.com/v0.2/api_reference/google_community/gmail/langchain_google_community.gmail.get_thread.GmailGetThread.html)\"\n+    \"- [GmailCreateDraft](https://python.langchain.com/api_reference/google_community/gmail/langchain_google_community.gmail.create_draft.GmailCreateDraft.html)\\n\",\n+    \"- [GmailSendMessage](https://python.langchain.com/api_reference/google_community/gmail/langchain_google_community.gmail.send_message.GmailSendMessage.html)\\n\",\n+    \"- [GmailSearch](https://python.langchain.com/api_reference/google_community/gmail/langchain_google_community.gmail.search.GmailSearch.html)\\n\",\n+    \"- [GmailGetMessage](https://python.langchain.com/api_reference/google_community/gmail/langchain_google_community.gmail.get_message.GmailGetMessage.html)\\n\",\n+    \"- [GmailGetThread](https://python.langchain.com/api_reference/google_community/gmail/langchain_google_community.gmail.get_thread.GmailGetThread.html)\"\n    ]\n   },\n   {\n@@ -177,7 +177,7 @@\n     \"\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\", temperature=0)\"\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\"\n    ]\n   },\n   {\n@@ -243,7 +243,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `GmailToolkit` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.gmail.toolkit.GmailToolkit.html).\"\n+    \"For detailed documentation of all `GmailToolkit` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.gmail.toolkit.GmailToolkit.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/infobip.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -106,9 +106,9 @@\n     \"from langchain import hub\\n\",\n     \"from langchain.agents import AgentExecutor, create_openai_functions_agent\\n\",\n     \"from langchain_community.utilities.infobip import InfobipAPIWrapper\\n\",\n-    \"from langchain_core.pydantic_v1 import BaseModel, Field\\n\",\n     \"from langchain_core.tools import StructuredTool\\n\",\n     \"from langchain_openai import ChatOpenAI\\n\",\n+    \"from pydantic import BaseModel, Field\\n\",\n     \"\\n\",\n     \"instructions = \\\"You are a coding teacher. You are teaching a student how to code. The student asks you a question. You answer the question.\\\"\\n\",\n     \"base_prompt = hub.pull(\\\"langchain-ai/openai-functions-template\\\")\\n\","
        },
        {
          "filename": "docs/docs/integrations/tools/jina_search.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -17,15 +17,15 @@\n    \"source\": [\n     \"# Jina Search\\n\",\n     \"\\n\",\n-    \"This notebook provides a quick overview for getting started with Jina [tool](/docs/integrations/tools/). For detailed documentation of all Jina features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html).\\n\",\n+    \"This notebook provides a quick overview for getting started with Jina [tool](/docs/integrations/tools/). For detailed documentation of all Jina features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html).\\n\",\n     \"\\n\",\n     \"## Overview\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n     \"\\n\",\n     \"| Class | Package | Serializable | JS support |  Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: | :---: |\\n\",\n-    \"| [JinaSearch](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html) | [langchain-community](https://python.langchain.com/v0.2/api_reference/community/) | \u274c | \u274c |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-community?style=flat-square&label=%20) |\\n\",\n+    \"| [JinaSearch](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html) | [langchain-community](https://python.langchain.com/api_reference/community/) | \u274c | \u274c |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-community?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Tool features\\n\",\n     \"| [Returns artifact](/docs/how_to/tool_artifacts/) | Native async | Return data | Pricing |\\n\",\n@@ -256,7 +256,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all Jina features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html\"\n+    \"For detailed documentation of all Jina features and configurations head to the API reference: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.jina_search.tool.JinaSearch.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/nvidia_riva.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 2,
          "patch": "@@ -527,7 +527,7 @@\n     \"## 6. Create Additional Chain Components\\n\",\n     \"As usual, declare the other parts of the chain. In this case, it's just a prompt template and an LLM.\\n\",\n     \"\\n\",\n-    \"You can use any [LangChain compatible LLM](https://python.langchain.com/v0.1/docs/integrations/llms/) in the chain. In this example, we use a [Mixtral8x7b NIM from NVIDIA](https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/). NVIDIA NIMs are supported in LangChain via the `langchain-nvidia-ai-endpoints` package, so you can easily build applications with best in class throughput and latency. \\n\",\n+    \"You can use any [LangChain compatible LLM](https://python.langchain.com/v0.1/docs/integrations/llms/) in the chain. In this example, we use a [Mixtral8x7b NIM from NVIDIA](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/). NVIDIA NIMs are supported in LangChain via the `langchain-nvidia-ai-endpoints` package, so you can easily build applications with best in class throughput and latency. \\n\",\n     \"\\n\",\n     \"LangChain compatible NVIDIA LLMs from [NVIDIA AI Foundation Endpoints](https://www.nvidia.com/en-us/ai-data-science/foundation-models/) can also be used by following these [instructions](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints). \"\n    ]\n@@ -547,7 +547,7 @@\n    \"id\": \"1744eec9\",\n    \"metadata\": {},\n    \"source\": [\n-    \"Follow the [instructions for LangChain](https://python.langchain.com/v0.2/docs/integrations/chat/nvidia_ai_endpoints/) to use NVIDIA NIM in your speech-enabled LangChain application. \\n\",\n+    \"Follow the [instructions for LangChain](https://python.langchain.com/docs/integrations/chat/nvidia_ai_endpoints/) to use NVIDIA NIM in your speech-enabled LangChain application. \\n\",\n     \"\\n\",\n     \"Set your key for NVIDIA API catalog, where NIMs are hosted for you to try.\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/tools/polygon.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -436,7 +436,7 @@\n    \"source\": [\n     \"### API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all the Polygon IO toolkit features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.polygon.toolkit.PolygonToolkit.html\"\n+    \"For detailed documentation of all the Polygon IO toolkit features and configurations head to the API reference: https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.polygon.toolkit.PolygonToolkit.html\"\n    ]\n   },\n   {\n@@ -654,10 +654,10 @@\n     \"\\n\",\n     \"For detailed documentation of all Polygon IO tools head to the API reference for each:\\n\",\n     \"\\n\",\n-    \"- Aggregate: https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.polygon.aggregates.PolygonAggregates.html\\n\",\n-    \"- Financials: https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.polygon.financials.PolygonFinancials.html\\n\",\n-    \"- Last Quote: https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.polygon.last_quote.PolygonLastQuote.html\\n\",\n-    \"- Ticker News: https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.polygon.ticker_news.PolygonTickerNews.html\"\n+    \"- Aggregate: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.polygon.aggregates.PolygonAggregates.html\\n\",\n+    \"- Financials: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.polygon.financials.PolygonFinancials.html\\n\",\n+    \"- Last Quote: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.polygon.last_quote.PolygonLastQuote.html\\n\",\n+    \"- Ticker News: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.polygon.ticker_news.PolygonTickerNews.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/python.ipynb",
          "status": "modified",
          "additions": 1,
          "deletions": 1,
          "patch": "@@ -15,7 +15,7 @@\n     \":::{.callout-caution}\\n\",\n     \"Python REPL can execute arbitrary code on the host machine (e.g., delete files, make network requests). Use with caution.\\n\",\n     \"\\n\",\n-    \"For more information general security guidelines, please see https://python.langchain.com/v0.2/docs/security/.\\n\",\n+    \"For more information general security guidelines, please see https://python.langchain.com/docs/security/.\\n\",\n     \":::\"\n    ]\n   },"
        },
        {
          "filename": "docs/docs/integrations/tools/requests.ipynb",
          "status": "modified",
          "additions": 8,
          "deletions": 8,
          "patch": "@@ -9,7 +9,7 @@\n     \"\\n\",\n     \"We can use the Requests [toolkit](/docs/concepts/#toolkits) to construct agents that generate HTTP requests.\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all API toolkit features and configurations head to the API reference for [RequestsToolkit](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.openapi.toolkit.RequestsToolkit.html).\\n\",\n+    \"For detailed documentation of all API toolkit features and configurations head to the API reference for [RequestsToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.openapi.toolkit.RequestsToolkit.html).\\n\",\n     \"\\n\",\n     \"## \u26a0\ufe0f Security note \u26a0\ufe0f\\n\",\n     \"There are inherent risks in giving models discretion to execute real-world actions. Take precautions to mitigate these risks:\\n\",\n@@ -225,11 +225,11 @@\n    \"id\": \"a21a6ca4-d650-4b7d-a944-1a8771b5293a\",\n    \"metadata\": {},\n    \"source\": [\n-    \"- [RequestsGetTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsGetTool.html)\\n\",\n-    \"- [RequestsPostTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsPostTool.html)\\n\",\n-    \"- [RequestsPatchTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsPatchTool.html)\\n\",\n-    \"- [RequestsPutTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsPutTool.html)\\n\",\n-    \"- [RequestsDeleteTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsDeleteTool.html)\"\n+    \"- [RequestsGetTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsGetTool.html)\\n\",\n+    \"- [RequestsPostTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsPostTool.html)\\n\",\n+    \"- [RequestsPatchTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsPatchTool.html)\\n\",\n+    \"- [RequestsPutTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsPutTool.html)\\n\",\n+    \"- [RequestsDeleteTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.requests.tool.RequestsDeleteTool.html)\"\n    ]\n   },\n   {\n@@ -250,7 +250,7 @@\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"from langgraph.prebuilt import create_react_agent\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\\n\",\n     \"\\n\",\n     \"system_message = \\\"\\\"\\\"\\n\",\n     \"You have access to an API to help answer user queries.\\n\",\n@@ -323,7 +323,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all API toolkit features and configurations head to the API reference for [RequestsToolkit](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.openapi.toolkit.RequestsToolkit.html).\"\n+    \"For detailed documentation of all API toolkit features and configurations head to the API reference for [RequestsToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.openapi.toolkit.RequestsToolkit.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/slack.ipynb",
          "status": "modified",
          "additions": 7,
          "deletions": 7,
          "patch": "@@ -6,7 +6,7 @@\n    \"source\": [\n     \"# Slack Toolkit\\n\",\n     \"\\n\",\n-    \"This will help you getting started with the Slack [toolkit](/docs/concepts/#toolkits). For detailed documentation of all SlackToolkit features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.slack.toolkit.SlackToolkit.html).\\n\",\n+    \"This will help you getting started with the Slack [toolkit](/docs/concepts/#toolkits). For detailed documentation of all SlackToolkit features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.slack.toolkit.SlackToolkit.html).\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -137,10 +137,10 @@\n    \"source\": [\n     \"This toolkit loads:\\n\",\n     \"\\n\",\n-    \"- [SlackGetChannel](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.slack.get_channel.SlackGetChannel.html)\\n\",\n-    \"- [SlackGetMessage](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.slack.get_message.SlackGetMessage.html)\\n\",\n-    \"- [SlackScheduleMessage](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.slack.schedule_message.SlackScheduleMessage.html)\\n\",\n-    \"- [SlackSendMessage](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.slack.send_message.SlackSendMessage.html)\"\n+    \"- [SlackGetChannel](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.slack.get_channel.SlackGetChannel.html)\\n\",\n+    \"- [SlackGetMessage](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.slack.get_message.SlackGetMessage.html)\\n\",\n+    \"- [SlackScheduleMessage](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.slack.schedule_message.SlackScheduleMessage.html)\\n\",\n+    \"- [SlackSendMessage](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.slack.send_message.SlackSendMessage.html)\"\n    ]\n   },\n   {\n@@ -161,7 +161,7 @@\n     \"from langchain_openai import ChatOpenAI\\n\",\n     \"from langgraph.prebuilt import create_react_agent\\n\",\n     \"\\n\",\n-    \"llm = ChatOpenAI(model=\\\"gpt-3.5-turbo-0125\\\")\\n\",\n+    \"llm = ChatOpenAI(model=\\\"gpt-4o-mini\\\")\\n\",\n     \"\\n\",\n     \"agent_executor = create_react_agent(llm, tools)\"\n    ]\n@@ -246,7 +246,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `SlackToolkit` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.slack.toolkit.SlackToolkit.html).\"\n+    \"For detailed documentation of all `SlackToolkit` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.slack.toolkit.SlackToolkit.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/sql_database.ipynb",
          "status": "modified",
          "additions": 9,
          "deletions": 9,
          "patch": "@@ -7,7 +7,7 @@\n    \"source\": [\n     \"# SQLDatabase Toolkit\\n\",\n     \"\\n\",\n-    \"This will help you getting started with the SQL Database [toolkit](/docs/concepts/#toolkits). For detailed documentation of all `SQLDatabaseToolkit` features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html).\\n\",\n+    \"This will help you getting started with the SQL Database [toolkit](/docs/concepts/#toolkits). For detailed documentation of all `SQLDatabaseToolkit` features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html).\\n\",\n     \"\\n\",\n     \"Tools within the `SQLDatabaseToolkit` are designed to interact with a `SQL` database. \\n\",\n     \"\\n\",\n@@ -80,8 +80,8 @@\n     \"\\n\",\n     \"The `SQLDatabaseToolkit` toolkit requires:\\n\",\n     \"\\n\",\n-    \"- a [SQLDatabase](https://python.langchain.com/v0.2/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) object;\\n\",\n-    \"- a LLM or chat model (for instantiating the [QuerySQLCheckerTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.sql_database.tool.QuerySQLCheckerTool.html) tool).\\n\",\n+    \"- a [SQLDatabase](https://python.langchain.com/api_reference/community/utilities/langchain_community.utilities.sql_database.SQLDatabase.html) object;\\n\",\n+    \"- a LLM or chat model (for instantiating the [QuerySQLCheckerTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.sql_database.tool.QuerySQLCheckerTool.html) tool).\\n\",\n     \"\\n\",\n     \"Below, we instantiate the toolkit with these objects. Let's first create a database object.\\n\",\n     \"\\n\",\n@@ -216,10 +216,10 @@\n    \"source\": [\n     \"API references:\\n\",\n     \"\\n\",\n-    \"- [QuerySQLDataBaseTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.sql_database.tool.QuerySQLDataBaseTool.html)\\n\",\n-    \"- [InfoSQLDatabaseTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.sql_database.tool.InfoSQLDatabaseTool.html)\\n\",\n-    \"- [ListSQLDatabaseTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.sql_database.tool.ListSQLDatabaseTool.html)\\n\",\n-    \"- [QuerySQLCheckerTool](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.sql_database.tool.QuerySQLCheckerTool.html)\"\n+    \"- [QuerySQLDataBaseTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.sql_database.tool.QuerySQLDataBaseTool.html)\\n\",\n+    \"- [InfoSQLDatabaseTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.sql_database.tool.InfoSQLDatabaseTool.html)\\n\",\n+    \"- [ListSQLDatabaseTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.sql_database.tool.ListSQLDatabaseTool.html)\\n\",\n+    \"- [QuerySQLCheckerTool](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.sql_database.tool.QuerySQLCheckerTool.html)\"\n    ]\n   },\n   {\n@@ -561,7 +561,7 @@\n    \"source\": [\n     \"## Specific functionality\\n\",\n     \"\\n\",\n-    \"`SQLDatabaseToolkit` implements a [.get_context](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html#langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.get_context) method as a convenience for use in prompts or other contexts.\\n\",\n+    \"`SQLDatabaseToolkit` implements a [.get_context](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html#langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.get_context) method as a convenience for use in prompts or other contexts.\\n\",\n     \"\\n\",\n     \"**\u26a0\ufe0f Disclaimer \u26a0\ufe0f** : The agent may generate insert/update/delete queries. When this is not expected, use a custom prompt or create a SQL users without write permissions.\\n\",\n     \"\\n\",\n@@ -586,7 +586,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all SQLDatabaseToolkit features and configurations head to the [API reference](https://python.langchain.com/v0.2/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html).\"\n+    \"For detailed documentation of all SQLDatabaseToolkit features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.sql.toolkit.SQLDatabaseToolkit.html).\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/tools/tavily_search.ipynb",
          "status": "modified",
          "additions": 3,
          "deletions": 3,
          "patch": "@@ -18,9 +18,9 @@\n     \"## Overview\\n\",\n     \"\\n\",\n     \"### Integration details\\n\",\n-    \"| Class | Package | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/tools/tavily_search) |  Package latest |\\n\",\n+    \"| Class | Package | Serializable | [JS support](https://js.langchain.com/docs/integrations/tools/tavily_search) |  Package latest |\\n\",\n     \"| :--- | :--- | :---: | :---: | :---: |\\n\",\n-    \"| [TavilySearchResults](https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html) | [langchain-community](https://python.langchain.com/v0.2/api_reference/community/index.html) | \u274c | \u2705 |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-community?style=flat-square&label=%20) |\\n\",\n+    \"| [TavilySearchResults](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html) | [langchain-community](https://python.langchain.com/api_reference/community/index.html) | \u274c | \u2705 |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-community?style=flat-square&label=%20) |\\n\",\n     \"\\n\",\n     \"### Tool features\\n\",\n     \"| [Returns artifact](/docs/how_to/tool_artifacts/) | Native async | Return data | Pricing |\\n\",\n@@ -350,7 +350,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all TavilySearchResults features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html\"\n+    \"For detailed documentation of all TavilySearchResults features and configurations head to the API reference: https://python.langchain.com/api_reference/community/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/activeloop_deeplake.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -65,7 +65,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"activeloop_token = getpass.getpass(\\\"activeloop token:\\\")\\n\",\n     \"embeddings = OpenAIEmbeddings()\"\n    ]"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/alibabacloud_opensearch.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -106,7 +106,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/apache_doris.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -245,7 +245,8 @@\n     \"import os\\n\",\n     \"from getpass import getpass\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass()\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/astradb.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -410,7 +410,7 @@\n    \"source\": [\n     \"#### Other search methods\\n\",\n     \"\\n\",\n-    \"There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for `AstraDBVectorStore` check out the [API reference](https://python.langchain.com/v0.2/api_reference/astradb/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html).\"\n+    \"There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for `AstraDBVectorStore` check out the [API reference](https://python.langchain.com/api_reference/astradb/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html).\"\n    ]\n   },\n   {\n@@ -459,9 +459,9 @@\n     \"\\n\",\n     \"For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\",\n     \"\\n\",\n-    \"- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\\n\",\n-    \"- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\\n\",\n-    \"- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)\"\n+    \"- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\\n\",\n+    \"- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\\n\",\n+    \"- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)\"\n    ]\n   },\n   {\n@@ -507,7 +507,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `AstraDBVectorStore` features and configurations head to the API reference:https://python.langchain.com/v0.2/api_reference/astradb/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html\"\n+    \"For detailed documentation of all `AstraDBVectorStore` features and configurations head to the API reference:https://python.langchain.com/api_reference/astradb/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/baiducloud_vector_search.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 2,
          "patch": "@@ -59,8 +59,10 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"QIANFAN_AK\\\"] = getpass.getpass(\\\"Your Qianfan AK:\\\")\\n\",\n-    \"os.environ[\\\"QIANFAN_SK\\\"] = getpass.getpass(\\\"Your Qianfan SK:\\\")\"\n+    \"if \\\"QIANFAN_AK\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"QIANFAN_AK\\\"] = getpass.getpass(\\\"Your Qianfan AK:\\\")\\n\",\n+    \"if \\\"QIANFAN_SK\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"QIANFAN_SK\\\"] = getpass.getpass(\\\"Your Qianfan SK:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/cassandra.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -90,7 +90,8 @@\n    \"metadata\": {},\n    \"outputs\": [],\n    \"source\": [\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OPENAI_API_KEY = \\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OPENAI_API_KEY = \\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/chroma.ipynb",
          "status": "modified",
          "additions": 7,
          "deletions": 7,
          "patch": "@@ -9,7 +9,7 @@\n     \"\\n\",\n     \"This notebook covers how to get started with the `Chroma` vector store.\\n\",\n     \"\\n\",\n-    \">[Chroma](https://docs.trychroma.com/getting-started) is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of `Chroma` at [this page](https://docs.trychroma.com/reference/py-collection), and find the API reference for the LangChain integration at [this page](https://python.langchain.com/v0.2/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html).\\n\",\n+    \">[Chroma](https://docs.trychroma.com/getting-started) is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0. View the full docs of `Chroma` at [this page](https://docs.trychroma.com/reference/py-collection), and find the API reference for the LangChain integration at [this page](https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html).\\n\",\n     \"\\n\",\n     \"## Setup\\n\",\n     \"\\n\",\n@@ -423,11 +423,11 @@\n    \"source\": [\n     \"#### Other search methods\\n\",\n     \"\\n\",\n-    \"There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for `AstraDBVectorStore` check out the [API reference](https://python.langchain.com/v0.2/api_reference/astradb/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html).\\n\",\n+    \"There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for `AstraDBVectorStore` check out the [API reference](https://python.langchain.com/api_reference/astradb/vectorstores/langchain_astradb.vectorstores.AstraDBVectorStore.html).\\n\",\n     \"\\n\",\n     \"### Query by turning into retriever\\n\",\n     \"\\n\",\n-    \"You can also transform the vector store into a retriever for easier usage in your chains. For more information on the different search types and kwargs you can pass, please visit the API reference [here](https://python.langchain.com/v0.2/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html#langchain_chroma.vectorstores.Chroma.as_retriever).\"\n+    \"You can also transform the vector store into a retriever for easier usage in your chains. For more information on the different search types and kwargs you can pass, please visit the API reference [here](https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html#langchain_chroma.vectorstores.Chroma.as_retriever).\"\n    ]\n   },\n   {\n@@ -463,9 +463,9 @@\n     \"\\n\",\n     \"For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\",\n     \"\\n\",\n-    \"- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\\n\",\n-    \"- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\\n\",\n-    \"- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)\"\n+    \"- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\\n\",\n+    \"- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\\n\",\n+    \"- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)\"\n    ]\n   },\n   {\n@@ -475,7 +475,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `Chroma` vector store features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html\"\n+    \"For detailed documentation of all `Chroma` vector store features and configurations head to the API reference: https://python.langchain.com/api_reference/chroma/vectorstores/langchain_chroma.vectorstores.Chroma.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/clickhouse.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -322,7 +322,7 @@\n    \"source\": [\n     \"#### Other search methods\\n\",\n     \"\\n\",\n-    \"There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for `Clickhouse` vector store check out the [API reference](https://python.langchain.com/v0.2/api_reference/community/vectorstores/langchain_community.vectorstores.clickhouse.Clickhouse.html).\"\n+    \"There are a variety of other search methods that are not covered in this notebook, such as MMR search or searching by vector. For a full list of the search abilities available for `Clickhouse` vector store check out the [API reference](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.clickhouse.Clickhouse.html).\"\n    ]\n   },\n   {\n@@ -360,9 +360,9 @@\n     \"\\n\",\n     \"For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\",\n     \"\\n\",\n-    \"- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\\n\",\n-    \"- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\\n\",\n-    \"- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)\"\n+    \"- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\\n\",\n+    \"- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\\n\",\n+    \"- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)\"\n    ]\n   },\n   {\n@@ -380,7 +380,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `AstraDBVectorStore` features and configurations head to the API reference:https://python.langchain.com/v0.2/api_reference/community/vectorstores/langchain_community.vectorstores.clickhouse.Clickhouse.html\"\n+    \"For detailed documentation of all `AstraDBVectorStore` features and configurations head to the API reference:https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.clickhouse.Clickhouse.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/couchbase.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -678,9 +678,9 @@\n     \"\\n\",\n     \"For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\",\n     \"\\n\",\n-    \"- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\\n\",\n-    \"- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\\n\",\n-    \"- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)\"\n+    \"- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\\n\",\n+    \"- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\\n\",\n+    \"- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)\"\n    ]\n   },\n   {\n@@ -742,7 +742,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `CouchbaseVectorStore` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/couchbase/vectorstores/langchain_couchbase.vectorstores.CouchbaseVectorStore.html\"\n+    \"For detailed documentation of all `CouchbaseVectorStore` features and configurations head to the API reference: https://python.langchain.com/api_reference/couchbase/vectorstores/langchain_couchbase.vectorstores.CouchbaseVectorStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/dashvector.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 2,
          "patch": "@@ -71,8 +71,10 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"DASHVECTOR_API_KEY\\\"] = getpass.getpass(\\\"DashVector API Key:\\\")\\n\",\n-    \"os.environ[\\\"DASHSCOPE_API_KEY\\\"] = getpass.getpass(\\\"DashScope API Key:\\\")\"\n+    \"if \\\"DASHVECTOR_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"DASHVECTOR_API_KEY\\\"] = getpass.getpass(\\\"DashVector API Key:\\\")\\n\",\n+    \"if \\\"DASHSCOPE_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"DASHSCOPE_API_KEY\\\"] = getpass.getpass(\\\"DashScope API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/databricks_vector_search.ipynb",
          "status": "modified",
          "additions": 7,
          "deletions": 4,
          "patch": "@@ -49,7 +49,10 @@\n     \"import os\\n\",\n     \"\\n\",\n     \"os.environ[\\\"DATABRICKS_HOST\\\"] = \\\"https://your-databricks-workspace\\\"\\n\",\n-    \"os.environ[\\\"DATABRICKS_TOKEN\\\"] = getpass.getpass(\\\"Enter your Databricks access token: \\\")\"\n+    \"if \\\"DATABRICKS_TOKEN\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"DATABRICKS_TOKEN\\\"] = getpass.getpass(\\n\",\n+    \"        \\\"Enter your Databricks access token: \\\"\\n\",\n+    \"    )\"\n    ]\n   },\n   {\n@@ -493,9 +496,9 @@\n     \"\\n\",\n     \"For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\",\n     \"\\n\",\n-    \"- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\\n\",\n-    \"- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\\n\",\n-    \"- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)\"\n+    \"- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\\n\",\n+    \"- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\\n\",\n+    \"- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/dingo.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -58,7 +58,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/documentdb.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -104,7 +104,8 @@\n     \"import os\\n\",\n     \"\\n\",\n     \"# Set up the OpenAI Environment Variables\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"os.environ[\\\"OPENAI_EMBEDDINGS_DEPLOYMENT\\\"] = (\\n\",\n     \"    \\\"smart-agent-embedding-ada\\\"  # the deployment name for the embedding model\\n\",\n     \")\\n\","
        },
        {
          "filename": "docs/docs/integrations/vectorstores/duckdb.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -33,7 +33,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/ecloud_vector_search.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -51,7 +51,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/elasticsearch.ipynb",
          "status": "modified",
          "additions": 4,
          "deletions": 4,
          "patch": "@@ -473,9 +473,9 @@\n     \"\\n\",\n     \"For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\",\n     \"\\n\",\n-    \"- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\\n\",\n-    \"- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\\n\",\n-    \"- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)\"\n+    \"- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\\n\",\n+    \"- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\\n\",\n+    \"- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)\"\n    ]\n   },\n   {\n@@ -601,7 +601,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `ElasticSearchStore` features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.ElasticsearchStore.html\"\n+    \"For detailed documentation of all `ElasticSearchStore` features and configurations head to the API reference: https://python.langchain.com/api_reference/elasticsearch/vectorstores/langchain_elasticsearch.vectorstores.ElasticsearchStore.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/epsilla.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -42,7 +42,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/faiss.ipynb",
          "status": "modified",
          "additions": 5,
          "deletions": 5,
          "patch": "@@ -328,7 +328,7 @@\n     \"#### Other search methods\\n\",\n     \"\\n\",\n     \"\\n\",\n-    \"There are a variety of other ways to search a FAISS vector store. For a complete list of those methods, please refer to the [API Reference](https://python.langchain.com/v0.2/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html)\\n\",\n+    \"There are a variety of other ways to search a FAISS vector store. For a complete list of those methods, please refer to the [API Reference](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html)\\n\",\n     \"\\n\",\n     \"### Query by turning into retriever\\n\",\n     \"\\n\",\n@@ -366,9 +366,9 @@\n     \"\\n\",\n     \"For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\\n\",\n     \"\\n\",\n-    \"- [Tutorials: working with external knowledge](https://python.langchain.com/v0.2/docs/tutorials/#working-with-external-knowledge)\\n\",\n-    \"- [How-to: Question and answer with RAG](https://python.langchain.com/v0.2/docs/how_to/#qa-with-rag)\\n\",\n-    \"- [Retrieval conceptual docs](https://python.langchain.com/v0.2/docs/concepts/#retrieval)\"\n+    \"- [Tutorials: working with external knowledge](https://python.langchain.com/docs/tutorials/#working-with-external-knowledge)\\n\",\n+    \"- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\\n\",\n+    \"- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/#retrieval)\"\n    ]\n   },\n   {\n@@ -510,7 +510,7 @@\n    \"source\": [\n     \"## API reference\\n\",\n     \"\\n\",\n-    \"For detailed documentation of all `FAISS` vector store features and configurations head to the API reference: https://python.langchain.com/v0.2/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html\"\n+    \"For detailed documentation of all `FAISS` vector store features and configurations head to the API reference: https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html\"\n    ]\n   }\n  ],"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/faiss_async.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -55,7 +55,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\\n\",\n     \"\\n\",\n     \"# Uncomment the following line if you need to initialize FAISS with no AVX2 optimization\\n\",\n     \"# os.environ['FAISS_NO_AVX2'] = '1'\\n\","
        },
        {
          "filename": "docs/docs/integrations/vectorstores/kdbai.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -61,7 +61,8 @@\n    \"source\": [\n     \"KDBAI_ENDPOINT = input(\\\"KDB.AI endpoint: \\\")\\n\",\n     \"KDBAI_API_KEY = getpass(\\\"KDB.AI API key: \\\")\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OpenAI API Key: \\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass(\\\"OpenAI API Key: \\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/kinetica.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -81,7 +81,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        },
        {
          "filename": "docs/docs/integrations/vectorstores/lancedb.ipynb",
          "status": "modified",
          "additions": 2,
          "deletions": 1,
          "patch": "@@ -62,7 +62,8 @@\n     \"import getpass\\n\",\n     \"import os\\n\",\n     \"\\n\",\n-    \"os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n+    \"if \\\"OPENAI_API_KEY\\\" not in os.environ:\\n\",\n+    \"    os.environ[\\\"OPENAI_API_KEY\\\"] = getpass.getpass(\\\"OpenAI API Key:\\\")\"\n    ]\n   },\n   {"
        }
      ],
      "file_patterns": {
        "security_files": 0,
        "config_files": 11,
        "dependency_files": 1,
        "test_files": 3,
        "unique_directories": 29,
        "max_directory_depth": 5
      },
      "context": {
        "surrounding_commits": [
          {
            "sha": "efadad6067095a2a9afd4c3063bf777ca076584a",
            "date": "2025-01-14T18:27:52Z",
            "author_login": "gkorland"
          },
          {
            "sha": "4ab04ad6be0f8f51d22a7df759d7719781fa22f5",
            "date": "2025-01-14T17:55:16Z",
            "author_login": "baskaryan"
          },
          {
            "sha": "d9b856abadef0e7e7338a82f0b2e1239ce3fbd61",
            "date": "2025-01-14T15:23:34Z",
            "author_login": "michaelnchin"
          },
          {
            "sha": "c55af44711ba9180ce8a51a55a385f31023341b5",
            "date": "2025-01-13T23:32:40Z",
            "author_login": "efriis"
          },
          {
            "sha": "cdf3a17e55bd594341c390051dc20c5e5a74b966",
            "date": "2025-01-13T21:25:00Z",
            "author_login": "efriis"
          }
        ]
      }
    }
  },
  "vulnerability_details": {
    "cvss_score": 9.8,
    "cvss_vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",
    "cwe_id": "CWE-89",
    "description": "A vulnerability in the GraphCypherQAChain class of langchain-ai/langchain version 0.2.5 allows for SQL injection through prompt injection. This vulnerability can lead to unauthorized data manipulation, data exfiltration, denial of service (DoS) by deleting all data, breaches in multi-tenant security environments, and data integrity issues. Attackers can create, update, or delete nodes and relationships without proper authorization, extract sensitive data, disrupt services, access data across different tenants, and compromise the integrity of the database.",
    "attack_vector": "NETWORK",
    "attack_complexity": "LOW"
  },
  "temporal_data": {
    "published_date": "2024-10-29T13:15:10.950",
    "last_modified": "2024-11-01T19:19:20.327",
    "fix_date": "2024-09-13T21:38:45Z"
  },
  "references": [
    {
      "url": "https://github.com/langchain-ai/langchain/commit/c2a3021bb0c5f54649d380b42a0684ca5778c255",
      "source": "security@huntr.dev",
      "tags": [
        "Patch"
      ]
    },
    {
      "url": "https://huntr.com/bounties/8f4ad910-7fdc-4089-8f0a-b5df5f32e7c5",
      "source": "security@huntr.dev",
      "tags": [
        "Exploit",
        "Third Party Advisory"
      ]
    }
  ],
  "collection_metadata": {
    "collected_at": "2025-01-11T23:09:27.105752",
    "processing_status": "raw"
  },
  "repository_context": {
    "name": "langchain",
    "owner": "langchain-ai",
    "created_at": "2022-10-17T02:58:36Z",
    "updated_at": "2025-01-14T13:08:38Z",
    "pushed_at": "2025-01-13T23:32:41Z",
    "size": 376391,
    "stars": 98220,
    "forks": 15956,
    "open_issues": 435,
    "watchers": 98220,
    "has_security_policy": false,
    "default_branch": "master",
    "protected_branches": [],
    "languages": {
      "Jupyter Notebook": 31945259,
      "Python": 19475935,
      "MDX": 56545,
      "Makefile": 55385,
      "Shell": 19562,
      "XSLT": 19446,
      "HTML": 9026,
      "TeX": 2242,
      "Dockerfile": 1311,
      "JavaScript": 471
    },
    "commit_activity": {
      "total_commits_last_year": 7057,
      "avg_commits_per_week": 135.71153846153845,
      "days_active_last_year": 327
    },
    "security_features": {
      "has_security_policy": false,
      "has_protected_branches": false,
      "has_wiki": false,
      "has_issues": true,
      "allow_forking": true,
      "is_template": false,
      "license": "mit"
    },
    "collected_at": "2025-01-14T13:11:47.805811"
  }
}